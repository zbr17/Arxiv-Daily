<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-04</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >自动驾驶与大模型</a>
<a href='#' >深度学习可解释性</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-04</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-04 12:26:27</p>
<p>已自动阅读了 202 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：114013</p>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration</h3>
<p><strong>Authors:</strong> Shaojie Zhang, Pei Fu, Ruoceng Zhang, Jiahui Yang, Anan Du, Xiuwen Xi, Shaokang Wang, Ying Huang, Bin Qin, Zhenbo Luo, Jian Luan</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 聚焦GUI Grounding的不确定性校准，通过双奖励机制优化接地准确性与置信度可靠性，直接对应多模态大模型中的GUI Grounding研究方向。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27266' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning</h3>
<p><strong>Authors:</strong> Jiawei Gu, Yunzhuo Hao, Huichen Will Wang, Linjie Li, Michael Qizhe Shieh, Yejin Choi, Ranjay Krishna, Yu Cheng</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 研究多模态 interleaved 思维链推理的涌现性质，提出ThinkMorph模型结合文本与图像的互补推理步骤，解决多模态推理的交互性问题，对多模态大模型的推理能力提升有理论与实践贡献。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27492' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources</h3>
<p><strong>Authors:</strong> Tong Shen, Jingai Yu, Dong Zhou, Dong Li, Emad Barsoum</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出高效多模态扩散Transformer架构，解决低资源场景下的快速图像合成问题，对应多模态大模型中的image generation方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27135' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds</h3>
<p><strong>Authors:</strong> Wu Wei, Xiaomeng Fan, Yuwei Wu, Zhi Gao, Pengxiang Li, Yunde Jia, Mehrtash Harandi</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 针对视觉-语言模型的模态对齐问题，提出树状分层特征提取与异构双曲流形对齐方法，解决现有方法中视觉与文本特征不对称的问题，对多模态大模型的模态融合有理论与实践贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27391' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding</h3>
<p><strong>Authors:</strong> Wei Xu, Cheng Wang, Dingkang Liang, Zongchuang Zhao, Xingyu Jiang, Peng Zhang, Xiang Bai</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 构建水下场景理解的多模态大模型NAUTILUS，结合水下成像物理先验的视觉特征增强模块，解决水下图像退化问题，对特定域多模态大模型的场景理解有重要贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27481' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum</h3>
<p><strong>Authors:</strong> Zhuoning Guo, Mingxin Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Xiaowen Chu</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出多模态金字塔课程学习用于通用视频检索，解决现有视频检索的泛化问题，对多模态大模型的视频文本检索泛化能力有重要贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27571' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised Reinforcement Learning</h3>
<p><strong>Authors:</strong> Yuhong Liu, Beichen Zhang, Yuhang Zang, Yuhang Cao, Long Xing, Xiaoyi Dong, Haodong Duan, Dahua Lin, Jiaqi Wang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出自监督强化学习框架Spatial-SSRL，通过5个空间 pretext任务提升LVLM的空间理解能力，解决LVLM的空间推理缺陷，对多模态大模型的空间智能提升有重要贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27606' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model</h3>
<p><strong>Authors:</strong> John Won, Kyungmin Lee, Huiwon Jang, Dongyoung Kim, Jinwoo Shin</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出双流扩散模型DUST用于世界模型增强的VLA模型，解决模态冲突问题，提升机器人政策学习性能，对多模态大模型的VLA与世界模型融合有重要贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27607' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation</h3>
<p><strong>Authors:</strong> Riccardo Brioschi, Aleksandr Alekseev, Emanuele Nevali, Berkay Döner, Omar El Malki, Blagoj Mitrevski, Leandro Kieliger, Mark Collier, Andrii Maksai, Jesse Berent, Claudiu Musat, Efi Kokiopoulou</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出素描引导的多模态布局生成方法，结合合成素描数据，解决布局生成的交互性问题，对多模态大模型的sketch-to-layout应用有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27632' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MM-OPERA: Benchmarking Open-ended Association Reasoning for Large Vision-Language Models</h3>
<p><strong>Authors:</strong> Zimeng Huang, Jinxin Ke, Xiaoxuan Fan, Yufeng Yang, Yang Liu, Liu Zhonghan, Zedi Wang, Junteng Dai, Haoyi Jiang, Yuyu Zhou, Keze Wang, Ziliang Chen</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 构建MM-OPERA基准评估LVLM的开放式关联推理能力，解决现有基准的封闭性问题，对多模态大模型的推理评估有重要贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.26937' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation</h3>
<p><strong>Authors:</strong> Tao Liu, Chongyu Wang, Rongjie Li, Yingchen Yu, Xuming He, Bai Song</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 针对多模态大模型在GUI导航中跨域泛化与历史利用的局限，提出整合结构化推理、动作预测和历史总结的框架，提升GUI导航性能，贴合多模态大模型的GUI Grounding研究方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27210' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench</h3>
<p><strong>Authors:</strong> Fenfen Lin, Yesheng Liu, Haiyu Xu, Chen Yue, Zheqi He, Mingxuan Zhao, Miguel Hu Chen, Jiakang Liu, JG Yao, Xi Yang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 构建MeasureBench基准测试VLM的视觉测量能力，分析VLM在精细空间接地的局限性，对应多模态大模型中的spatial grounding方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.26865' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Can MLLMs Read the Room? A Multimodal Benchmark for Verifying Truthfulness in Multi-Party Social Interactions</h3>
<p><strong>Authors:</strong> Caixin Kang, Yifei Huang, Liangyang Ouyang, Mingfang Zhang, Yoichi Sato</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出MIVA基准评估MLLMs在多模态社交场景中的真实性识别能力，对应多模态大模型方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27195' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FOCUS: Efficient Keyframe Selection for Long Video Understanding</h3>
<p><strong>Authors:</strong> Zirui Zhu, Hailun Xu, Yang Luo, Yong Liu, Kanchan Sarkar, Zhenheng Yang, Yang You</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 高效关键帧选择方法提升长视频理解效率，对应多模态大模型中的video understanding方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27280' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Understanding the Implicit User Intention via Reasoning with Large Language Model for Image Editing</h3>
<p><strong>Authors:</strong> Yijia Wang, Yiqing Shen, Weiming Chen, Zhihai He</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 利用LLM推理解决复杂图像编辑的用户意图理解，对应多模态大模型中的image editing方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27335' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RzenEmbed: Towards Comprehensive Multimodal Retrieval</h3>
<p><strong>Authors:</strong> Weijian Jian, Yajun Zhang, Dawei Liang, Chunyu Xie, Yixiao He, Dawei Leng, Yuhui Yin</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 统一多模态检索框架支持文本、图像、视频等模态，对应多模态大模型方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27350' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Generating Accurate and Detailed Captions for High-Resolution Images</h3>
<p><strong>Authors:</strong> Hankyeol Lee, Gawon Seo, Kyounggyu Lee, Dogun Kim, Kyungwoo Song, Jiyoung Jung</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 结合VLM、LLM与目标检测生成高分辨率图像详细caption，对应多模态大模型中的image understanding方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27164' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A Small-Data Pipeline with LoRA and Wan2.1 I2V</h3>
<p><strong>Authors:</strong> Meftun Akarsu, Kerem Catay, Sedat Bin Vedat, Enes Kutay Yarkan, Ilke Senturk, Arda Sar, Dafne Eksioglu</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出小数据场景下开源视频生成模型的微调流程，结合LoRA实现高效风格迁移与运动生成，解决视频生成的风格一致性与推理效率问题，对多模态大模型的视频生成应用有实用价值。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27364' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mitigating Semantic Collapse in Partially Relevant Video Retrieval</h3>
<p><strong>Authors:</strong> WonJun Moon, MinSeok Jung, Gilhan Park, Tae-Young Kim, Cheol-Ho Cho, Woojin Jun, Jae-Pil Heo</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 针对部分相关视频检索中的语义坍塌问题，提出文本相关性保留学习与跨分支视频对齐方法，改善视频-文本嵌入的语义一致性，对多模态大模型的视频文本交互检索有重要意义。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27432' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Pixels to Paths: A Multi-Agent Framework for Editable Scientific Illustration</h3>
<p><strong>Authors:</strong> Jianwen Sun, Fanrui Zhang, Yukang Feng, Chuanhao Li, Zizhen Li, Jiaxin Ai, Yifan Chang, Yu Dai, Kaipeng Zhang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出多智能体框架VisPainter用于可编辑的科学插图生成，支持矢量图编辑与多模态交互，解决科学插图的可编辑性问题，对多模态大模型的图像生成与可视化应用有价值。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27452' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MapSAM2: Adapting SAM2 for Automatic Segmentation of Historical Map Images and Time Series</h3>
<p><strong>Authors:</strong> Xue Xia, Randall Balestriero, Tao Zhang, Yixin Zhou, Andrew Ding, Dev Saini, Lorenz Hurni</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 基于SAM2的历史地图图像与时间序列自动分割框架，将图像与时间序列视为视频处理，解决历史地图的风格变异性问题，对多模态大模型的图像分割与时间序列理解有价值。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27547' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SmoothGuard: Defending Multimodal Large Language Models with Noise Perturbation and Clustering Aggregation</h3>
<p><strong>Authors:</strong> Guangzhi Su, Shuchang Huang, Yutong Ke, Zhuohang Liu, Long Qian, Kaizhu Huang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出SmoothGuard防御框架，通过噪声扰动与聚类聚合提升MLLM的鲁棒性，解决MLLM的对抗攻击问题，对多模态大模型的安全防御有贡献。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.26830' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ECVL-ROUTER: Scenario-Aware Routing for Vision-Language Models</h3>
<p><strong>Authors:</strong> Xin Tang, Youfang Han, Fangfei Gou, Wei Zhao, Xin Meng, Yang Yu, Jinguo Zhang, Yuanchun Shi, Yuntao Wang, Tengxiang Zhang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出首个面向视觉语言模型的场景感知路由框架，动态选择云端大模型或边缘小模型满足用户需求，直接关联“多模态大模型”，为VLM高效部署提供实践方案。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27256' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics</h3>
<p><strong>Authors:</strong> Simindokht Jahangard, Mehrzad Mohammadi, Abhinav Dhall, Hamid Rezatofighi</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出多模态神经符号框架，结合全景图像与3D点云，通过神经感知加符号推理解决机器人视觉接地的空间推理问题，符合多模态大模型的image understanding研究方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27033' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Gradient Descent as Loss Landscape Navigation: a Normative Framework for Deriving Learning Rules</h3>
<p><strong>Authors:</strong> John J. Vastola, Samuel J. Gershman, Kanaka Rajan</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出损失 landscape导航的规范框架，推导学习规则，解决优化算法的理论理解问题，对深度学习理论中的优化与学习规则有深度贡献。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.26997' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals</h3>
<p><strong>Authors:</strong> Xiangyu Fan, Zesong Qiu, Zhuguanyu Wu, Fanzhou Wang, Zhiqian Lin, Tianxiang Ren, Dahua Lin, Ruihao Gong, Lei Yang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出分阶段分布匹配蒸馏(Phased DMD)，解决扩散模型蒸馏的多样性与效率问题，对深度学习理论中的模型蒸馏与扩散模型优化有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27684' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BI-DCGAN: A Theoretically Grounded Bayesian Framework for Efficient and Diverse GANs</h3>
<p><strong>Authors:</strong> Mahsa Valizadeh, Rui Tuo, James Caverlee</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出贝叶斯DCGAN(BI-DCGAN)，解决GAN的模式崩溃问题，首次证明贝叶斯建模提升多样性，对深度学习理论中的GANs与贝叶斯方法有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.26892' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Higher-order Linear Attention</h3>
<p><strong>Authors:</strong> Yifan Zhang, Zhen Qin, Quanquan Gu</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出高阶线性注意力HLA，通过紧凑前缀统计量实现因果流式注意力，解决自注意力二次复杂度问题，直接关联“深度学习理论（network architecture）”，对Transformer架构优化具有重要意义。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27258' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Hierarchical Transformers for Unsupervised 3D Shape Abstraction</h3>
<p><strong>Authors:</strong> Aditya Vora, Lily Goli, Andrea Tagliasacchi, Hao Zhang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出无监督3D形状抽象的分层Transformer架构，探索分层网络设计，对应深度学习理论中的network architecture方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27088' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Sparse Model Inversion: Efficient Inversion of Vision Transformers for Data-Free Applications</h3>
<p><strong>Authors:</strong> Zixuan Hu, Yongxian Wei, Li Shen, Zhenyi Wang, Lei Li, Chun Yuan, Dacheng Tao</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 针对Vision Transformers的稀疏模型反演方法，提升数据无依赖场景的效率，对应深度学习理论中的network architecture方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27186' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts</h3>
<p><strong>Authors:</strong> Jingnan Gao, Zhe Wang, Xianze Fang, Xingyu Ren, Zhuo Chen, Shengqi Liu, Yuhao Cheng, Jiangjing Lyu, Xiaokang Yang, Yichao Yan</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 结合Mixture-of-Experts架构的3D视觉几何重建模型，探索混合专家网络设计，对应深度学习理论中的network architecture方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27234' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Rethinking Robust Adversarial Concept Erasure in Diffusion Models</h3>
<p><strong>Authors:</strong> Qinghong Yin, Yu Tian, Yue Zhang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 重新设计扩散模型的对抗性概念擦除方法，提升模型安全性与鲁棒性，对应深度学习理论中的模型优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27285' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Overcoming Prompts Pool Confusion via Parameterized Prompt for Incremental Object Detection</h3>
<p><strong>Authors:</strong> Zijia An, Boyu Diao, Ruiqi Liu, Libo Huang, Chuanguang Yang, Fei Wang, Zhulin An, Yongjun Xu</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出参数化Prompt解决增量目标检测中的Prompt池混淆问题，探索Prompt tuning技术，对应深度学习理论方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27316' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning</h3>
<p><strong>Authors:</strong> Kenneth Yang, Wen-Li Wei, Jen-Chun Lin</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 前馈式参数选择方法提升高效微调的内存与速度，对应深度学习理论中的parameter efficiency方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27359' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DeblurSDI: Blind Image Deblurring Using Self-diffusion</h3>
<p><strong>Authors:</strong> Yanlong Yang, Guanxiong Luo</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出基于自扩散的盲图像去模糊方法，无需预训练，通过迭代反向自扩散过程结合稀疏先验优化核与清晰图像，解决盲去模糊的逆问题，对深度学习理论中的扩散模型应用有创新贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27439' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Image Hashing via Cross-View Code Alignment in the Age of Foundation Models</h3>
<p><strong>Authors:</strong> Ilyass Moummad, Kawtar Zaher, Hervé Goëau, Alexis Joly</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出跨视图代码对齐的图像哈希方法，结合基础模型的嵌入，解决哈希的紧凑性与判别性问题，对深度学习理论中的哈希与表示学习有创新贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27584' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning</h3>
<p><strong>Authors:</strong> Samarup Bhattacharya, Anubhab Bhattacharya, Abir Chakraborty</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 结合对抗训练与难样本监督对比学习，提出ANCHOR框架提升表示鲁棒性，解决对抗训练与对比学习的结合问题，对深度学习理论中的鲁棒表示学习有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27599' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Gaussian Combined Distance: A Generic Metric for Object Detection</h3>
<p><strong>Authors:</strong> Ziqian Guan, Xieyi Fu, Pengjun Huang, Hengyuan Zhang, Hubin Du, Yongtao Liu, Yinglin Wang, Qang Ma</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出高斯组合距离(GCD)作为目标检测的度量，解决IoU与Wasserstein距离的缺陷，对深度学习理论中的目标检测度量与定位性能提升有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27649' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Layer of Truth: Probing Belief Shifts under Continual Pre-Training Poisoning</h3>
<p><strong>Authors:</strong> Svetlana Churina, Niranjan Chebrolu, Kokil Jaidka</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 研究持续预训练中毒下的信念漂移，提出Layer of Truth框架，解决LLM的事实完整性监测问题，对深度学习理论中的持续学习与模型鲁棒性有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.26829' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Accurate Target Privacy Preserving Federated Learning Balancing Fairness and Utility</h3>
<p><strong>Authors:</strong> Kangkang Sun, Jun Wu, Minyi Guo, Jianhua Li, Jianwei Huang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出联邦学习中的隐私与公平平衡方法FedPF，解决FL的隐私-公平-效用权衡问题，对深度学习理论中的联邦学习与公平性有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.26841' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CAS-Spec: Cascade Adaptive Self-Speculative Decoding for On-the-Fly Lossless Inference Acceleration of LLMs</h3>
<p><strong>Authors:</strong> Zhiyuan Ning, Jiawei Shao, Ruge Xu, Xinfei Guo, Jun Zhang, Chi Zhang, Xuelong Li</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出级联自适应自推测解码(CAS-Spec)，加速LLM推理，解决LLM的高效部署问题，对深度学习理论中的LLM推理优化有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.26843' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Jasmine: A Simple, Performant and Scalable JAX-based World Modeling Codebase</h3>
<p><strong>Authors:</strong> Mihir Mahajan, Alfred Nguyen, Franz Srambical, Stefan Bauer</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 发布JAX-based的世界模型代码库Jasmine，支持大规模训练，解决世界模型的训练效率问题，对深度学习理论中的世界模型研究有工具贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27002' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Exploring Landscapes for Better Minima along Valleys</h3>
<p><strong>Authors:</strong> Tong Zhao, Jiacheng Li, Yuanchang Zhou, Guangming Tan, Weile Jia</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 针对优化器到达局部极小值后无法探索更优解的问题，提出优化器适配器“E”以沿损失景观山谷寻找更优极小值，直接关联“深度学习理论（optimizer）”，为优化器设计提供新视角。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.27153' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AD-SAM: Fine-Tuning the Segment Anything Vision Foundation Model for Autonomous Driving Perception</h3>
<p><strong>Authors:</strong> Mario Camarena, Het Patel, Fatemeh Nazari, Evangelos Papalexakis, Mohamadhossein Noruzoliaee, Jia Chen</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 针对自动驾驶感知优化Segment Anything Model，提出双编码器与可变形解码器架构，提升语义分割性能，直接对应自动驾驶与大模型研究方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.27047' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar</h3>
<p><strong>Authors:</strong> Xiaozhi Li, Huijun Di, Jian Li, Feng Liu, Wei Liang</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 融合相机与4D雷达的多模态3D目标检测框架，提升自动驾驶感知的鲁棒性，对应自动驾驶与大模型方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.27166' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Mixture-of-Transformers Learn Faster: A Theoretical Study on Classification Problems</h3>
<p><strong>Authors:</strong> Hongbo Li, Qinhang Wu, Sen Lin, Yingbin Liang, Ness B. Shroff</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 理论研究Mixture-of-Transformers的学习动态，证明其比单Transformer收敛更快，解决MoE的学习效率问题，对深度学习理论中的MoE与Transformer有深度贡献
[PAPER_START]
Title: MLPerf Automotive
Authors: Radoyeh Shojaei (MLCommons, Autonomous Vehicle Computing Consortium), Predrag Djurdjevic (MLCommons, Autonomous Vehicle Computing Consortium), Mostafa El-Khamy (MLCommons, Autonomous Vehicle Computing Consortium), James Goel (MLCommons, Autonomous Vehicle Computing Consortium), Kasper Mecklenburg (MLCommons, Autonomous Vehicle Computing Consortium), John Owens (MLCommons, Autonomous Vehicle Computing Consortium), Pınar Muyan-Özelik (MLCommons, Autonomous Vehicle Computing Consortium), Tom St. John (MLCommons, Autonomous Vehicle Computing Consortium), Jinho Suh (MLCommons, Autonomous Vehicle Computing Consortium), Arjun Suresh (MLCommons, Autonomous Vehicle Computing Consortium)
Published: 2025-11-03
Link: https://arxiv.org/abs/2510.27065
Reason: 提出首个面向自动驾驶ML系统的标准化基准，解决了现有基准无法满足 automotive 工作负载安全和实时性约束的问题，直接关联“自动驾驶与大模型”研究方向，为自动驾驶领域ML系统性能评估提供统一框架。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.27004' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> NegoCollab: A Common Representation Negotiation Approach for Heterogeneous Collaborative Perception</h3>
<p><strong>Authors:</strong> Congzhang Shao, Quan Yuan, Guiyang Luo, Yue Hu, Danni Wang, Yilin Liu, Rui Pan, Bo Chen, Jinglin Li</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出异构协作感知的公共表示协商方法NegoCollab，解决多智能体的模态差异问题，对自动驾驶与大模型中的协作感知系统有重要贡献。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.27647' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Modified-Emergency Index (MEI): A Criticality Metric for Autonomous Driving in Lateral Conflict</h3>
<p><strong>Authors:</strong> Hao Cheng, Yanbo Jiang, Qingyuan Shi, Qingwen Meng, Keyu Chen, Wenhao Yu, Jianqiang Wang, Sifa Zheng</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 针对自动驾驶横向冲突的安全评估难题，改进Emergency Index提出MEI指标，通过Argoverse-2数据集验证其优于现有方法，贴合自动驾驶与大模型的安全评估研究方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.27333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Feature-Function Curvature Analysis: A Geometric Framework for Explaining Differentiable Models</h3>
<p><strong>Authors:</strong> Hamed Najafi, Dongsheng Luo, Jason Liu</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出几何框架FFCA，通过量化特征的Impact、Volatility、Non-linearity和Interaction四个维度，解决主流归因方法的局限性，直接针对“深度学习可解释性”，为模型解释提供全面几何视角。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.27207' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Measuring Chain-of-Thought Monitorability Through Faithfulness and Verbosity</h3>
<p><strong>Authors:</strong> Austin Meek, Eitan Sprejer, Iván Arcuschin, Austin J. Brockmeier, Steven Basart</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 结合“faithfulness”（CoT与内部推理一致性）和“verbosity”（CoT完整性）提出可监控性评分，解决CoT解释性核心问题，直接针对“深度学习可解释性”，为CoT评估提供量化指标。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.27378' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Atlas-Alignment: Making Interpretability Transferable Across Language Models</h3>
<p><strong>Authors:</strong> Bruno Puri, Jim Berend, Sebastian Lapuschkin, Wojciech Samek</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 提出Atlas-Alignment框架，通过对齐未知模型 latent 空间与Concept Atlas实现跨模型可解释性迁移，解决可解释性规模化难题，直接针对“深度学习可解释性”，对多模型解释具有重要价值。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.27413' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Thought Branches: Interpreting LLM Reasoning Requires Resampling</h3>
<p><strong>Authors:</strong> Uzay Macar, Paul C. Bogdan, Senthooran Rajamanoharan, Neel Nanda</p>
<p><strong>Published:</strong> 2025-11-03</p>
<p><strong>Reason:</strong> 指出单条CoT不足以理解LLM推理，提出重采样CoT分析因果影响，解决CoT解释性样本局限性问题，直接针对“深度学习可解释性”，为LLM推理解释提供可靠方法。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.27484' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>