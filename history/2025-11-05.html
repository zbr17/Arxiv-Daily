<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-05</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>深度学习理论</a>
<a href='#' >多模态大模型</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >自动驾驶与大模型</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-05</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-05 12:31:30</p>
<p>已自动阅读了 458 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：225568</p>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Linear Differential Vision Transformer: Learning Visual Contrasts via Pairwise Differentials</h3>
<p><strong>Authors:</strong> Yifan Pu (LeapLabTHU), Jixuan Ying (LeapLabTHU), Qixiu Li (LeapLabTHU), Tianzhu Ye (LeapLabTHU), Dongchen Han (LeapLabTHU), Xiaochen Wang (LeapLabTHU), Ziyi Wang (LeapLabTHU), Xinyu Shao (LeapLabTHU), Gao Huang (LeapLabTHU), Xiu Li (LeapLabTHU)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对Vision Transformer（ViT）自注意力机制高复杂度与冗余相关性问题，提出Visual-Contrast Attention（VCA）模块，将复杂度从O(N²C)降至O(NnC)，同时提升图像识别与生成性能，在DeiT、DiT等模型上验证有效性，契合深度学习理论中的网络架构方向。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00833' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Transformers as Intrinsic Optimizers: Forward Inference through the Energy Principle</h3>
<p><strong>Authors:</strong> Ruifeng Ren, Sheng Ouyang, Huayi Tang, Yong Liu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出统一能量基框架解释Transformer，将注意力机制与梯度下降算法关联并扩展到动量、NAG等变体，对深度学习理论中的Transformer机制和优化器设计有理论突破
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00907' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Parameter Interpolation Adversarial Training for Robust Image Classification</h3>
<p><strong>Authors:</strong> Xin Liu (unknown), Yichen Yang (unknown), Kun He (unknown), John E. Hopcroft (Cornell University)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对对抗训练中模型鲁棒性振荡与过拟合问题，提出参数插值对抗训练（PIAT）框架，通过参数插值与归一化均方误差损失提升模型鲁棒性，在CNN和ViT模型上验证有效性，符合深度学习理论中的模型鲁棒性方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00836' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FastBoost: Progressive Attention with Dynamic Scaling for Efficient Deep Learning</h3>
<p><strong>Authors:</strong> JunXi Yuan (unknown)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对高效深度学习中的参数-精度权衡问题，提出FastBoost架构，通过动态缩放渐进注意力（DSPA）与增强MBConv块实现参数减少与精度提升，在CIFAR基准上取得优异trade-off，符合深度学习理论中的网络架构方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01026' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MoSa: Motion Generation with Scalable Autoregressive Modeling</h3>
<p><strong>Authors:</strong> Mengyuan Liu, Sheng Yan, Yong Wang, Yingjie Li, Gui-Bin Bian, Hong Liu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出分层运动生成框架MoSa，结合分层残差向量量化变分自编码器（RQ-VAE）和可扩展自回归（SAR）建模，提升运动生成的质量与效率，符合深度学习理论中的VAE方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01200' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MVSMamba:. Multi-View Stereo with State Space ModelAuthors:Jianfei Jiang.Qiankun Liu,Hongyuan Liu.Haochen Yu.Liyong Wang.Jiansheng Chen.Huimin MaPublished:2025-11-04Link:https://arxiv.org/abs/ZS11.01315Reason:提出首个基于Mamba(状态空间模型)的多视图立体(MVS)网络MVSMamba，通过动态Mamba模块捕捉多视图特征交互，提升特征聚合效率和三维重建性能，符合深度学习理论中的网络架构方向。Score:8Field:深度学习理论</h3>
<p><strong>Authors:</strong> Jianfei Jiang.Qiankun Liu,Hongyuan Liu.Haochen Yu.Liyong Wang.Jiansheng Chen.Huimin MaPublished:2025-11-04Link:https://arxiv.org/abs/ZS11.01315Reason:提出首个基于Mamba(状态空间模型)的多视图立体(MVS)网络MVSMamba，通过动态Mamba模块捕捉多视图特征交互，提升特征聚合效率和三维重建性能，符合深度学习理论中的网络架构方向。Score:8Field:深度学习理论</p>
<p><strong>Published:</strong> 2025-11-04Link:https://arxiv.org/abs/ZS11.01315Reason:提出首个基于Mamba(状态空间模型)的多视图立体(MVS)网络MVSMamba，通过动态Mamba模块捕捉多视图特征交互，提升特征聚合效率和三维重建性能，符合深度学习理论中的网络架构方向。Score:8Field:深度学习理论</p>
<p><strong>Reason:</strong> 提出首个基于Mamba(状态空间模型)的多视图立体(MVS)网络MVSMamba，通过动态Mamba模块捕捉多视图特征交互，提升特征聚合效率和三维重建性能，符合深度学习理论中的网络架构方向。Score:8Field:深度学习理论</p>
<p><a href='https://arxiv.org/abs/ZS11.01315Reason:提出首个基于Mamba(状态空间模型)的多视图立体(MVS)网络MVSMamba，通过动态Mamba模块捕捉多视图特征交互，提升特征聚合效率和三维重建性能，符合深度学习理论中的网络架构方向。Score:8Field:深度学习理论' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MoSa: Motion Generation with Scalable Autoregressive Modeling</h3>
<p><strong>Authors:</strong> Mengyuan Liu,Sheng Yan,Y</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出统一的参数高效微调（PEFT）框架，通过校准预训练权重和正交旋转特征空间改进LoRA/DoRA，提升性能与效率，属于深度学习理论中的network architecture方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00051' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MISA: Memory-Efficient LLMs Optimization with Module-wise Importance Sampling</h3>
<p><strong>Authors:</strong> Yuxi Liu, Renjia Deng, Yutong He, Xue Wang, Tao Yao, Kun Yuan</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出模块级重要性采样的内存高效优化算法，解决LLM训练的高内存需求问题，理论分析收敛率并验证有效性，属于深度学习理论中的optimizer方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00056' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Why Federated Optimization Fails to Achieve Perfect Fitting? A Theoretical Perspective on Client-Side Optima</h3>
<p><strong>Authors:</strong> Zhongxiang Lei, Qi Yang, Ping Qiu, Gang Zhang, Yuanchi Ma, Jinyan Liu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 从理论角度解释了联邦优化中数据异质性导致无法完美拟合的根源，分析了局部最优差异对全局模型性能的影响，对深度学习理论中的优化器性能研究有重要参考价值
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00469' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Learning an Efficient Optimizer via Hybrid-Policy Sub-Trajectory Balance</h3>
<p><strong>Authors:</strong> Yunchuan Guan, Yu Liu, Ke Zhou, Hui Li, Sen Jia, Zhiqi Shen, Ziyang Wang, Xinglin Zhang, Tao Chen, Jenq-Neng Hwang, Lei Li</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出Lo-Hp框架，通过混合策略子轨迹平衡学习高效优化器，解决了权重生成中的过耦合和长horizon问题，对深度学习理论中的优化器设计有实践指导意义
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00543' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Attention Saturation and Gradient Suppression at Inflection Layers: Diagnosing and Mitigating Bottlenecks in Transformer Adaptation</h3>
<p><strong>Authors:</strong> Wang Zixian</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 分析Transformer微调中注意力饱和导致的梯度抑制问题，提出诊断指标和LoRA注入策略，对深度学习理论中的Transformer架构适配有重要贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00797' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Hidden Power of Normalization: Exponential Capacity Control in Deep Neural Networks</h3>
<p><strong>Authors:</strong> Khoat Than</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 从理论上证明归一化层能指数级降低网络Lipschitz常数，解释其稳定优化和泛化的机制，对深度学习理论中的归一化和容量控制有核心贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00958' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Energy-Efficient Deep Learning Without Backpropagation: A Rigorous Evaluation of Forward-Only Algorithms</h3>
<p><strong>Authors:</strong> Przemys{\l}aw Spyra (), Witold Dzwinel ()</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 挑战了反向传播是最优的传统假设，提出Mono-Forward算法，在MLP上比优化后的BP基线更准确，且能耗降低41%、训练速度快34%，为深度学习优化提供了节能且高性能的替代方案
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01061' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Saddle Point Remedy: Power of Variable Elimination in Non-convex Optimization</h3>
<p><strong>Authors:</strong> Min Gan (), Guang-Yong Chen (), Yang Yi (), Lin Yang ()</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 分析变量消除算法（如VarPro）对非凸优化中鞍点问题的解决作用，通过Hessian惯性和Schur补证明其能重塑目标函数临界点结构，为设计更鲁棒的优化算法提供了理论指导
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01234' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Towards 1000-fold Electron Microscopy Image Compression for Connectomics via VQ-VAE with Transformer Prior</h3>
<p><strong>Authors:</strong> Fuming Yang, Yicong Li, Hanspeter Pfister, Jeff W. Lichtman, Yaron Meirovitch</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 论文基于用户深度学习理论方向核心关注的VQ-VAE模型，结合Transformer先验实现电镜图像高倍压缩，直接关联VQ-VAE研究点
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00231' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning with Category-Equivariant Architectures for Human Activity Recognition</h3>
<p><strong>Authors:</strong> Yoshihiro Maruyama</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出类别等变的神经网络架构CatEquiv，编码时间、幅度和结构对称性，解决人体活动识别的泛化问题，符合深度学习理论中的网络架构方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01139' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Deceptive Flatness: Dual-Order Solution for Strengthening Adversarial Transferability</h3>
<p><strong>Authors:</strong> Zhixuan Zhang, Pingyu Wang, Xingjian Zheng, Linbo Qing, Qi Liu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出基于双阶信息的对抗攻击方法，解决“欺骗性平坦”导致的迁移性不足问题，通过优化梯度方向提升对抗样本的跨模型迁移能力，符合深度学习理论中的对抗鲁棒性方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01240' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning with Category-Equivariant Architectures for Human Activity Recognition</h3>
<p><strong>Authors:</strong> Yoshihiro MaruyamaPublished:%-1Link:%Reason:提出类别等变的神经网络架构CatEquiv，编码时|间、幅度和结构对称性，解决人体活动识别的泛化问题，符合深度学习理论中的网络架构方向Score:7</p>
<p><strong>Published:</strong> %-1Link:%Reason:提出类别等变的神经网络架构CatEquiv，编码时|间、幅度和结构对称性，解决人体活动识别的泛化问题，符合深度学习理论中的网络架构方向Score:7</p>
<p><strong>Reason:</strong> 提出类别等变的神经网络架构CatEquiv，编码时|间、幅度和结构对称性，解决人体活动识别的泛化问题，符合深度学习理论中的网络架构方向Score:7
Field:深度学习理论</p>
<p><a href='%Reason:提出类别等变的神经网络架构CatEquiv，编码时|间、幅度和结构对称性，解决人体活动识别的泛化问题，符合深度学习理论中的网络架构方向Score:7' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning with Category-Equivariant Architectures for Human Activity Recognition</h3>
<p><strong>Authors:</strong> Yoshihiro Maruyama</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> %提出类别等变的神经网络架构CatEquiv%编码时间、幅度和结构对称性%解决人体活动识别的泛化问题%符合深度学习理论中的网络架构方向Score:7Field:深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.0113%Reason:%提出类别等变的神经网络架构CatEquiv%编码时间、幅度和结构对称性%解决人体活动识别的泛化问题%符合深度学习理论中的网络架构方向Score:7Field:深度学习理论' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Cross-fluctuation phase transitions reveal sampling dynamics in diffusion models</h3>
<p><strong>Authors:</strong> Sai Niranjan Ramachandran, Manish Krishan Lal, Suvrit Sra</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 用统计物理中的交叉波动分析扩散模型的采样动力学，推导闭合形式并验证其对采样效率的提升，属于深度学习理论中扩散模型的关键分析。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00124' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Enhancing Adversarial Transferability by Balancing Exploration and Exploitation with Gradient-Guided Sampling</h3>
<p><strong>Authors:</strong> Zenghao Niu, Weicheng Xie, Siyang Song, Zitong Yu, Feng Liu, Linlin Shen</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 解决对抗攻击的探索-利用平衡问题，提升跨模型迁移性，属于深度学习理论中对抗 robustness的关键问题，方法简单有效。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00411' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Variational Autoencoder for Calibration: A New Approach</h3>
<p><strong>Authors:</strong> Travis Barrett, Amit Kumar Mishra, Joyce Mwangama</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出基于VAE的传感器校准新方法，验证了VAE同时作为自编码器和校准模型的能力，拓展了VAE在深度学习理论中的应用场景
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00475' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diluting Restricted Boltzmann Machines</h3>
<p><strong>Authors:</strong> C. D\'iaz-Faloh, R. Mulet</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 研究RBM在极端剪枝下的性能，验证了Lottery Ticket Hypothesis在RBM中的适用性，对深度学习理论中的网络架构稀疏化设计有参考价值
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.00648' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Stochastic Regret Guarantees for Online Zeroth- and First-Order Bilevel Optimization</h3>
<p><strong>Authors:</strong> Parvin Nazari (), Bojian Hou (), Davoud Ataee Tarzanagh (), Li Shen (), George Michailidis ()</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出新搜索方向，证明一阶和零阶随机在线双层优化算法可实现亚线性随机双层regret，无需窗口平滑，减少了超梯度估计的 oracle 依赖，提升了效率
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01126' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Regularization Implies balancedness in the deep linear network</h3>
<p><strong>Authors:</strong> Kathryn Lindsey (), Govind Menon ()</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 用几何不变理论研究深度线性网络，证明L2正则化最小化在平衡流形上，分解训练动态为正则化流和学习流，为深度学习平衡ness提供了统一数学框架
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01137' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Curvature Rate {\lambda}: A Scalar Measure of Input-Space Sharpness in Neural Networks</h3>
<p><strong>Authors:</strong> Jacob Poschl ()</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出输入空间曲率率{\lambda}，作为衡量模型功能平滑度的参数化不变标量，可通过正则化调整输入空间几何，比SAM更优地平衡精度与置信校准
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01438' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation</h3>
<p><strong>Authors:</strong> Yongyuan Liang, Wei Chow, Feng Li, Ziqiao Ma, Xiyao Wang, Jiageng Mao, Jiuhai Chen, Jiatao Gu, Yue Wang, Furong Huang</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出首个针对多模态生成中reciprocal cross-modal reasoning的基准ROVER，系统评估模型跨模态推理能力，揭示多模态模型关键缺陷，符合多模态大模型方向。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01163' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> OmniVLA: Unifiying Multi-Sensor Perception for Physically-Grounded Multimodal VLA</h3>
<p><strong>Authors:</strong> Heyu Guo, Shanmu Wang, Ruichun Ma, Shiqi Jiang, Yasaman Ghasempour, Omid Abari, Baining Guo, Lili Qi</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出多模态视觉-语言-动作（VLA）模型OmniVLA，整合RGB、红外、毫米波雷达、麦克风等多传感器，生成物理接地的空间表示，提升场景理解能力，符合多模态大模型方向。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01210' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MotionStream: Real-Time Video Generation with Interactive Motion Controls</h3>
<p><strong>Authors:</strong> Joonghyuk Shin, Zhengqi Li, Richard Zhang, Jun-Yan Zhu, Jaesik Park, Eli Schechtman, Xun Huang</p>
<p><strong>Published:</strong> , 将文本生成的对抗样本迁移到原始模型中，从而实现黑盒攻击., 2提出了一种新型的黑盒攻击方法，利用生成模型产生对抗样本，并通过迁移学习的方式攻击目标模型。., 3基于生成式对抗网络(GAN), 提出了一种高效攻击方式，使得攻击无需了解目标模型的结构和参数., 4利用条件生成模型生成针对性的对抗样本，提升攻击成功率和迁移性., 在ImageNet数据集上验证了方法有效性., 结果表明，该方法在黑盒攻击场景下优于现有方法，具有更高的成功率和迁移能力。., 该方法不依赖目标模型的内部信息，只需要其输出标签，适用于实际中的安全场景. 2025-11-04</p>
<p><strong>Reason:</strong> 提出实时视频生成框架MotionStream，通过对抗自蒸馏将双向教师模型蒸馏为因果学生模型，支持交互运动控制和无限长度视频生成，符合多模态大模型中的视频生成方向。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01266' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MotionStream:. Real-Time Video Generation with Interactive Motion Controls</h3>
<p><strong>Authors:</strong> Joonghyuk Shin, Zhengqi Li, Richard Zhang,Jun-Yan Zhu, Jaesik Park, Eli Schechtman, Xun HuangPublished:2025-11-04</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出实时视频生成框架MotionStream，通过对抗自蒸馏将双向教师模型蒸馏为因果学生模型，支持交互运动控制和无限长度视频生成，符合多模态大模型中的视频生成方向。
Score:9
Field:多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01266' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ROVER: Benchmarking Reciprocal Cross-Modal Reason ing for Omnimodal Generation</h3>
<p><strong>Authors:</strong> Yongyuan Liang.Wei Chow,Feng Li.Ziqiao Ma,Xiyao Wang.Jiageng Mao.Jiuhai Chen.Jiatao Gu,Yue Wang,Furong HuangPublished:%-1Link:https://arxiv.orgabs/%Reason:提出首个针对多模态生成中reciprocal cross-modal reasoning的基准ROVER，系统评估模型跨模态推理能力，揭示多模态模型关键缺陷，符合多模态大模型方向Score:9</p>
<p><strong>Published:</strong> %-1Link:https://arxiv.orgabs/%Reason:提出首个针对多模态生成中reciprocal cross-modal reasoning的基准ROVER，系统评估模型跨模态推理能力，揭示多模态模型关键缺陷，符合多模态大模型方向Score:9</p>
<p><strong>Reason:</strong> 提出首个针对多模态生成中reciprocal cross-modal reasoning的基准ROVER，系统评估模型跨模态推理能力，揭示多模态模型关键缺陷，符合多模态大模型方向Score:9
Field:多模态大模型</p>
<p><a href='https://arxiv.orgabs/%Reason:提出首个针对多模态生成中reciprocal cross-modal reasoning的基准ROVER，系统评估模型跨模态推理能力，揭示多模态模型关键缺陷，符合多模态大模型方向Score:9' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation</h3>
<p><strong>Authors:</strong> Yongyuan Liang.Wei Chow,Feng Li.Ziqiao Ma,Xiyao Wang.Jiageng Mao.Jiuhai Chen.Jiatao Gu,Yue Wang,Furong Huang</p>
<p><strong>Published:</strong> 2025-11-%</p>
<p><strong>Reason:</strong> %提出首个针对多模态生成中reciprocal cross-modal reasoning的基准ROVER%系统评估模型跨模态推理能力%揭示多模态模型关键缺陷%符合多模态大模型方向Score:9Field:多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.0116%Reason:%提出首个针对多模态生成中reciprocal cross-modal reasoning的基准ROVER%系统评估模型跨模态推理能力%揭示多模态模型关键缺陷%符合多模态大模型方向Score:9Field:多模态大模型' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence</h3>
<p><strong>Authors:</strong> Yi Zhang, Che Liu, Xiancong Ren, Hanchu Ni, Shuai Zhang, Zeyuan Ding, Jiayu Hu, Hanzhe Shan, Zhenwei Niu, Zhaoyang Liu, Yue Zhao, Junbo Qi, Qinfan Zhang, Dengjie Li, Yidong Wang, Jiachen Luo, Yong Dai, Jian Tang, Xiaozhu Ju</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 开源的大规模具身多模态基础模型，通过metalearning和RL提升性能，在embodied基准上超过开源竞品，对多模态大模型的具身应用有重要价值。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00108' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FreeSliders: Training-Free, Modality-Agnostic Concept Sliders for Fine-Grained Diffusion Control in Images, Audio, and Video</h3>
<p><strong>Authors:</strong> Rotem Ezra, Hedi Zisling, Nimrod Berman, Ilan Naiman, Alexey Gorkor, Liran Nochumsohn, Eliya Nachmani, Omri Azencot</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对图像、音频、视频多模态的细粒度扩散控制，属于用户多模态大模型方向中的image generation及可控生成研究范畴
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00103' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding</h3>
<p><strong>Authors:</strong> Janghoon Cho, Jungsoo Lee, Munawar Hayat, Kyuwoong Hwang, Fatih Porikli, Sungha Choi</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 解决长视频理解中视觉token过载问题，提出基于设施选址的高效token压缩方法，关联用户多模态大模型的video understanding研究
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00141' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Retrospect to Multi-prompt Learning across Vision and Language</h3>
<p><strong>Authors:</strong> Ziliang Chen, Xin Huang, Quanlong Guan, Liang Lin, Weiqi Luo</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 系统研究视觉-语言模型的多prompt学习，直接对应用户多模态大模型方向中的prompt learning与vision-language alignment研究点
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00191' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning</h3>
<p><strong>Authors:</strong> Xuanle Zhao, Deyang Jiang, Zhixiong Zeng, Lei Chen, Haibo Qiu, Jing Huang, Yufeng Zhong, Liming Zheng, Yilin Cao, Lin Ma</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出粗到细视觉强化学习框架统一多模态代码生成，属于用户多模态大模型方向中的multimodal code generation研究范畴
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00391' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection</h3>
<p><strong>Authors:</strong> Daichi Zhang, Tong Zhang, Jianmin Bao, Shiming Ge, Sabine Süsstrunk</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 利用CLIP的图像-文本错位特征实现通用假图像检测，关联用户多模态大模型方向中的vision-language alignment与image understanding研究
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00427' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding</h3>
<p><strong>Authors:</strong> Shijie Zhou (unknown), Viet Dac Lai (unknown), Hao Tan (unknown), Jihyung Kil (unknown), Wanrong Zhu (unknown), Changyou Chen (unknown), Ruiyi Zhang (unknown)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对多模态大模型在GUI Grounding任务中的注意力对齐问题，提出基于MLLM内在注意力的坐标无关监督微调框架，通过多模态注意力对齐和插件式放大阶段提升GUI grounding效率与性能，在ScreenSpot-Pro和OSWorld-G上取得3B模型最优结果，契合多模态大模型方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00810' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OMEGA: Optimized Multimodal Position Encoding Index Derivation with Global Adaptive Scaling for Vision-Language Models</h3>
<p><strong>Authors:</strong> Ruoxiang Huang (unknown), Xindian Ma (unknown), Rundong Kong (unknown), Zhen Yuan (unknown), Peng Zhang (unknown)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对视觉语言模型（VLMs）位置编码未考虑模态结构差异的问题，提出模态特定位置编码与全局自适应缩放策略，有效提升VLMs多模态任务性能，在Qwen2.5-VL、LLaVA等模型上验证有效性，符合多模态大模型方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00821' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis</h3>
<p><strong>Authors:</strong> Dongheng Lin (unknown), Mengxue Qu (unknown), Kunyang Han (unknown), Jianbo Jiao (unknown), Xiaojie Jin (unknown), Yunchao Wei (unknown)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对视频异常分析中检测、定位、解释的任务分割问题，提出统一推理框架，通过prompt链式推理连接多任务实现零-shot整体分析，在多个基准上取得最优零-shot性能，契合多模态大模型方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00962' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction</h3>
<p><strong>Authors:</strong> Narges Ghasemi, Amir Ziashahabi, Salman Avestimehr, Cyrus Shahabi</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 研究图像地理定位的分层序列预测方法，结合多模态大模型（MLLM）优化地理token的 hierarchical预测，提升定位精度，符合多模态大模型方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01082' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UniREditBench: A Unified Reasoning-based Image Editing Benchmark</h3>
<p><strong>Authors:</strong> Feng Han, Yibin Wang,Chenglin Li,Zheming Liang,Dianyi Wang,Yang Jiao,Zhipeng Wei,Chao Gong,Cheng Jin,Jingjing Chen,Jiaqi Wang</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出推理型图像编辑基准UniREditBench，覆盖真实与游戏场景共⑧大维度1⑧子维度，引入多模态双参考评估提升可靠性，符合多模态大模型中的图像编辑方向。
Score:8
Field:多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.0%412%95' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment</h3>
<p><strong>Authors:</strong> Xinyu Mao,Junsi Li,Haoji Zhang.Yu Liang.Ming SunPublished:2025-1Link:https://arxiv.orgabs/2511.01%0Reason:提出语义增强的补丁slimming框架SEPS，通过整合 dense和 sparse文本的统一语义，解决跨模态对齐中的补丁冗余和歧义问题，提升细粒度对齐性能，符合多模态大模型方向。Score:8Field:多模态大模型</p>
<p><strong>Published:</strong> 2025-1Link:https://arxiv.orgabs/2511.01%0Reason:提出语义增强的补丁slimming框架SEPS，通过整合 dense和 sparse文本的统一语义，解决跨模态对齐中的补丁冗余和歧义问题，提升细粒度对齐性能，符合多模态大模型方向。Score:8Field:多模态大模型</p>
<p><strong>Reason:</strong> 提出语义增强的补丁slimming框架SEPS，通过整合 dense和 sparse文本的统一语义，解决跨模态对齐中的补丁冗余和歧义问题，提升细粒度对齐性能，符合多模态大模型方向。Score:8Field:多模态大模型</p>
<p><a href='https://arxiv.orgabs/2511.01%0Reason:提出语义增强的补丁slimming框架SEPS，通过整合 dense和 sparse文本的统一语义，解决跨模态对齐中的补丁冗余和歧义问题，提升细粒度对齐性能，符合多模态大模型方向。Score:8Field:多模态大模型' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction</h3>
<p><strong>Authors:</strong> Narges Ghasemi, Amir Ziashahabi,Salm an Avestimehr,Cyrus Shahabi</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 研究图像地理定位的分层序列预测方法，结合多模态大模型(MLLM)优化地理token的hierarchical预测，提升定位精度%符合多模态大模型方向Score:8
Field:多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01082' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GeoToken:. Hierarchical Geolocalization of Images via Next Token Prediction</h3>
<p><strong>Authors:</strong> Narges Ghasemi, Amir Ziashahabi,Salm an Avestimehr,Cyrus Shahabi</p>
<p><strong>Published:</strong> 2025-11-%</p>
<p><strong>Reason:</strong> %研究图像地理定位的分层序列预测方法%结合多模态大模型(MLLM)优化地理token的hierarchical预测%提升定位精度%符合多模态大模型方向Score:8Field:多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.010%2Reason:%研究图像地理定位的分层序列预测方法%结合多模态大模型(MLLM)优化地理token的hierarchical预测%提升定位精度%符合多模态大模型方向Score:8Field:多模态大模型' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Wave-Particle (Continuous-Discrete) Dualistic Visual Tokenization for Unified Understanding and Generation</h3>
<p><strong>Authors:</strong> Yizhu Chen, Chen Ju, Zhicheng Wang, Shuai Xiao, Xu Chen, Jinsong Lan, Xiaoyong Zhu, Ying Chen</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出连续-离散双态视觉tokenizer，解决MLLM中视觉理解与生成的token矛盾，属于多模态大模型中的tokenizer方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01593' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Xiaoyu Zhan, Wenxuan Huang, Hao Sun, Xinyu Fu, Changfeng Ma, Shaosheng Cao, Bohan Jia, Shaohui Lin, Zhenfei Yin, Lei Bai, Wanli Ouyang, Yuanqi Li, Jie Guo, Yanwen Guo</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出Viewpoint Learning任务与数据集，通过两阶段微调提升MLLM的空间推理能力，属于多模态大模型中的image understanding方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01618' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> 3EED: Ground Everything Everywhere in 3D</h3>
<p><strong>Authors:</strong> Rong Li, Yuhao Dong, Tianshuai Hu, Ao Liang, Youquan Liu, Dongyue Lu, Liang Pan, Lingdong Kong, Junwei Liang, Ziwei Liu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 构建多平台3D视觉grounding基准，支持自动驾驶等场景下的embodied agent语言指代定位，属于多模态大模型中的GUI Grounding方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01755' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Bridging Vision, Language, and Mathematics: Pictographic Character Reconstruction with B\'ezier Curves</h3>
<p><strong>Authors:</strong> Zihao Wan, Pau Tong Lin Xu, Fuwen Luo, Ziyue Wang, Peng Li, Yang Liu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 将视觉语言模型（VLM）与几何程序合成结合，解决象形文字重建问题，验证了VLM对结构化视觉理解的能力，属于多模态大模型的核心研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00076' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UME-R1: Exploring Reasoning-Driven Generative Multimodal Embeddings</h3>
<p><strong>Authors:</strong> Zhibin Lan, Liqiang Niu, Fandong Meng, Jie Zhou, Jinsong Su</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出生成式多模态嵌入框架，结合MLLM的推理能力，在多模态基准上显著提升性能，揭示了生成式嵌入的优势，属于多模态大模型的重要研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00405' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Explore More, Learn Better: Parallel MLLM Embeddings under Mutual Information Minimization</h3>
<p><strong>Authors:</strong> Zhicheng Wang (), Chen Ju (), Xu Chen (), Shuai Xiao (), Jinsong Lan (), Xiaoyong Zhu (), Ying Chen (), Zhiguo Cao ()</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出平行解耦框架PDF，利用MLLM的可控性生成平行嵌入，通过互信息最小化提升多样性，在多模态嵌入基准上显著提升性能，且推理开销可忽略
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01588' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation</h3>
<p><strong>Authors:</strong> Tao Liu, Chongyu Wang, Rongjie Li, Yingchen Yu, Xuming He, Bai Song</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对多模态大模型在GUI导航中的跨域泛化与历史信息利用问题，提出结构化推理与历史总结框架，直接对应多模态大模型方向中的GUI Agent/Grounding研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.27210' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots</h3>
<p><strong>Authors:</strong> Junyao Shi (University of Pennsylvania), Rujia Yang (University of Pennsylvania), Kaitian Chao (University of Pennsylvania), Selina Bingqing Wan (University of Pennsylvania), Yifei Shao (University of Pennsylvania), Jiahui Lei (University of Pennsylvania), Jianing Qian (University of Pennsylvania), Long Le (University of Pennsylvania), Pratik Chaudhari (University of Pennsylvania), Kostas Daniilidis (University of Pennsylvania), Chuan Wen (University of Pennsylvania), Dinesh Jayaraman (University of Pennsylvania)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出Maestro框架，通过VLM编码代理动态组合机器人感知、规划和控制模块，实现零样本通用机器人政策，显著超越现有VLA模型的零样本性能，且具有易扩展性和适应性，对多模态大模型在机器人控制中的应用有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00917' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model</h3>
<p><strong>Authors:</strong> Zhe Li, Xiang Bai, Jieyu Zhang, Zhuangzhe Wu, Che Xu, Ying Li, Chengkai Hou, Shanghang Zhang</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出基于3D多模态语言模型的端到端自动重建框架URDF-Anything，通过[SEG] token机制和联合优化提升几何分割（mIoU提升17%）和运动学参数预测精度（平均误差降低29%），助力机器人仿真数字孪生构建，对多模态大模型在3D物体重建中的应用有重要意义。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00940' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Hongyin Zhang, Shuo Zhang, Junxi Jin, Qixin Zeng, Runze Li, Donglin Wang</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对VLA模型在分布外部署的鲁棒性问题，提出RobustVLA框架，通过Jacobian正则化（降低观测噪声敏感性）和smoothness正则化（稳定动作扰动）提升鲁棒性，在多机器人环境中优于现有方法，对多模态大模型的VLA可靠性提升有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01331' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process</h3>
<p><strong>Authors:</strong> Jiayi Chen, Wenxuan Song, Pengxiang Ding, Ziyang Zhou, Han Zhao, Feilong Tang, Donglin Wang, Haoang Li</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出联合离散去噪扩散过程（JD3P），将视觉-语言-动作多模态整合到统一去噪轨迹中，实现理解、生成与动作的内在协同，在CALVIN等基准上达到SOTA且推理速度快4倍，推动了多模态大模型在 embodied agent 中的应用。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01718' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image Super-Resolution</h3>
<p><strong>Authors:</strong> Peng Du, Hui Li, Han Xu, Paul Barom Jeon, Dongwook Lee, Daehyun Ji, Ran Yang, Feng Zhu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出结合扩散Transformer和多尺度小波谱的超分辨率模型DTWSR，利用Transformer捕捉多尺度频率子带关联，提升图像重建质量，符合多模态大模型中的图像生成方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01175' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model</h3>
<p><strong>Authors:</strong> Sampriti Soor,Alik Pramanick,Jothiprakash K,Arijit Sur</p>
<p><strong>Published:</strong> 2025-11-%4Link:https://arxiv.orgabs/%2511.01317Reason:提出结合CLIP的生成对抗攻击方法，利用CLIP的文本-图像对齐能力生成语义一致的对抗样本，提升攻击的有效性和视觉不可感知性，符合多模态大模型方向。Score:7Field:多模态大模型</p>
<p><strong>Reason:</strong> 提出结合CLIP的生成对抗攻击方法，利用CLIP的文本-图像对齐能力生成语义一致的对抗样本，提升攻击的有效性和视觉不可感知性，符合多模态大模型方向。Score:7Field:多模态大模型</p>
<p><a href='https://arxiv.orgabs/%2511.01317Reason:提出结合CLIP的生成对抗攻击方法，利用CLIP的文本-图像对齐能力生成语义一致的对抗样本，提升攻击的有效性和视觉不可感知性，符合多模态大模型方向。Score:7Field:多模态大模型' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image SuperResolution</h3>
<p><strong>Authors:</strong> Peng Du,Hui Li,Han Xu.Paul Barom Jeon.Dongwook Lee,Daehyun Ji.Ran Yang.Feng ZhuPublished:%Link:%Reason:提出结合扩散Transformer和多尺度小波谱的超分辨率模型DTWSR%利用Transformer捕捉多尺度频率子带关联，提升图像重建质量%符合多模态大模型中的图像生成方向Score:7Field:多模态大模型</p>
<p><strong>Published:</strong> %Link:%Reason:提出结合扩散Transformer和多尺度小波谱的超分辨率模型DTWSR%利用Transformer捕捉多尺度频率子带关联，提升图像重建质量%符合多模态大模型中的图像生成方向Score:7Field:多模态大模型</p>
<p><strong>Reason:</strong> 提出结合扩散Transformer和多尺度小波谱的超分辨率模型DTWSR%利用Transformer捕捉多尺度频率子带关联，提升图像重建质量%符合多模态大模型中的图像生成方向Score:7Field:多模态大模型</p>
<p><a href='%Reason:提出结合扩散Transformer和多尺度小波谱的超分辨率模型DTWSR%利用Transformer捕捉多尺度频率子带关联，提升图像重建质量%符合多模态大模型中的图像生成方向Score:7Field:多模态大模型' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image Super-Resolution</h3>
<p><strong>Authors:</strong> Peng Du,Hui Li,Han Xu.Paul Barom Jeon.Dongwook Lee,Daehyun Ji.Ran Yang,Feng Zhu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> %提出结合扩散Transformer和多尺度小波谱的超分辨率模型DTWSR%利用Transformer捕捉多尺度频率子带关联%提升图像重建质量%符合多模态大模型中的图像生成方向Score:7Field:多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.0117%Reason:%提出结合扩散Transformer和多尺度小波谱的超分辨率模型DTWSR%利用Transformer捕捉多尺度频率子带关联%提升图像重建质量%符合多模态大模型中的图像生成方向Score:7Field:多模态大模型' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image</h3>
<p><strong>Authors:</strong> Yuxiao Yang, Xiao-Xiao Long, Zhiyang Dou, Cheng Lin, Yuan Liu, Qingsong Yan, Yuexin Ma, Haoqian Wang, Zhiqiang Wu, Wei Yin</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出跨域扩散模型从单图生成高保真3D模型，解决现有方法的质量与效率问题，属于多模态大模型中的image generation方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01767' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bayesian Natural Gradient Fine-Tuning of CLIP Models via Kalman Filtering</h3>
<p><strong>Authors:</strong> Hossein Abdi (), Mingfei Sun (), Wei Pan ()</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 用卡尔曼滤波实现CLIP的贝叶斯自然梯度微调，结合二阶优化与贝叶斯推理，提升少样本泛化和OOD鲁棒性，是多模态模型微调的有效方法
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01694' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation</h3>
<p><strong>Authors:</strong> Xiangyu Shi, Zerui Li, Yanyuan Qiao, Qi Wu</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出无全景图的端到端零样本VLN-CE框架，仅用三幅正面RGB-D图像和自然语言指令，通过不确定性感知推理模块提升决策鲁棒性，显著降低每步延迟，提升实际环境适用性，对多模态大模型的Vision-and-Language Navigation研究有推动作用。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.00933' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Embodiment Transfer Learning for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Chengmeng Li, Yaxin Peng</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对VLA模型跨embodiment协作难题，提出ET-VLA框架，通过合成预训练（SCP）减少数据成本，结合Embodied Graph-of-Thought区分多embodiment功能，在仿真和真实机器人上验证优于OpenVLA，对多模态大模型的VLA跨域迁移有重要贡献。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01224' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Don't Just Search, Understand: Semantic Path Planning Agent for Spherical Tensegrity Robots in Unknown Environments</h3>
<p><strong>Authors:</strong> Junwen Zhang, Changyue Liu, Pengqi Fu, Xiang Guo, Ye Shi, Xudong Liang, Zhijian Wang, Hanzhi Ma</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出LLM驱动的SATPlanner语义路径规划代理，通过自适应观察窗口机制动态调整感知域，构建环境语义信念，实现线性增长的搜索空间和100%仿真成功率，减少搜索空间37.2%，对多模态大模型在机器人路径规划中的语义理解应用有推动作用。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01236' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models</h3>
<p><strong>Authors:</strong> Sarthak Mishra, Rishabh Dev Yadav, Avirup Das, Saksham Gupta, Wei Pan, Spandan Roy</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出AERMANI-VLM框架，通过结构化提示引导VLM生成推理轨迹，选择飞行安全技能，分离高层推理与低层控制，解决VLM驱动 aerial manipulator 的不安全性和不可靠性，在仿真和硬件上验证多步任务性能，对多模态大模型在 aerial 机器人控制中的应用有推动作用。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01472' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence</h3>
<p><strong>Authors:</strong> Renjun Gao, Peiyan Zhong</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 该系统整合多模态大语言模型（MLLMs）与分层多代理决策，解决智能辅助系统中的风险感知规划、用户个性化等问题，在多数据集上表现优于现有多模态模型，为多模态大模型在实际辅助场景的应用提供了可行框架。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01594' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Extremal Contours: Gradient-driven contours for compact visual attribution</h3>
<p><strong>Authors:</strong> Reza Karimzadeh,Albert Alonso,Frans Zdyb.Julius B.Kirkegaard,Bulat IbragimovPublished:%-1Link:https://arxiv.orgabs/2511.0141Reason:%提出训练-free的视觉归因方法Extremal Contours，通过梯度驱动优化轮廓参数，生成紧凑且可解释的视觉归因结果%符合深度学习可解释性方向。Score:9Field:深度学习可解释性</p>
<p><strong>Published:</strong> %-1Link:https://arxiv.orgabs/2511.0141Reason:%提出训练-free的视觉归因方法Extremal Contours，通过梯度驱动优化轮廓参数，生成紧凑且可解释的视觉归因结果%符合深度学习可解释性方向。Score:9Field:深度学习可解释性</p>
<p><strong>Reason:</strong> %提出训练-free的视觉归因方法Extremal Contours，通过梯度驱动优化轮廓参数，生成紧凑且可解释的视觉归因结果%符合深度学习可解释性方向。Score:9Field:深度学习可解释性</p>
<p><a href='https://arxiv.orgabs/2511.0141Reason:%提出训练-free的视觉归因方法Extremal Contours，通过梯度驱动优化轮廓参数，生成紧凑且可解释的视觉归因结果%符合深度学习可解释性方向。Score:9Field:深度学习可解释性' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion</h3>
<p><strong>Authors:</strong> Jaehyun Park (unknown), Konyul Park (unknown), Daehun Kim (unknown), Junseo Park (unknown), Jun Won Choi (unknown)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对自动驾驶多传感器融合模型的可解释性问题，提出层-wise模态分解（LMD）方法，后验分解各层模态信息以解释预测来源，在相机-雷达、相机-LiDAR等融合模型上验证有效性，符合深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.00859' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Automatically Finding Rule-Based Neurons in OthelloGPT</h3>
<p><strong>Authors:</strong> Aditya Singh, Zihang Wen, Srujananjali Medicherla, Adam Karvonen, Can Rager</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对OthelloGPT的可解释性研究，提出自动化方法识别规则基神经元，结合决策树和因果干预验证，对深度学习可解释性有直接贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.00059' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Priors in Time: Missing Inductive Biases for Language Model Interpretability</h3>
<p><strong>Authors:</strong> Ekdeep Singh Lubana, Can Rager, Sai Sumedh R. Hindupur, Valerie Costa, Greta Tuckute, Oam Patel, Sonia Krishna Murthy, Thomas Fel, Daniel Wurgaft, Eric J. Bigelow, Johnny Lin, Demba Ba, Martin Wattenberg, Fernanda Viegas, Melanie Weber, Aaron Mueller</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对语言模型解释性工具（如稀疏自编码器）忽略语言时间结构的问题，提出具有时间归纳偏置的Temporal Feature Analysis方法，改善对动态概念的解释能力，属于深度学习可解释性研究的关键问题。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.01836' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Feature-Guided Analysis of Neural Networks: A Replication Study</h3>
<p><strong>Authors:</strong> Federico Formica, Stefano Gregis, Aurora Francesca Zanenga, Andrea Rota, Mark Lawford, Claudio Menghi</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 复制验证特征引导分析方法的有效性，通过提取神经网络相关切片解释决策，属于深度学习可解释性中的white-box explanation方向，支持安全关键应用的解释需求。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.00052' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail</h3>
<p><strong>Authors:</strong> NVIDIA, Yan Wang, Wenjie Luo, Junjie Bai, Yulong Cao, Tong Che, Ke Chen, Yuxiao Chen, Jenna Diamond, Yifan Ding, Wenhao Ding, Liang Feng, Greg Heinrich, Jack Huang, Peter Karkus, Boyi Li, Pinyi Li, Tsung-Yi Lin, Dongran Liu, Ming-Yu Liu, Langechuan Liu, Zhijian Liu, Jason Lu, Yunxiang Mao, Pavlo Molchanov, Lindsey Pavao, Zhenghao Peng, Mike Ranzinger, Ed Schmerling, Shida Shen, Yunfei Shi, Sarah Tariq, Ran Tian, Tilman Wekel, Xinshuo Weng, Tianjun Xiao, Eric Yang, Xiaodong Yang, Yurong You, Xiaohui Zeng, Wenyuan Zhang, Boris Ivanovic, Marco Pavone</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> NVIDIA团队提出视觉-语言-动作模型（VLA），结合因果推理与轨迹规划解决自动驾驶长tail场景泛化问题，实现推理与动作预测的桥接，符合自动驾驶与大模型方向，机构与作者影响力强。
Score: 9
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.00088' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction</h3>
<p><strong>Authors:</strong> Yu Liu (unknown), Zhijie Liu (unknown), Zedong Yang (unknown), You-Fu Li (unknown), He Kong (unknown)</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 针对自动驾驶中行人意图预测的遮挡问题，提出遮挡感知扩散模型（ODM），通过扩散变压器重构遮挡运动模式并指导意图预测，在PIE和JAAD基准上取得更鲁棒性能，契合自动驾驶与大模型方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.00858' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Saliency-Guided Domain Adaptation for Left-Hand Driving in Autonomous Steering</h3>
<p><strong>Authors:</strong> Zahra Mehraban, Sebastien Glaser, Michael Milford, Ronald Schroeter</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 研究自动驾驶模型的域适应问题，通过翻转数据预训练和显著性分析引导模型关注左驾场景关键特征，提升跨域泛化性能，符合自动驾驶与大模型方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.01223' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop</h3>
<p><strong>Authors:</strong> YoungJae Cheong, Jhonghyun An</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出几何感知的适配器模块，通过保持点云邻域连续性和正则化结构脆弱区域，提升跨天气LiDAR语义分割性能，符合自动驾驶与大模型方向中的多传感器感知问题。
Score: 8
Field:, 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.01250' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UniLION: Towards Unified Autonomous Driving Model with Linear Group RNNs</h3>
<p><strong>Authors:</strong> Zhe Liu, Jinghua Hou, Xiaoqing Ye, Jingdong Wang, Hengshuang Zhao, Xiang Bai</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出统一自动驾驶架构，用线性组RNN高效处理多模态时序数据，支持3D感知、预测、规划等核心任务，属于自动驾驶与大模型方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.01768' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Embodied Cognition Augmented End2End Autonomous Driving</h3>
<p><strong>Authors:</strong> Ling Niu, Xiaoji Zheng, Han Wang, Chen Zheng, Ziyuan Yang, Bokui Chen, Jiangtao Gong</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 提出E³AD范式，通过视觉特征提取网络与EEG大模型的对比学习整合人类驾驶认知，提升端到端自动驾驶规划性能，是首次将embodied cognitive数据用于端到端自动驾驶，对自动驾驶与大模型的认知增强方向有重要创新。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.01334' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> X-TRACK: Physics-Aware xLSTM for Realistic Vehicle Trajectory Prediction</h3>
<p><strong>Authors:</strong> Aanchal Rajesh Chugh, Marion Neumeier, Sebastian Dorn</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 结合物理约束的xLSTM模型解决车辆轨迹预测问题，属于自动驾驶中的核心任务，提升了轨迹的现实性和准确性，符合自动驾驶与大模型方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.00266' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Gen AI in Automotive: Applications, Challenges, and Opportunities with a Case study on In-Vehicle Experience</h3>
<p><strong>Authors:</strong> Chaitanya Shinde, Divya Garikapati</p>
<p><strong>Published:</strong> 2025-11-04</p>
<p><strong>Reason:</strong> 综述生成式AI在汽车领域的应用（含自动驾驶、车载HMI），结合奔驰MBUX虚拟助手案例分析，符合自动驾驶与大模型方向的应用研究需求。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.00026' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>