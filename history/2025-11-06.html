<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-06</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>深度学习理论</a>
<a href='#' >多模态大模型</a>
<a href='#' >深度学习可解释性</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-06</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-06 12:28:40</p>
<p>已自动阅读了 236 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：120006</p>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Adam Reduces a Unique Form of Sharpness: Theoretical Insights Near the Minimizer Manifold</h3>
<p><strong>Authors:</strong> Xinghan Li, Haodong Wen, Kaifeng Lyu</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 理论分析了Adam优化器在极小值流形附近对独特锐度（$\tr(\Diag(\mH)^{1/2})$）的减少作用，区别于SGD的锐度度量（$\tr(\mH)$），通过随机微分方程的连续时间近似刻画其行为，并在带标签噪声的过参数化模型、稀疏线性回归任务上验证了理论结论，推进了优化器的理论理解。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02773' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Geometry of Grokking: Norm Minimization on the Zero-Loss Manifold</h3>
<p><strong>Authors:</strong> Tiberiu Musat</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 揭示Grokking现象的几何本质（零损失流形上的范数最小化），通过两层网络验证理论，对深度学习理论中的训练动力学研究有重要理论贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01938' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory</h3>
<p><strong>Authors:</strong> Prasanth K K, Shubham Sharma</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出Output-Conditioned Gating机制增强LSTM的长程记忆，通过注意力机制实现自反思，在Distractor Signal Task与ListOps上显著优于标准LSTM，对深度学习理论中的network architecture设计有改进。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01950' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Bulk-boundary decomposition of neural networks</h3>
<p><strong>Authors:</strong> Donghee Lee, Hye-Sung Lee, Jaeok Yi</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 将神经网络的Lagrangian分解为数据无关的体项与数据相关的边界项，建立场论框架解释训练动态，对深度学习理论中的训练过程分析有理论贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02003' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behavior</h3>
<p><strong>Authors:</strong> Daniel Aarao Reis Arturi, Eric Zhang, Andrew Ansah, Kevin Zhu, Ashwinee Panda, Aishwarya Balwani</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 从几何视角分析emergent misalignment的参数空间结构，发现跨任务的线性共享子空间，对深度学习理论中的参数空间研究有重要发现。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02022' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Path-Coordinated Continual Learning with Neural Tangent Kernel-Justified Plasticity: A Theoretical Framework with Near State-of-the-Art Performance</h3>
<p><strong>Authors:</strong> Rathin Chandra Shit</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 结合神经切线核（NTK）理论设计持续学习的塑性边界，提出路径协调框架，在Split-CIFAR10上实现近SOTA性能，对深度学习理论中的持续学习有理论与实践贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02025' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Natural Building Blocks for Structured World Models: Theory, Evidence, and Scaling</h3>
<p><strong>Authors:</strong> Lancelot Da Costa, Sanjeev Namjoshi, Mohammed Abbas Ansari, Bernhard Schölkopf</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出以HMM和sLDS为自然构建块的结构化世界模型框架，支持分层组合与生成/控制任务，对深度学习理论中的world model研究有理论贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02091' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster Decode Without Retraining</h3>
<p><strong>Authors:</strong> Costin-Andrei Oncescu, Qingyang Wu, Wai Tong Chung, Robert Wu, Bryan Gopal, Junxiong Wang, Tri Dao, Ben Athiwaratkun</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 针对MoE模型提出batch-aware专家路由方法，优化解码速度，属于深度学习理论中的网络架构（MoE）研究，符合用户方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02237' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error</h3>
<p><strong>Authors:</strong> Fengjuan Wang, Zhiyi Su, Xingzhu Hu, Cheng Wang, Mou Sun</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出无转换的FP8训练方案用于MoE模型，解决量化误差问题，属于深度学习理论中的网络架构（MoE）与低精度优化研究，符合用户方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02302' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models</h3>
<p><strong>Authors:</strong> Lejs Deen Behric, Liang Zhang, Bingcong Li, Kiran Koshy Thekumparampil</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 针对梯度-free的LLM微调场景提出ConMeZO优化器，通过自适应方向采样（限制在动量估计的锥内）改进MeZO的收敛速度，提供了最坏情况收敛率的理论证明，并在自然语言任务上验证了比MeZO快2倍的效果，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02757' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation</h3>
<p><strong>Authors:</strong> Bum Chul Kwon, Ben Shapira, Moshiko Raboh, Shreyans Sethi, Shruti Murarka, Joseph A Morrone, Jianying Hu, Parthasarathy Suryanarayanan</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出基于Transformer的VAE框架STAR-VAE，采用SELFIES编码保证分子语法有效性，支持属性引导的条件生成（通过 property predictor提供条件信号），并通过LoRA进行参数高效微调，在GuacaMol和MOSES基准上表现优异，属于深度学习理论中的VAE研究，且具有实际应用价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02769' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> On the Emergence of Induction Heads for In-Context Learning</h3>
<p><strong>Authors:</strong> Tiberiu Musat, Tiago Pimentel, Lorenzo Noci, Alessandro Stolfo, Mrinmaya Sachan, Thomas Hofmann</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 研究了Transformer中induction heads的涌现机制，通过最小化ICL任务和修改后的Transformer架构，解释了其权重矩阵的结构，证明训练动态受限于19维子空间（仅3维主导涌现），并分析了涌现时间与上下文长度的二次关系，推进了网络架构中induction heads的理论理解。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01033' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations</h3>
<p><strong>Authors:</strong> Shichao Fan, Kun Wu, Zhengping Che, Xinhua Wang, Di Wu, Fei Liao, Ning Liu, Yixue Zhang, Zhen Zhao, Zhiyuan Xu, Meng Li, Qingjie Liu, Shanghang Zhang, Min Wan, Jian Tang</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 论文提出双分支VQ-VAE学习统一视觉-运动表示（UVMC），VQ-VAE是您深度学习理论方向的重点内容之一，且结合多模态视觉-语言-动作模型，兼具理论创新与多模态应用价值
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02776' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training</h3>
<p><strong>Authors:</strong> Ahmet Erdem Pamuk, Emir Kaan Özdemir, Şuayp Talha Kocabay</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出结合量子叠加原理的优化器SGD，通过量子电路扰动改进模型训练，在序列分类与LLM微调上优于AdamW，对深度学习理论中的optimizer设计有创新性探索。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.01918' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Static Cutoffs: One-Shot Dynamic Thresholding for Diffusion Language Models</h3>
<p><strong>Authors:</strong> Jucheng Shen, Yeonju Ro</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出One-Shot Dynamic Thresholding（OSDT）优化扩散语言模型的推理，通过单序列校准阈值提升解码效率与准确性，对深度学习理论中的生成模型推理优化有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02077' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization Landscape</h3>
<p><strong>Authors:</strong> Xinyuan Song, Jiaye Teng, Ziye Ma</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 研究矩阵感知中核最优损失的鲁棒性与优化景观，涉及深度学习理论中的损失函数设计与优化稳定性，与用户关注的深度学习理论高度相关。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02122' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Neural network initialization with nonlinear characteristics and information on spectral bias</h3>
<p><strong>Authors:</strong> Hikaru Homma, Jun Ohkubo</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 研究神经网络初始化与谱偏差的关系，提出利用谱偏差信息优化初始化策略，属于深度学习理论中的初始化与谱偏差研究，符合用户方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02244' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Gradient-Variation Online Adaptivity for Accelerated Optimization with Hölder Smoothness</h3>
<p><strong>Authors:</strong> Yuheng Zhao, Yu-Hu Yan, Kfir Yehuda Levy, Peng Zhao</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 针对Hölder光滑函数的在线优化提出梯度变化自适应方法，属于深度学习理论中的优化算法研究，符合用户方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02276' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RoME: Domain-Robust Mixture-of-Experts for MILP Solution Prediction across Domains</h3>
<p><strong>Authors:</strong> Tianle Pu, Zijie Geng, Haoyang Liu, Shixuan Liu, Jie Wang, Li Zeng, Chao Chen, Changjun Fan</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出域鲁棒的MoE模型用于跨域MILP解预测，属于深度学习理论中的网络架构（MoE）与泛化研究，符合用户方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02331' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Variational Geometric Information Bottleneck: Learning the Shape of Understanding</h3>
<p><strong>Authors:</strong> Ronald Katende</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出几何信息瓶颈框架，结合互信息压缩与几何正则化，属于深度学习理论中的表示学习研究，符合用户方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02496' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Non-Adversarial Approach to Idempotent Generative Modelling</h3>
<p><strong>Authors:</strong> Mohammed Al-Jaff, Giovanni Luca Marchetti, Michael C Welle, Jens Lundell, Mats G. Gustafsson, Gustav Eje Henter, Hossein Azizpour, Danica Kragic</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出非对抗性幂等生成模型，解决生成模型的模式崩溃问题，属于深度学习理论中的生成模型研究，符合用户方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02614' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Nesterov-Accelerated Robust Federated Learning Over Byzantine Adversaries</h3>
<p><strong>Authors:</strong> Lihan Xu, Yanjie Dong, Gang Wang, Runhao Zeng, Xiaoyi Fan, Xiping Hu</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出拜占庭鲁棒的Nesterov加速联邦学习算法，属于深度学习理论中的优化算法（Nesterov加速）与联邦学习研究，符合用户方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02657' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Scalable Evaluation and Neural Models for Compositional Generalization</h3>
<p><strong>Authors:</strong> Giacomo Camposampiero, Pietro Barbiero, Michael Hersche, Roger Wattenhofer, Abbas Rahimi</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 研究组合泛化的可扩展评估与神经模型，属于深度学习理论中的泛化研究，符合用户方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02667' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> CFL: On the Use of Characteristic Function Loss for Domain Alignment in Machine Learning</h3>
<p><strong>Authors:</strong> Abdullah Almansour, Ozan Tonguz</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出特征函数损失用于域对齐，解决分布偏移问题，属于深度学习理论中的域适应与表示学习研究，符合用户方向。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02148' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Improving Unlearning with Model Updates Probably Aligned with Gradients</h3>
<p><strong>Authors:</strong> Virgile Dine, Teddy Furon, Charly Faure</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 研究模型遗忘中的梯度对齐更新，属于深度学习理论中的模型优化与更新研究，符合用户方向。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.02435' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> iFlyBot-VLA Technical Report</h3>
<p><strong>Authors:</strong> Yuan Zhang, Chenyu Xue, Wenjie Xu, Chao Ji, Jiajia wu, Jia Pan</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出大尺度Vision-Language-Action（VLA）模型iFlyBot-VLA，创新 latent action model、双层次动作表征框架及混合训练策略，实现视觉、语言与动作模态的对齐，实验在LIBERO Franka基准和真实场景中验证了优越性，对多模态大模型的动作感知与跨模态融合研究有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.01914' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning</h3>
<p><strong>Authors:</strong> Fangxun Shu, Yongjie Ye, Yue Liao, Zijian Kang, Weijie Yin, Jiacong Wang, Xiao Liang, Shuicheng Yan, Chao Feng</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出双奖励强化学习框架SAIL-RL，通过Thinking Reward（推理质量）和Judging Reward（推理策略适配）优化多模态大语言模型（MLLMs）的推理能力，减少幻觉并提升适应性，实验在SAIL-VL2上实现与GPT-4o竞争的性能，对MLLMs的可靠推理研究有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02280' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models</h3>
<p><strong>Authors:</strong> Tianfan Peng, Yuntao Du, Pengzhou Ji, Shijie Dong, Kailin Jiang, Mingchuan Ma, Yijun Tian, Jinhe Bi, Qian Li, Wei Du, Feng Xiao, Lizhen Cui</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 针对多模态大模型的视觉token冗余问题，提出UniPruneBench基准，系统评估视觉token压缩算法的有效性，涉及多模态大模型中的tokenizer优化，对提升模型效率有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02650' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Differentiable Hierarchical Visual Tokenization</h3>
<p><strong>Authors:</strong> Marius Aasan, Martine Hjelkrem-Tan, Nico Catalano, Changkyu Choi, Adín Ramírez Rivera</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出可微分分层视觉tokenizer，解决ViT固定patch忽略图像结构的问题，支持预训练模型的retrofitting，对多模态大模型的tokenization方法有创新性贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02652' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation</h3>
<p><strong>Authors:</strong> Kevin Qinghong Lin, Yuhao Zheng, Hangyu Ran, Dantong Zhu, Dongxing Mao, Linjie Li, Philip Torr, Alex Jinpeng Wang</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出将多模态理解重构为SVG代码生成任务，构建VCode基准评估VLMs的视觉编码能力，对多模态大模型中的visual-centric coding研究有重要推动作用。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02778' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought</h3>
<p><strong>Authors:</strong> Yiyang Zhou, Haoqin Tu, Zijun Wang, Zeyu Wang, Niklas Muennighoff, Fan Nie, Yejin Choi, James Zou, Chaorui Deng, Shen Yan, Haoqi Fan, Cihang Xie, Huaxiu Yao, Qinghao Ye</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出需要生成中间视觉图像的推理基准MIRA，评估多模态大模型的视觉链式思考能力，对多模态大模型的image understanding与reasoning研究有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02779' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment</h3>
<p><strong>Authors:</strong> Rohan Wandre, Yash Gajewar, Namrata Patel, Vivek Dhalkari</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出多模态RAG架构LUMA-RAG，解决多模态流数据的对齐与记忆管理问题，属于多模态大模型研究，符合用户方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02371' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Pinpointing Trigger Moment for Grounded Video QA: Enhancing Spatio-temporal Grounding in Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Jinhwan Seo, Yoonki Cho, Junhyug Noh, Sung-eui Yoon</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 针对多模态大语言模型的Grounded Video QA任务，提出三阶段 pipeline 及CORTEX prompt定位触发时刻，实现更准确的时空接地与跟踪，HOTA分数（0.4968）显著超过去年冠军（0.2704），对多模态大模型的视频QA时空推理研究有推动作用。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02182' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning</h3>
<p><strong>Authors:</strong> Jizheng Ma, Xiaofei Zhou, Yanlong Song, Han Yan</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出CoCoVa框架，通过Latent Q-Former和多任务训练实现视觉语言模型的连续潜空间推理，解决离散语言与连续视觉的表征鸿沟，实验显示1.5B模型性能超过7B-9B模型，提升准确性与token效率，对多模态大模型的潜空间理解研究有创新贡献。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02360' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ChartM$^3$: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension</h3>
<p><strong>Authors:</strong> Duo Xu, Hao Cheng, Xin Lin, Zhen Xie, Hao Wang</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出多阶段代码驱动 pipeline 构建ChartM³数据集，针对多模态大模型的复杂图表推理需求，生成多维度、多步骤的视觉推理数据，实验验证数据集能提升模型推理能力与跨域泛化，对MLLMs的图表理解研究有重要支撑作用。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02415' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TAUE: Training-free Noise Transplant and Cultivation Diffusion Model</h3>
<p><strong>Authors:</strong> Daichi Nagai, Ryugo Morita, Shunsuke Kitada, Hitoshi Iyatomi</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出训练-free的噪声移植与培育扩散模型TAUE，解决text-to-image模型的layer-wise控制难题，实现多图层语义与结构一致生成，性能接近fine-tuned方法，对多模态大模型的图像生成可控性研究有实用价值。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02580' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing</h3>
<p><strong>Authors:</strong> Antonio Oroz, Matthias Nießner, Tobias Kirschstein</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出结合感知监督的3D头部重建模型，支持通过互动GUI进行几何雕刻和外观风格化（自然语言/图像提示），符合多模态大模型中的GUI Grounding与image generation方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.02777' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LLEXICORP: End-user Explainability of Convolutional Neural Networks</h3>
<p><strong>Authors:</strong> Vojtěch Kůr, Adam Bajger, Adam Kukučka, Marek Hradil, Vít Musil, Tomáš Brazdil</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 结合概念相关性传播（CRP）与多模态大语言模型，自动生成CNN的概念解释和自然语言说明，提升CNN的可解释性，对深度学习可解释性中的white-box explanation有重要应用。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.02720' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Deciphering Personalization: Towards Fine-Grained Explainability in Natural Language for Personalized Image Generation Models</h3>
<p><strong>Authors:</strong> Haoming Wang, Wei Gao</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出FineXL技术，针对个性化图像生成提供细粒度的自然语言解释与量化评分，提升生成模型的可解释性，对深度学习可解释性中的white-box explanation有贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.01932' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Regularization Through Reasoning: Systematic Improvements in Language Model Classification via Explanation-Enhanced Fine-Tuning</h3>
<p><strong>Authors:</strong> Vivswan Shah, Randy Cogill, Hanwei Yue, Gopinath Chennupati, Rinat Khaziev</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出通过解释增强的微调将推理与正则化结合，减少模型过拟合并提升可解释性，揭示解释的结构而非语义是性能提升的关键，对深度学习可解释性与正则化的关联研究有贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.02044' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LLM Probing with Contrastive Eigenproblems: Improving Understanding and Applicability of CCS</h3>
<p><strong>Authors:</strong> Stefan F. Schouten, Peter Bloem</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 将Contrast-Consistent Search（CCS）重构为特征问题，解决初始化敏感问题，提升LLM探测的稳定性与可解释性，对深度学习可解释性中的mechanistic interpretability有帮助。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.02089' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Geometric Data Valuation via Leverage Scores</h3>
<p><strong>Authors:</strong> Rodrigo Mendoza-Smith</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出用杠杆分数替代Shapley值进行几何数据 valuation，解决Shapley值的计算难题，证明其满足Shapley公理且能保证下游模型性能，对深度学习可解释性中的数据 valuation研究有重要贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.02100' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ProtoTSNet: Interpretable Multivariate Time Series Classification With Prototypical Parts</h3>
<p><strong>Authors:</strong> Bartłomiej Małkus, Szymon Bobek, Grzegorz J. Nalepa</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 提出基于原型部分的可解释多变量时间序列分类模型，通过改进ProtoPNet架构实现ante-hoc可解释性，符合用户关注的深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.02152' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> llmSHAP: A Principled Approach to LLM Explainability</h3>
<p><strong>Authors:</strong> Filip Naudot, Tobias Sundqvist, Timotheus Kampik</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 论文将Shapley value应用于LLM的特征归因，聚焦LLM推理的可解释性问题，直接对应您关注的深度学习可解释性中的Shapley value核心方向，理论性强且针对LLM场景有实际意义
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.01311' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Interpretable Heart Disease Prediction via a Weighted Ensemble Model: A Large-Scale Study with SHAP and Surrogate Decision Trees</h3>
<p><strong>Authors:</strong> Md Abrar Hasnat, Md Jobayer, Md. Mehedi Hasan Shawon, Md. Golam Rabiul Alam</p>
<p><strong>Published:</strong> 2025-11-05</p>
<p><strong>Reason:</strong> 结合SHAP值与代理决策树，为心脏病预测模型提供可解释性，虽然应用于医疗，但核心验证了Shapley值在可解释性中的有效性，对深度学习可解释性中的Shapley value研究有支持作用。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.01947' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>