# ArXiv 每日推荐 - 2025-11-06

> 更新于北京时间：2025-11-06 12:28:40
> 已自动阅读了 236 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：120006

## 深度学习理论

### [Score: 9.0/10] Adam Reduces a Unique Form of Sharpness: Theoretical Insights Near the Minimizer Manifold
- **Authors:** Xinghan Li, Haodong Wen, Kaifeng Lyu
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02773](https://arxiv.org/abs/2511.02773)
- **Reason:** 理论分析了Adam优化器在极小值流形附近对独特锐度（$\tr(\Diag(\mH)^{1/2})$）的减少作用，区别于SGD的锐度度量（$\tr(\mH)$），通过随机微分方程的连续时间近似刻画其行为，并在带标签噪声的过参数化模型、稀疏线性回归任务上验证了理论结论，推进了优化器的理论理解。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] The Geometry of Grokking: Norm Minimization on the Zero-Loss Manifold
- **Authors:** Tiberiu Musat
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01938](https://arxiv.org/abs/2511.01938)
- **Reason:** 揭示Grokking现象的几何本质（零损失流形上的范数最小化），通过两层网络验证理论，对深度学习理论中的训练动力学研究有重要理论贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] EchoLSTM: A Self-Reflective Recurrent Network for Stabilizing Long-Range Memory
- **Authors:** Prasanth K K, Shubham Sharma
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01950](https://arxiv.org/abs/2511.01950)
- **Reason:** 提出Output-Conditioned Gating机制增强LSTM的长程记忆，通过注意力机制实现自反思，在Distractor Signal Task与ListOps上显著优于标准LSTM，对深度学习理论中的network architecture设计有改进。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Bulk-boundary decomposition of neural networks
- **Authors:** Donghee Lee, Hye-Sung Lee, Jaeok Yi
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02003](https://arxiv.org/abs/2511.02003)
- **Reason:** 将神经网络的Lagrangian分解为数据无关的体项与数据相关的边界项，建立场论框架解释训练动态，对深度学习理论中的训练过程分析有理论贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Shared Parameter Subspaces and Cross-Task Linearity in Emergently Misaligned Behavior
- **Authors:** Daniel Aarao Reis Arturi, Eric Zhang, Andrew Ansah, Kevin Zhu, Ashwinee Panda, Aishwarya Balwani
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02022](https://arxiv.org/abs/2511.02022)
- **Reason:** 从几何视角分析emergent misalignment的参数空间结构，发现跨任务的线性共享子空间，对深度学习理论中的参数空间研究有重要发现。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Path-Coordinated Continual Learning with Neural Tangent Kernel-Justified Plasticity: A Theoretical Framework with Near State-of-the-Art Performance
- **Authors:** Rathin Chandra Shit
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02025](https://arxiv.org/abs/2511.02025)
- **Reason:** 结合神经切线核（NTK）理论设计持续学习的塑性边界，提出路径协调框架，在Split-CIFAR10上实现近SOTA性能，对深度学习理论中的持续学习有理论与实践贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Natural Building Blocks for Structured World Models: Theory, Evidence, and Scaling
- **Authors:** Lancelot Da Costa, Sanjeev Namjoshi, Mohammed Abbas Ansari, Bernhard Schölkopf
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02091](https://arxiv.org/abs/2511.02091)
- **Reason:** 提出以HMM和sLDS为自然构建块的结构化世界模型框架，支持分层组合与生成/控制任务，对深度学习理论中的world model研究有理论贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster Decode Without Retraining
- **Authors:** Costin-Andrei Oncescu, Qingyang Wu, Wai Tong Chung, Robert Wu, Bryan Gopal, Junxiong Wang, Tri Dao, Ben Athiwaratkun
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02237](https://arxiv.org/abs/2511.02237)
- **Reason:** 针对MoE模型提出batch-aware专家路由方法，优化解码速度，属于深度学习理论中的网络架构（MoE）研究，符合用户方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization Error
- **Authors:** Fengjuan Wang, Zhiyi Su, Xingzhu Hu, Cheng Wang, Mou Sun
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02302](https://arxiv.org/abs/2511.02302)
- **Reason:** 提出无转换的FP8训练方案用于MoE模型，解决量化误差问题，属于深度学习理论中的网络架构（MoE）与低精度优化研究，符合用户方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free Finetuning of Large Language Models
- **Authors:** Lejs Deen Behric, Liang Zhang, Bingcong Li, Kiran Koshy Thekumparampil
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02757](https://arxiv.org/abs/2511.02757)
- **Reason:** 针对梯度-free的LLM微调场景提出ConMeZO优化器，通过自适应方向采样（限制在动量估计的锥内）改进MeZO的收敛速度，提供了最坏情况收敛率的理论证明，并在自然语言任务上验证了比MeZO快2倍的效果，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] STAR-VAE: Latent Variable Transformers for Scalable and Controllable Molecular Generation
- **Authors:** Bum Chul Kwon, Ben Shapira, Moshiko Raboh, Shreyans Sethi, Shruti Murarka, Joseph A Morrone, Jianying Hu, Parthasarathy Suryanarayanan
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02769](https://arxiv.org/abs/2511.02769)
- **Reason:** 提出基于Transformer的VAE框架STAR-VAE，采用SELFIES编码保证分子语法有效性，支持属性引导的条件生成（通过 property predictor提供条件信号），并通过LoRA进行参数高效微调，在GuacaMol和MOSES基准上表现优异，属于深度学习理论中的VAE研究，且具有实际应用价值。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] On the Emergence of Induction Heads for In-Context Learning
- **Authors:** Tiberiu Musat, Tiago Pimentel, Lorenzo Noci, Alessandro Stolfo, Mrinmaya Sachan, Thomas Hofmann
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01033](https://arxiv.org/abs/2511.01033)
- **Reason:** 研究了Transformer中induction heads的涌现机制，通过最小化ICL任务和修改后的Transformer架构，解释了其权重矩阵的结构，证明训练动态受限于19维子空间（仅3维主导涌现），并分析了涌现时间与上下文长度的二次关系，推进了网络架构中induction heads的理论理解。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations
- **Authors:** Shichao Fan, Kun Wu, Zhengping Che, Xinhua Wang, Di Wu, Fei Liao, Ning Liu, Yixue Zhang, Zhen Zhao, Zhiyuan Xu, Meng Li, Qingjie Liu, Shanghang Zhang, Min Wan, Jian Tang
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02776](https://arxiv.org/abs/2511.02776)
- **Reason:** 论文提出双分支VQ-VAE学习统一视觉-运动表示（UVMC），VQ-VAE是您深度学习理论方向的重点内容之一，且结合多模态视觉-语言-动作模型，兼具理论创新与多模态应用价值
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Superpositional Gradient Descent: Harnessing Quantum Principles for Model Training
- **Authors:** Ahmet Erdem Pamuk, Emir Kaan Özdemir, Şuayp Talha Kocabay
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01918](https://arxiv.org/abs/2511.01918)
- **Reason:** 提出结合量子叠加原理的优化器SGD，通过量子电路扰动改进模型训练，在序列分类与LLM微调上优于AdamW，对深度学习理论中的optimizer设计有创新性探索。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Beyond Static Cutoffs: One-Shot Dynamic Thresholding for Diffusion Language Models
- **Authors:** Jucheng Shen, Yeonju Ro
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02077](https://arxiv.org/abs/2511.02077)
- **Reason:** 提出One-Shot Dynamic Thresholding（OSDT）优化扩散语言模型的推理，通过单序列校准阈值提升解码效率与准确性，对深度学习理论中的生成模型推理优化有贡献。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization Landscape
- **Authors:** Xinyuan Song, Jiaye Teng, Ziye Ma
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02122](https://arxiv.org/abs/2511.02122)
- **Reason:** 研究矩阵感知中核最优损失的鲁棒性与优化景观，涉及深度学习理论中的损失函数设计与优化稳定性，与用户关注的深度学习理论高度相关。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Neural network initialization with nonlinear characteristics and information on spectral bias
- **Authors:** Hikaru Homma, Jun Ohkubo
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02244](https://arxiv.org/abs/2511.02244)
- **Reason:** 研究神经网络初始化与谱偏差的关系，提出利用谱偏差信息优化初始化策略，属于深度学习理论中的初始化与谱偏差研究，符合用户方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Gradient-Variation Online Adaptivity for Accelerated Optimization with Hölder Smoothness
- **Authors:** Yuheng Zhao, Yu-Hu Yan, Kfir Yehuda Levy, Peng Zhao
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02276](https://arxiv.org/abs/2511.02276)
- **Reason:** 针对Hölder光滑函数的在线优化提出梯度变化自适应方法，属于深度学习理论中的优化算法研究，符合用户方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] RoME: Domain-Robust Mixture-of-Experts for MILP Solution Prediction across Domains
- **Authors:** Tianle Pu, Zijie Geng, Haoyang Liu, Shixuan Liu, Jie Wang, Li Zeng, Chao Chen, Changjun Fan
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02331](https://arxiv.org/abs/2511.02331)
- **Reason:** 提出域鲁棒的MoE模型用于跨域MILP解预测，属于深度学习理论中的网络架构（MoE）与泛化研究，符合用户方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Variational Geometric Information Bottleneck: Learning the Shape of Understanding
- **Authors:** Ronald Katende
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02496](https://arxiv.org/abs/2511.02496)
- **Reason:** 提出几何信息瓶颈框架，结合互信息压缩与几何正则化，属于深度学习理论中的表示学习研究，符合用户方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] A Non-Adversarial Approach to Idempotent Generative Modelling
- **Authors:** Mohammed Al-Jaff, Giovanni Luca Marchetti, Michael C Welle, Jens Lundell, Mats G. Gustafsson, Gustav Eje Henter, Hossein Azizpour, Danica Kragic
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02614](https://arxiv.org/abs/2511.02614)
- **Reason:** 提出非对抗性幂等生成模型，解决生成模型的模式崩溃问题，属于深度学习理论中的生成模型研究，符合用户方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Nesterov-Accelerated Robust Federated Learning Over Byzantine Adversaries
- **Authors:** Lihan Xu, Yanjie Dong, Gang Wang, Runhao Zeng, Xiaoyi Fan, Xiping Hu
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02657](https://arxiv.org/abs/2511.02657)
- **Reason:** 提出拜占庭鲁棒的Nesterov加速联邦学习算法，属于深度学习理论中的优化算法（Nesterov加速）与联邦学习研究，符合用户方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Scalable Evaluation and Neural Models for Compositional Generalization
- **Authors:** Giacomo Camposampiero, Pietro Barbiero, Michael Hersche, Roger Wattenhofer, Abbas Rahimi
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02667](https://arxiv.org/abs/2511.02667)
- **Reason:** 研究组合泛化的可扩展评估与神经模型，属于深度学习理论中的泛化研究，符合用户方向。
Score: 7
Field: 深度学习理论

### [Score: 6.0/10] CFL: On the Use of Characteristic Function Loss for Domain Alignment in Machine Learning
- **Authors:** Abdullah Almansour, Ozan Tonguz
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02148](https://arxiv.org/abs/2511.02148)
- **Reason:** 提出特征函数损失用于域对齐，解决分布偏移问题，属于深度学习理论中的域适应与表示学习研究，符合用户方向。
Score: 6
Field: 深度学习理论

### [Score: 6.0/10] Improving Unlearning with Model Updates Probably Aligned with Gradients
- **Authors:** Virgile Dine, Teddy Furon, Charly Faure
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02435](https://arxiv.org/abs/2511.02435)
- **Reason:** 研究模型遗忘中的梯度对齐更新，属于深度学习理论中的模型优化与更新研究，符合用户方向。
Score: 6
Field: 深度学习理论

## 多模态大模型

### [Score: 8.0/10] iFlyBot-VLA Technical Report
- **Authors:** Yuan Zhang, Chenyu Xue, Wenjie Xu, Chao Ji, Jiajia wu, Jia Pan
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01914](https://arxiv.org/abs/2511.01914)
- **Reason:** 提出大尺度Vision-Language-Action（VLA）模型iFlyBot-VLA，创新 latent action model、双层次动作表征框架及混合训练策略，实现视觉、语言与动作模态的对齐，实验在LIBERO Franka基准和真实场景中验证了优越性，对多模态大模型的动作感知与跨模态融合研究有重要价值。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning
- **Authors:** Fangxun Shu, Yongjie Ye, Yue Liao, Zijian Kang, Weijie Yin, Jiacong Wang, Xiao Liang, Shuicheng Yan, Chao Feng
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02280](https://arxiv.org/abs/2511.02280)
- **Reason:** 提出双奖励强化学习框架SAIL-RL，通过Thinking Reward（推理质量）和Judging Reward（推理策略适配）优化多模态大语言模型（MLLMs）的推理能力，减少幻觉并提升适应性，实验在SAIL-VL2上实现与GPT-4o竞争的性能，对MLLMs的可靠推理研究有重要价值。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Can Visual Input Be Compressed? A Visual Token Compression Benchmark for Large Multimodal Models
- **Authors:** Tianfan Peng, Yuntao Du, Pengzhou Ji, Shijie Dong, Kailin Jiang, Mingchuan Ma, Yijun Tian, Jinhe Bi, Qian Li, Wei Du, Feng Xiao, Lizhen Cui
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02650](https://arxiv.org/abs/2511.02650)
- **Reason:** 针对多模态大模型的视觉token冗余问题，提出UniPruneBench基准，系统评估视觉token压缩算法的有效性，涉及多模态大模型中的tokenizer优化，对提升模型效率有重要价值。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Differentiable Hierarchical Visual Tokenization
- **Authors:** Marius Aasan, Martine Hjelkrem-Tan, Nico Catalano, Changkyu Choi, Adín Ramírez Rivera
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02652](https://arxiv.org/abs/2511.02652)
- **Reason:** 提出可微分分层视觉tokenizer，解决ViT固定patch忽略图像结构的问题，支持预训练模型的retrofitting，对多模态大模型的tokenization方法有创新性贡献。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation
- **Authors:** Kevin Qinghong Lin, Yuhao Zheng, Hangyu Ran, Dantong Zhu, Dongxing Mao, Linjie Li, Philip Torr, Alex Jinpeng Wang
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02778](https://arxiv.org/abs/2511.02778)
- **Reason:** 提出将多模态理解重构为SVG代码生成任务，构建VCode基准评估VLMs的视觉编码能力，对多模态大模型中的visual-centric coding研究有重要推动作用。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] When Visualizing is the First Step to Reasoning: MIRA, a Benchmark for Visual Chain-of-Thought
- **Authors:** Yiyang Zhou, Haoqin Tu, Zijun Wang, Zeyu Wang, Niklas Muennighoff, Fan Nie, Yejin Choi, James Zou, Chaorui Deng, Shen Yan, Haoqi Fan, Cihang Xie, Huaxiu Yao, Qinghao Ye
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02779](https://arxiv.org/abs/2511.02779)
- **Reason:** 提出需要生成中间视觉图像的推理基准MIRA，评估多模态大模型的视觉链式思考能力，对多模态大模型的image understanding与reasoning研究有重要价值。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment
- **Authors:** Rohan Wandre, Yash Gajewar, Namrata Patel, Vivek Dhalkari
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02371](https://arxiv.org/abs/2511.02371)
- **Reason:** 提出多模态RAG架构LUMA-RAG，解决多模态流数据的对齐与记忆管理问题，属于多模态大模型研究，符合用户方向。
Score: 8
Field: 多模态大模型

### [Score: 7.0/10] Pinpointing Trigger Moment for Grounded Video QA: Enhancing Spatio-temporal Grounding in Multimodal Large Language Models
- **Authors:** Jinhwan Seo, Yoonki Cho, Junhyug Noh, Sung-eui Yoon
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02182](https://arxiv.org/abs/2511.02182)
- **Reason:** 针对多模态大语言模型的Grounded Video QA任务，提出三阶段 pipeline 及CORTEX prompt定位触发时刻，实现更准确的时空接地与跟踪，HOTA分数（0.4968）显著超过去年冠军（0.2704），对多模态大模型的视频QA时空推理研究有推动作用。
Score: 7
Field: 多模态大模型

### [Score: 7.0/10] CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space Reasoning
- **Authors:** Jizheng Ma, Xiaofei Zhou, Yanlong Song, Han Yan
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02360](https://arxiv.org/abs/2511.02360)
- **Reason:** 提出CoCoVa框架，通过Latent Q-Former和多任务训练实现视觉语言模型的连续潜空间推理，解决离散语言与连续视觉的表征鸿沟，实验显示1.5B模型性能超过7B-9B模型，提升准确性与token效率，对多模态大模型的潜空间理解研究有创新贡献。
Score: 7
Field: 多模态大模型

### [Score: 7.0/10] ChartM$^3$: A Multi-Stage Code-Driven Pipeline for Constructing Multi-Dimensional and Multi-Step Visual Reasoning Data in Chart Comprehension
- **Authors:** Duo Xu, Hao Cheng, Xin Lin, Zhen Xie, Hao Wang
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02415](https://arxiv.org/abs/2511.02415)
- **Reason:** 提出多阶段代码驱动 pipeline 构建ChartM³数据集，针对多模态大模型的复杂图表推理需求，生成多维度、多步骤的视觉推理数据，实验验证数据集能提升模型推理能力与跨域泛化，对MLLMs的图表理解研究有重要支撑作用。
Score: 7
Field: 多模态大模型

### [Score: 7.0/10] TAUE: Training-free Noise Transplant and Cultivation Diffusion Model
- **Authors:** Daichi Nagai, Ryugo Morita, Shunsuke Kitada, Hitoshi Iyatomi
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02580](https://arxiv.org/abs/2511.02580)
- **Reason:** 提出训练-free的噪声移植与培育扩散模型TAUE，解决text-to-image模型的layer-wise控制难题，实现多图层语义与结构一致生成，性能接近fine-tuned方法，对多模态大模型的图像生成可控性研究有实用价值。
Score: 7
Field: 多模态大模型

### [Score: 7.0/10] PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing
- **Authors:** Antonio Oroz, Matthias Nießner, Tobias Kirschstein
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02777](https://arxiv.org/abs/2511.02777)
- **Reason:** 提出结合感知监督的3D头部重建模型，支持通过互动GUI进行几何雕刻和外观风格化（自然语言/图像提示），符合多模态大模型中的GUI Grounding与image generation方向。
Score: 7
Field: 多模态大模型

## 深度学习可解释性

### [Score: 8.0/10] LLEXICORP: End-user Explainability of Convolutional Neural Networks
- **Authors:** Vojtěch Kůr, Adam Bajger, Adam Kukučka, Marek Hradil, Vít Musil, Tomáš Brazdil
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02720](https://arxiv.org/abs/2511.02720)
- **Reason:** 结合概念相关性传播（CRP）与多模态大语言模型，自动生成CNN的概念解释和自然语言说明，提升CNN的可解释性，对深度学习可解释性中的white-box explanation有重要应用。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Deciphering Personalization: Towards Fine-Grained Explainability in Natural Language for Personalized Image Generation Models
- **Authors:** Haoming Wang, Wei Gao
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01932](https://arxiv.org/abs/2511.01932)
- **Reason:** 提出FineXL技术，针对个性化图像生成提供细粒度的自然语言解释与量化评分，提升生成模型的可解释性，对深度学习可解释性中的white-box explanation有贡献。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Regularization Through Reasoning: Systematic Improvements in Language Model Classification via Explanation-Enhanced Fine-Tuning
- **Authors:** Vivswan Shah, Randy Cogill, Hanwei Yue, Gopinath Chennupati, Rinat Khaziev
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02044](https://arxiv.org/abs/2511.02044)
- **Reason:** 提出通过解释增强的微调将推理与正则化结合，减少模型过拟合并提升可解释性，揭示解释的结构而非语义是性能提升的关键，对深度学习可解释性与正则化的关联研究有贡献。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] LLM Probing with Contrastive Eigenproblems: Improving Understanding and Applicability of CCS
- **Authors:** Stefan F. Schouten, Peter Bloem
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02089](https://arxiv.org/abs/2511.02089)
- **Reason:** 将Contrast-Consistent Search（CCS）重构为特征问题，解决初始化敏感问题，提升LLM探测的稳定性与可解释性，对深度学习可解释性中的mechanistic interpretability有帮助。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Geometric Data Valuation via Leverage Scores
- **Authors:** Rodrigo Mendoza-Smith
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02100](https://arxiv.org/abs/2511.02100)
- **Reason:** 提出用杠杆分数替代Shapley值进行几何数据 valuation，解决Shapley值的计算难题，证明其满足Shapley公理且能保证下游模型性能，对深度学习可解释性中的数据 valuation研究有重要贡献。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] ProtoTSNet: Interpretable Multivariate Time Series Classification With Prototypical Parts
- **Authors:** Bartłomiej Małkus, Szymon Bobek, Grzegorz J. Nalepa
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.02152](https://arxiv.org/abs/2511.02152)
- **Reason:** 提出基于原型部分的可解释多变量时间序列分类模型，通过改进ProtoPNet架构实现ante-hoc可解释性，符合用户关注的深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] llmSHAP: A Principled Approach to LLM Explainability
- **Authors:** Filip Naudot, Tobias Sundqvist, Timotheus Kampik
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01311](https://arxiv.org/abs/2511.01311)
- **Reason:** 论文将Shapley value应用于LLM的特征归因，聚焦LLM推理的可解释性问题，直接对应您关注的深度学习可解释性中的Shapley value核心方向，理论性强且针对LLM场景有实际意义
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Interpretable Heart Disease Prediction via a Weighted Ensemble Model: A Large-Scale Study with SHAP and Surrogate Decision Trees
- **Authors:** Md Abrar Hasnat, Md Jobayer, Md. Mehedi Hasan Shawon, Md. Golam Rabiul Alam
- **Published:** 2025-11-05
- **Link:** [https://arxiv.org/abs/2511.01947](https://arxiv.org/abs/2511.01947)
- **Reason:** 结合SHAP值与代理决策树，为心脏病预测模型提供可解释性，虽然应用于医疗，但核心验证了Shapley值在可解释性中的有效性，对深度学习可解释性中的Shapley value研究有支持作用。
Score: 7
Field: 深度学习可解释性

