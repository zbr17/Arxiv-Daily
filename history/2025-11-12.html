<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-12</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>深度学习可解释性</a>
<a href='#' >自动驾驶与大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >多模态大模型</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-12</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-12 12:38:24</p>
<p>已自动阅读了 499 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：257996</p>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Causal Tracing of Object Representations in Large Vision Language Models: Mechanistic Interpretability and Hallucination Mitigation</h3>
<p><strong>Authors:</strong> Qiming Li, Zekai Ye, Xiaocheng Feng, Weihong Zhong, Weitao Ma, Xiachong Feng</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出FCCT框架，因果追踪LVLM中的对象表示，量化视觉感知的因果效应，显著改进可解释性和幻觉问题，属于深度学习可解释性的核心方向。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.05923' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond Softmax: Dual-Branch Sigmoid Architecture for Accurate Class Activation Maps</h3>
<p><strong>Authors:</strong> Yoojin Oh, Junhyug Noh</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出双分支sigmoid头改进Class Activation Maps，解决softmax导致的logit偏移和符号坍塌问题，显著提升解释 fidelity，属于深度学习可解释性的核心方法创新。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.05590' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Flexible Concept Bottleneck Model</h3>
<p><strong>Authors:</strong> Xingbo Du, Qiantong Dou, Lei Fan, Rui Zhang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出灵活概念瓶颈模型（FCBM），支持动态概念替换与适配，属于深度学习可解释性方向，提升了概念瓶颈模型的适应性与可解释性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.06678' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Attribution to Action: Jointly ALIGNing Predictions and Explanations</h3>
<p><strong>Authors:</strong> Dongsheng Hong, Chao Chen, Yanhui Chen, Shanshan Lin, Zhihao Chen, Xiangwen Liao</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出ALIGN框架联合训练分类器与掩码器，对齐模型预测与解释，提升可解释性（充分性与全面性）及泛化性，属于深度学习可解释性方向
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.06944' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond Redundancy: Diverse and Specialized Multi-Expert Sparse Autoencoder</h3>
<p><strong>Authors:</strong> Zhen Xu, Zhen Tan, Song Wang, Kaidi Xu, Tianlong Chen</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对稀疏自动编码器（SAE）在LLM解释中存在的专家冗余问题，提出多专家SAE框架，提升解释性与计算效率，对深度学习可解释性中的SAE应用有重要贡献
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.05745' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Approximating Shapley Explanations in Reinforcement Learning</h3>
<p><strong>Authors:</strong> Daniel Beechey, Özgur Şimşek</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对RL中Shapley值解释的高计算成本问题，提出FastSVERL方法，解决时间依赖与off-policy数据挑战，对深度学习可解释性中的Shapley值应用有关键推进
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.06094' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TriShGAN: Enhancing Sparsity and Robustness in Multivariate Time Series Counterfactuals Explanation</h3>
<p><strong>Authors:</strong> Hongnan Ma, Yiwei Shi, Guanxiong Sun, Mengyue Yang, Weiru Liu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出TriShGAN框架，结合triplet loss和Shapelet Extractor，提升多变量时间序列反事实解释的稀疏性和鲁棒性，对深度学习可解释性中的反事实解释方向有重要贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.06529' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rank-1 LoRAs Encode Interpretable Reasoning Signals</h3>
<p><strong>Authors:</strong> Jake Ward, Paul Riechers, Adam Shai</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 研究Rank-1 LoRA对推理模型的可解释性贡献，发现其激活可对应推理特定行为，通过稀疏自动编码器识别细粒度单语义特征，为深度学习可解释性中模型推理机制的解析提供了新视角与实证支持。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.06739' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Robust Nearest Neighbour Retrieval Using Targeted Manifold Manipulation</h3>
<p><strong>Authors:</strong> B. Ghosh, H. Harikumar, S. Rana</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 基于流形操纵重新定义 nearest neighbour 检索，通过触发补丁引导特征空间扰动，提升可解释AI pipeline的鲁棒性，属于深度学习可解释性研究
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.06261' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> REOcc: Camera-Radar Fusion with Radar Feature Enrichment for 3D Occupancy Prediction</h3>
<p><strong>Authors:</strong> Chaehee Song, Sanmin Kim, Hyeonjun Jeong, Juyeb Shin, Joonhee Lim, Dongsuk Kum</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出雷达特征增强的camera-radar融合方法用于3D occupancy prediction，属于自动驾驶与大模型方向，提升了复杂环境下的occupancy预测精度。
Score: 9
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.06666' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> PlanT 2.0: Exposing Biases and Structural Flaws in Closed-Loop Driving</h3>
<p><strong>Authors:</strong> Simon Gerstenecker, Andreas Geiger, Katrin Renz</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 系统分析自动驾驶模型的偏差与缺陷，提出改进的PlanT 2.0并在CARLA上取得SOTA，推动了自动驾驶的data-centric开发与模型鲁棒性提升
Score: 9
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.07292' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Token Is All You Need: Cognitive Planning through Sparse Intent Alignment</h3>
<p><strong>Authors:</strong> Shiyao Sang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于稀疏意图对齐的认知规划方法，挑战自动驾驶中 exhaustive scene modeling 的传统假设，使用感知增强的BEV表示在nuPlan、nuScenes基准上验证，显著提升规划性能，针对自动驾驶与大模型的核心问题。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.05540' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AdaDrive: Self-Adaptive Slow-Fast System for Language-Grounded Autonomous Driving</h3>
<p><strong>Authors:</strong> Ruifei Zhang, Junlin Xie, Wei Zhang, Weikai Chen, Xiao Tan, Xiang Wan, Guanbin Li</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出自适应慢快框架，动态决策LLM调用时机与影响权重，提升语言引导自动驾驶的决策效率与准确性，属于自动驾驶与大模型研究
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.06253' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VLDrive: Vision-Augmented Lightweight MLLMs for Efficient Language-grounded Autonomous Driving</h3>
<p><strong>Authors:</strong> Ruifei Zhang, Wei Zhang, Xiao Tan, Sibei Yang, Xiang Wan, Xiaonan Luo, Guanbin Li</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 构建视觉增强的轻量级多模态大模型，优化视觉token生成与跨模态注意力，提升语言引导自动驾驶的效率，属于自动驾驶与大模型研究
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.06256' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LaneDiffusion: Improving Centerline Graph Learning via Prior Injected BEV Feature Generation</h3>
<p><strong>Authors:</strong> Zijie Wang, Weiming Zhang, Wei Zhang, Xiao Tan, Hongxing Liu, Yaowei Wang, Guanbin Li</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 利用扩散模型生成BEV特征先验，优化车道中心线图的空间推理与遮挡鲁棒性，属于自动驾驶与大模型中的车道感知研究
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.06272' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HENet++: Hybrid Encoding and Multi-task Learning for 3D Perception and End-to-end Autonomous Driving</h3>
<p><strong>Authors:</strong> Zhongyu Xia, Zhiwei Lin, Yongtao Wang, Ming-Hsuan Yang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出混合编码与多任务学习框架，提升3D感知（包括occupancy prediction）与端到端自动驾驶性能，在nuScenes基准上取得最优结果，属于自动驾驶与大模型方向
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.07106' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Dual-branch Spatial-Temporal Self-supervised Representation for Enhanced Road Network Learning</h3>
<p><strong>Authors:</strong> Qinghong Guo, Yu Wang, Ji Cao, Tongya Zheng, Junshu Dai, Bingde Hu, Shunyu Liu, Canghong Jin</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出DST双分支自监督框架，结合空间（图卷积、超图对比）和时间（因果Transformer的下一个token预测）模态，提升道路网络表示学习，对自动驾驶与大模型中的道路网络相关任务（如occupancy prediction）有重要支撑。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.06633' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Low-Rank Method for Vision Language Model Hallucination Mitigation in Autonomous Driving</h3>
<p><strong>Authors:</strong> Keke Long, Jiacheng Guo, Tianyun Zhang, Hongkai Yu, Xiaopeng Li</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对自动驾驶中视觉语言模型的幻觉问题，提出低秩方法优化候选caption排序，提升场景理解的准确性和实时性，对自动驾驶的可靠性有重要价值
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.06496' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Compressing Multi-Task Model for Autonomous Driving via Pruning and Knowledge Distillation</h3>
<p><strong>Authors:</strong> Jiayuan Wang, Q. M. Jonathan Wu, Ning Zhang, Katsuya Suto, Lei Zhong</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出结合任务感知安全剪枝与特征级知识蒸馏的多任务自动驾驶模型压缩框架，在BDD100K基准上实现参数减少32.7%且性能损失小，解决自动驾驶模型部署的关键问题。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.05557' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Polymap: generating high definition map based on rasterized polygons</h3>
<p><strong>Authors:</strong> Shiyu Gao, Hao Jiang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 以光栅化多边形重新诠释道路元素，通过实例分割框架生成高清地图，提升自动驾驶环境感知的泛化性，属于自动驾驶与大模型研究
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.05944' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation</h3>
<p><strong>Authors:</strong> Seungheon Song, Jaekoo Lee</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对自动驾驶中的OOD分割问题，提出结合视觉-语言模型的方法，通过语义增强提升模型对未见过物体的泛化能力，直接服务于自动驾驶系统的安全性与可靠性。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.07238' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion</h3>
<p><strong>Authors:</strong> June Moh Goo, Zichao Zeng, Jan Boehm</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出频率感知的LiDAR超分辨率框架，通过时空域融合提升低分辨率LiDAR的3D感知质量，直接服务于自动驾驶的环境感知任务。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.07377' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Multi-Agent AI Framework for Road Situation Detection and C-ITS Message Generation</h3>
<p><strong>Authors:</strong> Kailin Tong, Selim Solmaz, Kenan Mujkic, Gottfried Allmer, Bo Leng</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 结合多模态大语言模型与视觉感知构建路况检测框架，提升了C-ITS消息生成的准确性，对自动驾驶的智能交通系统有实践意义
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.06892' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Next-Latent Prediction Transformers Learn Compact World Models</h3>
<p><strong>Authors:</strong> Jayden Teoh, Manan Tomar, Kwangjun Ahn, Edward S. Hu, Pratyusha Sharma, Riashat Islam, Alex Lamb, John Langford</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对Transformer缺乏紧凑世界模型的问题，提出NextLat辅助目标，理论证明latents收敛到信念状态，实证提升序列建模与泛化能力，对深度学习理论中的Transformer表示学习有突破
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05963' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Convolutional Fully-Connected Capsule Network (CFC-CapsNet): A Novel and Fast Capsule Network</h3>
<p><strong>Authors:</strong> Pouya Shiri, Amirali Baniasadi</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出CFC-CapsNet改进传统CapsNet的网络结构，用CFC层生成更有效的胶囊，在CIFAR-10等数据集上提升accuracy和速度，属于深度学习理论的网络架构创新。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05617' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hilbert-Guided Block-Sparse Local Attention</h3>
<p><strong>Authors:</strong> Yunge Li, Lanyu Xu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 用Hilbert曲线改进局部注意力的block稀疏性，显著提升窗口注意力和滑动注意力的效率，属于深度学习理论的注意力机制创新。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05832' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Enhancing Diffusion Model Guidance through Calibration and Regularization</h3>
<p><strong>Authors:</strong> Seyed Alireza Javid, Amirhossein Bagheri, Nuria Gonz\'alez-Prelcic</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于Smooth ECE的校准目标和 divergence-regularized 采样方法，改进classifier-guided diffusion的FID，属于深度学习理论的扩散模型训练创新。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05844' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CoMA: Complementary Masking and Hierarchical Dynamic Multi-Window Self-Attention in a Unified Pre-training Framework</h3>
<p><strong>Authors:</strong> Jiaxuan Li, Qing Xu, Xiangjian He, Ziyu Liu, Chang Xing, Zhen Chen, Daokun Zhang, Rong Qu, Chang Wen Chen</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对Masked Autoencoders和ViT的局限性，提出互补掩码策略与分层动态多窗口自注意力机制，优化预训练效率与下游性能，属于深度学习理论中的网络架构研究
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05929' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Lookahead Unmasking Elicits Accurate Decoding in Diffusion Language Models</h3>
<p><strong>Authors:</strong> Sanghyun Lee, Seungryong Kim, Jongho Park, Dongmin Park</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出Lookahead Unmasking方法优化扩散语言模型的解码顺序，通过路径选择避免短视错误与传播，提升数学、编码等任务的性能，属于深度学习理论中的扩散模型与语言解码方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05563' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Depth-induced NTK: Bridging Over-parameterized Neural Networks and Deep Neural Kernels</h3>
<p><strong>Authors:</strong> Yong-Ming Tian, Shuang Liang, Shao-Qun Zhang, Feng-Lei Fan</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出深度诱导的神经 tangent kernel，连接过参数化网络与深度神经核，分析其训练不变性与谱特性，属于深度学习理论中的神经核与网络深度方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05585' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unveiling the Training Dynamics of ReLU Networks through a Linear Lens</h3>
<p><strong>Authors:</strong> Longqing Ye</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出将ReLU网络重铸为输入依赖的线性模型，通过有效权重的演变分析训练动态与类特异性表示形成，属于深度学习理论中的网络训练与表示学习方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05628' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Scaling Laws and In-Context Learning: A Unified Theoretical Framework</h3>
<p><strong>Authors:</strong> Sushant Mehta, Ishan Gupta</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出了缩放定律与Transformer中上下文学习（ICL）的统一理论框架，分析了模型深度、宽度、上下文长度等因素与ICL性能的幂律关系，提供了ICL涌现的必要充分条件，对深度学习理论的发展有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06232' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Mixtures of SubExperts for Large Language Continual Learning</h3>
<p><strong>Authors:</strong> Haeyong Kang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对大语言模型持续学习中的遗忘与参数膨胀问题，提出混合子专家（MoSEs）架构，结合稀疏混合专家与任务路由机制，实现知识保留与高效缩放，对深度学习理论中的网络架构优化有重要意义。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06237' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Transolver is a Linear Transformer: Revisiting Physics-Attention through the Lens of Linear Attention</h3>
<p><strong>Authors:</strong> Wenjie Hu, Sidun Liu, Peng Qiao, Zhenglun Sun, Yong Dou</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 重新审视Transolver的Physics-Attention机制，发现其为线性注意力的特例，提出LinearNO架构，在PDE基准上实现更优性能与更少参数，对Transformer网络架构的理论与应用有重要推进。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06294' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Vocabulary In-Context Learning in Transformers: Benefits of Positional Encoding</h3>
<p><strong>Authors:</strong> Qian Ma, Ruoxiang Xu, Yongqiang Cai</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 从近似理论角度分析位置编码对Transformer词汇级上下文学习（VICL）的作用，证明位置编码是VICL具备通用近似性的关键，对Transformer的理论理解有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06376' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FLEX: Continuous Agent Evolution via Forward Learning from Experience</h3>
<p><strong>Authors:</strong> Zhicheng Cai, Xinyuan Guo, Yu Pei, JiangTao Feng, Jiangjie Chen, Ya-Qin Zhang, Wei-Ying Ma, Mingxuan Wang, Hao Zhou</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出梯度-free的FLEX框架，通过结构化经验库和持续反射实现LLM代理的持续进化，提升数学推理、化学合成等任务性能，对深度学习理论中的持续学习方向有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06449' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DyKAF: Dynamical Kronecker Approximation of the Fisher Information Matrix for Gradient Preconditioning</h3>
<p><strong>Authors:</strong> Nikolay Yudin, Ekaterina Grishina, Andrey Veprikov, Alexandr Beznosikov, Maxim Rakhuba</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出DyKAF优化器，用Kronecker近似Fisher矩阵作为梯度预条件，提升LLM预训练与微调的性能，对深度学习理论中的优化器设计有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06477' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Route Experts by Sequence, not by Token</h3>
<p><strong>Authors:</strong> Tiansheng Wen, Yifei Wang, Aosong Feng, Long Ma, Xinyang Liu, Yifan Wang, Lixuan Guo, Bo Chen, Stefanie Jegelka, Chenyu You</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出SeqTopK路由策略，将MoE的专家分配从token级转为序列级，动态分配专家提升性能，对深度学习理论中的MoE网络架构优化有重要推进。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06494' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Optimistic Online-to-Batch Conversions for Accelerated Convergence and Universality</h3>
<p><strong>Authors:</strong> Yu-Hu Yan, Peng Zhao, Zhi-Hua Zhou</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出乐观在线到批量转换方法，结合NAG实现加速收敛与通用性，从在线学习角度解析NAG的优化机制，对深度学习理论中的优化算法理论有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06597' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Minimum Width of Deep Narrow Networks for Universal Approximation</h3>
<p><strong>Authors:</strong> Xiao-Song Yang, Qi Zhou, Xuan Zhou</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 研究深度窄网络实现通用逼近的最小宽度，针对ELU、LeakyReLU等激活函数给出上下界，通过几何方法与Poincaré-Miranda定理证明，对深度学习理论中网络架构的最小化设计有严格理论指导。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06837' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning</h3>
<p><strong>Authors:</strong> Lan Thi Ha Nguyen, Kien Ton Manh, Anh Do Duc, Nam Pham Hai</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出融合物理约束的增强型VAE，解决自监督强化学习中目标生成的物理一致性问题，属于深度学习理论中VAE方向的重要改进
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06745' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Latent Refinement via Flow Matching for Training-free Linear Inverse Problem Solving</h3>
<p><strong>Authors:</strong> Hossein Askari, Yadan Luo, Hongfu Sun, Fred Roosta</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 利用流匹配在潜在空间解决线性逆问题，优化生成模型的潜在表示与 posterior 覆盖，属于深度学习理论中的生成模型研究
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06138' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VAEVQ: Enhancing Discrete Visual Tokenization through Variational Modeling</h3>
<p><strong>Authors:</strong> Sicheng Yang, Xing Hu, Qiang Wu, Dawei Yang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 结合VAE与向量量化（VQ）改进离散视觉tokenization，解决VQ框架的潜在空间不平滑、表示一致性差等问题，对深度学习理论中的VQ-VAE和视觉tokenizer研究有贡献
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06863' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LeCoT: revisiting network architecture for two-view correspondence pruning</h3>
<p><strong>Authors:</strong> Luanyuan Dai, Xiaoyu Du, Jinhui Tang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 重新设计两视图对应剪枝的网络架构，提出空间-通道融合Transformer块，捕捉全局上下文信息，提升对应剪枝及下游任务性能，属于深度学习理论中的网络架构方向
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.07078' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection</h3>
<p><strong>Authors:</strong> Huizai Yao, Sicheng Zhao, Pengteng Li, Yi Cui, Shuo Lu, Weiyu Guo, Yunfan Lu, Yijie Xu, Hui Xiong</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出利用视觉基础模型增强源无关目标检测的框架，通过全局与实例级特征对齐解决域泛化与伪标签偏差问题，属于深度学习理论中的网络架构与迁移学习方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.07301' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting</h3>
<p><strong>Authors:</strong> Botao Ye, Boqi Chen, Haofei Xu, Daniel Barath, Marc Pollefeys</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出单模型前馈3D Gaussian Splatting框架，支持多视图输入与相机参数预测，解决传统3D重建的多模型依赖问题，属于深度学习理论中的网络架构与3D视觉方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.07321' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diversified Flow Matching with Translation Identifiability</h3>
<p><strong>Authors:</strong> Sagar Shrestha, Xiao Fu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于ODE的多样化流匹配框架，解决GAN的训练不稳定与轨迹缺失问题，实现可识别的域翻译，属于深度学习理论中的生成模型与流匹配方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05558' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Effective Test-Time Scaling of Discrete Diffusion through Iterative Refinement</h3>
<p><strong>Authors:</strong> Sanghyun Lee, Sunwoo Kim, Seungryong Kim, Jongho Park, Dongmin Park</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出迭代 refinement的离散扩散模型推理时缩放方法，通过原位修正提升奖励引导生成的质量与效率，属于深度学习理论中的扩散模型与推理优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05562' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Adaptive Sample-Level Framework Motivated by Distributionally Robust Optimization with Variance-Based Radius Assignment for Enhanced Neural Network Generalization Under Distribution Shift</h3>
<p><strong>Authors:</strong> Aheer Sravon, Devdyuti Mazumder, Md. Ibrahim</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于方差的自适应样本级DRO框架，通过个性化鲁棒性预算提升分布偏移下的模型泛化能力，属于深度学习理论中的优化与泛化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05568' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CoPRIS: Efficient and Stable Reinforcement Learning via Concurrency-Controlled Partial Rollout with Importance Sampling</h3>
<p><strong>Authors:</strong> Zekai Qu, Yinxu Pan, Ao Sun, Chaojun Xiao, Xu Han</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出并发控制部分rollout的RL框架，通过交叉阶段重要性采样修正离线轨迹偏差，提升LLMs的RL训练效率与稳定性，属于深度学习理论中的强化学习与效率优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05589' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FedSparQ: Adaptive Sparse Quantization with Error Feedback for Robust & Efficient Federated Learning</h3>
<p><strong>Authors:</strong> Chaimaa Medjadji, Sadi Alawadi, Feras M. Awaysheh, Guilain Leduc, Sylvain Kubler, Yves Le Traon</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出自适应稀疏量化与误差反馈的联邦学习框架，降低通信开销90%同时提升模型 accuracy 6%，属于深度学习理论中的分布式学习与压缩优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05591' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GRAVER: Generative Graph Vocabularies for Robust Graph Foundation Models Fine-tuning</h3>
<p><strong>Authors:</strong> Haonan Yuan, Qingyun Sun, Junhua Shi, Xingcheng Fu, Bryan Hooi, Jianxin Li, Philip S. Yu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出生成图词汇的图基础模型微调框架，通过 ego-graph 解纠缠与 MoE-CoE 网络提升少样本微调的鲁棒性，属于深度学习理论中的图模型与基础模型方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05592' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FlowNet: Modeling Dynamic Spatio-Temporal Systems via Flow Propagation</h3>
<p><strong>Authors:</strong> Yutong Feng, Xu Liu, Yutong Xia, Yuxuan Liang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于流传播的时空系统建模框架，捕捉非对称流交换与上下文交互，解决传统图模型的相似性假设局限，属于深度学习理论中的网络架构与时空建模方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05595' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Frequency Matters: When Time Series Foundation Models Fail Under Spectral Shift</h3>
<p><strong>Authors:</strong> Tianze Wang, Sofiane Ennadir, John Pertoft, Gabriela Zarzar Gandler, Lele Cao, Zineb Senane, Styliani Katsarou, Sahar Asadi, Axel Karlsson, Oleg Smirnov</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 分析时间序列基础模型在频谱偏移下的泛化失败，强调频率感知的重要性，为时间序列模型的预训练与评估提供新视角，属于深度学习理论中的泛化与时间序列方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05619' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Fooling Algorithms in Non-Stationary Bandits using Belief Inertia</h3>
<p><strong>Authors:</strong> Gal Mendelson, Eyal Tadmor</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出利用belief inertia构造非平稳bandits的adversarial实例，证明经典算法（如Explore Then Commit、UCB）的线性regret，属于深度学习理论中的强化学习与非平稳环境方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05620' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CAMP-HiVe: Cyclic Pair Merging based Efficient DNN Pruning with Hessian-Vector Approximation for Resource-Constrained Systems</h3>
<p><strong>Authors:</strong> Mohammad Helal Uddin, Sai Krishna Ghanta, Liam Seymour, Sabur Baidya</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于Hessian向量近似的循环对合并剪枝方法，在保留模型性能的同时显著降低计算需求，对深度学习理论中的模型压缩与资源高效部署有重要贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06265' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> How Wide and How Deep? Mitigating Over-Squashing of GNNs via Channel Capacity Constrained Estimation</h3>
<p><strong>Authors:</strong> Zinuo You, Jin Zheng, John Cartlidge</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于信息论信道容量的C3E框架，解决GNN中的过挤压问题，提供隐藏维度与深度的选择方法，对深度学习理论中的GNN网络架构优化有重要意义。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06443' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Adaptive Initial Residual Connections for GNNs with Theoretical Guarantees</h3>
<p><strong>Authors:</strong> Mohammad Shirzadi, Ali Safarpoor Dehkordi, Ahad N. Zehmakan</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出自适应初始残差连接，理论证明其防止GNN过平滑的有效性，提升异质图上的性能，对深度学习理论中的GNN网络架构改进有重要意义。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06598' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> On the Mechanisms of Collaborative Learning in VAE Recommenders</h3>
<p><strong>Authors:</strong> Tung-Long Vuong, Julien Monteil, Hien Dang, Volodymyr Vaskovych, Trung Le, Vu Nguyen</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 分析VAE推荐系统中协同学习的潜在机制（如潜变量邻近性、β-KL正则化与输入掩码的作用），提出锚定正则化稳定用户表示，对深度学习理论中VAE的协同学习原理与优化有深入解析，实验验证于多个推荐数据集。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06781' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TuckA: Hierarchical Compact Tensor Experts for Efficient Fine-Tuning</h3>
<p><strong>Authors:</strong> Qifeng Lei, Zhiyong Yang, Qianqian Xu, Cong Hua, Peisong Wen, Qingming Huang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对参数高效微调（PEFT）的样本多样性问题，提出Tucker分解的紧凑张量专家结构，结合分层策略与路由机制，实验验证在NLP、图像分类与数学推理任务上的有效性，对深度学习理论中模型高效适应的结构设计有创新贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.06859' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Can Training Dynamics of Scale-Invariant Neural Networks Be Explained by the Thermodynamics of an Ideal Gas?</h3>
<p><strong>Authors:</strong> Ildus Sadrtdinov, Ekaterina Lobacheva, Ivan Klimov, Mikhail I. Katsnelson, Dmitry Vetrov</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出热力学框架解释scale-invariant神经网络的SGD训练动态，建立学习率、权重衰减等超参数与热力学变量的类比，属于深度学习理论中的optimizer与训练动态研究
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.07308' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Understanding the role of depth in the neural tangent kernel for overparameterized neural networks</h3>
<p><strong>Authors:</strong> William St-Arnaud, Margarida Carvalho, Golnoosh Farnadi</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 分析深度对过参数化ReLU网络神经切线核的影响，理论推导极限核的性质，属于深度学习理论中的模型泛化分析
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.07272' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Few Govern the Many:Unveiling Few-Layer Dominance for Time Series Models</h3>
<p><strong>Authors:</strong> Xin Qiu, Junlong Tong, Yirong Sun, Yunpu Ma, Xiaoyu Shen</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 揭示时间序列模型中的少层主导现象，提出自动识别并保留主导层的方法，提升模型性能与效率，属于深度学习理论中的网络架构分析与优化
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.07237' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Routing Manifold Alignment Improves Generalization of Mixture-of-Experts LLMs</h3>
<p><strong>Authors:</strong> Zhongyang Li, Ziyue Li, Tianyi Zhou</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对MoE LLMs的路由器优化问题，提出RoMA方法对齐路由权重流形与任务嵌入流形，提升泛化性能，属于深度学习理论中网络架构的优化
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.07419' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Deep one-gate per layer networks with skip connections are universal classifiers</h3>
<p><strong>Authors:</strong> Raul Rojas</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 证明了带跳跃连接的单门多层感知机是通用分类器，揭示了简单网络架构的强大表达能力，属于深度学习理论中的网络架构与通用近似性方向。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05552' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Gradient Projection onto Historical Descent Directions for Communication-Efficient Federated Learning</h3>
<p><strong>Authors:</strong> Arnaud Descours (UCBL), Léonard Deroose, Jan Ramon</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出梯度投影到历史下降方向的联邦学习算法，通过共享子空间降低通信开销，属于深度学习理论中的分布式学习与梯度优化方向。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05593' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> FiCABU: A Fisher-Based, Context-Adaptive Machine Unlearning Processor for Edge AI</h3>
<p><strong>Authors:</strong> Eun-Su Cho, Jongin Choi, Jeongmin Jin, Jae-Jin Lee, Woojoo Lee</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于Fisher的上下文自适应机器unlearning框架，通过后端优先的逐层编辑优化边缘AI的unlearning效率，属于深度学习理论中的模型优化与隐私方向。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.05605' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Kunhao Li, Wenhao Li, Di Wu, Lei Yang, Jun Bai, Ju Jia, Jason Xue</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对多模态大模型（MLLMs）机器遗忘的跨模态不一致与通用知识下降问题，提出模态特异性归因的神经元路径编辑方法，实验证明多模态与文本任务上的遗忘率（最高87.75%）与知识保留均优于现有方法，对MLLMs的隐私保护与安全优化有重要价值。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06793' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning</h3>
<p><strong>Authors:</strong> Xinyan Cai, Shiguang Wu, Dafeng Chi, Yuzheng Zhuang, Xingyue Quan, Jianye Hao, Qiang Guan</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出EVLP多模态统一生成框架，联合建模语言推理与视觉生成，通过动态预训练和强化对齐解决长horizon任务的多模态规划问题，属于多模态大模型的核心研究方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.05553' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Walking the Schr\"odinger Bridge: A Direct Trajectory for Text-to-3D Generation</h3>
<p><strong>Authors:</strong> Ziying Li, Xuequan Lu, Xinkui Zhao, Guanjie Cheng, Shuiguang Deng, Jianwei Yin</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 用Schrödinger Bridge框架改进Text-to-3D生成的SDS方法，减少过饱和/过平滑 artifacts，提出TraCe框架提升3D生成质量，属于多模态大模型的3D生成核心方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.05609' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Long Grounded Thoughts: Distilling Compositional Visual Reasoning Chains at Scale</h3>
<p><strong>Authors:</strong> David Acuna, Chao-Han Huck Yang, Yuntian Deng, Jaehun Jung, Ximing Lu, Prithviraj Ammanabrolu, Hyunwoo Kim, Yuan-Hong Liao, Yejin Choi</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 生成1M+视觉推理数据，微调Qwen2.5-VL等模型，显著提升V* Bench、CV-Bench等视觉基准性能，属于多模态大模型的vision-centric reasoning核心方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.05705' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Open-World 3D Scene Graph Generation for Retrieval-Augmented Reasoning</h3>
<p><strong>Authors:</strong> Fei Yu, Quan Deng, Shengeng Tang, Yuehua Li, Lechao Cheng</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出开放世界3D场景图生成框架，结合VLM和检索推理，支持多模态查询和任务规划，属于多模态大模型的3D scene understanding核心方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.05894' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MALeR: Improving Compositional Fidelity in Layout-Guided Generation</h3>
<p><strong>Authors:</strong> Shivank Saxena, Dhruv Srivastava, Makarand Tapaswi</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 解决布局引导图像生成中的主体越界与属性泄漏问题，提升组合准确性与属性绑定能力，属于多模态大模型中的图像生成研究
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06002' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Neodragon: Mobile Video Generation using Diffusion Transformer</h3>
<p><strong>Authors:</strong> Animesh Karnewar, Denis Korzhenkov, Ioannis Lelekas, Adil Karjauv, Noor Fathima, Hanwen Xiong, Vancheeswaran Vaidyanathan, Will Zeng, Rafael Esteves, Tushar Singhal, Fatih Porikli, Mohsen Ghafoorian, Amirhossein Habibian</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对移动设备优化扩散Transformer视频生成，通过文本编码器蒸馏、 decoder 蒸馏等策略提升效率与质量，属于多模态大模型中的视频生成研究
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06055' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> NURBGen: High-Fidelity Text-to-CAD Generation through LLM-Driven NURBS Modeling</h3>
<p><strong>Authors:</strong> Muhammad Usama, Mohammad Sadil Khan, Didier Stricker, Muhammad Zeshan Afzal</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 基于LLM将文本转换为NURBS参数化表示，实现高保真text-to-CAD生成，属于多模态大模型中的text-to-3D生成研究
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06194' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Seq2Seq Models Reconstruct Visual Jigsaw Puzzles without Seeing Them</h3>
<p><strong>Authors:</strong> Gur Elkn, Ofir Itzhak Shahar, Ohad Ben-Shahar</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出通过专用tokenizer将拼图块转换为离散token序列，以seq2seq模型解决视觉拼图问题，涉及多模态大模型中的tokenizer与image understanding方向，展示了语言模型跨域解决视觉任务的能力。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06315' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> V-Shuffle: Zero-Shot Style Transfer via Value Shuffle</h3>
<p><strong>Authors:</strong> Haojun Tang, Qiwei Lin, Tongda Xu, Lida Huang, Yan Wang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出通过diffusion模型self-attention层的value特征shuffle解决风格迁移的内容泄漏问题，属于多模态大模型中的image generation方向，提升了zero-shot风格迁移的效果。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06365' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Zooming into Comics: Region-Aware RL Improves Fine-Grained Comic Understanding in Vision-Language Models</h3>
<p><strong>Authors:</strong> Yule Chen, Yufan Ren, Sabine Süsstrunk</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出区域感知强化学习（RARL）改进Vision-Language Models的漫画理解能力，属于多模态大模型中的Vision-Language Model与image understanding方向，提升了细粒度视觉任务性能。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06490' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs</h3>
<p><strong>Authors:</strong> Tianhao Peng, Haochen Wang, Yuanxing Zhang, Zekun Wang, Zili Wang, Ge Zhang, Jian Yang, Shihao Li, Yanghai Wang, Xintao Wang, Houyi Li, Wei Ji, Pengfei Wan, Wenhao Huang, Zhaoxiang Zhang, Jiaheng Liu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 构建首个针对多模态大模型的多视频理解评估基准MVU-Eval，覆盖8项核心能力与真实场景（如自动驾驶多传感器合成），填补了多视频理解评估的空白。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07250' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation</h3>
<p><strong>Authors:</strong> Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li, Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt Keutzer, Akio Kodaira, Chenfeng Xu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出实时交互式视频生成系统，通过SLO-aware调度与滚动KV缓存优化视频扩散模型的流式推理，支持低延迟、高帧率的生成任务，属于多模态大模型中的视频生成方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07399' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards</h3>
<p><strong>Authors:</strong> Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出基于空间奖励的多模态LLMs 3D推理框架，通过场景图构建与密集空间奖励提升模型的空间理解与推理能力，属于多模态大模型中的空间推理方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07403' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SSTODE: Ocean-Atmosphere Physics-Informed Neural</h3>
<p><strong>Authors:</strong> Peilin Yang, Yu Ma</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对多模态机器学习的分布鲁棒性问题，提出分布鲁棒优化（DRO）框架，结合理论分析（泛化上界、极小极大下界）与实证验证，为多模态大模型的鲁棒性研究提供了理论基础与实践方法
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.05716' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Adapting Web Agents with Synthetic Supervision</h3>
<p><strong>Authors:</strong> Zhaoyang Wang, Yiming Liang, Xuchao Zhang, Qianhui Wu, Siwei Han, Anson Bastos, Rujia Wang, Chetan Bansal, Baolin Peng, Jianfeng Gao, Saravan Rajmohan, Huaxiu Yao</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对Web Agent适应新网站的问题，提出SynthAgent合成监督框架，优化合成任务与轨迹质量，提升Web Agent适应性，对多模态大模型中的GUI Agent研究有实践价值
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06101' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Test-Time Iterative Error Correction for Efficient Diffusion Models</h3>
<p><strong>Authors:</strong> Yunshan Zhong, Yanwei Qi, Yuxin Zhang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对高效扩散模型推理中的误差累积问题，提出迭代误差校正（IEC）方法，理论证明将误差传播从指数级降为线性级，无需重新训练即可提升图像生成质量，对多模态大模型中的图像生成高效部署有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06250' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MULTIBENCH++: A Unified and Comprehensive Multimodal Fusion Benchmarking Across Specialized Domains</h3>
<p><strong>Authors:</strong> Leyan Xue, Zongbo Han, Kecheng Xue, Xiaohong Liu, Guangyu Wang, Changqing Zhang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出统一的多模态融合基准MULTIBENCH++，整合30+数据集、15种模态和20个任务，为多模态大模型的评估提供全面支撑，对多模态大模型的研究有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06452' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Mitigating Modality Imbalance in Multi-modal Learning via Multi-objective Optimization</h3>
<p><strong>Authors:</strong> Heshan Fernando, Parikshit Ram, Yi Zhou, Soham Dan, Horst Samulowitz, Nathalie Baracaldo, Tianyi Chen</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对多模态学习中模态不平衡导致性能下降的核心问题，提出多目标优化框架进行解决，提供了收敛保证，并在基准任务上验证了性能提升（如降低计算开销同时保持精度），对多模态大模型的模态平衡与融合研究有重要参考价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06686' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Multi-Modal Continual Learning via Cross-Modality Adapters and Representation Alignment with Knowledge Preservation</h3>
<p><strong>Authors:</strong> Evelyn Chee, Wynne Hsu, Mong Li Lee</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 聚焦多模态持续学习中的灾难性遗忘问题，提出跨模态适配器与表示对齐策略，结合知识保留机制，实验验证在类增量与域增量任务上优于基线模型，对多模态大模型的持续适应能力提升有实际意义。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06723' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Grounding Computer Use Agents on Human Demonstrations</h3>
<p><strong>Authors:</strong> Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对多模态大模型中的GUI Grounding问题，构建桌面环境的大规模grounding数据集GroundCUA，支持计算机使用代理的研究，与多模态大模型方向高度相关
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07332' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval</h3>
<p><strong>Authors:</strong> Shahram Najam Syed, Yatharth Ahuja, Arthur Jakobsson, Jeff Ichnowski</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对视觉-语言-动作（VLA）模型的自适应问题，提出经验回放与检索的优化方法，提升了机器人操纵任务的成功率，属于多模态大模型在机器人应用中的关键改进
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06202' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> How Do VLAs Effectively Inherit from VLMs?</h3>
<p><strong>Authors:</strong> Chuheng Zhang, Rushuai Yang, Xiaoyu Chen, Kaixin Wang, Li Zhao, Yi Chen, Jiang Bian</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 通过GrinningFace基准系统分析VLA继承VLM知识的机制，为多模态大模型的embodied control研究提供指导，明确了知识转移的关键技术
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06619' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Robot Learning from a Physical World Model</h3>
<p><strong>Authors:</strong> Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 结合语言指令、视频生成与物理世界重建，将虚拟视频运动转化为物理可行的机器人动作，涉及多模态处理，提升了机器人操纵的零-shot泛化能力
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07416' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MiVID: Multi-Strategic Self-Supervision for Video Frame Interpolation using Diffusion Model</h3>
<p><strong>Authors:</strong> Priyansh Srivastava, Romit Chatterjee, Abir Sen, Aradhana Behura, Ratnakar Dash</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出自监督扩散框架，结合3D U-Net与 temporal 注意力，提升视频帧插值的 temporal 一致性，属于多模态大模型中的视频生成研究
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06019' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> StreamSTGS: Streaming Spatial and Temporal Gaussian Grids for Real-Time Free-Viewpoint Video</h3>
<p><strong>Authors:</strong> Zhihui Ke, Yuyang Liu, Xiaobo Zhou, Tie Qiu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出实时流式自由视角视频表示，结合3D Gaussian与变形场，平衡生成质量与传输效率，属于多模态大模型中的视频生成研究
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06046' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MoRA: Missing Modality Low-Rank Adaptation for Visual Recognition</h3>
<p><strong>Authors:</strong> Shu Zhao, Nilesh Ahuja, Tan Yu, Tianyi Shen, Vijaykrishnan Narayanan</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出缺失模态下的低秩适应机制，平衡跨模态交互与模态特异性，提升多模态视觉识别鲁棒性，属于多模态大模型中的模态缺失处理研究
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06225' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VideoSSR: Video Self-Supervised Reinforcement Learning</h3>
<p><strong>Authors:</strong> Zefeng He, Xiaoye Qu, Yafu Li, Siyuan Huang, Daizong Liu, Yu Cheng</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出视频自监督强化学习框架，通过 pretext 任务生成训练数据，提升多模态大模型的视频理解能力，属于多模态大模型中的视频处理研究
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06281' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GazeVLM: A Vision-Language Model for Multi-Task Gaze Understanding</h3>
<p><strong>Authors:</strong> Athul M. Mathew, Haithem Hermassi, Thariq Khalid, Arshad Ali Khan, Riad Souissi</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 构建多任务gaze理解的Vision-Language Model，整合RGB、深度视觉模态与语言提示，属于多模态大模型方向，提升了gaze目标检测等任务的性能。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06348' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> AesTest: Measuring Aesthetic Intelligence from Perception to Production</h3>
<p><strong>Authors:</strong> Guolong Wang, Heng Huang, Zhiqiang Zhang, Wentian Li, Feilong Ma, Xin Jin</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 构建评估多模态大模型美学感知与生成能力的基准，覆盖感知、创作等多任务，属于多模态大模型方向，填补了美学智能评估的空白。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06360' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> NOAH: Benchmarking Narrative Prior driven Hallucination and Omission in Video Large Language Models</h3>
<p><strong>Authors:</strong> Kyuho Lee, Euntae Kim, Jinwoo Choi, Buru Chang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 构建评估Video LLMs中叙事先验导致的幻觉与遗漏的基准，属于多模态大模型方向，提升了Video LLMs的可靠性与可解释性。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06475' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SportR: A Benchmark for Multimodal Large Language Model Reasoning in Sports</h3>
<p><strong>Authors:</strong> Haotian Xia, Haonan Ge, Junbo Zou, Hyun Woo Choi, Xuebin Zhang, Danny Suradja, Botao Rui, Ethan Tran, Wendy Jin, Zhen Ye, Xiyang Lin, Christopher Lai, Shengjie Zhang, Junwen Miao, Shichao Chen, Rhys Tracy, Vicente Ordonez, Weining Shen, Hanjie Chen</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 构建评估MLLMs体育推理能力的基准，覆盖视觉感知、规则推理与视觉grounding，属于多模态大模型方向，支持体育领域多模态推理研究。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06499' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View</h3>
<p><strong>Authors:</strong> Jianyu Qi, Ding Zou, Wenrui Yan, Rui Ma, Jiaxu Li, Zhijie Zheng, Zhiguo Yang, Rongchang Zhao</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出难度感知的多模态post-training数据采样策略，属于多模态大模型方向，提升了MLLMs感知与推理能力的优化效率。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06722' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Generating an Image From 1,000 Words: Enhancing Text-to-Image With Structured Captions</h3>
<p><strong>Authors:</strong> Eyal Gutflaish, Eliran Kachlon, Hezi Zisman, Tal Hacham, Nimrod Sarid, Alexander Visheratin, Saar Huberman, Gal Davidi, Guy Bukchin, Kfir Goldberg, Ron Mokady</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 针对文本到图像模型的长结构化caption处理，提出DimFusion融合机制和TaBR评估协议，提升模型的可控性与表达性，属于多模态大模型中的图像生成方向
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06876' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Two-Stage System for Layout-Controlled Image Generation using Large Language Models and Diffusion Models</h3>
<p><strong>Authors:</strong> Jan-Hendrik Koch, Jonas Krumme, Konrad Gadzicki</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出两阶段系统，结合LLM生成结构化布局与扩散模型生成图像，解决文本到图像的布局控制问题，属于多模态大模型中的图像生成方向
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06888' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mono3DVG-EnSD: Enhanced Spatial-aware and Dimension-decoupled Text Encoding for Monocular 3D Visual Grounding</h3>
<p><strong>Authors:</strong> Yuzhen Li, Min Liu, Zhaoyang Li, Yuan Bian, Xueping Wang, Erbo Zhai, Yaonan Wang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 改进单目3D视觉grounding的文本编码，提出空间感知与维度解耦模块，提升文本与3D视觉的对齐性能，属于多模态大模型中的视觉grounding方向
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06908' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Omni-View: Unlocking How Generation Facilitates Understanding in Unified 3D Model based on Multiview images</h3>
<p><strong>Authors:</strong> JiaKui Hu, Shanshan Zhao, Qing-Guo Chen, Xuerui Qiu, Jialun Liu, Zhao Xu, Weihua Luo, Kaifu Zhang, Yanye Lu</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出Omni-View框架统一3D场景的理解与生成，结合多视图图像，探索“生成促进理解”的原理，提升3D场景理解与生成性能，属于多模态大模型中的3D图像理解与生成方向
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07222' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> 4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal Rectification for High-Quality and Consistent 4D Generation</h3>
<p><strong>Authors:</strong> Mengmeng Liu, Jiuming Liu, Yunpeng Zhang, Jiangtao Li, Michael Ying Yang, Francesco Nex, Hao Cheng</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出空间-时间校正的4D Gaussian生成框架，解决传统4D生成的时空一致性问题，支持高质量动态内容生成，属于多模态大模型中的4D视觉生成方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07241' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> StreamKV: Streaming Video Question-Answering with Segment-based KV Cache Retrieval and Compression</h3>
<p><strong>Authors:</strong> Yilong Chen, Xiang Bai, Zhibin Wang, Chengyu Bai, Yuhan Dai, Ming Lu, Shanghang Zhang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出面向流式视频问答的KV缓存优化框架，通过语义分段与自适应压缩提升Video-LLMs的推理效率与准确性，属于多模态大模型中的视频-语言交互方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07278' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VADER: Towards Causal Video Anomaly Understanding with Relation-Aware Large Language Models</h3>
<p><strong>Authors:</strong> Ying Cheng, Yu-Ho Lin, Min-Hung Chen, Fu-En Yang, Shang-Hong Lai</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 结合关系特征提取与LLMs实现视频异常的因果推理，生成可解释的异常描述，解决传统视频异常检测的语义理解不足问题，属于多模态大模型中的视频理解方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07299' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DIMO: Diverse 3D Motion Generation for Arbitrary Objects</h3>
<p><strong>Authors:</strong> Linzhan Mou, Jiahui Lei, Chen Wang, Lingjie Liu, Kostas Daniilidis</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出任意物体的多样3D运动生成框架，利用视频模型先验生成动态3D表示，支持运动插值与语言引导生成，属于多模态大模型中的3D动态生成方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07409' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective</h3>
<p><strong>Authors:</strong> Hao Wang, Sathwik Karnik, Bea Lim, Somil Bansal</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 从控制理论角度分析VLM作为闭环符号规划器的性能影响因素，为多模态大模型在机器人中的优化应用提供了理论指导
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07410' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> InfoAffect: A Dataset for Affective Analysis of Infographics</h3>
<p><strong>Authors:</strong> Zihang Fu, Yunchao Wang, Chenyu Huang, Guodao Sun, Ronghua Liang</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 构建infographics情感分析的多模态数据集，用MLLMs融合文本与视觉模态分析情感，属于多模态大模型方向，支持情感分析任务研究。
Score: 6
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.06404' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Inference-Time Scaling of Diffusion Models for Infrared Data Generation</h3>
<p><strong>Authors:</strong> Kai A. Horstmann, Maxim Clouser, Kia Khezeli</p>
<p><strong>Published:</strong> 2025-11-11</p>
<p><strong>Reason:</strong> 提出低数据场景下红外图像生成的推理时引导方法，通过域适应与验证器优化扩散模型的生成质量，属于多模态大模型中的特种图像生成方向。
Score: 6
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.07362' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>