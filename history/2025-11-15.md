# ArXiv 每日推荐 - 2025-11-15

> 更新于北京时间：2025-11-15 12:28:35
> 已自动阅读了 286 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：151829

## 多模态大模型

### [Score: 9.0/10] GridPrune: From "Where to Look" to "What to Select" in Visual Token Pruning for MLLMs
- **Authors:** Yuxiang Duan, Ao Li, Yingqin Li, Luyu Li, Pengwei Wang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10081](https://arxiv.org/abs/2511.10081)
- **Reason:** 针对MLLMs视觉token剪枝的空间分配低效问题，提出“全局引导-局部选择”的区域选择系统，在LLaVA-NeXT-7B上实现高剪枝率下的性能保持（96.98%性能/11.1% tokens），显著优于基线，是多模态大模型效率优化的关键技术。
Score: 9
Field: 多模态大模型

### [Score: 9.0/10] Rethinking Visual Information Processing in Multimodal LLMs
- **Authors:** Dongwan Kim, Viresh Ranjan, Takashi Nagata, Arnab Dhua, Amit Kumar K C
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10301](https://arxiv.org/abs/2511.10301)
- **Reason:** 重新思考MLLMs的视觉信息处理逻辑，提出LLaViT架构通过分离QKV投影、双向注意力等改进视觉特征整合，显著优于LLaVA基线（甚至超越两倍参数模型），是多模态大模型的核心架构创新。
Score: 9
Field: 多模态大模型

### [Score: 9.0/10] SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation
- **Authors:** Wei Li, Renshan Zhang, Rui Shao, Zhijian Fang, Kaiwen Zhou, Zhuotao Tian, Liqiang Nie
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10518](https://arxiv.org/abs/2511.10518)
- **Reason:** 提出语义对齐的稀疏化与增强框架，通过双视觉剪枝与分层融合提升VLA性能，在LIBERO基准上超越OpenVLA 21.1%且效率提升3倍，符合多模态大模型的GUI Agent方向，是机器人操作的关键技术创新。
Score: 9
Field: 多模态大模型

### [Score: 9.0/10] OmniVGGT: Omni-Modality Driven Visual Geometry Grounded
- **Authors:** Haosong Peng, Hao Li, Yalun Dai, Yushi Lan, Yihang Luo, Tianyu Qi, Zhengshen Zhang, Yufeng Zhan, Junfei Zhang, Wenchao Xu, Ziwei Liu
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10560](https://arxiv.org/abs/2511.10560)
- **Reason:** 提出多模态视觉几何接地框架OmniVGGT，融合RGB、深度、相机参数等模态，提升3D基础模型在深度估计、相机姿态估计等任务性能，并赋能VLA模型优化机器人任务，对多模态大模型视觉几何理解有核心贡献。
Score: 9
Field: 多模态大模型

### [Score: 9.0/10] Depth Anything 3: Recovering the Visual Space from Any Views
- **Authors:** Haotong Lin, Sili Chen, Junhao Liew, Donny Y. Chen, Zhenyu Li, Guang Shi, Jiashi Feng, Bingyi Kang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10647](https://arxiv.org/abs/2511.10647)
- **Reason:** 提出DA3模型，从任意视觉输入恢复空间一致几何结构，在相机姿态估计、几何精度等任务超越SOTA，显著提升多模态大模型3D视觉理解能力。
Score: 9
Field: 多模态大模型

### [Score: 8.0/10] MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation
- **Authors:** Ye Tian (), Ling Yang (), Jiongfan Yang (), Anran Wang (), Yu Tian (), Jiani Zheng (), Haochen Wang (), Zhiyang Teng (), Zhuochen Wang (), Yinjie Wang (), Yunhai Tong (), Mengdi Wang (), Xiangtai Li ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09611](https://arxiv.org/abs/2511.09611)
- **Reason:** 提出并行多模态扩散框架解决思维感知生成中的错误传播问题，通过监督微调和平行强化学习提升跨模态对齐与语义一致性，在ParaBench上比SOTA模型Bagel提升6.9% Output Alignment，是多模态大模型在思维感知生成领域的重要改进。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control
- **Authors:** Arman Zarei (), Samyadeep Basu (), Mobina Pournemat (), Sayan Nag (), Ryan Rossi (), Soheil Feizi ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09715](https://arxiv.org/abs/2511.09715)
- **Reason:** 针对指令图像编辑中固定强度的局限性，提出SliderEdit框架实现连续细粒度指令控制，无需单独训练每个属性，提升编辑可控性与语义一致性，适用于多模态交互场景，实验改进FLUX-Kontext等模型性能。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Remember Me: Bridging the Long-Range Gap in LVLMs with Three-Step Inference-Only Decay Resilience Strategies
- **Authors:** Peng Gao (), Yujian Lee (), Xiaofeng Zhang (), Zailong Chen (), Hui Zhang ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09868](https://arxiv.org/abs/2511.09868)
- **Reason:** 针对LVLMs中ROPE导致的长距离注意力衰减问题，提出三步推理策略（语义驱动、距离感知、强化 distant依赖），在不训练的情况下提升VQA性能，有效解决多模态大模型的全局上下文记忆问题。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models
- **Authors:** Liheng Zhang (), Jin Wang (), Hui Li (), Bingfeng Zhang (), Weifeng Liu ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09883](https://arxiv.org/abs/2511.09883)
- **Reason:** 针对3D-VLMs的计算瓶颈，提出分层补偿压缩策略（全局结构压缩+自适应细节挖掘），实现98%的3D token reduction并保持性能，大幅提升多模态大模型的效率，实验验证优于现有方法。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models
- **Authors:** Xinyi Wang (), Xun Yang (), Yanlong Xu (), Yuchen Wu (), Zhen Li (), Na Zhao ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10017](https://arxiv.org/abs/2511.10017)
- **Reason:** 提出结合MLLMs的3D细粒度具身推理框架，通过环绕视图投影与CoT推理解决交互三元组（位置、运动类型、轴）预测问题，在SceneFun3D上实现SOTA性能，是多模态大模型在具身智能的创新应用。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] VLF-MSC: Vision-Language Feature-Based Multimodal Semantic Communication System
- **Authors:** Gwangyeon Ahn, Jiwan Seo, Joonhyuk Kang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10074](https://arxiv.org/abs/2511.10074)
- **Reason:** 提出基于视觉语言特征的多模态语义通信系统，利用预训练VLM生成统一视觉语言特征以支持图像和文本生成，解决了现有方法模态分离的问题，实验验证了低SNR下的语义准确性和带宽效率，符合多模态大模型研究方向。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Right Looks, Wrong Reasons: Compositional Fidelity in Text-to-Image Generation
- **Authors:** Mayank Vatsa, Aparna Bharati, Richa Singh
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10136](https://arxiv.org/abs/2511.10136)
- **Reason:** 系统分析文本到图像生成模型的组合逻辑缺陷（否定、计数、空间关系），指出训练数据缺失、注意力架构限制和评估指标偏差的核心问题，对多模态大模型的image generation方向有重要理论指导意义。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] TubeRMC: Tube-conditioned Reconstruction with Mutual Constraints for Weakly-supervised Spatio-Temporal Video Grounding
- **Authors:** Jinxuan Li, Yi Zhang, Jian-Fang Hu, Chaolei Tan, Tianming Liang, Beihao Xia
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10241](https://arxiv.org/abs/2511.10241)
- **Reason:** 针对弱监督时空视频grounding的目标定位不准确问题，提出tube条件重建与互约束框架，通过时空约束提升文本-视觉对齐精度，实验验证了在VidSTG和HCSTVG上的性能优势，符合多模态大模型的GUI Grounding方向。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Adaptive Residual-Update Steering for Low-Overhead Hallucination Mitigation in Large Vision Language Models
- **Authors:** Zhengtao Zou, Ya Gao, Jiarui Guan, Bin Li, Pekka Marttinen
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10292](https://arxiv.org/abs/2511.10292)
- **Reason:** 提出低开销的LVLMs幻觉缓解框架，通过残差更新引导生成视觉接地文本，解决了现有方法计算成本高的问题，实验验证了在POPE和CHAIR上的幻觉抑制效果，属于多模态大模型的可靠性优化。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation
- **Authors:** Xun Huang, Shijia Zhao, Yunxiang Wang, Xin Lu, Wanfa Zhang, Rongsheng Qu, Weixin Li, Yunhong Wang, Chenglu Wen
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10376](https://arxiv.org/abs/2511.10376)
- **Reason:** 提出多模态3D场景图的零样本具身导航系统，通过关键子图选择与闭环推理提升导航精度，实验验证了在GOAT-Bench和HM3D-OVON上的SOTA性能，符合多模态大模型的image understanding与导航方向。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation
- **Authors:** Isabela Albuquerque, Ira Ktena, Olivia Wiles, Ivana Kajić, Amine Rannen-Triki, Cristina Vasconcelos, Aida Nematzadeh
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10547](https://arxiv.org/abs/2511.10547)
- **Reason:** 针对文本到图像生成模型的多样性评估难题，提出系统的人类评估框架、 curated prompt集及对比方法，为多模态大模型的图像生成质量优化提供关键评估工具与 insights。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] A Style is Worth One Code: Unlocking Code-to-Style Image Generation with Discrete Style Space
- **Authors:** Huijie Liu, Shuhao Cui, Haoxiang Cao, Shuai Ma, Kai Wu, Guoliang Kang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10555](https://arxiv.org/abs/2511.10555)
- **Reason:** 提出首个开源代码到风格图像生成方法CoTyle，通过离散风格码本与自回归生成器实现精准风格控制，解决现有方法风格一致性与创造性不足问题，推动多模态大模型风格生成研究。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models
- **Authors:** Aleksandr Razin, Danil Kazantsev, Ilya Makarov
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10629](https://arxiv.org/abs/2511.10629)
- **Reason:** 提出轻量级 latent 超分模块LUA，直接在扩散模型 latent 空间完成超分，解决高分辨率生成速度与质量难题，比图像空间超分快3倍，对多模态大模型图像生成效率提升具实用价值。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling
- **Authors:** Jiahao Wang, Weiye Xu, Aijun Yang, Wengang Zhou, Lewei Lu, Houqiang Li, Xiaohua Wang, Jinguo Zhu
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10648](https://arxiv.org/abs/2511.10648)
- **Reason:** 提出自洽采样SCS，通过视觉扰动与轨迹重采样解决多模态大模型RL微调中不可靠轨迹问题，提升推理准确性，对多模态大模型对齐训练具关键改进作用。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey
- **Authors:** Yuchen Huang, Sijia Li, Minghao Liu, Wei Liu, Shijue Huang, Zhiyuan Fan, Hou Pong Chan, Yi R. Fung
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09586](https://arxiv.org/abs/2511.09586)
- **Reason:** 系统综述LLM Agents环境缩放方法，提出GEF循环框架，分析环境对Agent能力的影响，为多模态大模型Agent环境设计提供指导。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] ACT as Human: Multimodal Large Language Model Data Annotation with Critical Thinking
- **Authors:** Lequan Lin, Dai Shi, Andi Han, Feng Chen, Qiuzheng Chen, Jiawen Li, Zhaoyang Li, Jiyuan Li, Zhenbang Sun, Junbin Gao
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09833](https://arxiv.org/abs/2511.09833)
- **Reason:** 提出ACT数据 pipeline，用多模态LLM完成标注与纠错，提升标注质量同时降低90%人力成本，对多模态大模型训练数据构建具实用价值。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] T2IBias: Uncovering Societal Bias Encoded in the Latent Space of Text-to-Image Generative Models
- **Authors:** Abu Sufian, Cosimo Distante, Marco Leo, Hanan Salam
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10089](https://arxiv.org/abs/2511.10089)
- **Reason:** 研究文本到图像生成模型潜在空间中的社会偏见，分析主流模型的性别与种族偏向，属于多模态大模型中的图像生成研究。
Score: 8
Field: 多模态大模型

### [Score: 8.0/10] Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention
- **Authors:** Zhe Xu, Zhicai Wang, Junkang Wu, Jinda Lu, Xiang Wang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10268](https://arxiv.org/abs/2511.10268)
- **Reason:** Addresses object hallucinations in Large Vision-Language Models (LVLMs) using causal analysis, relevant to reliability and interpretability in multi-modal large models.
Score: 8
Field: 多模态大模型

### [Score: 7.0/10] Out-of-Context Misinformation Detection via Variational Domain-Invariant Learning with Test-Time Training
- **Authors:** Xi Yang, Han Zhang, Zhijian Lin, Yibiao Hu, Hong Han
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10213](https://arxiv.org/abs/2511.10213)
- **Reason:** 针对图文错位的上下文外虚假信息检测，提出域不变学习与测试时训练方法，属于多模态大模型中的图像-文本理解研究。
Score: 7
Field: 多模态大模型

### [Score: 7.0/10] OutSafe-Bench: A Benchmark for Multimodal Offensive Content Detection in Large Language Models
- **Authors:** Yuping Yan, Yuhan Xie, Yuanshuai Li, Yingchao Yu, Lingjuan Lyu, Yaochu Jin
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10287](https://arxiv.org/abs/2511.10287)
- **Reason:** 构建多模态大模型的有害内容检测基准，覆盖文本、图像、音频、视频，属于多模态大模型中的内容安全研究。
Score: 7
Field: 多模态大模型

### [Score: 6.0/10] SlideBot: A Multi-Agent Framework for Generating Informative, Reliable, Multi-Modal Presentations
- **Authors:** Eric Xie, Danielle Waterfield, Michael Kennedy, Aidong Zhang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09804](https://arxiv.org/abs/2511.09804)
- **Reason:** Develops a multi-agent framework for generating multi-modal presentations (text, figures, LaTeX) using LLMs, aligned with multi-modal large model research.
Score: 6
Field: 多模态大模型

## 自动驾驶与大模型

### [Score: 9.0/10] LiNeXt: Revisiting LiDAR Completion with Efficient Non-Diffusion Architectures
- **Authors:** Wenzhe He, Xiaojun Chen, Ruiqi Wang, Ruihui Li, Huilong Pi, Jiapeng Zhang, Zhuo Tang, Kenli Li
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10209](https://arxiv.org/abs/2511.10209)
- **Reason:** 提出非扩散的LiDAR补全网络，通过Noise-to-Coarse模块和距离感知采样策略，实现199.8x推理加速、50.7% Chamfer Distance降低，是自动驾驶与大模型中实时场景补全的关键技术，适用于自动驾驶感知系统。
Score: 9
Field: 自动驾驶与大模型

### [Score: 8.0/10] Robust Object Detection with Pseudo Labels from VLMs using Per-Object Co-teaching
- **Authors:** Uday Bhaskar (), Rishabh Bhattacharya (), Avinash Patel (), Sarthak Khoche (), Praveen Anil Kulkarni (), Naresh Manwani ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09955](https://arxiv.org/abs/2511.09955)
- **Reason:** 针对自动驾驶中目标检测的标注成本问题，用VLM生成伪标签并结合per-object co-teaching过滤噪声，在KITTI数据集上提升YOLOv5m的mAP@0.5从31.12%到46.61%，是自动驾驶与大模型结合的实用方案。
Score: 8
Field: 自动驾驶与大模型

### [Score: 8.0/10] HeatV2X: Scalable Heterogeneous Collaborative Perception via Efficient Alignment and Interaction
- **Authors:** Yueran Zhao, Zhang Zhang, Chao Sun, Tianze Wang, Chao Yue, Nuoran Li
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10211](https://arxiv.org/abs/2511.10211)
- **Reason:** 提出可扩展的异构V2X协同感知框架，通过局部异构微调与全局协同微调实现多模态特征对齐，解决了现有方法 scalability差的问题，实验验证了在OPV2V-H和DAIR-V2X上的感知性能优势，属于自动驾驶与大模型的协同感知方向。
Score: 8
Field: 自动驾驶与大模型

### [Score: 7.0/10] Social LSTM with Dynamic Occupancy Modeling for Realistic Pedestrian Trajectory Prediction
- **Authors:** Ahmed Alia (), Mohcine Chraibi (), Armin Seyfried ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09735](https://arxiv.org/abs/2511.09735)
- **Reason:** 针对自动驾驶中行人轨迹预测的碰撞问题，改进Social LSTM加入动态占据空间损失函数，结合碰撞 penalty与位移误差优化，在多密度数据集上降低31%碰撞率并提升预测 accuracy，是自动驾驶感知模块的实用改进。
Score: 7
Field: 自动驾驶与大模型

### [Score: 7.0/10] SAMIRO: Spatial Attention Mutual Information Regularization with a Pre-trained Model as Oracle for Lane Detection
- **Authors:** Hyunjong Lee, Jangho Lee, Jaekoo Lee
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10385](https://arxiv.org/abs/2511.10385)
- **Reason:** 提出空间注意力互信息正则化方法，利用预训练模型作为Oracle引导车道特征学习，解决了现有方法对复杂环境鲁棒性差的问题，实验验证了在CULane、Tusimple等数据集上的性能提升，属于自动驾驶与大模型的车道检测方向。
Score: 7
Field: 自动驾驶与大模型

## 深度学习理论

### [Score: 9.0/10] Making Every Head Count: Sparse Attention Without the Speed-Performance Trade-off
- **Authors:** Mingkuan Zhao, Wentao Hu, Jiayin Wang, Xin Lai, Tianchen Huang, Yuheng Min, Rui Yan, Xiaoyan Zhu
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09596](https://arxiv.org/abs/2511.09596)
- **Reason:** 提出SPAttention，通过结构化稀疏化划分多head注意力计算任务，提升训练吞吐量2倍且保持/超越dense attention性能，对深度学习理论注意力机制优化有核心贡献。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] On the Convergence of Overparameterized Problems: Inherent Properties of the Compositional Structure of Neural Networks
- **Authors:** Arthur Castello Branco de Oliveira, Dhruv Jatkar, Eduardo Sontag
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09810](https://arxiv.org/abs/2511.09810)
- **Reason:** 分析过参数化神经网络梯度流收敛性，证明任意实解析成本函数的全局收敛性，刻画优化景观结构特性（如鞍点稳定性），对深度学习理论优化景观与收敛性研究具核心理论价值。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] AdaptViG: Adaptive Vision GNN with Exponential Decay Gating
- **Authors:** Mustafa Munir (), Md Mostafijur Rahman (), Radu Marculescu ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09942](https://arxiv.org/abs/2511.09942)
- **Reason:** 提出自适应视觉GNN架构，通过指数衰减门控机制平衡长距离特征聚合与效率，相比ViG-B提升0.3%准确率且减少80%参数，是深度学习理论中Vision GNN网络架构的重要优化。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Physics informed Transformer-VAE for biophysical parameter estimation: PROSAIL model inversion in Sentinel-2 imagery
- **Authors:** Prince Mensah, Pelumi Victor Aderinto, Ibrahim Salihu Yusuf, Arnu Pretorius
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10387](https://arxiv.org/abs/2511.10387)
- **Reason:** 提出物理感知的Transformer-VAE架构，将PROSAIL辐射传输模型作为可微分解码器，实现生物物理参数的无监督估计，属于深度学习理论中的VAE架构创新，实验验证了在LAI和CCC retrieval上的准确性。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] SPOT: Sparsification with Attention Dynamics via Token Relevance in Vision Transformers
- **Authors:** Oded Schlesinger, Amirhossein Farzam, J. Matias Di Martino, Guillermo Sapiro
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10488](https://arxiv.org/abs/2511.10488)
- **Reason:** 提出ViT的token稀疏化框架，利用注意力动态与token相关性推断重要性，实现40%计算效率提升同时保持精度，属于深度学习理论中的网络架构优化，实验验证了在图像分类任务上的有效性。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Boosted GFlowNets: Improving Exploration via Sequential Learning
- **Authors:** Pedro Dall'Antonia, Tiago da Silva, Daniel Augusto de Souza, Césare Lincoln C. Mattos, Diego Mesquita
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09677](https://arxiv.org/abs/2511.09677)
- **Reason:** 提出Boosted GFlowNets，通过顺序训练ensemble优化残差奖励，解决探索不平衡问题，提升采样多样性与覆盖度，推动深度学习理论生成模型探索机制研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] TawPipe: Topology-Aware Weight Pipeline Parallelism for Accelerating Long-Context Large Models Training
- **Authors:** Houming Wu, Ling Chen
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09741](https://arxiv.org/abs/2511.09741)
- **Reason:** 提出TawPipe，利用集群拓扑优化权重管道并行，将通信限制在节点内以降低跨节点流量，提升长上下文大模型训练吞吐量与 scalability，对深度学习理论分布式训练优化具实用价值。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Koopman Invariants as Drivers of Emergent Time-Series Clustering in Joint-Embedding Predictive Architectures
- **Authors:** Pablo Ruiz-Morales, Dries Vanoost, Davy Pissoort, Mathias Verbeke
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09783](https://arxiv.org/abs/2511.09783)
- **Reason:** 提出JEPA预测目标隐含学习Koopman不变量，解释时间序列聚类现象，证明线性预测器的约束作用，为深度学习理论自监督表示学习内在机制提供理论支撑。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Learning Intersections of Halfspaces under Factorizable Distribution
- **Authors:** Ilias Diakonikolas, Mingchen Ma, Lisheng Ren, Christos Tzamos
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09832](https://arxiv.org/abs/2511.09832)
- **Reason:** 提出因子分布下半空间交集学习算法，突破CSQ的quasipolynomial复杂度壁垒，实现多项式时间学习，对深度学习理论可学习性与表示学习研究具重要贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Explore and Establish Synergistic Effects Between Weight Pruning and Coreset Selection in Neural Network Training
- **Authors:** Weilin Wan, Fan Yi, Weizhong Zhang, Quan Zhou, Cheng Jin
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09901](https://arxiv.org/abs/2511.09901)
- **Reason:** 探索权重剪枝与coreset选择的协同效应，提出SWaST机制解决双重损失问题，提升模型准确性（最高17.83%）与效率（FLOPs降低10%-90%），对深度学习理论模型压缩与效率优化具重要贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Incremental Generation is Necessity and Sufficient for Universality in Flow-Based Modelling
- **Authors:** Hossein Rouhvarzi, Anastasis Kratsios
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09902](https://arxiv.org/abs/2511.09902)
- **Reason:** 研究流基生成模型的通用近似性，证明增量生成对其universality的必要性与充分性，属于深度学习理论中生成模型的核心理论问题。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] A Novel Data-Dependent Learning Paradigm for Large Hypothesis Classes
- **Authors:** Alireza F. Pour, Shai Ben-David
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09996](https://arxiv.org/abs/2511.09996)
- **Reason:** 提出针对大假设类的新型数据依赖学习范式，分析其泛化能力，属于深度学习理论中的学习范式研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] BuddyMoE: Exploiting Expert Redundancy to Accelerate Memory-Constrained Mixture-of-Experts Inference
- **Authors:** Yun Wang, Lingyun Yang, Senhao Yu, Yixiao Wang, Ruixing Li, Zhixiang Wei, James Yen, Zhengwei Qi
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10054](https://arxiv.org/abs/2511.10054)
- **Reason:** 针对MoE模型的内存约束推理问题，提出利用专家冗余加速的方法，属于深度学习理论中网络架构（MoE）的优化研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Impact of Layer Norm on Memorization and Generalization in Transformers
- **Authors:** Rishi Singhal, Jung-Eun Kim
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10566](https://arxiv.org/abs/2511.10566)
- **Reason:** Analyzes the role of LayerNorm in memorization and learning for Pre- and Post-LayerNorm Transformers, providing key insights into a fundamental network component.
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Intilligence Foundation Model: A New Perspective to Approach Artificial General Intelligence
- **Authors:** Borui Cai, Yao Zhao
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10119](https://arxiv.org/abs/2511.10119)
- **Reason:** Introduces a state neural network architecture for AGI, combining biological inspiration with deep learning theory to model intelligent behavior.
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] RWKV-PCSSC: Exploring RWKV Model for Point Cloud Semantic Scene Completion
- **Authors:** Wenzhe He (), Xiaojun Chen (), Wentang Chen (), Hongyu Wang (), Ying Liu (), Ruihui Li ()
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09878](https://arxiv.org/abs/2511.09878)
- **Reason:** 将RWKV机制引入点云语义场景补全，提出轻量级网络架构（RWKV-SG与RWKV-PD模块），相比PointSSC减少4.18×参数并提升1.37×内存效率，是深度学习理论中网络架构在3D任务的创新应用。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Split-Layer: Enhancing Implicit Neural Representation by Maximizing the Dimensionality of Feature Space
- **Authors:** Zhicheng Cai, Hao Zhu, Linsen Chen, Qiu Shen, Xun Cao
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10142](https://arxiv.org/abs/2511.10142)
- **Reason:** 提出Split-Layer改进隐式神经表示（INR）的特征空间维度，通过分支分割和Hadamard乘积构建高次多项式空间，在图像拟合、CT重建、3D形状表示等任务上显著优于现有方法，属于深度学习理论中的网络架构创新。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Group Averaging for Physics Applications: Accuracy Improvements at Zero Training Cost
- **Authors:** Valentino F. Foit, David W. Hogg, Soledad Villar
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09573](https://arxiv.org/abs/2511.09573)
- **Reason:** 研究组平均对物理应用中模型准确性的提升，证明零训练成本下的泛化改进，揭示对称性对模型泛化的作用，为深度学习理论泛化机制研究提供新视角。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Generalization Can Emerge in Tabular Foundation Models From a Single Table
- **Authors:** Junwei Ma, Nour Shaheen, Alex Labach, Amine Mhedhbi, Frank Hutter, Anthony L. Caterini, Valentin Thomas
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09665](https://arxiv.org/abs/2511.09665)
- **Reason:** 发现单表自监督预训练可产生强泛化表格基础模型，分析数据任务量对泛化的影响，挑战大规模数据依赖的传统观点，为深度学习理论少样本泛化研究提供启发。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Is nasty noise actually harder than malicious noise?
- **Authors:** Guy Blanc, Yizhi Huang, Tal Malkin, Rocco A. Servedio
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09763](https://arxiv.org/abs/2511.09763)
- **Reason:** 比较恶意噪声与nasty噪声下的学习难度，证明分布独立与固定分布下的差异，提出ICE算法的等价性，为深度学习理论鲁棒学习可学习性研究提供新视角。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Fractional neural attention for efficient multiscale sequence processing
- **Authors:** Cheng Kevin Qu, Andrew Ly, Pulin Gong
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10208](https://arxiv.org/abs/2511.10208)
- **Reason:** 提出分数神经注意力机制，基于分数拉普拉斯算子实现多尺度序列处理，属于深度学习理论中注意力机制的创新研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] EDGC: Entropy-driven Dynamic Gradient Compression for Efficient LLM Training
- **Authors:** Qingao Yi, Jiaang Duan, Hanwen Hu, Qin Hua, Haiyan Zhao, Shiyou Qian, Dingyu Yang, Jian Cao, Jinghua Tang, Yinghao Yu, Chenzhi Liao, Kangjin Wang, Liping Zhang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10333](https://arxiv.org/abs/2511.10333)
- **Reason:** 提出熵驱动的动态梯度压缩框架，优化LLM训练的通信效率，属于深度学习理论中优化器（梯度优化）的研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Neuronal Fluctuations: Learning Rates vs Participating Neurons
- **Authors:** Darsh Pareek, Umesh Kumar, Ruthu Rao, Ravi Janjam
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10435](https://arxiv.org/abs/2511.10435)
- **Reason:** 系统研究学习率对神经网络权重波动的影响，建立学习率与模型性能的关联，属于深度学习理论中优化器（学习率）的研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Holonorm
- **Authors:** Daryl Noupa Yongueng, Hamidou Tembine
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10504](https://arxiv.org/abs/2511.10504)
- **Reason:** Proposes Holonorm, a novel normalization method for Transformers that addresses limitations of Tanh and softsign, relevant to network architecture in deep learning theory.
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Belief Net: A Filter-Based Framework for Learning Hidden Markov Models from Observations
- **Authors:** Reginald Zhiyan Chen, Heng-Sheng Chang, Prashant G. Mehta
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10571](https://arxiv.org/abs/2511.10571)
- **Reason:** Introduces Belief Net, a structured neural network framework for learning HMMs that combines traditional probabilistic models with deep learning architecture.
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Semi-Unified Sparse Dictionary Learning with Learnable Top-K LISTA and FISTA Encoders
- **Authors:** Fengsheng Lin, Shengyi Yan, Trac Duy Tran
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10575](https://arxiv.org/abs/2511.10575)
- **Reason:** Combines sparse dictionary learning with deep LISTA/FISTA encoders, bridging traditional sparse models with modern deep learning architecture.
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Adaptive Hyperbolic Kernels: Modulated Embedding in de Branges-Rovnyak Spaces
- **Authors:** Leping Si, Meimei Yang, Hui Xue, Shipeng Zhu, Pengfei Fang
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.09921](https://arxiv.org/abs/2511.09921)
- **Reason:** Proposes adaptive hyperbolic kernels for hierarchical data (NLP, CV), enhancing network architecture for handling complex hierarchical structures.
Score: 7
Field: 深度学习理论

### [Score: 6.0/10] Gradient Flow Equations for Deep Linear Neural Networks: A Survey from a Network Perspective
- **Authors:** Joel Wendin, Claudio Altafini
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10362](https://arxiv.org/abs/2511.10362)
- **Reason:** 综述深度线性神经网络的梯度流方程，分析其动力学与损失景观，属于深度学习理论中梯度流的理论研究。
Score: 6
Field: 深度学习理论

## Autonomous driving and big models

### [Score: 9.0/10] nuPlan-R: A Closed-Loop Planning Benchmark for Autonomous Driving via Reactive Multi-Agent Simulation
- **Authors:** Mingxing Peng, Ruoyu Yao, Xusen Guo, Jun Ma
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10403](https://arxiv.org/abs/2511.10403)
- **Reason:** Develops a reactive closed-loop planning benchmark for autonomous driving using learning-based agents, improving realistic evaluation of planning algorithms which is critical for autonomous driving research.
Score: 9
Field: Autonomous driving and big models

### [Score: 8.0/10] Querying Labeled Time Series Data with Scenario Programs
- **Authors:** Edward Kim, Devan Shanker, Varun Bharadwaj, Hongbeen Park, Jinkyu Kim, Hazem Torfah, Daniel J Fremont, Sanjit A Seshia
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10627](https://arxiv.org/abs/2511.10627)
- **Reason:** Introduces a framework to query labeled time series data for AV failure scenarios, bridging the sim-to-real gap in autonomous driving which fits the autonomous driving and big models direction.
Score: 8
Field: Autonomous driving and big models

### [Score: 8.0/10] LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction
- **Authors:** Benjamin Stoler, Jonathan Francis, Jean Oh
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10411](https://arxiv.org/abs/2511.10411)
- **Reason:** Addresses long-tail compositional zero-shot generalization for trajectory prediction in autonomous driving, enhancing robustness to rare safety-critical scenarios which aligns with autonomous driving research.
Score: 8
Field: Autonomous driving and big models

## 深度学习可解释性

### [Score: 8.0/10] How does My Model Fail? Automatic Identification and Interpretation of Physical Plausibility Failure Modes with Matryoshka Transcoders
- **Authors:** Yiming Tang, Abhijeet Sinha, Dianbo Liu
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10094](https://arxiv.org/abs/2511.10094)
- **Reason:** 提出Matryoshka Transcoders框架，自动识别并解释生成模型的物理合理性失败模式，属于深度学习可解释性中的故障模式解释研究。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Improving Perturbation-based Explanations by Understanding the Role of Uncertainty Calibration
- **Authors:** Thomas Decker, Volker Tresp, Florian Buettner
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10439](https://arxiv.org/abs/2511.10439)
- **Reason:** 研究不确定性校准对扰动基解释的影响，提出ReCalX方法改进解释鲁棒性，属于深度学习可解释性中的扰动解释优化研究。
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Physically Interpretable Multi-Degradation Image Restoration via Deep Unfolding and Explainable Convolution
- **Authors:** Hu Gao, Xiaoning Lei, Xichen Xu, Depeng Dang, Lizhuang Ma
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10166](https://arxiv.org/abs/2511.10166)
- **Reason:** 结合深度展开网络和可解释卷积模块，实现多退化图像恢复的物理可解释性，解决了现有方法模态分离和可解释性差的问题，实验验证了在多退化任务上的有效性，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] eXIAA: eXplainable Injections for Adversarial Attack
- **Authors:** Leonardo Pesce, Jiawen Wei, Gianmarco Mengaldo
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10088](https://arxiv.org/abs/2511.10088)
- **Reason:** 提出针对后验可解释性方法的黑盒对抗攻击，暴露解释方法的脆弱性，属于深度学习可解释性中的鲁棒性研究。
Score: 7
Field: 深度学习可解释性

## Deep learning explainability

### [Score: 8.0/10] Explaining Decentralized Multi-Agent Reinforcement Learning Policies
- **Authors:** Kayla Boggess, Sarit Kraus, Lu Feng
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10409](https://arxiv.org/abs/2511.10409)
- **Reason:** Focuses on generating policy summarizations and query-based explanations for decentralized MARL policies, addressing a key gap in explainable AI for multi-agent systems which fits deep learning explainability.
Score: 8
Field: Deep learning explainability

### [Score: 7.0/10] Beyond Verification: Abductive Explanations for Post-AI Assessment of Privacy Leakage
- **Authors:** Belona Sonna, Alban Grastien, Claire Benn
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10284](https://arxiv.org/abs/2511.10284)
- **Reason:** Proposes a formal framework using abductive explanations to audit AI privacy leakage, generating human-understandable explanations that align with the deep learning explainability focus on white-box explanation.
Score: 7
Field: Deep learning explainability

### [Score: 7.0/10] Using Certifying Constraint Solvers for Generating Step-wise Explanations
- **Authors:** Ignace Bleukx, Maarten Flippo, Bart Bogaerts, Emir Demirović, Tias Guns
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10428](https://arxiv.org/abs/2511.10428)
- **Reason:** Uses constraint solver proofs to accelerate step-wise explanation generation, improving the efficiency of explainable AI which is core to deep learning explainability.
Score: 7
Field: Deep learning explainability

### [Score: 7.0/10] Preference Elicitation for Step-Wise Explanations in Logic Puzzles
- **Authors:** Marco Foschini, Marianne Defresne, Emilio Gamba, Bart Bogaerts, Tias Guns
- **Published:** 2025-11-14
- **Link:** [https://arxiv.org/abs/2511.10436](https://arxiv.org/abs/2511.10436)
- **Reason:** Investigates interactive preference elicitation to learn user preferences for step-wise explanations in logic puzzles, enhancing explainability via user-centric design which aligns with deep learning explainability.
Score: 7
Field: Deep learning explainability

