<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-18</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>多模态大模型</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >深度学习理论</a>
<a href='#' >自动驾驶与大模型</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-18</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-18 12:27:17</p>
<p>已自动阅读了 252 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：129168</p>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Fast Data Attribution for Text-to-Image Models</h3>
<p><strong>Authors:</strong> Sheng-Yu Wang (unknown), Aaron Hertzmann (unknown), Alexei A Efros (University of California, Berkeley), Richard Zhang (unknown), Jun-Yan Zhu (Carnegie Mellon University)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出高效数据归因方法解决文本到图像模型计算量大问题，对多模态生成模型的可解释性和数据影响分析有重要价值
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10721' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Abstract 3D Perception for Spatial Intelligence in Vision-Language Models</h3>
<p><strong>Authors:</strong> Yifan Liu (unknown), Fangneng Zhan (unknown), Kaichen Zhou (unknown), Yilun Du (unknown), Paul Pu Liang (Columbia University), Hanspeter Pfister (Harvard University)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出SandboxVLM框架解决VLM在3D任务中的模态gap问题，提升空间推理和物理理解能力
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10946' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Draft and Refine with Visual Experts</h3>
<p><strong>Authors:</strong> Sungheon Jeong (unknown), Ryozo Masukawa (unknown), Jihong Park (unknown), Sanggeon Yun (unknown), Wenjun Huang (unknown), Hanning Chen (unknown), Mahdi Imani (unknown), Mohsen Imani (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出DnR框架解决LVLM幻觉问题，通过视觉专家反馈提升视觉接地能力
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11005' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> VisMem: Latent Vision Memory Unlocks Potential of Vision-Language Models</h3>
<p><strong>Authors:</strong> Xinlei Yu (unknown), Chengming Xu (unknown), Guibin Zhang (unknown), Zhangquan Chen (unknown), Yudong Zhang (unknown), Yongbo He (unknown), Peng-Tao Jiang (unknown), Jiangning Zhang (unknown), Xiaobin Hu (unknown), Shuicheng Yan (National University of Singapore)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出VisMem框架解决VLM视觉处理瓶颈，提升视觉接地和生成一致性
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11007' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> NP-LoRA: Null Space Projection Unifies Subject and Style in LoRA Fusion</h3>
<p><strong>Authors:</strong> Chuheng Chen (unknown), Xiaofei Zhou (unknown), Geyuan Zhang (unknown), Yong Huang (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出NP-LoRA方法解决LoRA融合中的主题与风格干扰问题，提升生成一致性
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11051' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Co-EPG: A Framework for Co-Evolution of Planning and Grounding in Autonomous GUI Agents</h3>
<p><strong>Authors:</strong> Yuan Zhao, Hualei Zhu, Tingyu Jiang, Shen Li, Xiaohang Xu, Hao Henry Wang</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 针对自主GUI代理的规划与接地协同进化框架，解决当前GUI Agent中交叉模型协同不足和过度依赖合成数据的问题，符合多模态大模型中的GUI Agent与GUI Grounding研究方向，实验验证在基准数据集上优于现有方法。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10705' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Out-of-Distribution Detection with Positive and Negative Prompt Supervision Using Large Language Models</h3>
<p><strong>Authors:</strong> Zhixia He (unknown), Chen Zhao (unknown), Minglai Shao (unknown), Xintao Wu (unknown), Xujiang Zhao (unknown), Dong Li (unknown), Qin Tian (unknown), Linlin Yu (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 利用大语言模型生成正负prompt增强多模态模型OOD检测能力，提升开放场景鲁棒性
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10923' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Preserving Cross-Modal Consistency for CLIP-based Class-Incremental Learning</h3>
<p><strong>Authors:</strong> Haoran Chen (unknown), Houze Xu (unknown), Micah Goldblum (unknown), Daoguo Dong (unknown), Zuxuan Wu (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出DMC框架解决CLIP增量学习中的跨模态一致性问题，提升连续学习性能
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10974' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PAS: A Training-Free Stabilizer for Temporal Encoding in Video LLMs</h3>
<p><strong>Authors:</strong> Bowen Sun (unknown), Yujun Cai (unknown), Ming-Hsuan Yang (University of California, Merced), Hang Wu (unknown), Yiwei Wang (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出PAS训练-free方法解决视频LLM时间不一致问题，提升视频理解鲁棒性
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10979' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CLUE: Controllable Latent space of Unprompted Embeddings for Diversity Management in Text-to-Image Synthesis</h3>
<p><strong>Authors:</strong> Keunwoo Park (unknown), Jihye Chae (unknown), Joong Ho Ahn (unknown), Jihoon Kweon (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出CLUE框架实现文本到图像合成的多样性和稳定性，无需额外数据，在医疗场景表现优异
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10993' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PROMISE: Prompt-Attentive Hierarchical Contrastive Learning for Robust Cross-Modal Representation with Missing Modalities</h3>
<p><strong>Authors:</strong> Jiajun Chen (unknown), Sai Cheng (unknown), Yutao Yuan (unknown), Yirui Zhang (unknown), Haitao Yuan (unknown), Peng Peng (unknown), Yi Zhong (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出PROMISE框架解决缺失模态下的跨模态表示问题，提升模型鲁棒性
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.10997' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SP-Guard: Selective Prompt-adaptive Guidance for Safe Text-to-Image Generation</h3>
<p><strong>Authors:</strong> Sumin Yu (unknown), Taesup Moon (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出SP-Guard方法解决文本到图像生成安全问题，提升安全性同时最小化内容改变
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11014' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Accelerating Controllable Generation via Hybrid-grained Cache</h3>
<p><strong>Authors:</strong> Lin Liu (unknown), Huixia Ben (unknown), Shuo Wang (unknown), Jinda Lu (unknown), Junxiang Qiu (unknown), Shengeng Tang (unknown), Yanbin Hao (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出HGC方法通过混合粒度缓存加速可控生成，平衡效率与质量
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11031' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hyperbolic Hierarchical Alignment Reasoning Network for Text-3D Retrieval</h3>
<p><strong>Authors:</strong> Wenrui Li (unknown), Yidan Lu (unknown), Yeyu Chai (unknown), Rui Zhao (unknown), Hengyu Man (unknown), Xiaopeng Fan (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出H²ARN框架用双曲空间解决文本-3D检索的层次表示和冗余问题，提升跨模态匹配性能
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11045' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LiteAttention: A Temporal Sparse Attention for Diffusion Transformers</h3>
<p><strong>Authors:</strong> Dor Shmilovich (unknown), Tony Wu (unknown), Aviad Dahan (unknown), Yuval Domb (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出LiteAttention时间稀疏注意力，减少扩散Transformer计算开销，提升视频生成效率
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11062' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VIDEOP2R: Video Understanding from Perception to Reasoning</h3>
<p><strong>Authors:</strong> Yifan Jiang, Yueying Wang, Rui Zhao, Toufiq Parag, Zhimin Chen, Zhenyu Liao, Jayakrishnan Unnikrishnan</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 针对大视频语言模型（LVLMs）的强化微调问题，提出过程感知的RFT框架提升视频推理能力，属于多模态大模型研究范畴。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11113' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hindsight Distillation Reasoning with Knowledge Encouragement Preference for Knowledge-based Visual Question Answering</h3>
<p><strong>Authors:</strong> Yu Zhao, Ying Zhang, Xuhui Sui, Baohang Zhou, Li Shen, Dacheng Tao</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出HinD框架解决多模态大语言模型（MLLMs）的知识推理问题，提升知识型VQA任务性能，属于多模态大模型方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11132' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Viper-F1: Fast and Fine-Grained Multimodal Understanding with Cross-Modal State-Space Modulation</h3>
<p><strong>Authors:</strong> Quoc-Huy Trinh, Mustapha Abdullahi, Do Duy Hung Trinh, Bo Zhao, Debesh Jha</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出跨模态状态空间调制模型提升多模态细粒度理解效率，属于多模态大模型中的multimodal understanding方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11177' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Discovering Meaningful Units with Visually Grounded Semantics from Image Captions</h3>
<p><strong>Authors:</strong> Melika Behjati, James Henderson</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 从图像字幕中发现视觉接地的语义单元，属于多模态大模型中的GUI Grounding方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11262' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Comprehension of Multilingual Expressions Referring to Target Objects in Visual Inputs</h3>
<p><strong>Authors:</strong> Francisco Nogueira, Alexandre Bernardino, Bruno Martins</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 研究多语言表达式的视觉接地，属于多模态大模型中的GUI Grounding与multilingual visual grounding方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11427' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> WEAVE: Unleashing and Benchmarking the In-context Interleaved Comprehension and Generation</h3>
<p><strong>Authors:</strong> Wei Chow, Jiachun Pan, Yongyuan Liang, Mingze Zhou, Xue Song, Liyu Jia, Saining Zhang, Siliang Tang, Juncheng Li, Fengda Zhang, Weijia Wu, Hanwang Zhang, Tat-Seng Chua</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出WEAVE基准测试多模态模型的上下文交互理解与生成，属于多模态大模型中的benchmark与模型评估。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11434' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VP-Bench: A Comprehensive Benchmark for Visual Prompting in Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Mingjie Xu, Jinpeng Chen, Yuzhi Zhao, Jason Chun Lok Li, Yue Qiu, Zekang Du, Mengyang Wu, Pingping Zhang, Kun Li, Hongzheng Yang, Wenao Ma, Jiaheng Wei, Qinbin Li, Kangcheng Liu, Wenqiang Lei</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出首个系统评估多模态大语言模型（MLLMs）视觉提示理解能力的基准，覆盖8种形状、355种属性组合的3万条可视化提示，评估28个主流MLLMs（含GPT-4o、InternVL3等），分析VP属性、问题排列、模型规模等关键影响因素，为多模态大模型的视觉grounding研究提供核心参考框架。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11438' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ImAgent: A Unified Multimodal Agent Framework for Test-Time Scalable Image Generation</h3>
<p><strong>Authors:</strong> Kaishen Wang, Ruibo Chen, Tong Zheng, Heng Huang</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出训练-free的统一多模态代理框架，整合推理、生成、自评估流程，解决文本到图像生成的随机性与语义不一致问题，提升图像生成的 fidelity与语义对齐度，为多模态大模型的图像生成任务提供高效解决方案。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11483' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Bridging Hidden States in Vision-Language Models</h3>
<p><strong>Authors:</strong> Benjamin Fein-Ashley, Jacob Fein-Ashley</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 针对视觉语言模型的模态融合问题，提出轻量跨模态注意力层，直接对齐视觉与文本编码器的隐藏状态，在保持双编码器效率的同时提升检索、VQA等任务性能，对多模态大模型的架构设计与模态融合研究有创新贡献。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11526' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DiffPro: Joint Timestep and Layer-Wise Precision Optimization for Efficient Diffusion Inference</h3>
<p><strong>Authors:</strong> Farhana Amin, Sabiha Afroz, Kanchon Gharami, Mona Moghadampanah, Dimitrios S. Nikolopoulos</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出联合优化扩散模型时间步和层精度的框架，在减少推理成本的同时保持生成质量，符合多模态大模型中的image generation研究方向，实验验证在标准基准上取得显著效率提升。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11446' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities</h3>
<p><strong>Authors:</strong> Yiyun Zhou (Zhejiang University), Mingjing Xu (Zhejiang University), Jingwei Shi (Zhejiang University), Quanjiang Li (Zhejiang University), Jingyuan Chen (Zhejiang University)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出TLV-CoRe方法，用于触觉-语言-视觉多模态协作表示学习，引入Sensor-Aware Modulator和Unified Bridging Adapter提升跨模态对齐与传感器无关表示，与多模态大模型方向高度相关
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11512' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EmoVid: A Multimodal Emotion Video Dataset for Emotion-Centric Video Understanding and Generation</h3>
<p><strong>Authors:</strong> Zongyang Qiu (unknown), Bingyuan Wang (unknown), Xingbei Chen (unknown), Yingqing He (unknown), Zeyu Wang (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 构建EmoVid多模态情感视频数据集，支持情感中心的视频理解和生成
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11002' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Evaluating Latent Generative Paradigms for High-Fidelity 3D Shape Completion from a Single Depth Image</h3>
<p><strong>Authors:</strong> Matthias Humt (unknown), Ulrich Hillenbrand (unknown), Rudolph Triebel (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 比较扩散与自回归模型在3D形状补全中的性能，为多模态模型选择提供依据
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11074' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Refine and Align: Confidence Calibration through Multi-Agent Interaction in VQA</h3>
<p><strong>Authors:</strong> Ayush Pandey, Jai Bardhan, Ishita Jain, Ramya S Hebbalaguppe, Rohan Raju Dhanakshirur, Lovekesh Vig</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出多智能体交互的VQA置信度校准方法，涉及视觉语言模型（VLMs），属于多模态大模型方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11169' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Geospatial Chain of Thought Reasoning for Enhanced Visual Question Answering on Satellite Imagery</h3>
<p><strong>Authors:</strong> Shambhavi Shanker, Manikandan Padmanaban, Jagabondhu Hazra</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 结合地理空间链思维提升卫星图像VQA性能，属于多模态大模型中的VQA任务。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11198' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Questioning the Stability of Visual Question Answering</h3>
<p><strong>Authors:</strong> Amir Rosenfeld, Neta Glazer, Ethan Fetaya</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 研究视觉问答模型的稳定性，涉及视觉语言模型（VLMs）的鲁棒性，属于多模态大模型方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11206' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CountSteer: Steering Attention for Object Counting in Diffusion Models</h3>
<p><strong>Authors:</strong> Hyemin Boo, Hyoryung Kim, Myungjin Lee, Seunghyeon Lee, Jiyoung Lee, Jang-Hwan Choi, Hyunsoo Cho</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出注意力引导方法提升扩散模型的目标计数能力，属于多模态大模型中的image generation方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11253' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> AUVIC: Adversarial Unlearning of Visual Concepts for Multi-modal Large Language Models</h3>
<p><strong>Authors:</strong> Haokun Chen, Jianing Li, Yao Zhang, Jinhe Bi, Yan Xia, Jindong Gu, Volker Tresp</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出对抗性遗忘方法用于多模态大模型的视觉概念移除，属于多模态大模型中的模型优化与隐私保护。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11299' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DocSLM: A Small Vision-Language Model for Long Multimodal Document Understanding</h3>
<p><strong>Authors:</strong> Tanveer Hannan, Dimitrios Mallios, Parth Pathak, Faegheh Sardari, Thomas Seidl, Gedas Bertasius, Mohsen Fayyaz, Sunando Sengupta</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出小视觉语言模型用于长文档多模态理解，属于多模态大模型中的multimodal document understanding方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11313' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> BOFA: Bridge-Layer Orthogonal Low-Rank Fusion for CLIP-Based Class-Incremental Learning</h3>
<p><strong>Authors:</strong> Lan Li, Tao Hu, Da-Wei Zhou, Han-Jia Ye, De-Chuan Zhan</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出CLIP的桥接层正交低秩融合方法用于类增量学习，属于多模态大模型中的CLIP改进与增量学习。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11421' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Synthetic Scenes to Real Performance: Enhancing Spatial Reasoning in VLMs</h3>
<p><strong>Authors:</strong> Massimo Rizzoli, Simone Alghisi, Seyed Mahed Mousavi, Giuseppe Riccardi</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 针对视觉语言模型（VLMs）空间推理的偏差与过拟合问题，提出控制合成数据生成与标注的方法，减少数据分布不均，提升真实场景的空间推理性能，对多模态大模型的视觉理解与推理能力增强有重要应用价值。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11440' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PAS : Prelim Attention Score for Detecting Object Hallucinations in Large Vision--Language Models</h3>
<p><strong>Authors:</strong> Nhat Hoang-Xuan, Minh Vu, My T. Thai, Manish Bhattarai</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 针对大视觉语言模型的物体幻觉问题，提出轻量、训练-free的Prelim Attention Score，通过注意力权重量化模型对输入图像的依赖，实现实时幻觉检测，对多模态大模型的鲁棒性与可靠性研究有重要意义。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11502' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Low-Bit, High-Fidelity: Optimal Transport Quantization for Flow Matching</h3>
<p><strong>Authors:</strong> Dara Varam, Diaa A. Abuhani, Imran Zualkernan, Raghad AlDamani, Lujain Khalil</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 将最优传输量化应用于Flow Matching生成模型，在低比特条件下保持生成质量和潜在空间稳定性，属于多模态大模型中的image generation方向，优于现有量化方案。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11418' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Scalable Policy Evaluation with Video World Models</h3>
<p><strong>Authors:</strong> Wei-Cheng Tseng (NVIDIA), Jinwei Gu (NVIDIA), Qinsheng Zhang (NVIDIA), Hanzi Mao (NVIDIA), Ming-Yu Liu (NVIDIA), Florian Shkurti (University of Toronto), Lin Yen-Chen (NVIDIA)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 探索用动作条件视频生成模型作为世界模型进行机器人策略评估，利用互联网视频预训练缓解数据收集成本，涉及多模态（视频、动作）世界模型，与多模态大模型方向相关
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11520' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> PhaseWin Search Framework Enable Efficient Object-Level Interpretation</h3>
<p><strong>Authors:</strong> Zihan Gu (unknown), Ruoyu Chen (unknown), Junchi Zhang (Shanghai Jiao Tong University), Yue Hu (unknown), Hua Zhang (unknown), Xiaochun Cao (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出PhaseWin算法解决目标级模型归因效率问题，实现高忠实度区域归因，提升可解释性的实际部署能力
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.10914' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Explainable Deep Convolutional Multi-Type Anomaly Detection</h3>
<p><strong>Authors:</strong> Alex George, Lyudmila Mihaylova, Sean Anderson</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出可解释的多类型异常检测框架，解决异常检测的可解释性问题，属于深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.11165' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Accuracy-Preserving CNN Pruning Method under Limited Data Availability</h3>
<p><strong>Authors:</strong> Daisuke Yasui (unknown), Toshitaka Matsuki (unknown), Hiroshi Sato (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 利用可解释AI技术LRP改进CNN剪枝，在有限数据下保持精度，展示可解释性方法在模型压缩中的实际应用价值
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.10861' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ERMoE: Eigen-Reparameterized Mixture-of-Experts for Stable Routing and Interpretable Specialization</h3>
<p><strong>Authors:</strong> Anzhe Cheng (unknown), Shukai Duan (unknown), Shixuan Li (unknown), Chenzhong Yin (unknown), Mingxi Cheng (unknown), Heng Ping (unknown), Tamoghna Chattopadhyay (unknown), Sophia I Thomopoulos (unknown), Shahin Nazarian (unknown), Paul Thompson (unknown), Paul Bogdan (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出ERMoE架构解决MoE路由不稳定和专家利用问题，提升模型可解释性，对深度学习理论中的模型设计有贡献
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.10971' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Optimizing Mixture of Block Attention</h3>
<p><strong>Authors:</strong> Guangxuan Xiao, Junxian Guo, Kasra Mazaheri, Song Han</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 分析Mixture of Block Attention（MoBA）架构的性能机制，提出硬件感知的FlashMoBA优化GPU实现，属于深度学习理论中的network architecture研究方向，提升LLM长上下文处理效率。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11571' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Arcee: Differentiable Recurrent State Chain for Generative Vision Modeling with Mamba SSMs</h3>
<p><strong>Authors:</strong> Jitesh Chavan, Rohit Lal, Anand Kamat, Mengjia Xu</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出Arcee改进Mamba模型的递归状态链，提升生成视觉建模性能，属于深度学习理论中的network architecture方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11243' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Training Neural Networks at Any Scale</h3>
<p><strong>Authors:</strong> Thomas Pethick, Kimon Antonakopoulos, Antonio Silveti-Falls, Leena Chennuru Vankadara, Volkan Cevher</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 综述大规模神经网络训练的现代优化方法，强调适应问题结构的重要性，属于深度学习理论中的optimizer研究方向，为大模型训练提供方法指导。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11163' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Rethinking Autoregressive Models for Lossless Image Compression via Hierarchical Parallelism and Progressive Adaptation</h3>
<p><strong>Authors:</strong> Daxin Li (unknown), Yuanchao Bai (unknown), Kai Wang (unknown), Wenbo Zhao (unknown), Junjun Jiang (unknown), Xianming Liu (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出HPAC自回归模型解决传统模型计算成本高问题，实现高效无损图像压缩
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.10991' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SUPER Decoder Block for Reconstruction-Aware U-Net Variants</h3>
<p><strong>Authors:</strong> Siheon Joo (unknown), Hongjo Kim (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出SUPER解码器块改进U-Net重建能力，提升高频率细节恢复效果
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11015' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> OT-ALD: Aligning Latent Distributions with Optimal Transport for Accelerated Image-to-Image Translation</h3>
<p><strong>Authors:</strong> Zhanpeng Wang, Shuting Cao, Yuhang Lu, Yuhan Li, Na Lei, Zhongxuan Luo</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出基于最优传输的潜在分布对齐方法加速图像翻译，属于深度学习理论中的模型改进与优化。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11162' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Parameter-Efficient MoE LoRA for Few-Shot Multi-Style Editing</h3>
<p><strong>Authors:</strong> Cong Cao, Yujie Xu, Xiaodong Xu</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出参数高效的MoE LoRA方法用于少样本多风格编辑，属于深度学习理论中的模型架构与参数优化。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11236' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Multistability of Self-Attention Dynamics in Transformers</h3>
<p><strong>Authors:</strong> Claudio Altafini</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 研究Transformer自注意力动力学的多稳定性，分类均衡点为共识、二分共识等类型，属于深度学习理论中的network architecture方向，深化对Transformer结构动态行为的理解。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11553' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Semantic VLM Dataset for Safe Autonomous Driving</h3>
<p><strong>Authors:</strong> Yuankai He (unknown), Weisong Shi (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 针对自动驾驶场景构建用于训练视觉-语言模型的语义数据集，支持可解释的场景级理解，为自动驾驶中的多模态大模型应用提供数据基础
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.10701' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AirCopBench: A Benchmark for Multi-drone Collaborative Embodied Perception and Reasoning</h3>
<p><strong>Authors:</strong> Jirong Zha (unknown), Yuxuan Fan (unknown), Tianyu Zhang (unknown), Geng Chen (unknown), Yingfeng Chen (unknown), Chen Gao (unknown), Xinlei Chen (unknown)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 构建多无人机协作感知基准，评估多模态大模型协作能力，为自动驾驶多agent系统提供评估工具
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11025' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GraphPilot: Grounded Scene Graph Conditioning for Language-Based Autonomous Driving</h3>
<p><strong>Authors:</strong> Fabian Schmidt, Markus Enzweiler, Abhinav Valada</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出场景图条件的语言驱动自动驾驶方法，属于自动驾驶与大模型中的language-based autonomous driving任务。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11266' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Autonomous Vehicle Path Planning by Searching With Differentiable Simulation</h3>
<p><strong>Authors:</strong> Asen Nachkov (ETH Zurich), Jan-Nico Zaech (ETH Zurich), Danda Pani Paudel (ETH Zurich), Xi Wang (ETH Zurich), Luc Van Gool (ETH Zurich)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 研究自动驾驶路径规划，提出Differentiable Simulation for Search (DSS)框架，利用可微分模拟器Waymax优化动作序列，提升路径规划精度和效率，与自动驾驶与大模型方向高度相关
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11043' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Reverberation: Learning the Latencies Before Forecasting Trajectories</h3>
<p><strong>Authors:</strong> Conghao Wong, Ziqian Zou, Beihao Xia, Xinge You</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出Reverberation模型学习轨迹预测中的延迟，属于自动驾驶与大模型中的轨迹预测任务。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11164' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CATS-V2V: A Real-World Vehicle-to-Vehicle Cooperative Perception Dataset with Complex Adverse Traffic Scenarios</h3>
<p><strong>Authors:</strong> Hangyu Li, Bofeng Cao, Zhaohui Liang, Wuzhen Li, Juyoung Oh, Yuxuan Chen, Shixiao Liang, Hang Zhou, Chengyuan Ma, Jiaxi Liu, Zheng Li, Peng Zhang, KeKe Long, Maolin Liu, Jackson Jiang, Chunlei Yu, Shengxiang Liu, Hongkai Yu, Xiaopeng Li</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 构建车车协作感知数据集，针对复杂交通场景，为自动驾驶研究提供数据支撑，属于自动驾驶与大模型方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11168' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Miniature Testbed for Validating Multi-Agent Cooperative Autonomous Driving</h3>
<p><strong>Authors:</strong> Hyunchul Bae (Seoul National University), Eunjae Lee (Seoul National University), Jehyeop Han (Seoul National University), Minhee Kang (Seoul National University), Jaehyeon Kim (Seoul National University), Junggeun Seo (Seoul National University), Minkyun Noh (Seoul National University), Heejin Ahn (Seoul National University)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 提出用于验证多智能体协作自动驾驶的微型测试床，集成ROS2和CARLA，支持V2V/V2I通信与协作驾驶功能验证，与自动驾驶与大模型方向相关
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11022' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Simulating an Autonomous System in CARLA using ROS 2</h3>
<p><strong>Authors:</strong> Joseph Abdo (Khalifa University), Aditya Shibu (Khalifa University), Moaiz Saeed (Khalifa University), Abdul Maajid Aga (Khalifa University), Apsara Sivaprazad (Khalifa University), Mohamed Al-Musleh (Khalifa University)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 基于CARLA和ROS2构建自动驾驶系统模拟框架，针对Formula Student UK Driverless竞赛验证感知、规划与控制模块，与自动驾驶与大模型方向相关
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11310' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> A Comparative Evaluation of Prominent Methods in Autonomous Vehicle Certification</h3>
<p><strong>Authors:</strong> Mustafa Erdem Kırmızıgül (Istanbul Technical University), Hasan Feyzi Doğruyol (Istanbul Technical University), Haluk Bayram (Istanbul Technical University)</p>
<p><strong>Published:</strong> 2025-11-17</p>
<p><strong>Reason:</strong> 比较评估自动驾驶车辆认证的主要方法，提出认证流程 pipeline，涉及安全要求验证与方法应用，与自动驾驶与大模型方向相关
Score: 6
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2511.11484' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>