<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-19</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >深度学习理论</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >大模型新技术</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-19</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-19 12:54:23</p>
<p>已自动阅读了 665 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：341376</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video Multimodal Language Models</h3>
<p><strong>Authors:</strong> Siyou Li, Huanan Wu, Juexi Shao, Yinghao Ma, Yujian Gan, Yihao Luo, Yuwei Wang, Dong Nie, Lu Wang, Wengqing Wu, Le Zhang, Massimo Poesio, Juntao Yu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Query-aware Token Selector（QTSplus）动态选择长视频关键视觉token，集成到Qwen2.5-VL后实现89%视觉流压缩与28%延迟降低，在8项长视频基准上保持精度，属于原生多模态大模型中的长视频处理与tokenizer优化方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11910' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Target-Balanced Score Distillation</h3>
<p><strong>Authors:</strong> Zhou Xu, Qi Wang, Yuxiao Yang, Luyuan Zhang, Zhang Liang, Yang Li</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Target-Balanced Score Distillation（TBSD）解决Score Distillation Sampling（SDS）的过饱和、过平滑问题，通过多目标优化平衡纹理真实度与形状准确性，提升3D资产生成质量，属于原生多模态大模型中的3D图像生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11710' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing</h3>
<p><strong>Authors:</strong> Hossein Mohebbi, Mohammed Abdulrahman, Yanting Miao, Pascal Poupart, Suraj Kothawade</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出反射式强化学习框架Image-POSER，协调多专家模型处理长prompt的图像生成与编辑，在对齐、保真度和美学上优于基线模型，且人类评估更偏好，属于原生多模态大模型中的图像生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11780' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial Close-ups</h3>
<p><strong>Authors:</strong> Songsong Zhang, Chuanqi Tang, Hongguang Zhang, Guijian Tang, Minglong Li, Xueqiong Li, Shaowu Yang, Yuanxi Peng, Wenjing Yang, Jing Zhao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Dual-Line Inference（DLI）与Identity Adaptive Fusion（IdAF）策略，打破面部特写限制，实现身份保留与场景语义的协同优化，支持电影级角色-场景生成，属于原生多模态大模型中的个性化图像生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11989' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound</h3>
<p><strong>Authors:</strong> Dengming Zhang, Weitao You, Jingxiong Li, Weishen Lin, Wenda Shi, Xue Zhao, Heda Zuo, Junxian Wu, Lingyun Sun</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出VAEmotionLLM框架，通过视觉引导音频对齐让VLM理解视听情感，在ArtEmoBenchmark上取得SOTA结果，属于原生多模态大模型中的视听多模态融合方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12077' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Direct Visual Grounding by Directing Attention of Visual Tokens</h3>
<p><strong>Authors:</strong> Parsa Esmaeilkhani, Longin Jan Latecki</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对VLMs中视觉token注意力不足的核心问题，提出KLAL损失直接监督视觉token的注意力分布，显著提升视觉接地任务性能，对原生多模态大模型的视觉-语言对齐有重要改进。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12738' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding</h3>
<p><strong>Authors:</strong> Jiaze Li, Hao Yin, Wenhui Tan, Jingyang Chen, Boshen Xu, Yuxun Qu, Yijing Chen, Jianzhong Ju, Zhenbo Luo, Jian Luan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对长视频理解的文本反射不足问题，提出多模态内省推理框架REVISOR，结合视觉段引导和DADR奖励机制，显著提升多模态LLM的长视频推理能力，对原生多模态大模型的复杂任务适应有重要改进。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13026' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> 3DAlign-DAER: Dynamic Attention Policy and Efficient Retrieval Strategy for Fine-grained 3D-Text Alignment at Scale</h3>
<p><strong>Authors:</strong> Yijia Fan, Jusheng Zhang, Kaitong Cai, Jing Yang, Jian Wang, Keze Wang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对3D-文本跨模态对齐的细粒度语义匹配与大尺度数据库性能下降问题，提出动态注意力策略（DAP）捕捉文本与3D几何的细粒度对应，并设计高效检索策略（ERS）优化大尺度推理，属于原生多模态大模型中的3D-文本对齐研究，创新点突出且实用价值高。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13211' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing</h3>
<p><strong>Authors:</strong> Jongha Kim, Minseong Bae, Sanghyeok Lee, Jinsung Yoon, Hyunwoo J. Kim</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对表格理解的多模态大模型挑战，提出渐进式问题条件注入与令牌聚焦策略，生成更具针对性和紧凑性的视觉特征，在提升性能的同时降低了27% FLOPs和30%内存占用，是原生多模态大模型在特定任务上的高效优化工作。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13283' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Part-X-MLLM: Part-aware 3D Multimodal Large Language Model</h3>
<p><strong>Authors:</strong> Chunshi Wang, Junliang Ye, Yunhan Yang, Yang Li, Zizhuo Lin, Jun Zhu, Zhuo Chen, Yawei Luo, Chunchao Guo</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出部分感知的3D多模态大模型，通过结构化语法生成程序统一3D检测、生成与编辑任务，实现了3D场景的端到端理解与操作，属于原生多模态大模型的3D理解方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13647' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AnchorDS: Anchoring Dynamic Sources for Semantically Consistent Text-to-3D Generation</h3>
<p><strong>Authors:</strong> Jiayin Zhu, Linlin Yang, Yicong Li, Angela Yao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出AnchorDS改进文本到3D生成的分数蒸馏机制，解决语义过度平滑问题，提升多模态3D生成的语义一致性和效率，与原生多模态大模型中的图像生成方向高度相关。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11692' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Simple Vision-Language Math Reasoning via Rendered Text</h3>
<p><strong>Authors:</strong> Matvey Skripkin, Elizaveta Goncharova, Andrey Kuznetsov</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 将LaTeX公式渲染为图像，结合结构化思维链提示训练视觉语言模型，提升数学推理性能，属于原生多模态大模型中的视觉-语言融合方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11704' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> To Align or Not to Align: Strategic Multimodal Representation Alignment for Optimal Performance</h3>
<p><strong>Authors:</strong> Wanlong Fang, Tianle Zhang, Alvin Chan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 研究多模态学习中显式表示对齐的策略，提出可控对比学习模块探索对齐强度的最优水平，对原生多模态大模型的表示学习有重要价值。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12121' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Uncovering and Mitigating Transient Blindness in Multimodal Model Editing</h3>
<p><strong>Authors:</strong> Xiaoqi Han, Ru Li, Ran Yi, Hongye Tan, Zhuomin Liang, Víctor Gutiérrez-Basulto, Jeff Z. Pan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 发现多模态模型编辑中“transient blindness”现象（过度依赖文本忽略视觉），提出locality-aware对抗损失平衡跨模态表征，提升编辑效果和locality，对多模态模型优化有重要意义。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13243' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Improved Masked Image Generation with Knowledge-Augmented Token Representations</h3>
<p><strong>Authors:</strong> Guotao Liang, Baoquan Zhang, Zhiyuan Wen, Zihao Han, Yunming Ye</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Knowledge-Augmented Masked Image Generation（KA-MIG）框架，引入token级语义依赖知识（共现、相似性、位置不兼容）增强表示学习，提升掩码图像生成质量，属于原生多模态大模型中的掩码图像生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12032' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Point Cloud Quantization through Multimodal Prompting for 3D Understanding</h3>
<p><strong>Authors:</strong> Hongxuan Li (College of Intelligence and Computing, Tianjin University), Wencheng Zhu (College of Intelligence and Computing, Tianjin University, Haihe Laboratory of Information Technology Application Innovation), Huiying Xu (School of Computer Science and Technology, Zhejiang Normal University), Xinzhong Zhu (School of Computer Science and Technology, Zhejiang Normal University), Pengfei Zhu (College of Intelligence and Computing, Tianjin University)</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对点云量化问题提出多模态提示驱动框架，利用预训练文本嵌入作为原型先验，融合视觉与原型特征生成混合表示，提升3D理解性能，属于原生多模态大模型研究范畴。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12079' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Adaptive Begin-of-Video Tokens for Autoregressive Video Diffusion Models</h3>
<p><strong>Authors:</strong> Tianle Cheng, Zeyan Zhang, Kaifeng Gao, Jun Xiao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出自适应视频开始令牌（ada-BOV）优化自回归视频扩散模型，解决长视频生成的一致性与动态性问题，属于原生多模态大模型中的视频生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12099' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> OAD-Promoter: Enhancing Zero-shot VQA using Large Language Models with Object Attribute Description</h3>
<p><strong>Authors:</strong> Quanxing Xu, Ling Zhou, Feifei Zhang, Jinyu Tian, Rubing Huang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出OAD-Promoter框架通过物体属性描述增强LLM-based VQA的零样本性能，解决语言偏置与OOD泛化问题，属于原生多模态大模型中的VQA任务。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12131' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MAVIS: A Benchmark for Multimodal Source Attribution in Long-form Visual Question Answering</h3>
<p><strong>Authors:</strong> Seokwon Song, Minsu Park, Gunhee Kim</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 构建首个多模态源归因基准MAVIS，评估多模态大模型长文本VQA的源引用能力，填补多模态源归因基准空白，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12142' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FIA-Edit: Frequency-Interactive Attention for Efficient and High-Fidelity Inversion-Free Text-Guided Image Editing</h3>
<p><strong>Authors:</strong> Kaixiang Yang, Boyang Shen, Xin Li, Yuchen Dai, Yuxuan Luo, Yueran Ma, Wei Fang, Qiang Li, Zhiwei Wang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出频率交互注意力框架实现高效高保真无逆作文本引导图像编辑，提升文本与图像的特征对齐，属于原生多模态大模型中的图像编辑方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12151' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective</h3>
<p><strong>Authors:</strong> Wang Luo, Di Wu, Hengyuan Na, Yinlin Zhu, Miao Hu, Guocong Quan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Completion-by-Correction范式，利用图像到3D模型先验修正点云补全，提升结构一致性与细节完整性，属于原生多模态大模型中的3D理解方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12170' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MixAR: Mixture Autoregressive Image Generation</h3>
<p><strong>Authors:</strong> Jinyuan Hu, Jiayou Zhang, Shaobo Cui, Kun Zhang, Guangyi Chen</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出MixAR框架结合离散令牌与连续潜空间自回归建模，解决离散令牌信息丢失问题，提升图像生成 fidelity，属于原生多模态大模型中的图像生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12181' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LSS3D: Learnable Spatial Shifting for Consistent and High-Quality 3D Generation from Single-Image</h3>
<p><strong>Authors:</strong> Zhuojiang Cai, Yiheng Zhang, Meitong Guo, Mingdao Wang, Yuwang Wang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出可学习空间偏移方法，结合输入视图约束优化3D生成的一致性与质量，支持非正面视角输入，属于原生多模态大模型中的3D生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12202' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction</h3>
<p><strong>Authors:</strong> Jiaqi Wu, Yaosen Chen, Shuyuan Zhu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出几何信息提取与解耦注意力机制增强多视图生成的一致性与细节，通过自适应学习优化空间关系，属于原生多模态大模型中的多视图生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12204' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mixture of States: Routing Token-Level Dynamics for Multimodal Generation</h3>
<p><strong>Authors:</strong> Haozhe Liu, Ding Liu, Mingchen Zhuge, Zijian Zhou, Tian Xie, Sen He, Yukang Yang, Shuming Liu, Yuren Cong, Jiadong Guo, Hongyu Xu, Ke Xu, Kam-Woh Ng, Juan C. Pérez, Juan-Manuel Pérez-Rúa, Tao Xiang, Wei Liu, Shikun Liu, Jürgen Schmidhuber</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出令牌级动态路由的混合状态框架，结合离散令牌与连续潜空间建模，提升多模态生成效率与质量，属于原生多模态大模型中的多模态生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12207' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CrossVid: A Comprehensive Benchmark for Evaluating Cross-Video Reasoning in Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Jingyao Li, Jingyun Wang, Molin Tan, Haochen Wang, Cilin Yan, Likun Shi, Jiayin Cai, Xiaolong Jiang, Yao Hu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 构建CrossVid基准评估多模态大模型的跨视频推理能力，覆盖四层十项任务，反映真实场景视频理解需求，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12263' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models</h3>
<p><strong>Authors:</strong> Sepehr Kazemi Ranjbar, Kumail Alhamoud, Marzyeh Ghassemi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出子空间建模方法解决VLM的否定理解问题，通过球形帽构造否定区域，提升否定推理准确性，属于原生多模态大模型中的VLM方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12331' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding</h3>
<p><strong>Authors:</strong> Zhanheng Nie (), Chenghan Fu (), Daoze Zhang (), Junxian Wu (), Wanxian Guan (), Pengjie Wang (), Jian Xu (), Bo Zheng ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对电商多模态理解的模态不平衡、对齐不足和噪声问题，提出MOON2.0，包含模态驱动MoE、双级对齐和MLLM-based图像文本共增强，提升零样本性能，对原生多模态大模型的表示学习有贡献。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12449' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions</h3>
<p><strong>Authors:</strong> Xiaoyu Lin (), Aniket Ghorpade (), Hansheng Zhu (), Justin Qiu (), Dea Rrozhani (), Monica Lama (), Mick Yang (), Zixuan Bian (), Ruohan Ren (), Alan B. Hong (), Jiatao Gu (), Chris Callison-Burch ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出音频驱动的DenseAnnotate平台，生成大规模多模态（图像、3D、多语言文本）密集标注数据，训练的模型在多语言、文化对齐和3D空间能力上有提升，对原生多模态大模型的数据构建和训练有重要价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12452' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction</h3>
<p><strong>Authors:</strong> Yukuo Ma (), Cong Liu (), Junke Wang (), Junqi Liu (), Haibin Huang (), Zuxuan Wu (), Chi Zhang (), Xuelong Li ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出TempoMaster，通过逐帧速率预测生成长视频，结合双向注意力与跨帧速率自回归，提升长视频的视觉质量和时间连贯性，对原生多模态大模型的长视频生成任务有贡献。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12578' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Video Finetuning Improves Reasoning Between Frames</h3>
<p><strong>Authors:</strong> Ruiqi Yang, Tian Yun, Zihan Wang, Ellie Pavlick</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 系统研究视频微调对多模态LLM帧间推理的影响，提出vCoT视觉思维链分析，发现视频微调能隐式捕捉帧间过渡，为原生多模态大模型从图像到视频的扩展提供了重要 insights。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12868' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Explore How to Inject Beneficial Noise in MLLMs</h3>
<p><strong>Authors:</strong> Ruishu Zhu, Sida Huang, Ziheng Jiao, Hongyuan Zhang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对MLLMs微调中跨模态异质性问题，提出MuNG多模态噪声生成器，通过变分推断注入有益噪声，实现参数高效的跨模态对齐提升，对原生多模态大模型的微调优化有创新价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12917' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework</h3>
<p><strong>Authors:</strong> Diego Ortego, Marlon Rodr\'iguez, Mario Almagro, Kunal Dahiya, David Jim\'enez, Juan C. SanMiguel</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出ViXML多模态框架，将视觉模型高效整合到极端多标签分类任务中，解决大模型在多模态场景下的性能与效率平衡问题，符合原生多模态大模型的研究方向，对多模态大模型的实际应用有推动作用。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13189' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SkyReels-Text: Fine-grained Font-Controllable Text Editing for Poster Design</h3>
<p><strong>Authors:</strong> Yunjie Yu, Jingchen Wu, Junchen Zhu, Chunze Lin, Guibin Chen</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 解决了专业海报设计中字体可控的文本编辑痛点，无需字体标签或微调，仅通过裁剪 glyph 补丁即可实现多区域不同字体风格的文本修改，在文本 fidelity 与视觉 realism 上达到SOTA，属于原生多模态大模型的文本-图像协同编辑方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13285' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TripleFDS: Triple Feature Disentanglement and Synthesis for Scene Text Editing</h3>
<p><strong>Authors:</strong> Yuchen Bao, Yiting Wang, Wenjian Huang, Haowei Wang, Shen Chen, Taiping Yao, Shouhong Ding, Jianguo Zhang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出文本风格、内容与背景三特征解纠缠框架，通过SCB Group构造训练数据，解决了场景文本编辑中特征纠缠问题，提升了编辑的可控性与一致性，属于原生多模态大模型的文本-图像编辑方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13399' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling</h3>
<p><strong>Authors:</strong> Adam Hazimeh, Ke Wang, Mark Collier, Gilles Baechler, Efi Kokiopoulou, Pascal Frossard</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出SliDer框架，利用VLM将光栅文档转换为可编辑SVG，通过迭代优化提升重建质量，解决了静态文档的编辑痛点，属于原生多模态大模型的文档理解与生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13478' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Hierarchical Prompt Learning for Image- and Text-Based Person Re-Identification</h3>
<p><strong>Authors:</strong> Linhan Zhou, Shuang Li, Neng Dong, Yonghang Tai, Yafei Zhang, Huafeng Li</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出分层提示学习框架，联合优化图像-图像与文本-图像的行人重识别，通过身份级与实例级提示增强跨模态语义对齐，提升了多任务性能，属于原生多模态大模型的跨模态检索方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13575' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting</h3>
<p><strong>Authors:</strong> Jiangnan Ye, Jiedong Zhuang, Lianrui Mu, Wenjie Zheng, Jiaqi Hu, Xingze Zou, Jing Wang, Haoji Hu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出训练-free的多视图扩散模型扩展，通过LVLM解析文本生成光照先验，结合几何约束提升多视图一致性，实现文本引导的3D场景重新照明，属于原生多模态大模型的3D场景编辑方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13684' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine</h3>
<p><strong>Authors:</strong> Xincheng Shuai, Zhenyuan Qin, Henghui Ding, Dacheng Tao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出3D-aware的自回归框架，通过学习3D变换序列实现物理一致的多轮图像编辑，提升了编辑的连贯性与真实性，属于原生多模态大模型的3D图像编辑方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.13713' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Small Vocabularies, Big Gains: Pretraining and Tokenization in Time Series Models</h3>
<p><strong>Authors:</strong> Alexis Roger, Gwen Legate, Kashif Rasul, Yuriy Nevmyvaka, Irina Rish</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 研究时间序列tokenizer设计与多模态共享词汇策略，符合原生多模态大模型的tokenizer优化方向
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.11622' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MMSense: Adapting Vision-based Foundation Model for Multi-task Multi-modal Wireless Sensing</h3>
<p><strong>Authors:</strong> Zhizhen Li, Xuanhao Luo, Xueren Ge, Longyu Zhou, Xingqin Lin, Yuchen Liu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出多模态多任务无线传感基础模型，整合图像、雷达、LiDAR和文本数据，实现跨模态对齐与任务自适应。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.12305' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> PipeDiT: Accelerating Diffusion Transformers in Video Generation with Task Pipelining and Model Decoupling</h3>
<p><strong>Authors:</strong> Sijie Wang, Qiang Wang, Shaohuai Shi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出PipeDiT框架，通过任务流水线与模型解耦加速扩散Transformer视频生成，在OpenSoraPlan与HunyuanVideo上实现1.06x-4.02x速度提升，属于高效大模型训练与推理中的视频生成加速方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12056' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SpecQuant: Spectral Decomposition and Adaptive Truncation for Ultra-Low-Bit LLMs Quantization</h3>
<p><strong>Authors:</strong> Zhixiong Zhao, Fangxin Liu, Junjie Wang, Chenyang Guan, Zongwu Wang, Li Jiang, Haibing Guan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 基于频谱分解的LLM超低比特量化方法，在保持精度的同时提升推理速度与内存效率，是高效大模型推理的重要突破
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.11663' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CompressNAS : A Fast and Efficient Technique for Model Compression using Decomposition</h3>
<p><strong>Authors:</strong> Sudhakar Sah, Nikhil Chabbra, Matthieu Durnerin</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出CompressNAS框架，将低秩分解的rank选择转化为全局搜索问题，在ImageNet（ResNet-18压缩8x，精度下降<4%）和COCO（YOLOv5s压缩2x无精度损失）数据集上实现高效模型压缩，属于高效大模型训练与推理中的模型压缩方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.11716' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OmniSparse: Training-Aware Fine-Grained Sparse Attention for Long-Video MLLMs</h3>
<p><strong>Authors:</strong> Feng Chen, Yefei He, Shaoxuan He, Yuanyu He, Jing Liu, Lequan Lin, Akide Liu, Zhaoyang Li, Jiyuan Zhang, Zhenbang Sun, Bohan Zhuang, Qi Wu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出训练感知的细粒度稀疏注意力框架，通过查询选择、KV选择与缓存 slimming 加速长视频MLLMs推理，解决长视频处理高计算复杂度问题，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12201' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> D³ToM: Decider-Guided Dynamic Token Merging for Accelerating Diffusion MLLMs</h3>
<p><strong>Authors:</strong> Shuochen Chang, Xiaofeng Zhang, Qingyang Liu, Li Niu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出决策引导的动态令牌合并方法，通过前一步令牌生成重要性地图，合并冗余视觉令牌加速Diffusion MLLMs推理，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12280' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fast Reasoning Segmentation for Images and Videos</h3>
<p><strong>Authors:</strong> Yiqing Shen, Mathias Unberath</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出FastReasonSeg，通过数字孪生表示与蒸馏实现高效推理分割， distilled 0.6B模型优于20倍参数模型，支持资源受限环境实时部署，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12368' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MSLoRA: Multi-Scale Low-Rank Adaptation via Attention Reweighting</h3>
<p><strong>Authors:</strong> Xu Yang (), Gady Agam ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出MSLoRA，一种 backbone-agnostic的参数高效适配器，结合低秩线性投影与多尺度非线性变换调制空间和通道注意力，统一CNN和ViT的适应，提升迁移性能且仅用不足5%的backbone参数，对高效大模型适应有重要价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12400' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning</h3>
<p><strong>Authors:</strong> Jingqi Xu (), Jingxi Lu (), Chenghao Li (), Sreetama Sarkar (), Souvik Kundu (), Peter A. Beerel ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出RedVTP，训练-free的视觉token剪枝方法，通过掩码响应token的注意力估计重要性，剪枝不重要token，提升LLaDA-V和LaViDa的吞吐量（最高186%）和降低延迟（最高64.97%），不损失甚至提升精度，对高效大模型推理有价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12428' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ActVAR: Activating Mixtures of Weights and Tokens for Efficient Visual Autoregressive Generation</h3>
<p><strong>Authors:</strong> Kaixin Zhang, Ruiqing Yang, Yuan Zhang, Shan You, Tao Huang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对视觉自回归（VAR）模型的计算成本问题，提出动态激活权重和token的双稀疏框架，结合知识蒸馏保持性能，显著提升生成效率，对高效大模型训练与推理有实际贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12893' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VVS: Accelerating Speculative Decoding for Visual Autoregressive Generation via Partial Verification Skipping</h3>
<p><strong>Authors:</strong> Haotian Dong, Ye Li, Rongwei Lu, Chen Tang, Shu-Tao Xia, Zhi Wang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出部分验证跳过的投机解码框架，通过动态令牌选择与特征缓存减少目标模型前向传递次数（2.8×），显著提升视觉自回归生成的推理效率，属于高效大模型训练与推理中的推理加速方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13587' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding</h3>
<p><strong>Authors:</strong> Shrenik Patel, Daivik Patel</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出动态令牌丢弃与压缩内存框架，减少长视频理解的令牌处理量（87%），通过共识检索机制保留关键上下文，提升了长视频推理效率与准确性，属于高效大模型训练与推理中的长视频处理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13644' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity</h3>
<p><strong>Authors:</strong> Junwei Yu, Trevor Darrell, XuDong Wang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> [PAPER_START]
Title: The Anatomy of a Triton Attention Kernel
Authors: Burkhard Ringlein, Jan van Lunteren, Radu Stoica, Thomas Parnell
Published: 2025-11-18
Link: https://arxiv.org/abs/2511.11581
Reason: 研究基于Triton的高效注意力核设计，提升LLM跨GPU推理性能，对高效大模型推理系统优化有重要价值
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13714' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EcoSpa: Efficient Transformer Training with Coupled Sparsity</h3>
<p><strong>Authors:</strong> Jinqi Xiao, Cheng Luo, Lingyi Huang, Cheng Yang, Yang Sui, Huy Phan, Xiao Zang, Yibiao Ying, Zhexiang Tang, Anima Anandkumar, Bo Yuan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出耦合稀疏性的高效Transformer训练框架，显著减少内存占用与训练时间，属于高效大模型训练的关键优化
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.11641' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Uncertainty Makes It Stable: Curiosity-Driven Quantized Mixture-of-Experts</h3>
<p><strong>Authors:</strong> Sebastián Andrés Cajas Ordóñez, Luis Fernando Torres Torres, Mackenzie J. Meni, Carlos Andrés Duran Paredes, Eric Arazo, Cristian Bosch, Ricardo Simon Carbajo, Yuan Lai, Leo Anthony Celi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 结合量化和好奇心驱动的混合专家架构，提升边缘设备LLM推理的效率和稳定性，属于高效大模型训练与推理中的量化和MoE研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.11743' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Conformal Constrained Policy Optimization for Cost-Effective LLM Agents</h3>
<p><strong>Authors:</strong> Wenwen Si, Sooyong Jang, Insup Lee, Osbert Bastani</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 结合约束策略优化和 conformal预测，优化LLM代理的成本效率和可靠性，属于高效大模型训练与推理中的成本优化研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.11828' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Selecting Fine-Tuning Examples by Quizzing VLMs</h3>
<p><strong>Authors:</strong> Tenghao Ji, Eytan Adar</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 通过视觉语言模型“测试”选择LoRA微调示例，提升文本到图像模型的对齐和真实感，属于高效大模型训练与推理中的微调优化研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12002' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Scaling Law Analysis in Federated Learning: How to Select the Optimal Model Size?</h3>
<p><strong>Authors:</strong> Xuanyu Chen, Nan Yang, Shuai Wang, Dong Yuan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析联邦学习中的模型缩放定律，推导PAC-Bayes边界得出最优模型大小与客户端数量的关系，对高效大模型联邦训练有指导意义。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12188' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Optimal Self-Consistency for Efficient Reasoning with Large Language Models</h3>
<p><strong>Authors:</strong> Austin Feng, Marius Alonso, Ambroise Odonnat</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析自一致性(SC)的缩放行为，提出Blend-ASC动态分配样本，提升LLM推理的样本效率。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12309' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BitSnap: Checkpoint Sparsification and Quantization in LLM Training</h3>
<p><strong>Authors:</strong> Qingping Li, Yanxin Peng, Baodong Wu, Shigang Li, Guohao Dai, Shengen Yan, Yu Wang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出LLM训练中的checkpoint稀疏化与量化方法，动态适应训练阶段，实现16x压缩比且不损失精度。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12376' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Global-Lens Transformers: Adaptive Token Mixing for Dynamic Link Prediction</h3>
<p><strong>Authors:</strong> Tao Zou, Chengfeng Wu, Tianxi Liao, Junchen Ye, Bowen Du</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出注意力-free的Global-Lens Transformer，通过自适应token混合提升动态图任务的效率与性能，属于高效大模型训练与推理中的高效Transformer架构设计。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12442' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity</h3>
<p><strong>Authors:</strong> Vladimír Macko, Vladimír Boža</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对LLM剪枝后低稀疏度场景下的SpMV问题，提出GPU优化的格式和内核，显著提升推理速度和内存利用率，解决了低稀疏度剪枝LLM的部署瓶颈，具有实际应用价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13061' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OTARo: Once Tuning for All Precisions toward Robust On-Device LLMs</h3>
<p><strong>Authors:</strong> Shaoyuan Chen, Zhixuan Chen, Dawei Yang, Zhihang Yuan, Qiang Wu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出一次微调支持多精度量化的方法，通过Shared Exponent Floating Point机制和动态稀疏调整策略，解决on-device LLMs不同精度切换的问题，提升模型鲁棒性和部署灵活性。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13147' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ParaDySe: A Parallel-Strategy Switching Framework for Dynamic Sequence Lengths in Transformer</h3>
<p><strong>Authors:</strong> Zhixin Ou, Peng Liang, Jianchen Han, Baihui Liu, Linbo Qiao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对Transformer动态序列长度的训练问题，提出自适应并行策略切换框架，通过成本模型选择最优策略，解决短序列通信瓶颈和长序列OOM问题，提升LLM训练效率。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13198' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TokenSqueeze: Performance-Preserving Compression for Reasoning LLMs</h3>
<p><strong>Authors:</strong> Yuxiang Zhang, Zhengxu Yu, Weihang Pan, Zhongming Jin, Qiang Fu, Deng Cai, Binbin Lin, Jieping Ye</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出基于自生成数据的CoT token压缩方法，通过自适应问题复杂度匹配和语言 refinement，在保持推理性能的同时减少token使用，平衡了推理效率和准确性。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13223' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> D²-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation</h3>
<p><strong>Authors:</strong> Zheyuan Zhang (), Jiwei Zhang (), Boyu Zhou (), Linzhimeng Duan (), Hong Chen ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出D²-VPR，结合知识蒸馏和可变形聚合，减少视觉基础模型（如DINOv2）的参数（约64.2%）和计算量（约62.6%），保持VPR性能，对高效大模型训练与推理（模型压缩、蒸馏）有贡献。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12528' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression</h3>
<p><strong>Authors:</strong> Keshav Gupta, Akshat Sanghvi, Shreyas Reddy Palley, Astitva Srivastava, Charu Sharma, Avinash Sharma</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 利用局部对称性引入可学习镜像消除3D Gaussian Splatting的冗余基元，在现有压缩方法基础上进一步提升压缩比（平均108×压缩）并保持渲染质量，属于高效大模型训练与推理中的高压缩方向，直接解决3D大模型的内存占用痛点。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.13264' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond One-Way Pruning: Bidirectional Pruning-Regrowth for Extreme Accuracy-Sparsity Tradeoff</h3>
<p><strong>Authors:</strong> Junchen Liu, Yi Sheng</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出双向剪枝-再生策略，优化模型压缩的精度-稀疏性权衡，对高效大模型训练中的模型压缩有重要价值
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.11675' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LILogic Net: Compact Logic Gate Networks with Learnable Connectivity for Efficient Hardware Deployment</h3>
<p><strong>Authors:</strong> Katarzyna Fojcik, Renaldas Zioma, Jogundas Armaitis</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 设计可学习连接的逻辑门网络，大幅减少模型大小，提升硬件部署效率，属于高效大模型训练与推理中的硬件友好架构设计。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12340' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Tailored Primitive Initialization is the Secret Key to Reinforcement Learning</h3>
<p><strong>Authors:</strong> Yihang Yao, Guangtao Zeng, Raina Wu, Yang Zhang, Ding Zhao, Zhang-Wei Hong, Chuang Gan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Tailor微调管道，通过生成高质量推理原语初始化LLM，提升RL训练的样本效率。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12429' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VISAGNN: Versatile Staleness-Aware Efficient Training on Large-Scale Graphs</h3>
<p><strong>Authors:</strong> Rui Xue</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出VISAGNN解决大规模图GNN训练中的stale嵌入问题，通过动态适应stale标准提升训练效率与精度。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12434' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Uncover and Unlearn Nuisances: Agnostic Fully Test-Time Adaptation</h3>
<p><strong>Authors:</strong> Ponhvoan Srey, Yaxin Shi, Hangwei Qian, Jing Li, Ivor W. Tsang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出AFTTA方法解决全测试时间适应问题，通过揭示并遗忘干扰因素，提升模型对未知域的泛化能力，属于高效大模型推理中的测试时间适应优化。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.12491' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Reasoning: From Reflection to Solution</h3>
<p><strong>Authors:</strong> Zixi Li</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出推理是状态空间中迭代算子应用的理论，解释现有LLM推理缺陷并提出改进架构，属于深度学习理论中的LLM推理机制研究。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11712' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MFI-ResNet: Efficient ResNet Architecture Optimization via MeanFlow Compression and Selective Incubation</h3>
<p><strong>Authors:</strong> Nuolin Sun (), Linyuan Wang (), Haonan Wei (), Lei Li (), Bin Yan ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 从ODE视角将ResNet与MeanFlow结合，提出MFI-ResNet，通过压缩-扩展策略优化网络架构，在CIFAR数据集上减少约45%参数同时提升精度，从生成模型视角理解判别模型，对深度学习理论（网络架构）有贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12422' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Denoising Vision Transformer Autoencoder with Spectral Self-Regularization</h3>
<p><strong>Authors:</strong> Xunzhi Xiang (), Xingye Tian (), Guiyu Zhang (), Yabo Chen (), Shaofeng Zhang (), Xuebo Wang (), Xin Tao (), Qi Fan ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Denoising-VAE，通过光谱自正则化抑制高维VAE latent的高频噪声，解决高维latent影响扩散模型训练的问题，提升扩散模型的收敛速度（2倍）和生成/重建性能，对深度学习理论（自编码器优化）有贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12633' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Optimizing Input of Denoising Score Matching is Biased Towards Higher Score Norm</h3>
<p><strong>Authors:</strong> Tongda Xu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析去噪分数匹配的输入优化偏差，指出其偏向高分数范数，影响扩散模型性能，属于深度学习理论中的扩散模型训练研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11727' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> KAN/H: Kolmogorov-Arnold Network using Haar-like bases</h3>
<p><strong>Authors:</strong> Susumu Katayama</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出使用Haar-like基的Kolmogorov-Arnold网络变体，简化超参数调优，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11736' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Coordinate Descent for Network Linearization</h3>
<p><strong>Authors:</strong> Vlad Rakhlin, Amir Jevnisek, Shai Avidan</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 使用坐标下降直接优化离散域的ReLU计数，减少推理延迟，属于深度学习理论中的网络线性化和效率研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11781' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Better LLM Reasoning via Dual-Play</h3>
<p><strong>Authors:</strong> Zhengxin Zhang, Chengyu Huang, Aochong Oliver Li, Claire Cardie</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出双玩对抗训练框架，通过提议者-解决者模型提升LLM推理性能，属于深度学习理论中的LLM推理研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11881' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Understanding InfoNCE: Transition Probability Matrix Induced Feature Clustering</h3>
<p><strong>Authors:</strong> Ge Cheng, Shuo Wang, Yun Zhang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 从转移概率矩阵角度理论分析InfoNCE的特征聚类机制，提出改进的SC-InfoNCE损失，深化对比学习理论理解。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12180' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CAO: Curvature-Adaptive Optimization via Periodic Low-Rank Hessian Sketching</h3>
<p><strong>Authors:</strong> Wenzhang Du (Mahanakorn University of Technology, International College, Bangkok, Thailand)</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对一阶优化器在尖锐、各向异性区域收敛慢的问题，提出曲率自适应优化方法，通过周期性低秩Hessian子空间预条件梯度，实验验证在CIFAR-10/100上比Adam快2.95倍，属于深度学习理论中的优化器方向，具有理论和实践价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12548' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Training Instabilities Induce Flatness Bias in Gradient Descent</h3>
<p><strong>Authors:</strong> Lawrence Wang, Stephen J. Roberts</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析训练不稳定性对梯度下降的隐式偏差影响，揭示其驱动参数向平坦极小值区域移动以提升泛化性能的机制，结合理论分析和实验验证，深化了对深度学习优化泛化的理解，属于深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12558' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AdamX: An Adam improvement algorithm based on a novel exponential decay mechanism for the second-order moment estimate</h3>
<p><strong>Authors:</strong> Meng Zhu, Quan Xiao, Weidong Min</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对Adam优化器易收敛到非平坦最小值的问题，提出新的二阶矩估计指数衰减机制，使训练后期退化到SGD以提升稳定性和泛化能力，实验表明优于Adam及其变体且开源代码，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.13465' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LE-CapsNet: A Light and Enhanced Capsule Network</h3>
<p><strong>Authors:</strong> Pouya Shiri, Amirali Baniasadi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对Capsule Network速度慢、参数多、精度不足的问题，提出LE-CapsNet改进架构，通过优化结构在CIFAR-10（76.73%准确率）和AffNIST（94.3%准确率）数据集上实现了更高精度与4倍推理加速，属于深度学习理论中的网络架构优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11708' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Toward bilipshiz geometric models</h3>
<p><strong>Authors:</strong> Yonatan Sverdlov, Eitan Rosen, Nadav Dym</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析点云模型的双Lipschitz等价性，揭示现有不变网络的局限性并提出改进方法，提升3D点云对应关系任务性能，属于深度学习理论中的模型几何性质分析方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11735' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection</h3>
<p><strong>Authors:</strong> Ori Meiraz, Sharon Shalev, Avishai Weizman</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 将Mixture-of-Experts架构与YOLO结合，提出自适应专家路由策略，动态分配特征到专业专家分支，提升了目标检测的mAP与AR性能，属于深度学习理论中的网络架构优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.13344' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FUSE: A Flow-based Mapping Between Shapes</h3>
<p><strong>Authors:</strong> Lorenzo Olearo, Giulio Viganò, Daniele Baieri, Filippo Maggioli, Simone Melzi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出基于流匹配模型的3D形状映射神经表示，支持跨点云、网格等表示的形状匹配，提升了匹配的覆盖度与准确性，属于深度学习理论中的表示学习方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.13431' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse</h3>
<p><strong>Authors:</strong> Yuanchao Wang, Tian Qin, Eduardo Valle, Bruno Abrahao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 基于神经崩溃理论提出自监督OOD检测框架，通过合成伪OOD特征提升语义相似OOD样本的检测性能，解决了现有方法对标注OOD数据的依赖，属于深度学习理论中的OOD检测方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.13539' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation</h3>
<p><strong>Authors:</strong> Ziyang Huang, Jiagang Chen, Jin Liu, Shunping Ji</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对3D Gaussian Splatting的优化瓶颈，提出两阶段优化框架（自适应探索+曲率引导利用），提升了渲染质量与收敛速度，属于深度学习理论中的优化算法方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.13571' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Do traveling waves make good positional encodings?</h3>
<p><strong>Authors:</strong> Chase van de Geijn, Ayush Paliwal, Timo L\"uddecke, Alexander S. Ecker</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 研究基于行波的位置编码（RollPE）及其与RoPE的等价性，属于深度学习理论中的网络架构设计创新
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11668' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Tighter Truncated Rectangular Prism Approximation for RNN Robustness Verification</h3>
<p><strong>Authors:</strong> Xingqi Lin, Liangyu Chen, Min Wu, Min Zhang, Zhenbing Zeng</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对RNN鲁棒性验证中的非线性激活函数过近似问题，提出截断长方体近似方法，提升验证精度，属于深度学习理论中的网络鲁棒性研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11699' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FSC-Net: Fast-Slow Consolidation Networks for Continual Learning</h3>
<p><strong>Authors:</strong> Mohamed El Gorrim</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 受神经科学记忆巩固启发，提出双网络架构分离快速任务学习与渐进知识巩固，缓解灾难性遗忘，属于深度学习理论中的持续学习和网络架构研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11707' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diffusion Models: A Mathematical Introduction</h3>
<p><strong>Authors:</strong> Sepehr Maleki, Negar Pourmoazemi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 从高斯分布基本性质出发推导扩散生成模型，涵盖前向过程、反向 posterior和变分边界，属于深度学习理论中的扩散模型数学基础研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.11746' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Variation-Bounded Loss for Noise-Tolerant Learning</h3>
<p><strong>Authors:</strong> Jialiang Wang, Xiong Zhou, Xianming Liu, Gangfeng Hu, Deming Zhai, Junjun Jiang, Haoliang Li</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出变分有界损失(VBL)解决噪声标签问题，理论分析变分比与鲁棒性的关系，属于深度学习理论中的损失函数与鲁棒优化研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12143' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MPD-SGR: Robust Spiking Neural Networks with Membrane Potential Distribution-Driven Surrogate Gradient Regularization</h3>
<p><strong>Authors:</strong> Runhao Jiang, Chengzhi Jiang, Rui Yan, Huajin Tang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 研究脉冲神经网络鲁棒性，通过膜电位分布与替代梯度交互分析，提出MPD-SGR正则化提升对抗鲁棒性，属于深度学习理论中的网络架构与鲁棒优化。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12199' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> On the Dimension-Free Approximation of Deep Neural Networks for Symmetric Korobov Functions</h3>
<p><strong>Authors:</strong> Yulong Lu, Tong Mao, Jinchao Xu, Yahong Yang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析深度神经网络对对称Korobov函数的无维度近似能力，证明收敛率和常数因子多项式缩放，属于深度学习理论中的网络近似能力研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12398' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> BSO: Binary Spiking Online Optimization Algorithm</h3>
<p><strong>Authors:</strong> Yu Liang, Yu Yang, Wenjie Wei, Ammar Belatreche, Shuai Wang, Malu Zhang, Yang Yang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出BSO在线优化算法，用于二进制脉冲神经网络，直接通过翻转信号更新权重，降低训练内存，属于深度学习理论中的优化器与网络架构研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.12502' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Self-Organization of Attractor Landscapes in High-Capacity Kernel Logistic Regression Hopfield Networks</h3>
<p><strong>Authors:</strong> Akira Tamamori</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析高容量核Hopfield网络的能量景观，提出Pinnacle Sharpness指标量化吸引子稳定性，揭示其自组织机制，对深度学习理论中的网络动力学研究有重要贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.13053' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Rethinking Deep Alignment Through The Lens Of Incomplete Learning</h3>
<p><strong>Authors:</strong> Thong Bach, Dung Nguyen, Thao Minh Le, Truyen Tran</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析大模型安全对齐中的不完全学习问题，提出针对性完成方法提升对抗鲁棒性，属于大模型安全与对齐的关键问题研究。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12155' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> The 'Sure' Trap: Multi-Scale Poisoning Analysis of Stealthy Compliance-Only Backdoors in Fine-Tuned Large Language Models</h3>
<p><strong>Authors:</strong> Yuting Tan, Yi Huang, Zhuo Li</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析LLM微调中的“合规性后门”攻击，揭示良性标签中毒的隐蔽风险，提出行为门机制的理解。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12414' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> On the Fundamental Limits of LLMs at Scale</h3>
<p><strong>Authors:</strong> Muhammad Ahmed Mohsin, Muhammad Umer, Ahsan Bilal, Zeeshan Memon, Muhammad Ibtsaam Qadir, Sagnik Bhattacharya, Hassan Rizwan, Abhiram R. Gorle, Maahe Zehra Kazmi, Ayesha Mohsin, Muhammad Usman Rafique, Zihao He, Pulkit Mehta, Muhammad Ali Jamshed, John M. Cioffi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 构建统一框架分析LLM缩放的五大基础限制（幻觉、上下文压缩、推理退化、检索脆弱、多模态错位），结合计算、信息、学习的基础理论，深化了对大模型安全与对齐的理解，具有重要理论价值。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12869' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> The Second Law of Intelligence: Controlling Ethical Entropy in Autonomous Systems</h3>
<p><strong>Authors:</strong> Samih Fadli</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出AI系统的伦理熵概念，证明无约束AI的伦理熵会自发增加，推导了对齐工作的临界稳定边界，通过仿真验证了正则化对齐对维持系统稳定性的作用，为大模型安全与对齐提供了定量热力学框架。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.10704' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Defending Unauthorized Model Merging via Dual-Stage Weight Protection</h3>
<p><strong>Authors:</strong> Wei-Jia Chen, Min-Yen Tsai, Cheng-Yi Lee, Chia-Mu Yu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出MergeGuard双阶段权重保护框架，通过任务相关信息重分配与结构化扰动注入，防止未授权模型合并（合并模型精度下降达90%），保护模型知识产权，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11851' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Suppressing VLM Hallucinations with Spectral Representation Filtering</h3>
<p><strong>Authors:</strong> Ameen Ali, Tamim Zoabi, Lior Wolf</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出谱表示过滤方法，通过 eigendecomposition 识别并衰减幻觉模式，抑制VLM的虚假描述，提升模型可靠性，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12220' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Model Inversion Attack Against Deep Hashing</h3>
<p><strong>Authors:</strong> Dongdong Zhao, Qiben Xu, Ranxin Fang, Baogang Song</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出首个针对深度哈希的扩散模型 inversion框架DHMI，通过聚类辅助与 surrogate 引导生成高保真图像，揭示深度哈希的隐私风险，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12233' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning</h3>
<p><strong>Authors:</strong> Ankita Raj, Chetan Arora</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 首次针对开放词汇目标检测器（OVODs）的后门攻击研究，提出TrAP多模态prompt调优策略，揭示prompt tuning的攻击表面，为大模型安全领域的后门攻击防御提供了关键分析和方法。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12735' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SAGA: Source Attribution of Generative AI Videos</h3>
<p><strong>Authors:</strong> Rohit Kundu, Vishal Mohanty, Hao Xiong, Shan Jia, Athula Balachandran, Amit K. Roy-Chowdhury</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 首次提出大规模AI生成视频的来源归因框架，实现多粒度（真实性、模型版本、开发团队等）归因，结合视频Transformer和数据高效策略，为大模型安全的生成内容追责提供了关键工具。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12834' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GrOCE:Graph-Guided Online Concept Erasure for Text-to-Image Diffusion Models</h3>
<p><strong>Authors:</strong> Ning Han, Zhenyu Ge, Feng Han, Yuhua Sun, Chengqing Li, Jingjing Chen</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对文本到图像扩散模型的概念擦除需求，提出图引导的在线概念擦除框架，无需训练即可实现精确、自适应的有害/无关概念去除，对大模型安全与对齐的内容控制有高效解决方案。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12968' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> What Color Is It? A Text-Interference Multimodal Hallucination Benchmark</h3>
<p><strong>Authors:</strong> Jinkun Zhao, Lei Huang, Wenjun Wu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对多模态大模型的颜色幻觉问题构建基准，分析了幻觉成因并探索缓解方案，有助于提升模型的视觉感知鲁棒性，属于大模型安全与对齐中的幻觉检测方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13400' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task</h3>
<p><strong>Authors:</strong> Xingming Long, Jie Zhang, Shiguang Shan, Xilin Chen</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 聚焦多模态模型在自愿想象任务中的幻觉问题，提出VOPE评估方法，揭示了现有模型的幻觉局限性及缓解方法的不足，属于大模型安全与对齐中的幻觉评估方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13420' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline</h3>
<p><strong>Authors:</strong> Rui Zuo, Qinyue Tong, Zhe-Ming Lu, Ziqian Lu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出无训练的MLLM伪造检测 pipeline，无需额外训练即可提升篡改定位准确性与文本解释丰富性，突破了现有方法对大规模训练的依赖，属于大模型安全与对齐中的伪造检测方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13442' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Language-Guided Invariance Probing of Vision-Language Models</h3>
<p><strong>Authors:</strong> Jae Joong Lee</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 构建LGIP基准评估VLM对语言扰动的不变性与敏感性，揭示了现有模型的语言鲁棒性不足，为优化模型的语言理解能力提供了方向，属于大模型安全与对齐中的语言鲁棒性评估方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13494' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks</h3>
<p><strong>Authors:</strong> Md. Iqbal Hossain, Afia Sajeeda, Neeresh Kumar Perla, Ming Shao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出针对多模态对比学习模型的后门攻击防御策略，通过Oracle监督识别触发器与受害者样本，仅用少量数据即可纠正中毒模型，属于大模型安全与对齐中的后门防御方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13545' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond Superficial Forgetting: Thorough Unlearning through Knowledge Density Estimation and Block Re-insertion</h3>
<p><strong>Authors:</strong> Feng Guo, Yuntao Wen, Shen Gao, Junshuo Zhang, Shuo Shang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出知识密度引导的机器遗忘方法，解决大模型隐私合规中的残留知识问题，属于大模型安全与对齐的核心研究
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11667' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> On the Trade-Off Between Transparency and Security in Adversarial Machine Learning</h3>
<p><strong>Authors:</strong> Lucas Fenaux, Christopher Srinivasa, Florian Kerschbaum</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 研究对抗机器学习中透明度与安全性的权衡，通过博弈论分析两者冲突，属于大模型安全与对齐中的安全研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11842' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Systematic Study of Model Extraction Attacks on Graph Foundation Models</h3>
<p><strong>Authors:</strong> Haoyan Xu, Ruizhi Qian, Jiate Li, Yushun Dong, Minghao Lin, Hanson Yan, Zhengtao Yao, Qinghua Liu, Junhao Dong, Ruopeng Huang, Yue Zhao, Mengyuan Li</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 系统研究图基础模型的模型提取攻击，定义六种攻击场景并提出轻量级提取方法，属于大模型安全与对齐中的模型安全研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11912' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EARL: Entropy-Aware RL Alignment of LLMs for Reliable RTL Code Generation</h3>
<p><strong>Authors:</strong> Jiahe Shi, Zhengqi Gao, Ching-Yun Ko, Duane Boning</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 使用熵感知强化学习对齐LLM生成可靠的RTL代码，集中梯度更新于高熵关键token，属于大模型安全与对齐中的代码生成对齐研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12033' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AlignTree: Efficient Defense Against LLM Jailbreak Attacks</h3>
<p><strong>Authors:</strong> Gil Goren, Shahar Katz, Lior Wolf</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出AlignTree防御LLM越狱攻击，通过随机森林监测激活状态，无需额外提示或guard模型，兼顾效率与鲁棒性。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12217' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EcoAlign: An Economically Rational Framework for Efficient LVLM Alignment</h3>
<p><strong>Authors:</strong> Ruoxi Cheng, Haoxuan Ma, Teng Ma, Hongyi Zhang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对大视觉语言模型（LVLM）的对齐难题，将对齐重构为经济理性搜索问题，通过权衡安全、效用与计算成本的前瞻函数优化策略，实验验证在多模型（3闭源+2开源）、多数据集上实现安全与效用的SOTA性能，同时降低计算成本，直接对应大模型安全与对齐核心方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11301' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Dynamic Parameter Optimization for Highly Transferable Transformation-Based Attacks</h3>
<p><strong>Authors:</strong> Jiaming Liang, Chi-Man Pun</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对变换基攻击的参数优化问题，提出Dynamic Parameter Optimization（DPO），基于rise-then-fall模式提升攻击迁移性，在多个模型与任务上验证有效性，属于大模型安全与对齐中的对抗攻击防御方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11993' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias</h3>
<p><strong>Authors:</strong> Wenqian Ye, Di Wang, Guangtao Zheng, Bohan Liu, Aidong Zhang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对CLIP的多模态虚假偏差问题，提出SAGE提示探索方法，无需训练即可通过引导提示选择减轻偏差，提升模型鲁棒性，为大模型安全与对齐的偏差 mitigation提供了轻量解决方案。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13005' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VEIL: Jailbreaking Text-to-Video Models via Visual Exploitation from Implicit Language</h3>
<p><strong>Authors:</strong> Zonghao Ying, Moyang Chen, Nizhang Li, Zhiqiang Wang, Wenxin Zhang, Quanchen Zou, Zonglei Jing, Aishan Liu, Xianglong Liu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出通过隐式语言的视觉利用（中性场景锚点+潜在听觉触发+风格调制）实现文本到视频模型的越狱攻击，揭示了多模态大模型在隐式语义引导下的安全漏洞，属于大模型安全与对齐中的攻击机制研究，对模型安全防护有重要参考意义。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13127' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Output Supervision Can Obfuscate the Chain of Thought</h3>
<p><strong>Authors:</strong> Jacob Drori, Luke Marks, Bryce Woodworth, Alex Cloud, Alexander Matt Turner</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 分析输出监督导致的CoT混淆问题及 mitigation方法，对大模型对齐中的安全监控有重要理论贡献
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11584' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Calibrated Adversarial Sampling: Multi-Armed Bandit-Guided Generalization Against Unforeseen Attacks</h3>
<p><strong>Authors:</strong> Rui Wang, Zeming Wei, Xiyue Zhang, Meng Sun</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 用多臂赌博机框架动态设计对抗采样的奖励与探索-利用平衡，提升模型对未预见攻击的鲁棒性。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.12265' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Good, The Bad, and The Hybrid: A Reward Structure Showdown in Reasoning Models Training</h3>
<p><strong>Authors:</strong> Subramanyam Sahoo</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 研究RLHF中硬奖励、连续奖励和混合奖励结构对LLM推理训练的影响，提出自适应混合奖励调度器，提升收敛速度和稳定性，对大模型对齐研究有重要价值。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13016' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Incoherent Beliefs & Inconsistent Actions in Large Language Models</h3>
<p><strong>Authors:</strong> Arka Pal, Teo Kitanovski, Arthur Liang, Akilesh Potti, Micah Goldblum</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 研究LLM在动态环境中的信念更新不一致和行动与信念不一致问题，发现即使高性能模型也存在此类问题，揭示了LLM在复杂真实场景中的行为预测困难，对大模型安全与对齐研究有重要启示。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13240' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Aligning Machiavellian Agents: Behavior Steering via Test-Time Policy Shaping</h3>
<p><strong>Authors:</strong> Dena Mujtaba, Brian Hu, Anthony Hoogs, Arslan Basharat</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对预训练智能体的对齐挑战，提出测试时策略塑造方法，通过场景-动作属性分类器引导RL agent行为，在无需重训的情况下实现伦理属性对齐，实验在MACHIAVELLI基准（134文本游戏）上验证了对不道德行为的有效抑制，属于大模型安全与对齐中的agent对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.11551' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Did Models Sufficient Learn? Attribution-Guided Training via Subset-Selected Counterfactual Augmentation</h3>
<p><strong>Authors:</strong> Yannan Chen, Ruoyu Chen, Bin Zeng, Wei Wang, Shiming Liu, Qunli Zhang, Zheng Hu, Laiyuan Wang, Yaowei Wang, Xiaochun Cao</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 利用Counterfactual LIMA归因方法识别模型关键预测区域，通过反事实增强训练提升模型因果学习能力与泛化性，将可解释性 insights 融入模型优化，属于深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.12100' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> X-VMamba: Explainable Vision Mamba</h3>
<p><strong>Authors:</strong> Mohamed A. Mabrok, Yalda Zafari</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对Vision Mamba架构的可解释性空白，提出可控性基于的解释框架，结合Jacobian和Gramian方法实现高效、无修改的单前向解释，填补了SSMs模型空间信息处理的理解 gap，对深度学习可解释性领域有重要贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.12694' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Concept Regions Matter: Benchmarking CLIP with a New Cluster-Importance Approach</h3>
<p><strong>Authors:</strong> Aishwarya Agarwal, Srikrishna Karanam, Vineet Gandhi</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对CLIP的背景依赖问题，提出CCI聚类重要性解释方法，通过patch聚类评估概念区域的贡献，显著提升解释的忠实性，并构建COVAR基准分离误差来源，对深度学习可解释性领域有方法和基准的双重贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.12978' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations</h3>
<p><strong>Authors:</strong> Yehonatan Elisha, Seffi Cohen, Oren Barkan, Noam Koenigstein</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对显著性图解释存在的目的不明确、与用户查询对齐不足等核心问题，提出RFxG分类框架梳理解释类型，并设计新的 faithfulness 指标评估解释质量，直接关联深度学习可解释性中视觉解释方法的优化，具有理论指导和实践改进价值。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.13081' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Accuracy is Not Enough: Poisoning Interpretability in Federated Learning via Color Skew</h3>
<p><strong>Authors:</strong> Farhin Farhad Riya, Shahinul Hoque, Jinyuan Stella Sun, Olivera Kotevska</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 揭示了联邦学习中可解释性的攻击表面，提出颜色扰动中毒攻击方法，降低了Grad-CAM的解释 fidelity，证明了“准确预测不等于忠实解释”，属于深度学习可解释性与大模型安全的交叉研究方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.13535' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Which Sparse Autoencoder Features Are Real? Model-X Knockoffs for False Discovery Rate Control</h3>
<p><strong>Authors:</strong> Tsogt-Ochir Enkhbayar</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 引入Model-X Knockoffs控制稀疏自编码器特征选择的假发现率，解决可解释特征识别问题，属于深度学习可解释性中的特征解释方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.11711' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FLEX: Feature Importance from Layered Counterfactual Explanations</h3>
<p><strong>Authors:</strong> Nawid Keshtmand, Roussel Desmond Nzoyem, Jeffrey Nicholas Clark</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 将反事实解释转化为局部、区域和全局的特征重要性，桥接局部 recourse与全局归因，属于深度学习可解释性中的反事实解释研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.11891' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Black-Box to White-Box: Control-Theoretic Neural Network Interpretability</h3>
<p><strong>Authors:</strong> Jihoon Moon</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出控制理论框架，将训练好的神经网络视为非线性状态空间系统，通过局部线性化、能控能观Gramians等分析内部计算，将黑盒模型转化为局部白盒模型，直接服务于深度学习可解释性中的白盒解释需求，理论与实验结合。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.12852' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Weight-sparse transformers have interpretable circuits</h3>
<p><strong>Authors:</strong> Leo Gao, Achyuta Rajaram, Jacob Coxon, Soham V. Govande, Bowen Baker, Dan Mossing</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 通过权重稀疏化训练Transformer，使其具有更易理解的电路结构，研究稀疏性与可解释性的权衡，还初步探索了对现有dense模型的解释方法，属于深度学习可解释性研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.13653' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Explainable AI-Generated Image Detection RewardBench</h3>
<p><strong>Authors:</strong> Michael Yang, Shijian Deng, William T. Doan, Kai Wang, Tianyu Yang, Harsh Singh, Yapeng Tian</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 构建XAIGID-RewardBench基准评估MLLMs对AI生成图像检测解释的评判能力，分析模型推理与人类判断的差距，属于深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.12363' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond saliency: enhancing explanation of speech emotion recognition with expert-referenced acoustic cues</h3>
<p><strong>Authors:</strong> Seham Nasr, Zhao Ren, David Johnson</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 结合专家声学线索提升SER模型的可解释性，连接显著性与理论驱动的声学特征，属于深度学习可解释性的实践创新
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.11691' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LAYA: Layer-wise Attention Aggregation for Interpretable Depth-Aware Neural Networks</h3>
<p><strong>Authors:</strong> Gennaro Vessio</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出层间注意力聚合的输出头，动态整合中间层特征，在提升模型性能的同时提供可解释的层归因分数，直接响应深度学习可解释性中的白盒解释需求，实验验证有效。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.12723' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Explainable RL Policies by Distilling to Locally-Specialized Linear Policies with Voronoi State Partitioning</h3>
<p><strong>Authors:</strong> Senne Deproost, Dennis Steckelmacher, Ann Nowé</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出用Voronoi状态划分将RL黑盒政策蒸馏为局部线性模型，提升政策的可解释性，同时保持性能，为RL的可解释性研究提供了新方法。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.13322' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation</h3>
<p><strong>Authors:</strong> Yushe Cao (), Dianxi Shi (), Xing Fu (), Xuechao Zou (), Haikuo Peng (), Xueqi Li (), Chun Yu (), Junliang Xing ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出MDiTFace，结合扩散Transformer与统一token化处理掩码和文本，通过解耦注意力机制减少计算开销（94%），提升面部生成的保真度和条件一致性，对扩散大模型新技术有贡献。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.12631' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Recurrent Autoregressive Diffusion: Global Memory Meets Local Attention</h3>
<p><strong>Authors:</strong> Taiye Chen, Zihan Ding, Anjian Li, Christina Zhang, Zeqi Xiao, Yisen Wang, Chi Jin</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 将RNN（LSTM）融入扩散Transformer框架，提出RAD解决长视频生成的遗忘和时空不一致问题，为扩散类大模型的长序列生成提供了新技术路径，属于大模型新技术的重要探索。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.12940' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MeanFlow Transformers with Representation Autoencoders</h3>
<p><strong>Authors:</strong> Zheyuan Hu, Chieh-Hsin Lai, Ge Wu, Yuki Mitsufuji, Stefano Ermon</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对MeanFlow模型的训练不稳定和计算成本问题，提出基于RAE潜在空间的训练与采样优化，结合一致性蒸馏和 bootstrap 策略，显著提升生成效率和性能，属于大模型新技术的优化创新。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.13019' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model</h3>
<p><strong>Authors:</strong> Fei Kong</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 将Denoising Diffusion Codebook Models（DDCM）扩展到DDPM、Score-Based Models等主流扩散模型，提出通用的gDDCM框架，实现更高效的图像tokenization，提升了扩散模型的压缩与生成性能，属于大模型新技术中的扩散模型改进方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.13387' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Distribution Matching Distillation Meets Reinforcement Learning</h3>
<p><strong>Authors:</strong> Dengyang Jiang, Dongyang Liu, Zanyi Wang, Qilong Wu, Xin Jin, David Liu, Zhen Li, Mengmeng Wang, Peng Gao, Harry Yang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 将强化学习引入扩散模型蒸馏，提出DMDR框架，通过RL引导少步生成的模式覆盖，提升了扩散模型的生成质量与效率，属于大模型新技术中的扩散模型与RL结合方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.13649' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models</h3>
<p><strong>Authors:</strong> Harold Haodong Chen, Disen Lan, Wen-Jie Shu, Qingyang Liu, Zihan Wang, Sirui Chen, Wenkai Cheng, Kanghao Chen, Hongfei Zhang, Zixin Zhang, Rongjin Guo, Yu Cheng, Ying-Cong Chen</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 构建视频生成的推理基准（TiViBench），评估模型的结构、空间、符号与动作推理能力，提出VideoTPO策略提升推理性能，为视频生成模型的推理能力优化提供了方向，属于大模型新技术中的视频生成推理方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.13704' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hierarchical Schedule Optimization for Fast and Robust Diffusion Model Sampling</h3>
<p><strong>Authors:</strong> Aihua Zhu, Rui Su, Qinglin Zhao, Li Feng, Meng Shen, Shibo He</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出分层调度优化加速扩散模型采样，属于大模型新技术中的diffusion LLM高效推理方向
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.11688' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Chain-of-Generation: Progressive Latent Diffusion for Text-Guided Molecular Design</h3>
<p><strong>Authors:</strong> Lingxiao Li, Haobo Zhang, Bin Chen, Jiayu Zhou</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出渐进式潜在扩散框架，将文本提示分解为语义片段引导分子生成，属于大模型新技术中的扩散LLM应用研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.11894' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.5/10]</span> Experience-Guided Adaptation of Inference-Time Reasoning Strategies</h3>
<p><strong>Authors:</strong> Adam Stein, Matthew Trager, Benjamin Bowman, Michael Kleinman, Aditya Chattopadhyay, Wei Xia, Stefano Soatto</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出基于经验引导的推理时策略自适应框架EGuR，通过LLM元策略动态生成包含LLM调用、工具配置、采样参数的完整推理流程，解决现有方法无法灵活调整策略组件的问题，实验在多基准任务上提升准确率并降低资源消耗，属于大模型推理新技术范畴。
Score: 7.5
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.11519' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors</h3>
<p><strong>Authors:</strong> Qifeng Chen, Jiarun Liu, Rengan Xie, Tao Tang, Sicong Du, Yiru Zhao, Yuchi Huo, Sheng Yang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出LiDAR-GS++，利用扩散先验增强LiDAR高斯重建的几何一致性与细节，属于大模型新技术中的diffusion LLM应用方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.12304' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models</h3>
<p><strong>Authors:</strong> Zhiguang Lu (), Qianqian Xu (), Peisong Wen (), Siran Da (), Qingming Huang ()</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出HiGFA，利用扩散模型的时间动态进行分层引导，早期用强文本和轮廓引导建立全局结构，后期用细粒度分类器引导和动态强度调制，生成精准的细粒度合成数据，提升分类性能，对扩散大模型的新技术应用有贡献。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.12547' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TSGDiff: Rethinking Synthetic Time Series Generation from a Pure Graph Perspective</h3>
<p><strong>Authors:</strong> Lifeng Shen, Xuyang Li, Lele Long</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 将时间序列表示为动态图，结合扩散模型生成高质量时间序列，提出图感知Topo-FID指标，属于大模型新技术中的扩散模型应用创新。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.12174' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diffusion Model Based Signal Recovery Under 1-Bit Quantization</h3>
<p><strong>Authors:</strong> Youming Chen, Zhaoqiang Liu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出Diff-OneBit用扩散模型解决1位量化的信号恢复问题，结合可微分surrogate似然函数，提升恢复质量与效率。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.12471' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Stabilizing Self-Consuming Diffusion Models with Latent Space Filtering</h3>
<p><strong>Authors:</strong> Zhongteng Cai, Yaxuan Wang, Yang Liu, Xueru Zhang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对自消耗扩散模型的训练不稳定和模型崩溃问题，分析 latent空间退化机制并提出LSF方法过滤不真实合成数据，属于大模型新技术中的扩散模型优化方向，实验验证有效缓解模型崩溃。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.12742' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image</h3>
<p><strong>Authors:</strong> Ziang Cao, Fangzhou Hong, Zhaoxi Chen, Liang Pan, Ziwei Liu</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出模拟就绪的物理3D资产生成框架，从单张图像生成带几何、关节与物理属性的3D资产，可直接用于机器人政策学习，解决了物理资产短缺的问题，属于多模态智能体的物理资产生成方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.13648' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Co-EPG: A Framework for Co-Evolution of Planning and Grounding in Autonomous GUI Agents</h3>
<p><strong>Authors:</strong> Yuan Zhao, Hualei Zhu, Tingyu Jiang, Shen Li, Xiaohang Xu, Hao Henry Wang</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 针对GUI智能体中规划与grounding协同不足的问题，提出自迭代训练框架Co-EPG，通过Group Relative Policy Optimization和数据蒸馏实现两者协同进化，在Multimodal-Mind2Web和AndroidControl基准上超过SOTA，属于多模态智能体中的GUI Agent研究。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.10705' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE</h3>
<p><strong>Authors:</strong> Lipeng Wang, Hongxing Fan, Haohua Chen, Zehuan Huang, Lu Sheng</p>
<p><strong>Published:</strong> 2025-11-18</p>
<p><strong>Reason:</strong> 提出动态时间选择MoE框架，结合文本语义与运动上下文引导专家路由，提升了3D人体交互生成的个体特征保留与语义 fidelity，属于多模态智能体的交互生成方向。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.13488' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>