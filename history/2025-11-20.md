# ArXiv 每日推荐 - 2025-11-20

> 更新于北京时间：2025-11-20 12:24:55
> 已自动阅读了 282 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：140346

## 深度学习理论

### [Score: 9.0/10] Step by Step Network
- **Authors:** Dongchen Han, Tianzhu Ye, Zhuofan Xia, Kaiyi Chen, Yulin Wang, Hanting Chen, Gao Huang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14329](https://arxiv.org/abs/2511.14329)
- **Reason:** 提出StepsNet解决残差网络深度瓶颈（ shortcut degradation与宽度限制），理论与实验验证深层模型性能提升，属于深度学习理论的网络架构方向
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Compiling to linear neurons
- **Authors:** Joey Velez-Ginorio, Nada Amin, Konrad Kording, Steve Zdancewic
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13769](https://arxiv.org/abs/2511.13769)
- **Reason:** 提出Cajal语言将算法编译为线性神经元，桥接离散算法与梯度学习，提升网络可解释性和学习效率，属于深度学习理论基础研究。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Self-Attention as Distributional Projection: A Unified Interpretation of Transformer Architecture
- **Authors:** Nihal Mehta
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13780](https://arxiv.org/abs/2511.13780)
- **Reason:** 从分布语义角度统一解释Transformer自注意力机制，揭示其投影原理，为网络架构设计提供理论依据，属于深度学习理论核心研究。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] Can You Learn to See Without Images? Procedural Warm-Up for Vision Transformers
- **Authors:** Zachary Shinnick (University of Adelaide), Liangze Jiang (University of Adelaide), Hemanth Saratchandran (University of Adelaide), Damien Teney (University of Adelaide), Anton van den Hengel (University of Adelaide, Amazon Web Services)
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13945](https://arxiv.org/abs/2511.13945)
- **Reason:** 提出了基于 procedural 数据的视觉Transformer预热策略，通过抽象计算先验提升数据效率与下游性能，对深度学习理论中的模型初始化与归纳偏置研究有重要贡献，实验验证了1% procedural数据等价于28% ImageNet数据的性能提升。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Attention Via Convolutional Nearest Neighbors
- **Authors:** Mingi Kang, Jeová Farias Sales Rocha Neto
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14137](https://arxiv.org/abs/2511.14137)
- **Reason:** 提出卷积与自注意力的统一k近邻聚合框架，溶解两者边界，为网络架构设计提供新视角，实验验证在VGG和ViT上的有效性
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] DeepDefense: Layer-Wise Gradient-Feature Alignment for Building Robust Neural Networks
- **Authors:** Ci Lin, Tet Yeap, Iluju Kiringa, Biwei Zhang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13749](https://arxiv.org/abs/2511.13749)
- **Reason:** 提出层-wise梯度-特征对齐正则化方法，显著提升模型对抗鲁棒性（APGD攻击下比标准对抗训练高15.2%），属于深度学习理论中的鲁棒性研究方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Complex-Weighted Convolutional Networks: Provable Expressiveness via Complex Diffusion
- **Authors:** Cristina L\'opez Amado, Tassilo Schwarz, Yu Tian, Renaud Lambiotte
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13937](https://arxiv.org/abs/2511.13937)
- **Reason:** 提出复杂加权卷积网络，通过复杂扩散提升GNN表达性，解决过平滑和异质性问题，属于深度学习理论中网络架构改进。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] On the Gradient Complexity of Private Optimization with Private Oracles
- **Authors:** Michael Menart, Aleksandar Nikolov
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13999](https://arxiv.org/abs/2511.13999)
- **Reason:** 研究私有优化的梯度复杂度下界，揭示差分隐私优化的 runtime  penalty，属于深度学习理论中优化算法基础研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] AdamHD: Decoupled Huber Decay Regularization for Language Model Pre-Training
- **Authors:** Fu-Ming Guo, Yingfang Fan
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14721](https://arxiv.org/abs/2511.14721)
- **Reason:** 提出了基于Huber衰减的优化器正则方法，改进了AdamW的L2正则缺陷，提升了语言模型预训练的效率和性能，对优化器理论和实践均有贡献。
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Parameter Aware Mamba Model for Multi-task Dense Prediction
- **Authors:** Xinzhuo Yu, Yunzhi Zhuge, Sitong Gong, Lu Zhang, Pingping Zhang, Huchuan Lu
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14503](https://arxiv.org/abs/2511.14503)
- **Reason:** 提出Parameter Aware Mamba模型，针对多任务密集预测优化Mamba架构，属于深度学习理论中的网络结构研究方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] DeCo-VAE: Learning Compact Latents for Video Reconstruction via Decoupled Representation
- **Authors:** Xiangchen Yin, Jiahui Yuan, Zhangchi Hu, Wenzhang Sun, Jie Chen, Xiaozhen Qiao, Hao Li, Xiaoyan Sun
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14530](https://arxiv.org/abs/2511.14530)
- **Reason:** 提出DeCo-VAE模型，通过解耦表示学习视频重建的紧凑潜空间，属于深度学习理论中的网络结构（VAE）研究方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] ARC Is a Vision Problem!
- **Authors:** Keya Hu, Ali Cy, Linlu Qiu, Xiaoman Delores Ding, Runqian Wang, Yeyin Eva Zhu, Jacob Andreas, Kaiming He
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14761](https://arxiv.org/abs/2511.14761)
- **Reason:** 将ARC抽象推理问题建模为图像到图像翻译任务，用ViT从头训练取得优于现有方法的效果，属于深度学习理论中的网络结构（ViT）应用方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] MoETTA: Test-Time Adaptation Under Mixed Distribution Shifts with MoE-LayerNorm
- **Authors:** Xiao Fan, Jingyan Jiang, Zhaoru Chen, Fanding Huang, Xiao Chen, Qinting Jiang, Bowen Zhang, Xing Tang, Zhi Wang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13760](https://arxiv.org/abs/2511.13760)
- **Reason:** 提出MoETTA框架，用混合专家（MoE）架构处理混合分布偏移的测试时适应，属于深度学习理论中的鲁棒性与自适应研究方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Data Whitening Improves Sparse Autoencoder Learning
- **Authors:** Ashwin Saraswatula, David Klindt
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13981](https://arxiv.org/abs/2511.13981)
- **Reason:** 验证数据白化对稀疏自编码器的提升，改进优化景观，提升可解释性指标，属于深度学习理论中自编码器训练优化方法。
Score: 7
Field: 深度学习理论

## 大模型新技术

### [Score: 9.0/10] Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model
- **Authors:** Xiyuan Wang, Muhan Zhang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14716](https://arxiv.org/abs/2511.14716)
- **Reason:** 提出DSD框架，首次实现端到端训练的单网络Diffusion模型，解决潜空间坍塌问题，在ImageNet上取得优异FID，是Diffusion LLM的重要突破，属于大模型新技术方向。
Score: 9
Field: 大模型新技术

### [Score: 9.0/10] SCALEX: Scalable Concept and Latent Exploration for Diffusion Models
- **Authors:** E. Zhixuan Zeng, Yuhao Chen, Alexander Wong
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13750](https://arxiv.org/abs/2511.13750)
- **Reason:** 提出SCALEX框架，自动探索Diffusion模型潜空间并检测 bias（如性别-职业刻板印象），属于大模型新技术（Diffusion LLM）方向。
Score: 9
Field: 大模型新技术

### [Score: 8.0/10] InstantViR: Real-Time Video Inverse Problem Solver with Distilled Diffusion Prior
- **Authors:** Weimin Bai, Suzhe Xu, Yiwei Ren, Jinhua Hao, Ming Sun, Wenzheng Chen, He Sun
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14208](https://arxiv.org/abs/2511.14208)
- **Reason:** 将视频扩散模型蒸馏为因果自回归模型，实现实时视频逆问题求解，属于大模型新技术中的diffusion LLM方向
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] FreeSwim: Revisiting Sliding-Window Attention Mechanisms for Training-Free Ultra-High-Resolution Video Generation
- **Authors:** Yunfeng Wu, Jiayi Song, Zhenxiong Tan, Zihao He, Songhua Liu
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14712](https://arxiv.org/abs/2511.14712)
- **Reason:** 提出训练-free的超高清视频生成方法，基于预训练视频Diffusion Transformer改进滑动窗口注意力，解决重复内容与全局一致性问题，属于大模型新技术（Diffusion LLM）方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Zero-shot Synthetic Video Realism Enhancement via Structure-aware Denoising
- **Authors:** Yifan Wang, Liya Ji, Zhanghan Ke, Harry Yang, Ser-Nam Lim, Qifeng Chen
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14719](https://arxiv.org/abs/2511.14719)
- **Reason:** 提出零样本合成视频真实感增强方法，基于Diffusion视频基础模型利用结构信息引导去噪，保持结构与语义一致性，属于大模型新技术（Diffusion LLM）方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] CFG-EC: Error Correction Classifier-Free Guidance
- **Authors:** Nakkyu Yang, Yechan Lee, SooJean Han
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14075](https://arxiv.org/abs/2511.14075)
- **Reason:** 改进Classifier-Free Guidance，通过误差校正提升生成质量和prompt对齐，属于大模型新技术中生成模型优化方法。
Score: 8
Field: 大模型新技术

## 深度学习可解释性

### [Score: 9.0/10] ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design
- **Authors:** Emanuel Covaci, Fabian Galis, Radu Balan, Daniela Zaharie, Darian Onchis
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13809](https://arxiv.org/abs/2511.13809)
- **Reason:** 提出ScoresActivation将特征重要性集成到训练中，提升模型全局可解释性，与SHAP值对齐且速度更快，属于深度学习可解释性创新方法。
Score: 9
Field: 深度学习可解释性

### [Score: 8.0/10] nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers
- **Authors:** Clément Dumas
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14465](https://arxiv.org/abs/2511.14465)
- **Reason:** 提出了用于Transformer机制可解释性的标准化接口工具，解决了现有工具在兼容性和标准化上的问题，为Transformer模型的机制可解释性研究提供了实用支持。
Score: 8
Field: 深度学习可解释性

## 大模型安全与对齐

### [Score: 9.0/10] From Narrow Unlearning to Emergent Misalignment: Causes, Consequences, and Containment in LLMs
- **Authors:** Erum Mushtaq, Anil Ramakrishna, Satyapriya Krishna, Sattvik Sahai, Prasoon Goyal, Kai-Wei Chang, Tao Zhang, Rahul Gupta
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14017](https://arxiv.org/abs/2511.14017)
- **Reason:** 研究窄域遗忘导致的LLM emergent misalignment，提出恢复对齐方法，揭示概念纠缠原因，属于大模型安全与对齐核心问题。
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] N-GLARE: An Non-Generative Latent Representation-Efficient LLM Safety Evaluator
- **Authors:** Zheyu Lin, Jirui Yang, Hengqi Guo, Yubing Bao, Yao Guan
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14195](https://arxiv.org/abs/2511.14195)
- **Reason:** 提出基于latent表示的LLM安全评估方法，无需生成文本，降低99%成本，属于大模型安全与对齐高效评估工具。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] MVI-Bench: A Comprehensive Benchmark for Evaluating Robustness to Misleading Visual Inputs in LVLMs
- **Authors:** Huiyi Chen, Jiawei Peng, Dehai Min, Changchang Sun, Kaijie Chen, Yan Yan, Xu Yang, Lu Cheng
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14159](https://arxiv.org/abs/2511.14159)
- **Reason:** 首个针对LVLM误导性视觉输入鲁棒性的综合基准，设计分层 taxonomy与细粒度指标，助力大模型安全可靠部署
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Robustness of LLM-enabled vehicle trajectory prediction under data security threats
- **Authors:** Feilong Wang, Fuqiang Liu
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13753](https://arxiv.org/abs/2511.13753)
- **Reason:** 分析LLM-enabled车辆轨迹预测模型的对抗脆弱性，提出单特征差分进化攻击方法，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Scaling Patterns in Adversarial Alignment: Evidence from Multi-LLM Jailbreak Experiments
- **Authors:** Samuel Nathanson, Rebecca Williams, Cynthia Matuszek
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13788](https://arxiv.org/abs/2511.13788)
- **Reason:** 研究LLM对抗对齐的缩放模式，发现模型大小与越狱成功率的相关性，为大模型安全对齐提供实证依据。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Observational Auditing of Label Privacy
- **Authors:** Iden Kalemaj, Luca Melis, Maxime Boucher, Ilya Mironov, Saeed Mahloujifar
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14084](https://arxiv.org/abs/2511.14084)
- **Reason:** 提出观察性标签隐私审计框架，无需修改数据集，提升大规模系统隐私评估效率，属于大模型安全与对齐隐私保护研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] A Comprehensive Study of Implicit and Explicit Biases in Large Language Models
- **Authors:** Fatima Kazi, Alex Young, Yash Inani, Setareh Rafatirad
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14153](https://arxiv.org/abs/2511.14153)
- **Reason:** 全面研究LLM隐式和显式偏见，提出检测框架并改进模型性能，属于大模型安全与对齐公平性研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation
- **Authors:** Bastien Vuillod, Pierre-Alain Moellic, Jean-Max Dutertre
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14406](https://arxiv.org/abs/2511.14406)
- **Reason:** 研究联邦学习中模型适应的后门攻击寿命，揭示LoRA对攻击的影响，属于大模型安全与对齐对抗攻击研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior
- **Authors:** Dalia Ali, Dora Zhao, Allison Koenecke, Orestis Papakyriakopoulos
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14476](https://arxiv.org/abs/2511.14476)
- **Reason:** 研究了大语言模型对齐中多元价值观的整合，分析了不同社会群体偏好及技术设计（如DPO vs GRPO、评分尺度）对安全、包容性和模型行为的影响，对大模型安全与对齐的实践具有重要参考价值
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] Coffee: Controllable Diffusion Fine-tuning
- **Authors:** Ziyao Zeng (University of Waterloo), Jingcheng Ni (University of Waterloo), Ruyi Liu (University of Waterloo), Alex Wong (University of Waterloo)
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14113](https://arxiv.org/abs/2511.14113)
- **Reason:** 提出了基于语言引导的扩散模型可控微调方法，通过正则化防止模型学习不期望概念，无需额外训练且支持灵活修改目标，解决了扩散微调中的可控性问题，对大模型安全与对齐有重要意义。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Certified Signed Graph Unlearning
- **Authors:** Junpeng Zhao, Lin Li, Kaixi Hu, Kaize Shi, Jingling Yuan
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14168](https://arxiv.org/abs/2511.14168)
- **Reason:** 提出有证书的符号图遗忘方法，保护隐私并保持模型效用，属于大模型安全与对齐隐私保护研究。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Jailbreaking Large Vision Language Models in Intelligent Transportation Systems
- **Authors:** Badhan Chandra Das, Md Tasnim Jawad, Md Jueal Mia, M. Hadi Amini, Yanzhao Wu
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13892](https://arxiv.org/abs/2511.13892)
- **Reason:** 分析了多模态大模型在智能交通系统中的越狱攻击漏洞，提出了攻击方法和防御策略，对大模型安全与对齐研究具有参考价值。
Score: 7
Field: 大模型安全与对齐

## 高效大模型训练与推理

### [Score: 9.0/10] MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts
- **Authors:** Wenfeng Wang, Jiacheng Liu, Xiaofeng Hou, Xinfeng Xia, Peng Tang, Mingxuan Zhang, Chao Li, Minyi Guo
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14102](https://arxiv.org/abs/2511.14102)
- **Reason:** 提出MoE模型推测量化解码框架，通过专家预取加速推理，提升2.34倍速度，属于高效大模型训练与推理关键优化。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design
- **Authors:** Jiawei Yi, Ping Gong, Youhui Bai, Jiaqi Ruan, Shengnan Wang, Pengcheng Wang, Haibo Wang, Weiguang Wang, Xia Zhu, Feng Wu, Cheng Li
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14510](https://arxiv.org/abs/2511.14510)
- **Reason:** 针对LLM推理中KVCache的CPU瓶颈问题，通过算法-系统协同设计提出优化方案，有效提升了推理吞吐量，对大模型高效推理具有重要实践价值。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] CORE: Compact Object-centric REpresentations as a New Paradigm for Token Merging in LVLMs
- **Authors:** Jingyu Lei (National University of Singapore), Gaoang Wang (National University of Singapore), Der-Horng Lee (National University of Singapore)
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14072](https://arxiv.org/abs/2511.14072)
- **Reason:** 提出了面向大视觉语言模型（LVLM）的对象中心token合并范式，通过分割解码器引导token合并，解决了LVLM中视觉token冗余问题，实验显示极端压缩（保留2.2%token）仍保持97.4%基线性能，对高效大模型推理有重要价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] AdaTok: Adaptive Token Compression with Object-Aware Representations for Efficient Multimodal LLMs
- **Authors:** Xinliang Zhang, Lei Zhu, Hangzhou He, Shuang Zeng, Ourui Fu, Jiakui Hu, Zhengjian Yao, Yanye Lu
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14169](https://arxiv.org/abs/2511.14169)
- **Reason:** 提出对象级token合并策略，平衡token压缩与性能，在多模态LLM中实现高效推理，符合高效大模型训练与推理方向
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] OmniZip: Audio-Guided Dynamic Token Compression for Fast Omnimodal Large Language Models
- **Authors:** Keda Tao, Kele Shao, Bohan Yu, Weiqiang Wang, Jian liu, Huan Wang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14582](https://arxiv.org/abs/2511.14582)
- **Reason:** 提出训练-free的音频引导多模态token压缩框架，实现3.42倍推理加速和1.4倍内存减少，解决全模态大模型的计算瓶颈，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Co-Me: Confidence-Guided Token Merging for Visual Geometric Transformers
- **Authors:** Yutian Chen, Yuheng Qiu, Ruogu Li, Ali Agha, Shayegan Omidshafiei, Jay Patrikar, Sebastian Scherer
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14751](https://arxiv.org/abs/2511.14751)
- **Reason:** 提出置信度引导的token合并方法，加速视觉几何Transformer推理（最高11.3倍加速），无需再训练，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Library Liberation: Competitive Performance Matmul Through Compiler-composed Nanokernels
- **Authors:** Arun Thangamani, Md Asghar Ahmad Shahid, Adam Siemieniuk, Rolf Morel, Renato Golin, Alexander Heinecke
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13764](https://arxiv.org/abs/2511.13764)
- **Reason:** 提出编译器自动生成高性能矩阵乘法内核的方法，性能优于现有库，属于高效大模型训练与推理中的基础设施（LLM Infra）方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Dynamic Temperature Scheduler for Knowledge Distillation
- **Authors:** Sibgat Ul Islam, Jawad Ibn Ahad, Fuad Rahman, Mohammad Ruhul Amin, Nabeel Mohammed, Shafin Rahman
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13767](https://arxiv.org/abs/2511.13767)
- **Reason:** 提出动态温度调度策略优化知识蒸馏，解决固定温度的次优问题，在多任务上验证有效性，属于高效大模型训练的关键方法。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Beat the long tail: Distribution-Aware Speculative Decoding for RL Training
- **Authors:** Zelei Shao, Vikranth Srivatsa, Sanjana Srivastava, Qingyang Wu, Alpay Ariyak, Xiaoxia Wu, Ameen Patel, Jue Wang, Percy Liang, Tri Dao, Ce Zhang, Yiying Zhang, Ben Athiwaratkun, Chenfeng Xu, Junxiong Wang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13841](https://arxiv.org/abs/2511.13841)
- **Reason:** 提出分布感知推测解码框架DAS，加速RL训练rollout过程，减少50%时间且保持性能，属于高效大模型训练关键优化。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Weight Variance Amplifier Improves Accuracy in High-Sparsity One-Shot Pruning
- **Authors:** Vincent-Daniel Yun, Junhyuk Jo, Sunwoo Lee
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14282](https://arxiv.org/abs/2511.14282)
- **Reason:** 提出权重方差放大器提升高稀疏度一键剪枝准确性，属于高效大模型训练中模型压缩优化。
Score: 8
Field: 高效大模型训练与推理

## 原生多模态大模型

### [Score: 9.0/10] EBind: a practical approach to space binding
- **Authors:** Jim Broadbent, Felix Cohen, Frederik Hvilsh{\o}j, Eric Landau, Eren Sasoglu
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14229](https://arxiv.org/abs/2511.14229)
- **Reason:** 提出多模态空间绑定方法EBind，用小模型超越大模型性能，属于原生多模态大模型创新研究。
Score: 9
Field: 原生多模态大模型

### [Score: 8.0/10] Let Language Constrain Geometry: Vision-Language Models as Semantic and Spatial Critics for 3D Generation
- **Authors:** Weimin Bai, Yubo Li, Weijian Luo, Zeqiang Lai, Yequan Wang, Wenzheng Chen, He Sun
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14271](https://arxiv.org/abs/2511.14271)
- **Reason:** 将VLM作为语义与空间评论家注入3D生成，提升语义对齐与几何一致性，涉及原生多模态大模型的跨模态推理
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] UniGen-1.5: Enhancing Image Generation and Editing through Reward Unification in Reinforcement Learning
- **Authors:** Rui Tian, Mingfei Gao, Haiming Gang, Jiasen Lu, Zhe Gan, Yinfei Yang, Zuxuan Wu, Afshin Dehghan
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14760](https://arxiv.org/abs/2511.14760)
- **Reason:** 提出统一强化学习奖励模型的多模态大语言模型（MLLM），增强图像生成与编辑能力，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models
- **Authors:** Xiaoxing Lian, Aidong Yang, Jun Zhu, Peng Wang, Yue Zhang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13782](https://arxiv.org/abs/2511.13782)
- **Reason:** 系统分析了当前VLMs在空间推理上的缺陷，提出了SpatiaLite基准和Imagery Driven Framework，对多模态大模型的空间推理能力研究具有推动作用。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] FAPE-IR: Frequency-Aware Planning and Execution Framework for All-in-One Image Restoration
- **Authors:** Jingren Liu (Beijing Institute of Technology), Shuning Xu (Beijing Institute of Technology), Qirui Yang (Beijing Institute of Technology), Yun Wang (Beijing Institute of Technology), Xiangyu Chen (Beijing Institute of Technology), Zhong Ji (Beijing Institute of Technology)
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14099](https://arxiv.org/abs/2511.14099)
- **Reason:** 提出了融合多模态大语言模型（MLLM）规划与频率感知扩散执行的全场景图像恢复框架，将语义规划与频率特征结合，实现统一可解释的多任务恢复，实验验证了跨7个任务的SOTA性能。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] SMART: Shot-Aware Multimodal Video Moment Retrieval with Audio-Enhanced MLLM
- **Authors:** An Yu, Weiheng Lu, Jian Li, Zhenfei Zhang, Yunhang Shen, Felix X. -F. Ye, Ming-Ching Chang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14143](https://arxiv.org/abs/2511.14143)
- **Reason:** 基于MLLM整合音频与视觉特征，提出镜头感知token压缩优化时间结构，提升视频时刻检索性能，涉及多模态大模型与token处理
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] GloTok: Global Perspective Tokenizer for Image Reconstruction and Generation
- **Authors:** Xuan Zhao, Zhongyu Zhang, Yuge Huang, Yuxi Mi, Guodong Mu, Shouhong Ding, Jun Wang, Rizen Guo, Shuigeng Zhou
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14184](https://arxiv.org/abs/2511.14184)
- **Reason:** 利用全局关系信息优化tokenizer语义分布，提升图像重建与生成质量，涉及原生多模态大模型的tokenizer与图像生成方向
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model
- **Authors:** Rishi Gupta, Mukilan Karuppasamy, Shyam Marjit, Aditay Tripathi, Anirban Chakraborty
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14368](https://arxiv.org/abs/2511.14368)
- **Reason:** 构建大规模图像-素描-指令数据集，训练开放权重的素描-语言模型，提升LVLM对抽象视觉输入的理解，属于原生多模态大模型
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Vision Large Language Models Are Good Noise Handlers in Engagement Analysis
- **Authors:** Alexander Vedernikov, Puneet Kumar, Haoyu Chen, Tapio Seppänen, Xiaobai Li
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14749](https://arxiv.org/abs/2511.14749)
- **Reason:** 利用视觉大语言模型（VLMs）优化交互分析的标注与训练，结合视觉与语言信息，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement
- **Authors:** Zhe Yang, Wenrui Li, Hongtao Chen, Penghong Wang, Ruiqin Xiong, Xiaopeng Fan
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13755](https://arxiv.org/abs/2511.13755)
- **Reason:** 提出RedReg框架，调节多模态冗余信息以平衡多模态优化，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection
- **Authors:** Han Wang, Deyi Ji, Junyu Lu, Lanyun Zhu, Hailong Zhang, Haiyang Wu, Liqun Liu, Peng Shu, Roy Ka-Wei Lee
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.13759](https://arxiv.org/abs/2511.13759)
- **Reason:** 利用多智能体视觉语言模型（MA-VLMs）引导自训练，处理低资源冒犯性内容检测，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

## 多模态智能体

### [Score: 8.0/10] Agentic Video Intelligence: A Flexible Framework for Advanced Video Exploration and Understanding
- **Authors:** Hong Gao, Yiming Bao, Xuezhen Tu, Yutong Xu, Yue Jin, Yiyang Mu, Bin Zhong, Linan Yue, Min-Ling Zhang
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14446](https://arxiv.org/abs/2511.14446)
- **Reason:** 提出训练-free的智能体框架，模拟人类视频理解的Retrieve-Perceive-Review三阶段推理，提升长视频推理与可解释性，符合多模态智能体方向
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design
- **Authors:** Xinpeng Chen, Xiaofeng Han, Kaihao Zhang, Guochao Ren, Yujie Wang, Wenhao Cao, Yang Zhou, Jianfeng Lu, Zhenbo Song
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14101](https://arxiv.org/abs/2511.14101)
- **Reason:** 提出了LLM驱动的多Agent协同框架用于自动化页面设计，解决了GUI设计的效率问题，对多模态智能体的GUI相关任务具有实际应用价值。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation
- **Authors:** Yu Zhong, Zihao Zhang, Rui Zhang, Lingdong Huang, Haihan Gao, Shuo Wang, Da Li, Ruijian Han, Jiaming Guo, Shaohui Peng, Di Huang, Yunji Chen
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14131](https://arxiv.org/abs/2511.14131)
- **Reason:** 提出了双进程思维框架，结合LLM的泛化能力与VLN领域专家模型，提升了Vision-and-Language Navigation的性能和效率，对多模态智能体的导航任务研究有帮助。
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution
- **Authors:** N Dinesh Reddy, Sudeep Pillai
- **Published:** 2025-11-19
- **Link:** [https://arxiv.org/abs/2511.14210](https://arxiv.org/abs/2511.14210)
- **Reason:** 设计多模态视觉代理框架，整合工具调用与跨模态推理，实现先进视觉任务执行，符合多模态智能体方向
Score: 7
Field: 多模态智能体

