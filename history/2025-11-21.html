<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-21</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >多模态智能体</a>
<a href='#' >深度学习理论</a>
<a href='#' >大模型新技术</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >大模型安全与对齐</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-21</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-21 12:26:56</p>
<p>已自动阅读了 218 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：114984</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Kandinsky 5.0: A Family of Foundation Models for Image and Video Generation</h3>
<p><strong>Authors:</strong> Vladimir Arkhipkin, Vladimir Korviakov, Nikolai Gerasimenko, Denis Parkhomenko, Viacheslav Vasilev, Alexey Letunovskiy, Maria Kovaleva, Nikolai Vaulin, Ivan Kirillov, Lev Novitskiy, Denis Koposov, Nikita Kiselev, Alexander Varlamov, Dmitrii Mikhailov, Vladimir Polovnikov, Andrey Shutkin, Ilya Vasiliev, Julia Agafonova, Anastasiia Kargapoltseva, Anna Dmitrienko, Anastasia Maltseva, Anna Averchenkova, Olga Kim, Tatiana Nikulina, Denis Dimitrov</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出Kandinsky 5.0系列图像和视频生成基础模型，涵盖轻量与专业版本，采用多阶段训练及质量增强技术，在图像视频生成任务上达到SOTA，是原生多模态大模型的典型成果。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.14993' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> VisPlay: Self-Evolving Vision-Language Models from Images</h3>
<p><strong>Authors:</strong> Yicheng He, Chengsong Huang, Zongxia Li, Jiaxin Huang, Yonghui Yang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出自进化的强化学习框架，让视觉语言模型从图像中自主提升推理能力，无需人工标注，属于原生多模态大模型中的自我改进方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.15661' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Evaluating Multimodal Large Language Models on Vertically Written Japanese Text</h3>
<p><strong>Authors:</strong> Keito Sasagawa, Shuhei Kurita, Daisuke Kawahara</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 针对竖排日文文本系统评估现有MLLM的性能，发现其处理竖排文本的不足，并通过合成数据集微调提升性能，对原生多模态大模型的跨语言/文本格式适应性研究有重要价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.15059' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Physics-Based Benchmarking Metrics for Multimodal Synthetic Images</h3>
<p><strong>Authors:</strong> Kishor Datta Gupta, Marufa Kamal, Md. Mahfuzur Rahman, Fahad Rahman, Mohd Ariful Haque, Sunzida Siddique</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出PCMDE metric结合LLM、知识映射与VLMs评估多模态合成图像的物理一致性，解决现有 metrics 无法捕捉语义/结构准确性的问题，对原生多模态大模型的评估体系有重要改进。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.15204' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Breaking Expert Knowledge Limits: Self-Pruning for Large Language Models</h3>
<p><strong>Authors:</strong> Haidong Kang, Lihong Lin, Enneng Yang, Hongning Dai, Hao Wang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出AutoPrune方法，利用LLM自身设计修剪算法并解决高修剪率下的离群值问题，无需专家知识，显著提升修剪效率与性能，属于高效大模型训练与推理中的模型压缩方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15390' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MoDES: Accelerating Mixture-of-Experts Multimodal Large Language Models via Dynamic Expert Skipping</h3>
<p><strong>Authors:</strong> Yushi Huang, Zining Wang, Zhihang Yuan, Yifu Ding, Ruihao Gong, Jinyang Guo, Xianglong Liu, Jun Zhang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出动态专家跳过框架，解决MoE多模态大模型的推理效率问题，结合全局调制与双模态阈值，显著提升推理速度与性能，属于高效大模型训练与推理中的MoE优化方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15690' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Logit-Based Losses Limit the Effectiveness of Feature Knowledge Distillation</h3>
<p><strong>Authors:</strong> Nicholas Cooper, Lijun Chen, Sailesh Dwivedy, Danna Gurari</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 论文聚焦知识蒸馏中特征蒸馏的损失函数优化，提出仅用特征损失的框架并设计知识质量 metric 识别有效教师层，在图像分类任务上取得显著性能提升，对高效大模型训练中的知识蒸馏方法有重要改进。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.14981' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Comprehensive Study on Visual Token Redundancy for Discrete Diffusion-based Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Duo Li, Zuhao Yang, Xiaoqin Zhang, Ling Shao, Shijian Lu</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 系统研究离散扩散MLLM中的视觉token冗余问题，揭示不同架构与任务下的冗余规律并提出优化策略，对高效大模型训练中的token效率提升有直接贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15098' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Multimodal Continual Instruction Tuning with Dynamic Gradient Guidance</h3>
<p><strong>Authors:</strong> Songze Li, Mingyu Gao, Tonghua Su, Xu-Yao Zhang, Zhongjie Wang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出动态梯度引导的多模态持续指令调优方法，通过近似旧任务梯度缓解灾难性遗忘，在不扩展模型的情况下取得SOTA性能，是高效大模型训练中持续学习的关键创新。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15164' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> IPTQ-ViT: Post-Training Quantization of Non-linear Functions for Integer-only Vision Transformers</h3>
<p><strong>Authors:</strong> Gihwan Kim, Jemin Lee, Hyungshin Kim</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 针对Vision Transformer提出训练后量化框架，解决非线性层量化的精度损失问题，实现全整数推理，属于高效大模型训练与推理中的模型压缩方向，具有实用价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15369' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> D4C: Data-free Quantization for Contrastive Language-Image Pre-training Models</h3>
<p><strong>Authors:</strong> Wenlun Zhang, Yunshan Zhong, Zihao Ding, Xinyu Li, Kentaro Yoshioka</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 针对CLIP提出无数据量化框架，解决现有方法语义不足与多样性低的问题，显著提升量化后的零样本分类性能，属于高效大模型训练与推理中的模型压缩方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15411' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning</h3>
<p><strong>Authors:</strong> Yuxuan Gu, Weimin Bai, Yifei Wang, Weijian Luo, He Sun</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 蒸馏加速masked auto-regressive扩散模型的推理，支持RL post-training，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15190' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Quant-Trim in Practice: Improved Cross-Platform Low-Bit Deployment on Edge NPUs</h3>
<p><strong>Authors:</strong> Rayen Dhahri, Steffen Urban</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出Quant-Trim生成硬件中性的低比特模型，提升跨平台部署一致性和效率，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15300' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Parameter Importance-Driven Continual Learning for Foundation Models</h3>
<p><strong>Authors:</strong> Lingxiang Wang, Hainan Zhang, Zhiming Zheng</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 基于参数重要性选择核心参数更新，实现持续学习，提升训练效率，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15375' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking</h3>
<p><strong>Authors:</strong> Sifan Zhou, Yichao Cao, Jiahao Nie, Yuqian Fu, Ziyu Zhao, Xiaobo Lu, Shuo Wang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出信息瓶颈引导的动态token压缩框架，解决点云跟踪中的空间与信息冗余问题，提升跟踪效率与性能，属于高效大模型训练与推理中的token压缩方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15580' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization</h3>
<p><strong>Authors:</strong> Yifeng Ding, Hung Le, Songyang Han, Kangrui Ruan, Zhenghui Jin, Varun Kumar, Zijian Wang, Anoop Deoras</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出GTPO算法用于LLM的多轮工具集成推理训练，通过turn-level奖励等提升训练效果，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.14846' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EntroPIC: Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control</h3>
<p><strong>Authors:</strong> Kai Yang, Xin Xu, Yangkun Chen, Weijie Liu, Jiafei Lyu, Zichuan Lin, Deheng Ye, Saiyong Yang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 用比例积分控制稳定LLM长期训练的熵，避免过早收敛，包含理论分析，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15248' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning</h3>
<p><strong>Authors:</strong> Yanchen Xu, Ziheng Jiao, Hongyuan Zhang, Xuelong Li</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 用GRPO驱动的RL微调表示模型，优化表示学习，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15256' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SNAP: Low-Latency Test-Time Adaptation with Sparse Updates</h3>
<p><strong>Authors:</strong> Hyeongheon Cha, Dong Min Kim, Hye Won Chung, Taesik Gong, Sung-Ju Lee</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 通过稀疏更新和代表性记忆实现低延迟测试时间适应，提升边缘设备推理效率，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15276' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Impact of Quantization on Large Reasoning Model Reinforcement Learning</h3>
<p><strong>Authors:</strong> Medha Kumar, Zifei Xu, Xin Wang, Tristan Webb</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 系统研究了量化（PTQ、QAT、QLoRA）对大模型强化学习的影响，发现PTQ和QLoRA在数学基准上的性能优于量化感知RL训练，属于高效大模型训练与推理中的量化压缩方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15694' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> AutoTool: Efficient Tool Selection for Large Language Model Agents</h3>
<p><strong>Authors:</strong> Jingyi Jia, Qinbin Li</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出基于历史轨迹的图结构框架，通过工具使用惯性建模减少LLM的重复推理调用，降低工具选择的时间成本，属于高效大模型训练与推理中的推理效率优化。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.14650' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Computer-Use Agents as Judges for Generative User Interface</h3>
<p><strong>Authors:</strong> Kevin Qinghong Lin, Siyuan Hu, Linjie Li, Zhengyuan Yang, Lijuan Wang, Philip Torr, Mike Zheng Shou</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出用计算机使用代理（CUA）作为生成式用户界面（GUI）的评判，构建AUI-Gym基准，推动代理参与GUI设计，属于多模态智能体中的GUI Agent方向。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.15567' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Think Visually, Reason Textually: Vision-Language Synergy in ARC</h3>
<p><strong>Authors:</strong> Beichen Zhang, Yuhang Zang, Xiaoyi Dong, Yuhang Cao, Haodong Duan, Dahua Lin, Jiaqi Wang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出视觉语言协同推理策略，结合视觉抽象与语言规则执行，解决ARC抽象推理问题，属于多模态智能体中的视觉语言推理方向。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.15703' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Senyu Fei, Siyin Wang, Li Ji, Ao Li, Shiduo Zhang, Liming Liu, Jinlong Hou, Jingjing Gong, Xianzhong Zhao, Xipeng Qiu</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 针对视觉-语言-动作（VLA）模型依赖专家演示的问题，提出自参考策略优化框架，利用模型自身成功轨迹解决奖励稀疏问题，在LIBERO基准上实现从48.9%到99.2%的成功利率提升，直接服务于多模态智能体的政策优化
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.15605' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AVATAAR: Agentic Video Answering via Temporal Adaptive Alignment and Reasoning</h3>
<p><strong>Authors:</strong> Urjitkumar Patel, Fang-Chun Yeh, Chinmay Gondhalekar</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出Agentic视频问答框架，结合全局摘要与局部推理，通过反馈循环提升时间推理与叙事理解性能，属于多模态智能体中的视频理解方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.15578' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design</h3>
<p><strong>Authors:</strong> Xinpeng Chen, Xiaofeng Han, Kaihao Zhang, Guochao Ren, Yujie Wang, Wenhao Cao, Yang Zhou, Jianfeng Lu, Zhenbo Song</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出LLM驱动的多agent协同框架用于移动应用页面自动设计，通过OrchestratorAgent协调语义解析、布局生成、模板检索等子agent，解决了布局设计的复杂性问题，属于多模态智能体中的GUI Agent方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.14101' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation</h3>
<p><strong>Authors:</strong> Yu Zhong, Zihao Zhang, Rui Zhang, Lingdong Huang, Haihan Gao, Shuo Wang, Da Li, Ruijian Han, Jiaming Guo, Shaohui Peng, Di Huang, Yunji Chen</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出双进程框架整合轻量级VLN专家模型（Runner）和多模态LLM推理（Ruminator），通过Regulator协调两种模式，提升Vision-and-Language Navigation的性能，属于多模态智能体中的导航任务。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.14131' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> C2F-Space: Coarse-to-Fine Space Grounding for Spatial Instructions using Vision-Language Models</h3>
<p><strong>Authors:</strong> Nayoung Oh, Dohyun Kim, Junhyeong Bang, Rohan Paul, Daehyung Park</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出粗到细的空间接地框架，结合视觉语言模型（VLM）的空间理解能力与超像素细化模块，解决传统方法难以处理的复杂空间推理问题，在空间接地基准与机器人拾取任务中验证了有效性，与多模态智能体的空间理解需求高度相关
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.15333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> From Low-Rank Features to Encoding Mismatch: Rethinking Feature Distillation in Vision Transformers</h3>
<p><strong>Authors:</strong> Huiyuan Tian, Bonan Xu, Shijian Li, Xin Jin</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 通过SVD与SEP分析揭示ViT特征蒸馏失败的原因（编码不匹配），提出宽度对齐策略，显著提升蒸馏性能，属于深度学习理论中的网络架构与特征表示方向。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.15572' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Transformer Injectivity & Geometric Robustness - Analytic Margins and Bi-Lipschitz Uniformity of Sequence-Level Hidden States</h3>
<p><strong>Authors:</strong> Mikael von Strauss</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 研究Transformer的单射性、几何鲁棒性及量化影响，涉及模型表示的理论分析（分离边际、co-Lipschitz常数），符合深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.14808' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Dynamic Nested Hierarchies: Pioneering Self-Evolution in Machine Learning Architectures for Lifelong Intelligence</h3>
<p><strong>Authors:</strong> Akbar Anbar Jafari, Cagri Ozcinar, Gholamreza Anbarjafari</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出动态嵌套层次结构解决终身学习中的模型刚性问题，支持架构自调整，包含数学证明和收敛性分析，符合深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.14823' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Complex variational autoencoders admit K\"ahler structure</h3>
<p><strong>Authors:</strong> Andrew Gracyk</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 分析复杂VAE的Kähler几何结构，推导Fisher信息度量与KL散度的关系，符合深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.15172' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> KrawtchoukNet: A Unified GNN Solution for Heterophily and Over-smoothing with Adaptive Bounded Polynomials</h3>
<p><strong>Authors:</strong> Huseyin Goksu</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出KrawtchoukNet解决GNN的异质性和过平滑问题，符合深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.15327' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LaguerreNet: Advancing a Unified Solution for Heterophily and Over-smoothing with Adaptive Continuous Polynomials</h3>
<p><strong>Authors:</strong> Huseyin Goksu</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出LaguerreNet解决GNN的异质性和过平滑问题，符合深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.15328' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation</h3>
<p><strong>Authors:</strong> Jing Cao, Kui Jiang, Shenyi Li, Xiaocheng Feng, Yong Huang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出自进化对比学习框架SEC-Depth，利用训练中间参数构建latency模型，通过对比损失提升深度估计鲁棒性，是深度学习理论中对比学习策略的重要改进。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.15167' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> On the Internal Semantics of Time-Series Foundation Models</h3>
<p><strong>Authors:</strong> Atharva Pandey, Abhilash Neog, Gautam Jajoo</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 系统分析时间序列基础模型的层语义和表示演化，符合深度学习理论方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.15324' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Towards Understanding Layer Contributions in Tabular In-Context Learning Models</h3>
<p><strong>Authors:</strong> Amir Rezaei Balef, Mykhailo Koshil, Katharina Eggensperger</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 分析tabular ICL模型的层贡献和潜在空间演化，符合深度学习理论方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.15432' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Reasoning via Video: The First Evaluation of Video Models' Reasoning Abilities through Maze-Solving Tasks</h3>
<p><strong>Authors:</strong> Cheng Yang, Haiyuan Wan, Yiran Peng, Xin Cheng, Zhaoyang Yu, Jiayi Zhang, Junchi Yu, Xinlei Yu, Xiawu Zheng, Dongzhan Zhou, Chenglin Wu</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出VR-Bench基准首次系统评估视频模型的推理能力，通过迷宫任务验证视频模型的空间推理潜力，开创了大模型新技术中视频模型推理能力研究的新方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.15065' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Learning to Expand Images for Efficient Visual Autoregressive Modeling</h3>
<p><strong>Authors:</strong> Ruiqing Yang, Kaixin Zhang, Zheng Zhang, Shan You, Tao Huang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出基于螺旋扩展的视觉自回归生成范式（EAR），模拟人类中心向外的感知模式，提升生成效率与质量，属于大模型新技术中的自回归生成方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.15499' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FlashMesh: Faster and Better Autoregressive Mesh Synthesis via Structured Speculation</h3>
<p><strong>Authors:</strong> Tingrui Shen, Yiheng Zhang, Chen Tang, Chuan Ping, Zixing Zhao, Le Wan, Yuwang Wang, Ronggang Wang, Shengfeng He</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出结构化推测的自回归网格合成框架，利用网格的结构相关性加速生成，提升效率与质量，属于大模型新技术中的3D生成方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.15618' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> First Frame Is the Place to Go for Video Content Customization</h3>
<p><strong>Authors:</strong> Jingxi Chen, Zongxia Li, Zhichao Liu, Guangyao Shi, Xiyang Wu, Fuxiao Liu, Cornelia Fermuller, Brandon Y. Feng, Yiannis Aloimonos</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 揭示视频生成模型中第一帧作为概念记忆缓冲的作用，提出仅用少量训练样例实现视频内容定制，属于大模型新技术中的视频生成方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.15700' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Reasoning in Diffusion Large Language Models is Concentrated in Dynamic Confusion Zones</h3>
<p><strong>Authors:</strong> Ranfei Chen, Ming Chen, Kaifei Wang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 分析diffusion LLM的推理集中在动态混淆区，提出ATPO优化，符合大模型新技术方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.15208' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MambaTrack3D: A State Space Model Framework for LiDAR-Based Object Tracking under High Temporal Variation</h3>
<p><strong>Authors:</strong> Shengjing Tian, Yinan Han, Xiantong Zhao, Xuehu Liu, Qi Lang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 将状态空间模型Mamba应用于LiDAR目标跟踪，设计MIP与GFEM模块解决高时间变化下的跟踪问题，是大模型新技术中状态空间模型的重要应用创新。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.15077' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DEVAL: A Framework for Evaluating and Improving the Derivation Capability of Large Language Models</h3>
<p><strong>Authors:</strong> Yifan Li, Qin Li, Min Zhang, Min Zhang, Peixin Wang</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出DEVAL框架评估LLM的推导能力，提出Derivation Prompting提升该能力，揭示LLM在应用推导关系时的性能下降问题，符合大模型新技术方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.14813' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> When to Think and When to Look: Uncertainty-Guided Lookback</h3>
<p><strong>Authors:</strong> Jing Bi (Yolo), Filippos Bellos (Yolo), Junjia Guo (Yolo), Yayuan Li (Yolo), Chao Huang (Yolo), Yunlong (Yolo), Tang (Mark), Luchuan Song (Mark), Susan Liang (Mark), Zhongfei (Mark), Zhang, Jason J. Corso, Chenliang Xu</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出不确定性引导的回溯策略，结合视觉与语言模型的优势，改善视觉语言模型的推理性能，属于深度学习可解释性中的不确定性量化方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.15613' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Structured Contrastive Learning for Interpretable Latent Representations</h3>
<p><strong>Authors:</strong> Zhengyang Shen, Hua Tu, Mayue Shi</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 通过结构化对比学习得到可解释的latent表示，解决表示对无关变换的脆弱性，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.14920' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Knowledge Graphs as Structured Memory for Embedding Spaces: From Training Clusters to Explainable Inference</h3>
<p><strong>Authors:</strong> Artur A. Oliveira, Mateus Espadoto, Roberto M. Cesar Jr., Roberto Hirata Jr</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 用知识图谱增强嵌入空间的推理，提供可解释的推断，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.14961' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CID: Measuring Feature Importance Through Counterfactual Distributions</h3>
<p><strong>Authors:</strong> Eddie Conti, \'Alvaro Parafita, Axel Brando</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 通过反事实分布测量特征重要性，提升解释忠实性，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.15371' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> It's LIT! Reliability-Optimized LLMs with Inspectable Tools</h3>
<p><strong>Authors:</strong> Ruixin Zhang, Jon Donnelly, Zhicheng Guo, Ghazal Khalighinejad, Haiyang Huang, Alina Jade Barnett, Cynthia Rudin</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出LIT框架通过可检查工具提升LLM可靠性，构建基准数据集和可靠性成本函数，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.14903' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior</h3>
<p><strong>Authors:</strong> Dalia Ali, Dora Zhao, Allison Koenecke, Orestis Papakyriakopoulos</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 系统研究了LLM对齐中多元价值观的整合，分析了人口统计学效应（如性别、种族、政治倾向）和技术设计选择（如评分尺度、分歧处理、优化技术）对模型行为的影响，揭示了安全与包容性的权衡，属于大模型安全与对齐的核心问题。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.14476' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> HV-Attack: Hierarchical Visual Attack for Multimodal Retrieval Augmented Generation</h3>
<p><strong>Authors:</strong> Linyin Luo, Yujuan Ding, Yunshan Ma, Wenqi Fan, Hanjiang Lai</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出针对多模态检索增强生成（MRAG）的分层视觉攻击方法，仅通过图像扰动降低检索与生成性能，揭示MRAG系统的安全漏洞，属于大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.15435' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Transferable Dual-Domain Feature Importance Attack against AI-Generated Image Detector</h3>
<p><strong>Authors:</strong> Weiheng Zhu, Gang Cao, Jing Liu, Lifang Yu, Shaowei Weng</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出双域特征重要性攻击（DuFIA），通过空间与频率域的特征扰动降低AI生成图像检测器的性能，具有跨模型迁移性，属于大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.15571' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs</h3>
<p><strong>Authors:</strong> Xiaoxuan Wang, Bo Liu, Song Jiang, Jingzhou Liu, Jingyuan Qi, Xia Chen, Baosheng He</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 提出GRPO-Verif优化LLM的自验证能力，提升推理可靠性，符合大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.15137' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Jailbreaking Large Vision Language Models in Intelligent Transportation Systems</h3>
<p><strong>Authors:</strong> Badhan Chandra Das, Md Tasnim Jawad, Md Jueal Mia, M. Hadi Amini, Yanzhao Wu</p>
<p><strong>Published:</strong> 2025-11-20</p>
<p><strong>Reason:</strong> 分析了智能交通系统中LVLM的jailbreaking漏洞，提出基于图像排版 manipulation和多轮prompt的攻击方法，以及多分层响应过滤防御，属于大模型安全与对齐中的安全问题。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.13892' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>