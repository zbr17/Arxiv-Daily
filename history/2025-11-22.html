<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-22</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >大模型新技术</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-22</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-22 12:24:43</p>
<p>已自动阅读了 228 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：118664</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SAM 3D: 3Dfy Anything in Images</h3>
<p><strong>Authors:</strong> SAM 3D Team, Xingyu Chen, Fu-Jen Chu, Pierre Gleize, Kevin J Liang, Alexander Sax, Hao Tang, Weiyao Wang, Michelle Guo, Thibaut Hardin, Xiang Li, Aohan Lin, Jiawei Liu, Ziqi Ma, Anushka Sagar, Bowen Song, Xiaodong Wang, Jianing Yang, Bowen Zhang, Piotr Dollár, Georgia Gkioxari, Matt Feiszli, Jitendra Malik</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文提出SAM 3D，通过人机协作标注 pipeline 构建大规模视觉接地3D重建数据，结合多阶段训练框架实现从单张图像的3D物体重建，在人类偏好测试中对现有方法取得5:1胜率，作者团队包含Jitendra Malik等知名学者，属于原生多模态大模型中的3D理解与图像生成前沿研究。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16624' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Click2Graph: Interactive Panoptic Video Scene Graphs from a Single Click</h3>
<p><strong>Authors:</strong> Raphael Ruschel, Hardikkumar Prajapati, Awsafur Rahman, B. S. Manjunath</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出首个交互式全景视频场景图生成框架，结合视觉提示（点击）与时空语义推理，实现从单点击到跨时间场景图的生成，推动多模态可解释视频理解。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.15948' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LEGO-SLAM: Language-Embedded Gaussian Optimization SLAM</h3>
<p><strong>Authors:</strong> Sibaek Lee, Seongbo Ha, Kyeongsu Kang, Joonyeol Choi, Seungjun Tak, Hyeonwoo Yu</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 首次将语言特征整合到3D Gaussian Splatting SLAM中，通过场景自适应编码器压缩语言嵌入，实现实时开放词汇映射，同时减少内存使用（60%），推动多模态SLAM的实用化。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16144' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Video2Layout: Recall and Reconstruct Metric-Grounded Cognitive Map for Spatial Reasoning</h3>
<p><strong>Authors:</strong> Yibin Huang, Wang Xu, Wanyue Zhang, Helu Zhi, Jingjing Huang, Yangbin Xu, Yangang Sun, Conghui Zhu, Tiejun Zhao</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出从视频重建 metric-grounded空间布局的框架，通过连续边界坐标量化空间关系，提升MLLM的定量空间推理能力，在QVS-Bench上比网格图模型高4.92%。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16160' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> NaTex: Seamless Texture Generation as Latent Color Diffusion</h3>
<p><strong>Authors:</strong> Zeqiang Lai, Yunfei Zhao, Zibo Zhao, Xin Yang, Xin Huang, Jingwei Huang, Xiangyu Yue, Chunchao Guo</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文提出原生纹理生成框架NaTex，通过 latent color diffusion 直接在3D空间预测纹理颜色，解决了传统多视图扩散方法的 occlusion、对齐与一致性问题，属于原生多模态大模型中的图像生成研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16317' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding</h3>
<p><strong>Authors:</strong> Boshen Xu, Zihan Xiao, Jiaze Li, Jianzhong Ju, Zhenbo Luo, Jian Luan, Qin Jin</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文提出混合Mamba-Transformer的视觉语言模型TimeViper，通过TransV模块将视觉token压缩到指令token，实现小时级长视频处理（超过10,000帧），同时分析了Mamba与Transformer层的注意力行为，为长视频理解的多模态模型设计提供了新 insights。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16595' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MiMo-Embodied: X-Embodied Foundation Model Technical Report</h3>
<p><strong>Authors:</strong> Xiaoshuai Hao, Lei Zhou, Zhijian Huang, Zhiwen Hou, Yingbo Tang, Lingfeng Zhang, Guang Li, Zheng Lu, Shuhuai Ren, Xianhui Meng, Yuchen Zhang, Jing Wu, Jinghui Lu, Chenxu Dang, Jiayi Guan, Jianhua Wu, Zhiyi Hou, Hanbing Li, Shumeng Xia, Mingliang Zhou, Yinan Zheng, Zihao Yue, Shuhao Gu, Hao Tian, Yuannan Shen, Jianwei Cui, Wen Zhang, Shaoqing Xu, Bing Wang, Haiyang Sun, Zeyu Zhu, Yuncheng Jiang, Zibin Guo, Chuhong Gong, Chaofan Zhang, Wenbo Ding, Kun Ma, Guang Chen, Rui Cai, Diyun Xiang, Heng Qu, Fuli Luo, Hangjun Ye, Long Chen</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 开源首个跨Embodied领域（自动驾驶与Embodied AI）的多模态基础模型MiMo-Embodied，在17个Embodied AI基准和12个自动驾驶基准上取得SOTA，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16518' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LLaVA³: Representing 3D Scenes like a Cubist Painter to Boost 3D Scene Understanding of VLMs</h3>
<p><strong>Authors:</strong> Doriand Petit, Steve Bourgeois, Vincent Gay-Bellile, Florian Chabot, Loïc Barthe</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文受立体派绘画启发，提出LLaVA³方法，通过多视图2D图像构建3D场景的全向视觉表示，无需微调即可提升视觉语言模型（VLM）的3D场景理解能力，在3D VQA与语言接地任务上优于现有2D-based VLM方案。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16454' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Contrastive vision-language learning with paraphrasing and negation</h3>
<p><strong>Authors:</strong> Kwun Ho Ngan, Saman Sadeghi Afgeh, Joe Townsend, Artur d'Avila Garcez</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文提出SemCLIP，通过结合paraphrasing（ paraphrase 文本）与negation（否定文本）改进视觉语言对比学习，使paraphrase文本更接近原图嵌入、否定文本更远离，在CC-Neg基准上图像检索准确率从68.1%提升至78.1%，增强了视觉语言模型的语义鲁棒性。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16527' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning to Think Fast and Slow for Visual Language Models</h3>
<p><strong>Authors:</strong> Chenyu Lin, Cheng Chi, Jinlin Wu, Sharon Li, Kaiyang Zhou</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出强化学习方法让视觉语言模型（VLMs）根据任务难度自动切换快慢思考模式，提升推理效率和token利用率，属于原生多模态大模型方向的推理优化。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16670' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Thinking-while-Generating: Interleaving Textual Reasoning throughout Visual Generation</h3>
<p><strong>Authors:</strong> Ziyu Guo, Renrui Zhang, Hongyu Li, Manyuan Zhang, Xinyan Chen, Sifan Wang, Yan Feng, Peng Pei, Pheng-Ann Heng</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出Thinking-while-Generating框架，在视觉生成过程中 interleaved文本推理，提升生成内容的语义丰富性和上下文一致性，属于原生多模态大模型方向的多模态生成优化。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16671' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EvoLMM: Self-Evolving Large Multimodal Models with Continuous Rewards</h3>
<p><strong>Authors:</strong> Omkat Thawakar, Shravan Venkatraman, Ritesh Thawkar, Abdelrahman Shaker, Hisham Cholakkal, Rao Muhammad Anwer, Salman Khan, Fahad Khan</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出自进化框架EvoLMM，通过Proposer（生成问题）和Solver（解决问题）的协同自监督学习，提升大 multimodal模型（LMMs）的推理能力，属于原生多模态大模型方向的自改进研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16672' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ODE-ViT: Plug & Play Attention Layer from the Generalization of the ViT as an Ordinary Differential Equation</h3>
<p><strong>Authors:</strong> Carlos Boned Riera, David Romero Sanchez, Oriol Ramos Terrades</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 将Vision Transformer重构为满足适定性与稳定性的ODE系统，减少参数同时保持性能，还提出teacher-student框架提升效果，属于深度学习理论中网络架构与动力学分析的创新。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.16501' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Almost Sure Convergence Analysis of Differentially Private Stochastic Gradient Methods</h3>
<p><strong>Authors:</strong> Amartya Mukherjee, Jun Liu</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 证明差分隐私SGD及其动量变体的几乎必然收敛性，属于深度学习理论中优化器的理论分析，为差分隐私训练提供更严格的理论保证。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.16587' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TetraSDF: Precise Mesh Extraction with Multi-resolution Tetrahedral Grid</h3>
<p><strong>Authors:</strong> Seonghun Oh, Youngjung Uh, Jin-Hwa Kim</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文针对神经符号距离函数（SDF）的网格提取问题，提出结合ReLU MLP与多分辨率四面体位置编码器的TetraSDF框架，利用连续分段仿射（CPWA）结构追踪ReLU线性区域，对深度学习理论中的分段线性模型与网络架构设计有创新贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.16273' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Broad stochastic configuration residual learning system for norm-convergent universal approximation</h3>
<p><strong>Authors:</strong> Han Su, Zhongyan Li, Wanquan Liu</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出BSCRLS算法解决宽残差学习系统的泛逼近问题，基于更严格的norm收敛证明其普遍性，属于深度学习理论中的网络架构与泛逼近理论。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.16550' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.5/10]</span> Loss Functions Robust to the Presence of Label Errors</h3>
<p><strong>Authors:</strong> Nicholas Pellegrino, David Szczecina, Paul Fieguth</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出两种抗标签错误的损失函数，通过de-weight或忽略难样本提升标签错误下的模型性能，属于深度学习理论中损失函数优化的重要研究。
Score: 7.5
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.16512' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Evolution Strategies at the Hyperscale</h3>
<p><strong>Authors:</strong> Bidipta Sarkar, Mattie Fellows, Juan Agustin Duque, Alistair Letcher, Antonio Le\'on Villares, Anya Sims, Dylan Cope, Jarek Liesen, Lukas Seier, Theo Wolf, Uljad Berdica, Alexander David Goldie, Aaron Courville, Karin Sevegnani, Shimon Whiteson, Jakob Nicolaus Foerster</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出EGGROLL算法用低秩扰动实现大规模进化策略，减少计算与内存开销，属于高效大模型训练与推理中的优化方法。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16652' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> FT-NCFM: An Influence-Aware Data Distillation Framework for Efficient VLA Models</h3>
<p><strong>Authors:</strong> Kewei Chen, Yayu Long, Shuai Li, Mingsheng Shang</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出FT-NCFM数据蒸馏框架，结合因果归因与对比验证评估样本价值，合成信息密集数据集，仅用5%数据即可达到全量数据85-90%的性能，显著提升VLA模型训练效率，属于高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16233' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> Dynamic Participation in Federated Learning: Benchmarks and a Knowledge Pool Plugin</h3>
<p><strong>Authors:</strong> Ming-Lun Lee, Fu-Shiang Yang, Cheng-Kuan Lin, Yan-Ann Chen, Chih-Yu Lin, Yu-Chee Tseng</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出KPFL框架解决联邦学习中的动态参与问题，通过知识池与生成式蒸馏提升鲁棒性，属于高效大模型训练与推理中的联邦学习优化。
Score: 8.5
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16523' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter</h3>
<p><strong>Authors:</strong> Qinghao Hu, Shang Yang, Junxian Guo, Xiaozhe Yao, Yujun Lin, Yuxian Gu, Han Cai, Chuang Gan, Ana Klimovic, Song Han</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出TLT系统通过自适应投机解码加速推理RL训练，解决长响应的计算瓶颈，属于高效大模型训练与推理中的推理优化。
Score: 8.5
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16665' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EfficientSAM3: Progressive Hierarchical Distillation for Video Concept Segmentation from SAM1, 2, and 3</h3>
<p><strong>Authors:</strong> Chengxi Zeng, Yuxuan Jiang, Aaron Zhang</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出Progressive Hierarchical Distillation策略，将SAM3的能力迁移到轻量级模型，优化编码器、 temporal memory和端到端微调，实现高效的视频概念分割与跟踪，显著提升推理效率并保持性能。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15833' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AMS-KV: Adaptive KV Caching in Multi-Scale Visual Autoregressive Transformers</h3>
<p><strong>Authors:</strong> Boxun Xu, Yu Wang, Zihu Wang, Peng Li</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 针对多尺度视觉自回归Transformer的KV缓存瓶颈，提出尺度自适应的KV缓存策略，优先存储关键尺度的KV，减少内存使用（最高84.83%）和自注意力延迟（60.48%），同时保持生成质量。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16047' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Progressive Supernet Training for Efficient Visual Autoregressive Modeling</h3>
<p><strong>Authors:</strong> Xiaoyue Chen, Yuling Shi, Kaiyuan Li, Huandong Wang, Yong Li, Xiaodong Gu, Xinlei Chen, Mingbao Lin</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文提出VARiant框架，通过渐进式超网络训练策略，在视觉自回归模型中实现不同深度子网络的权重共享与联合优化，在保持生成质量（FID仅轻微上升）的同时，将内存消耗降低40%-80%，属于高效大模型训练与推理中的模型压缩研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16546' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Teacher-Guided One-Shot Pruning via Context-Aware Knowledge Distillation</h3>
<p><strong>Authors:</strong> Md. Samiul Alim, Sharjil Khan, Amrijit Biswas, Fuad Rahman, Shafin Rahman, Nabeel Mohammed</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文提出教师引导的单步剪枝框架，结合上下文感知知识蒸馏，利用教师模型的梯度信号优化参数重要性评分，在CIFAR-10等基准上实现高稀疏度（如90%）下的性能保持，优于EPG、EPSD等现有剪枝方法，属于高效大模型训练与推理中的模型剪枝研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16653' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy</h3>
<p><strong>Authors:</strong> Yang Tian, Yuyin Yang, Yiman Xie, Zetao Cai, Xu Shi, Ning Gao, Hangxu Liu, Xuekun Jiang, Zherui Qiu, Feng Yuan, Yaping Li, Ping Wang, Junhao Cai, Jia Zeng, Hao Dong, Jiangmiao Pang</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出大规模高保真合成数据集InternData-A1，仅用合成数据预训练VLA模型即可匹配真实数据预训练的π₀模型性能，且实现零-shot sim-to-real迁移，显著降低VLA模型训练的数据依赖，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16651' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Pluggable Pruning with Contiguous Layer Distillation for Diffusion Transformers</h3>
<p><strong>Authors:</strong> Jian Ma, Qirong Peng, Xujie Zhu, Peixing Xie, Chen Chen, Haonan Lu</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 针对Diffusion Transformers的大参数问题，提出结构化剪枝框架PPCL，通过线性探测和连续层蒸馏，在减少50%参数的同时保持生成质量，适用于资源受限环境。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16156' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Global Resolution: Optimal Multi-Draft Speculative Sampling via Convex Minimization</h3>
<p><strong>Authors:</strong> Rahul Krishna Thomas, Arka Pal</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 针对多draft speculative sampling的优化问题，提出基于凸优化的最优解，提升LLM推理的接受率和效率，是高效大模型训练与推理方向的推理优化关键方法。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15898' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ILoRA: Federated Learning with Low-Rank Adaptation for Heterogeneous Client Aggregation</h3>
<p><strong>Authors:</strong> Junchao Zhou, Junkang Liu, Fanhua Shang</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 针对联邦学习中LoRA的初始化不稳定、rank不兼容和客户端漂移问题，提出ILoRA框架，通过QR初始化、Concatenated QR聚合和rank-aware优化器提升联邦LoRA的训练稳定性和效率，属于高效大模型训练与推理方向的联邦学习优化。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16069' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and Turn</h3>
<p><strong>Authors:</strong> Chao Yu (Tsinghua University), Qixin Tan (Tsinghua University), Jiaxuan Gao (Tsinghua University), Shi Yu (Tsinghua University), Hong Lu (Tsinghua University), Xinting Yang (Tsinghua University), Zelai Xu (Tsinghua University), Yu Wang (Tsinghua University), Yi Wu (Tsinghua University), Eugene Vinitsky (New York University)</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出3D测试时缩放框架，整合context、batch和turn三个维度的测试时优化，提升LLM推理的准确性和效率，属于高效大模型训练与推理方向的测试时性能增强。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.15738' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Change-of-Basis Pruning via Rotational Invariance</h3>
<p><strong>Authors:</strong> Alex Ning, Vainateya Rangaraju</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出旋转不变的激活函数（TSRAs）用于Change-of-Basis剪枝，解决结构化剪枝的表示空间问题，提升剪枝效率和精度，是高效大模型训练与推理方向的模型压缩方法创新。
Score: 6
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16061' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SafeRBench: A Comprehensive Benchmark for Safety Assessment in Large Reasoning Models</h3>
<p><strong>Authors:</strong> Xin Gao, Shaohan Yu, Zerui Chen, Yueming Lyu, Weichen Yu, Guanghao Li, Jiyao Liu, Jianxiong Gao, Jian Liang, Ziwei Liu, Chenyang Si</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出SafeRBench基准评估大推理模型的端到端安全，覆盖输入、推理、输出多维度，属于大模型安全与对齐的重要工具。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.15169' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> As If We've Met Before: LLMs Exhibit Certainty in Recognizing Seen Files</h3>
<p><strong>Authors:</strong> Haodong Li, Jingqi Zhang, Xiao Cheng, Peihua Mai, Haoyu Wang, Yan Pang</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出COPYCHECK框架用不确定性检测LLM训练数据中的版权内容，属于大模型安全与对齐中的训练数据透明度问题。
Score: 8.5
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.15192' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Yuping Yan, Yuhan Xie, Yinxin Zhang, Lingjuan Lyu, Yaochu Jin</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 首次系统研究VLA模型的多模态对抗鲁棒性，提出VLA-Fool框架涵盖文本、视觉和跨模态攻击，揭示即使小扰动也会导致行为偏差，推动大模型安全研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.16203' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> An Image Is Worth Ten Thousand Words: Verbose-Text Induction Attacks on VLMs</h3>
<p><strong>Authors:</strong> Zhi Luo, Zenghui Yuan, Wenqi Wei, Daizong Liu, Pan Zhou</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出针对VLM的verbose文本诱导攻击，通过两阶段框架生成对抗图像，导致VLM生成冗长低信息输出，揭示VLM的安全脆弱性，属于大模型安全研究。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.16163' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Descend or Rewind? Stochastic Gradient Descent Unlearning</h3>
<p><strong>Authors:</strong> Siqiao Mu, Diego Klabjan</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 研究stochastic R2D和D2D的机器遗忘算法，证明非凸损失下的$(\epsilon, \delta)$认证遗忘保证，为大模型安全与对齐方向的机器遗忘提供理论支撑。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.15983' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> Correlation-Aware Feature Attribution Based Explainable AI</h3>
<p><strong>Authors:</strong> Poushali Sengupta, Yan Zhang, Frank Eliassen, Sabita Maharjan</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出ExCIR与BlockCIR方法，解决现有全局归因方法计算成本高、相关输入下稳定性差的问题，通过相关感知归因与分组扩展提升可解释性的效率与稳定性，属于深度学习可解释性的核心研究。
Score: 8.5
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.16482' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Graph Diffusion Counterfactual Explanation</h3>
<p><strong>Authors:</strong> David Bechtoldt, Sidney Bender</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出Graph Diffusion Counterfactual Explanation框架，结合离散扩散模型与classifier-free guidance生成图数据的反事实解释，解决图数据离散性与非欧特性带来的可解释性难题，属于深度学习可解释性的重要研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.16287' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Target Refocusing via Attention Redistribution for Open-Vocabulary Semantic Segmentation: An Explainability Perspective</h3>
<p><strong>Authors:</strong> Jiahao Li, Yang Lu, Yachao Zhang, Yong Xie, Fangyong Wang, Yuan Xie, Yanyun Qu</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 从可解释性角度分析CLIP的注意力机制，发现CLIP会分散注意力到无关token，提出RF-CLIP重定向注意力到目标区域，提升开放词汇分割性能，属于白盒解释方法。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.16170' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RB-FT: Rationale-Bootstrapped Fine-Tuning for Video Classification</h3>
<p><strong>Authors:</strong> Meilong Xu, Di Fu, Jiaxing Zhang, Gong Yu, Jiayu Zheng, Xiaoling Hu, Dongdi Zhao, Feiyang Li, Chao Chen, Yong Cao</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出用VLM生成文本rationale引导视频分类的微调，强制模型阐述领域逻辑，桥接时空内容与抽象标签的gap，提升小数据下的性能，属于可解释性方法。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.15923' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Sparse Autoencoders are Topic Models</h3>
<p><strong>Authors:</strong> Leander Girrbach, Zeynep Akata</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文将稀疏自编码器（SAE）重新解释为主题模型，通过扩展Latent Dirichlet Allocation到嵌入空间推导SAE目标，证明SAE特征可作为主题组件，提升了SAE的可解释性，为跨模态主题分析提供了白盒解释工具。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.16309' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> An Interpretability-Guided Framework for Responsible Synthetic Data Generation in Emotional Text</h3>
<p><strong>Authors:</strong> Paula Joy B. Martinez, Jose Marie Antonio Miñoza, Sebastian C. Ibañez</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 利用Shapley Additive Explanations（SHAP）引导LLM生成合成情感文本，提升合成数据的可解释性和可靠性，是深度学习可解释性方向在合成数据生成中的应用研究。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.16132' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> gfnx: Fast and Scalable Library for Generative Flow Networks in JAX</h3>
<p><strong>Authors:</strong> Daniil Tiapkin, Artem Agarkov, Nikita Morozov, Ian Maksimov, Askar Tsyganov, Timofei Gritsaev, Sergey Samsonov</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 开发gfnx库实现高效的Generative Flow Networks，比PyTorch版本快数倍，属于大模型新技术中GFlowNets的工程化创新。
Score: 8.5
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.16592' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Breaking the Bottleneck with DiffuApriel: High-Throughput Diffusion LMs with Mamba Backbone</h3>
<p><strong>Authors:</strong> Vaibhav Singh, Oleksiy Ostapenko, Pierre-André Noël, Torsten Scholak</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出DiffuApriel框架，将扩散语言模型（diffusion LM）与Mamba backbone结合，解决Transformer-based扩散LM的推理效率瓶颈，显著提升长序列生成吞吐量，是大模型新技术方向（diffusion LLM）的重要效率改进。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.15927' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Saving Foundation Flow-Matching Priors for Inverse Problems</h3>
<p><strong>Authors:</strong> Yuxiang Wan, Ryan Devera, Wenjie Zhang, Ju Sun</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出FMPlug框架改进基础流匹配模型在逆问题中的性能，属于大模型新技术中流匹配生成模型的应用创新。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.16520' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Decoupling Complexity from Scale in Latent Diffusion Model</h3>
<p><strong>Authors:</strong> Tianxiong Zhong, Xingye Tian, Xuebo Wang, Boyuan Jiang, Xin Tao, Pengfei Wan</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出DCS-LDM，将 latent diffusion模型的复杂度与尺度解耦，通过分层尺度无关潜空间支持任意分辨率生成，属于diffusion大模型的新技术。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.16117' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TRIM: Scalable 3D Gaussian Diffusion Inference with Temporal and Spatial Trimming</h3>
<p><strong>Authors:</strong> Zeyuan Yin, Xiaoming Liu</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 论文针对3D高斯扩散模型推理效率低的问题，提出TRIM框架，通过时间轨迹修剪与空间实例掩码降噪策略，在不损失生成质量的前提下加速推理，支持inference-time模型缩放，属于大模型新技术中的扩散模型优化研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.16642' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EvoVLA: Self-Evolving Vision-Language-Action Model</h3>
<p><strong>Authors:</strong> Zeting Liu, Zida Yang, Zeyu Zhang, Hao Tang</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 针对长 horizon机器人操纵的VLA模型，提出Stage-Aligned Reward、Pose-Based Object Exploration和长时记忆，提升任务成功率（69.2% vs 基线59%）和样本效率，减少幻觉。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.16166' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight</h3>
<p><strong>Authors:</strong> Yi Yang, Xueqi Li, Yiyang Chen, Jin Song, Yihan Wang, Zipeng Xiao, Jiadi Su, You Qiaoben, Pengfei Liu, Zhijie Deng</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出解耦视觉 foresight的VLA框架，通过meta queries和Diffusion Transformer捕捉 latent动作，提升语言理解和推理能力，在LIBERO基准上达到96.7%成功率。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.16175' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration</h3>
<p><strong>Authors:</strong> Yifu Guo, Zishan Xu, Zhiyuan Yao, Yuquan Lu, Jiaye Lin, Sen Hu, Zhenheng Tang, Yingchao Li, Huacan Wang, Ronghao Chen</p>
<p><strong>Published:</strong> 2025-11-21</p>
<p><strong>Reason:</strong> 提出Octopus多模态智能体框架，通过六种核心能力编排实现自主多模态推理，构建Octopus-Bench基准验证其在多任务上的最优性能，与多模态智能体研究方向高度契合。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.15351' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>