<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-25</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >深度学习理论</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >大模型新技术</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-25</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-25 12:25:39</p>
<p>已自动阅读了 207 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：100013</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SAM 3: Segment Anything with Concepts</h3>
<p><strong>Authors:</strong> Nicolas Carion (Meta), Laura Gustafson (Meta), Yuan-Ting Hu (Meta), Shoubhik Debnath (Meta), Ronghang Hu (Meta), Didac Suris (Meta), Chaitanya Ryali (Meta), Kalyan Vasudev Alwala (Meta), Haitham Khedr (Meta), Andrew Huang (Meta), Jie Lei (Meta), Tengyu Ma (Meta), Baishan Guo (Meta), Arpit Kalla (Meta), Markus Marks (Meta), Joseph Greer (Meta), Meng Wang (Meta), Peize Sun (Meta), Roman Rädle (Meta), Triantafyllos Afouras (Meta), Effrosyni Mavroudi (Meta), Katherine Xu (Meta), Tsung-Han Wu (Meta), Yu Zhou (Meta), Liliane Momeni (Meta), Rishi Hazra (Meta), Shuangrui Ding (Meta), Sagar Vaze (Meta), Francois Porcher (Meta), Feng Li (Meta), Siyuan Li (Meta), Aishwarya Kamath (Meta), Ho Kei Cheng (Meta), Piotr Dollár (Meta), Nikhila Ravi (Meta), Kate Saenko (Boston University), Pengchuan Zhang (Meta), Christoph Feichtenhofer (Meta)</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出统一的概念分割模型SAM 3，支持图像/视频的概念提示分割，改进SAM的视觉分割能力，构建大规模数据集及SA-Co基准并开源模型，对原生多模态大模型的视觉理解任务有重要推进。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16719' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SpatialGeo:Boosting Spatial Reasoning in Multimodal LLMs via Geometry-Semantics Fusion</h3>
<p><strong>Authors:</strong> Jiajie Guo, Qingpeng Zhu, Jin Zeng, Xiaolong Wu, Changyong He, Weida Wang</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 针对多模态大模型（MLLMs）空间推理能力不足的问题，提出融合几何特征与语义特征的视觉编码器，增强空间感知能力，显著提升空间推理任务 accuracy，对原生多模态大模型的空间能力优化有重要贡献。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17308' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Video-R4: Reinforcing Text-Rich Video Reasoning with Visual Rumination</h3>
<p><strong>Authors:</strong> Yolo Yunlong Tang, Daiki Shimada, Hang Hua, Chao Huang, Jing Bi, Rogerio Feris, Chenliang Xu</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出视觉反思框架解决文本丰富视频推理中的细粒度证据遗漏问题，通过迭代帧选择、区域缩放与推理状态更新提升多模态推理能力，属于原生多模态大模型的推理优化研究
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17490' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UniModel: A Visual-Only Framework for Unified Multimodal Understanding and Generation</h3>
<p><strong>Authors:</strong> Chi Zhang (Xi'an Jiaotong University), Jiepeng Wang (Xi'an Jiaotong University), Youming Wang (Xi'an Jiaotong University), Yuanzhi Liang (Xi'an Jiaotong University), Xiaoyan Yang (Xi'an Jiaotong University), Zuoxin Li (Xi'an Jiaotong University), Haibin Huang (Xi'an Jiaotong University), Xuelong Li (Xi'an Jiaotong University)</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出纯视觉原生的多模态统一框架，将文本转为图像输入，用扩散模型统一理解与生成任务，实现跨模态对齐及循环一致生成，对原生多模态大模型的统一化范式有新颖贡献。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16917' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MMT-ARD: Multimodal Multi-Teacher Adversarial Distillation for Robust Vision-Language Models</h3>
<p><strong>Authors:</strong> Yuqi Li, Junhao Dong, Chuanguang Yang, Shiping Wen, Piotr Koniusz, Tingwen Huang, Yingli Tian, Yew-Soon Ong</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出多模态多教师对抗蒸馏框架，通过双教师知识融合与动态权重分配策略，提升视觉语言模型的对抗鲁棒性与训练效率，属于原生多模态大模型的鲁棒性优化研究
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17448' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Downscaling Intelligence: Exploring Perception and Reasoning Bottlenecks in Small Multimodal Models</h3>
<p><strong>Authors:</strong> Mark Endo, Serena Yeung-Levy</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 系统分析小参数多模态模型的感知与推理瓶颈，揭示LLM降维对视觉能力的影响，并提出视觉提取调优与Extract+Think方法优化性能，与原生多模态大模型的高效化研究高度相关
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17487' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Stable diffusion models reveal a persisting human and AI gap in visual creativity</h3>
<p><strong>Authors:</strong> Silvia Rondini, Claudia Alvarez-Martin, Paula Angermair-Barkai, Olivier Penacchio, M. Paz, Matthew Pelowski, Dan Dediu, Antoni Rodriguez-Fornells, Xim Cerda-Company</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 以Stable Diffusion为对象研究视觉创造力的人机差异，涉及原生多模态大模型中的图像生成方向，对理解生成模型的创造能力有价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.16814' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SafeR-CLIP: Mitigating NSFW Content in Vision-Language Models While Preserving Pre-Trained Knowledge</h3>
<p><strong>Authors:</strong> Adeel Yousaf (University of Central Florida), Joseph Fioresi (University of Central Florida), James Beetham (University of Central Florida), Amrit Singh Bedi (University of Central Florida), Mubarak Shah (University of Central Florida)</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 针对视觉语言模型的NSFW内容问题，提出proximity-aware重定向方法解决安全与预训练知识保留的权衡，构建NSFW-Caps基准，对大模型安全与对齐的内容安全任务有关键贡献。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.16743' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MultiPriv: Benchmarking Individual-Level Privacy Reasoning in Vision-Language Models</h3>
<p><strong>Authors:</strong> Xiongtao Sun (Singapore Management University), Hui Li (Singapore Management University), Jiaming Zhang (Singapore Management University), Yujie Yang (Singapore Management University), Kaili Liu (Singapore Management University), Ruxin Feng (Singapore Management University), Wen Jun Tan (Singapore Management University), Wei Yang Bryan Lim (Singapore Management University)</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 首个针对视觉语言模型个人隐私推理的基准，提出PPR框架评估50+模型，揭示现有模型的隐私推理漏洞，对大模型安全与对齐的隐私保护研究有重要推动作用。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.16940' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Intervene-All-Paths: Unified Mitigation of LVLM Hallucinations across Alignment Formats</h3>
<p><strong>Authors:</strong> Jiaye Qian, Ge Zheng, Yuchen Zhu, Sibei Yang</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 针对多模态大模型（LVLM）的幻觉问题，揭示幻觉源于多路径（图像到输入文本、图像到输出文本、文本到文本）的交互，并提出针对不同对齐格式的关键头干预方法，有效降低幻觉，对大模型安全与对齐研究有重要价值。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17254' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FIRM: Federated In-client Regularized Multi-objective Alignment for Large Language Models</h3>
<p><strong>Authors:</strong> Fatemeh Nourzad, Amirhossein Roknilamouki, Eylem Ekici, Jia Liu, Ness B. Shroff</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出联邦学习下的多目标对齐算法，通过客户端内正则化缓解分歧漂移，在保护隐私的同时平衡LLM的有用性与无害性，属于大模型安全与对齐的重要研究
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.16992' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Geometric-Disentangelment Unlearning</h3>
<p><strong>Authors:</strong> Duo Zhou, Yuji Zhang, Tianxin Wei, Ruizhong Qiu, Ke Yang, Xiao Lin, Cheng Qian, Jingrui He, Hanghang Tong, Heng Ji, Huan Zhang</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 从几何角度提出解耦遗忘方法，将遗忘更新分解为保留空间的切向与法向分量，在有效遗忘的同时保护保留知识，解决机器遗忘中的关键权衡问题，属于大模型安全与对齐中的隐私保护研究
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17100' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Neighbor GRPO: Contrastive ODE Policy Optimization Aligns Flow Models</h3>
<p><strong>Authors:</strong> Dailan He (The Chinese University of Hong Kong), Guanlin Feng (The Chinese University of Hong Kong), Xingtong Ge (The Chinese University of Hong Kong), Yazhe Niu (The Chinese University of Hong Kong), Yi Zhang (The Chinese University of Hong Kong), Bingqi Ma (The Chinese University of Hong Kong), Guanglu Song (The Chinese University of Hong Kong), Yu Liu (The Chinese University of Hong Kong), Hongsheng Li (The Chinese University of Hong Kong)</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出Neighbor GRPO算法，用ODE对比优化对齐流动模型，解决SDE方法的效率与兼容性问题，提升生成模型对齐效果，对大模型安全与对齐的生成模型对齐任务有重要贡献。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.16955' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ATAC: Augmentation-Based Test-Time Adversarial Correction for CLIP</h3>
<p><strong>Authors:</strong> Linxiang Su, András Balogh</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 针对CLIP的对抗脆弱性问题，提出测试时增强的嵌入空间校正方法，在显著提升鲁棒性的同时保持低计算开销，对大模型安全中的对抗鲁棒性问题有实际解决价值。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17362' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Why Do Language Model Agents Whistleblow?</h3>
<p><strong>Authors:</strong> Kushal Agrawal, Frank Xiao, Guido Bergman, Asa Cooper Stickland</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 研究LLM智能体的“告密”行为（未受指令时向第三方披露不当行为），分析模型家族、任务复杂度等因素的影响，属于大模型安全与对齐中的agent行为安全性研究
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17085' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> That's not natural: The Impact of Off-Policy Training Data on Probe Performance</h3>
<p><strong>Authors:</strong> Nathalie Kirch, Samuel Dower, Adrians Skapars, Ekdeep Singh Lubana, Dmitrii Krasheninnikov</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 系统分析Off-Policy训练数据对LLM监控探针性能的影响，涉及大模型安全与对齐中的监控可靠性问题。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17408' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Revisiting Multimodal KV Cache Compression: A Frequency-Domain-Guided Outlier-KV-Aware Approach</h3>
<p><strong>Authors:</strong> Yaoxin Yang, Peng Ye, Xudong Tan, Chongjun Tu, Maosen Zhao, Jia Hao, Tao Chen</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 从频域分布角度重新设计多模态KV缓存压缩方法，通过异常KV识别与动态预算分配，在降低内存占用的同时提升解码速度，属于高效大模型推理的关键优化技术
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.16786' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Stable Coresets via Posterior Sampling: Aligning Induced and Full Loss Landscapes</h3>
<p><strong>Authors:</strong> Wei-Kai Chang, Rajiv Khanna</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出基于后验采样的稳定Coreset选择方法，通过对齐诱导损失与全损失景观提升训练效率，属于高效大模型训练的关键技术。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17399' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Sparse Mixture-of-Experts for Multi-Channel Imaging: Are All Channel Interactions Required?</h3>
<p><strong>Authors:</strong> Sukwon Yun, Heming Yao, Burkhard Hoeckendorf, David Richmond, Aviv Regev, Russell Littman</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 针对多通道图像任务中ViT的效率瓶颈，提出稀疏混合专家架构（MoE-ViT），通过选择相关通道专家减少不必要的交互，在不牺牲性能的前提下提升效率，对高效大模型训练与推理有应用价值。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17400' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Unified Stability Analysis of SAM vs SGD: Role of Data Coherence and Emergence of Simplicity Bias</h3>
<p><strong>Authors:</strong> Wei-Kai Chang, Rajiv Khanna</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 针对SAM与SGD的稳定性及收敛性展开理论分析，探讨数据一致性对优化器行为和简单性偏差的影响，直接关联深度学习理论中的优化器研究方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17378' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs</h3>
<p><strong>Authors:</strong> Oliver Kramer</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出Cognitive BASIC语言用于LLM的可解释推理，将推理过程结构化展示，属于白盒解释方法，直接对应深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.16837' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DAPS++: Rethinking Diffusion Inverse Problems with Decoupled Posterior Annealing</h3>
<p><strong>Authors:</strong> Hao Chen, Renzheng Zhang, Scott S. Howard</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 重新诠释扩散模型在逆问题中的作用，提出DAPS++方法优化推理过程，属于大模型新技术中的扩散模型研究方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17038' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Diversity Has Always Been There in Your Visual Autoregressive Models</h3>
<p><strong>Authors:</strong> Tong Wang (University of Electronic Science and Technology of China), Guanyu Yang (University of Electronic Science and Technology of China), Nian Liu (University of Electronic Science and Technology of China), Kai Wang (University of Electronic Science and Technology of China), Yaxing Wang (University of Electronic Science and Technology of China), Abdelrahman M Shaker (MBZUAI), Salman Khan (MBZUAI), Fahad Shahbaz Khan (MBZUAI), Senmao Li (University of Electronic Science and Technology of China)</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 揭示视觉自回归模型的内在多样性，提出DiverseVAR方法无需额外训练即可恢复生成多样性，对大模型新技术的生成模型多样性提升有重要意义。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17074' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Spanning Tree Autoregressive Visual Generation</h3>
<p><strong>Authors:</strong> Sangkyu Lee (KAIST), Changho Lee (KAIST), Janghoon Han (KAIST), Hosung Song (KAIST), Tackgeun You (KAIST), Hwasup Lim (KAIST), Stanley Jungkyu Choi (KAIST), Honglak Lee (KAIST), Youngjae Yu (KAIST)</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出STAR模型，用生成树遍历顺序改进自回归生成，保持性能与推理灵活性，对大模型新技术的自回归生成方法有新颖贡献。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17089' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Progress-Think: Semantic Progress Reasoning for Vision-Language Navigation</h3>
<p><strong>Authors:</strong> Shuo Wang, Yucheng Wang, Guoxin Lian, Yongcai Wang, Maiyue Chen, Kaihui Wang, Bo Zhang, Zhizhong Su, Yutian Zhou, Wanting Li, Deying Li, Zhaoxin Fan</p>
<p><strong>Published:</strong> 2025-11-24</p>
<p><strong>Reason:</strong> 提出语义进度推理框架优化视觉语言导航，解决长 horizon 导航中的进度理解问题，属于多模态智能体中的导航方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.17097' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>