<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-26</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>深度学习可解释性</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习理论</a>
<a href='#' >大模型新技术</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-26</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-26 12:53:54</p>
<p>已自动阅读了 653 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：360624</p>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Understanding Counting Mechanisms in Large Language and Vision-Language Models</h3>
<p><strong>Authors:</strong> Hosein Hasani, Amirmohammad Izadi, Fatemeh Askari, Mobin Bagherian, Sadegh Mohammadian, Mohammad Izadi, Mahdieh Soleymani Baghshah</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 采用因果中介、激活补丁等方法，结合CountScope工具研究LLM和LVLM的计数机制，揭示层wise计数过程与内部计数器机制，属于深度学习可解释性方向。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.17699' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Can Vision-Language Models Count? A Synthetic Benchmark and Analysis of Attention-Based Interventions</h3>
<p><strong>Authors:</strong> Saurav Sengupta, Nazanin Moradinasab, Jiebei Liu, Donald E. Brown</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建合成基准评估VLM计数能力，分析注意力干预对计数性能的影响，揭示VLM计数任务中的偏差与改进方向，属于深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.17722' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MGA-VQA: Secure and Interpretable Graph-Augmented Visual Question Answering with Memory-Guided Protection Against Unauthorized Knowledge Use</h3>
<p><strong>Authors:</strong> Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Dheeraj Kulshrestha, Rajiv Ramnath</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出图增强VQA框架，通过图基决策路径与结构化内存访问实现可解释性，同时保护未授权知识使用，属于深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.17881' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SHAP Distance: An Explainability-Aware Metric for Evaluating the Semantic Fidelity of Synthetic Tabular Data</h3>
<p><strong>Authors:</strong> Ke Yu (), Shigeru Ishikura (), Yukari Usukura (), Yuki Shigoku (), Teruaki Hayashi ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 基于SHAP值提出语义保真评估指标，解决合成数据的可解释性问题，属于深度学习可解释性中的Shapley value应用
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.17590' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BlockCert: Certified Blockwise Extraction of Transformer Mechanisms</h3>
<p><strong>Authors:</strong> Sandro Andric</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出块级提取Transformer机制并提供形式化认证的框架，连接机械可解释性与形式化推理，推动深度学习可解释性研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.17645' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unboxing the Black Box: Mechanistic Interpretability for Algorithmic Understanding of Neural Networks</h3>
<p><strong>Authors:</strong> Bianka Kowalska (), Halina Kwaśnicka ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 系统提出了机械可解释性的统一分类法，分析了关键技术并结合示例说明，为神经网络的算法级可解释性研究提供了基础框架和方法论指导。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.19265' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Extracting Robust Register Automata from Neural Networks over Data Sequences</h3>
<p><strong>Authors:</strong> Chih-Duo Hong, Hongjian Jiang, Anthony W. Lin, Oliver Markgraf, Julian Parsert, Tony Tan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 从处理数据序列的神经网络中提取鲁棒寄存器自动机，实现白盒可解释性，推动深度学习可解释性研究
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.19100' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.5/10]</span> Matching-Based Few-Shot Semantic Segmentation Models Are Interpretable by Design</h3>
<p><strong>Authors:</strong> Pasquale De Marinis, Uzay Kaymak, Rogier Brussee, Gennaro Vessio, Giovanna Castellano</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 首次针对匹配-based少样本分割模型的可解释性，提出Affinity Explainer，利用模型结构特性提取归因图，解释支持图像像素对查询分割的贡献，提升模型透明度，是深度学习可解释性在少样本任务的具体应用。
Score: 7.5
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.18163' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DiVE-k: Differential Visual Reasoning for Fine-grained Image Recognition</h3>
<p><strong>Authors:</strong> Raja Kumar (), Arka Sadhu (), Ram Nevatia ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出DiVE-k框架，用top-k生成作为训练信号，提升细粒度图像识别的差分推理能力，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.18305' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TRANSPORTER: Transferring Visual Semantics from VLM Manifolds</h3>
<p><strong>Authors:</strong> Alexandros Stergiou ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出TRANSPORTER方法，生成反映VLM预测规则的视频，帮助理解VLM的内部过程，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.18359' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> VisReason: A Large-Scale Dataset for Visual Chain-of-Thought Reasoning</h3>
<p><strong>Authors:</strong> Lingxiao Li, Yifan Wang, Xinyan Gao, Chen Tang, Xiangyu Yue, Chenyu You</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> A Large-Scale Dataset for Visual Chain-of-Thought Reasoning
Authors: Lingxiao Li, Yifan Wang, Xinyan Gao, Chen Tang, Xiangyu Yue, Chenyu You
Published: 2025-11-25
Link: https://arxiv.org/abs/2511.17731
Reason: 构建包含489K示例的大规模视觉Chain-of-Thought推理数据集（含165K专家级子集），用于训练多模态大模型的视觉推理能力，推动MLLM更系统的推理性能，属于原生多模态大模型方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17731' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Plan-X: Instruct Video Generation via Semantic Planning</h3>
<p><strong>Authors:</strong> Lun Huang, You Xie, Hongyi Xu, Tianpei Gu, Chenxu Zhang, Guoxian Song, Zenan Li, Xiaochen Zhao, Linjie Luo, Guillermo Sapiro</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对视频生成中的语义对齐问题，提出Plan-X框架，利用语义规划器生成文本接地的时空语义token，结合LLM的推理能力和扩散模型的生成能力，减少视觉幻觉，提升视频生成的语义一致性和指令遵循度。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17986' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> UltraFlux: Data-Model Co-Design for High-quality Native 4K Text-to-Image Generation across Diverse Aspect Ratios</h3>
<p><strong>Authors:</strong> Tian Ye, Song Fei, Lei Zhu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对原生4K文本到图像生成的多挑战（位置编码、VAE压缩等），采用数据模型协同设计，构建MultiAspect-4K-1M数据集并提出UltraFlux模型，提升4K生成的质量、美学和AR适应性，匹配或超越 proprietary模型。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18050' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MammothModa2: A Unified AR-Diffusion Framework for Multimodal Understanding and Generation</h3>
<p><strong>Authors:</strong> Tao Shen (), Xin Wan (), Taicai Chen (), Rui Zhang (), Junwen Pan (), Dawei Lu (), Fanding Lei (), Zhilin Lu (), Yunfei Yang (), Chen Cheng (), Qi She (), Chang Liu (), Zhenbang Sun ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出MammothModa2统一框架，结合AR语义规划和扩散生成，提升多模态理解与生成性能，符合原生多模态大模型方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18262' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Plug-and-Play Multi-Concept Adaptive Blending for High-Fidelity Text-to-Image Synthesis</h3>
<p><strong>Authors:</strong> Young-Beom Woo</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对文本到图像生成中多概念整合的语义不一致问题，提出引导外观注意力、掩码引导噪声混合等策略，提高生成保真度，属于原生多模态大模型中的图像生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17615' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ConsistCompose: Unified Multimodal Layout Control for Image Composition</h3>
<p><strong>Authors:</strong> Xuanke Shi (), Boxuan Li (), Xiaoyang Han (), Zhongang Cai (), Lei Yang (), Dahua Lin (), Quan Wang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出ConsistCompose统一框架，用布局坐标嵌入语言提示，提升布局可控的图像合成性能，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ViMix-14M: A Curated Multi-Source Video-Text Dataset with Long-Form, High-Quality Captions and Crawl-Free Access</h3>
<p><strong>Authors:</strong> Timing Yang (), Sucheng Ren (), Alan Yuille (), Feng Wang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建ViMix-14M多源视频文本数据集，支持多模态模型训练，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18382' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Disc3D: Automatic Curation of High-Quality 3D Dialog Data via Discriminative Object Referring</h3>
<p><strong>Authors:</strong> Siyuan Wei, Chunjie Wang, Xiao Liu, Xiaosheng Yan, Zhishan Zhou, Rui Huang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出全自动3D对话数据构建管道，解决3D MLLM数据稀缺和视角/对象指代歧义问题，生成2M样本的Disc3D数据集，显著提升3D MLLM多任务性能，属于原生多模态大模型的关键数据支撑研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18817' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HunyuanVideo 1.5 Technical Report</h3>
<p><strong>Authors:</strong> Bing Wu, Chang Zou, Changlin Li, Duojun Huang, Fang Yang, Hao Tan, Jack Peng, Jianbing Wu, Jiangfeng Xiong, Jie Jiang,  Linus,  Patrol, Peizhen Zhang, Peng Chen, Penghao Zhao, Qi Tian, Songtao Liu, Weijie Kong, Weiyan Wang, Xiao He, Xin Li, Xinchi Deng, Xuefei Zhe, Yang Li, Yanxin Long, Yuanbo Peng, Yue Wu, Yuhong Liu, Zhenyu Wang, Zuozhuo Dai, Bo Peng, Coopers Li, Gu Gong, Guojian Xiao, Jiahe Tian, Jiaxin Lin, Jie Liu, Jihong Zhang, Jiesong Lian, Kaihang Pan, Lei Wang, Lin Niu, Mingtao Chen, Mingyang Chen, Mingzhe Zheng, Miles Yang, Qiangqiang Hu, Qi Yang, Qiuyong Xiao, Runzhou Wu, Ryan Xu, Rui Yuan, Shanshan Sang, Shisheng Huang, Siruis Gong, Shuo Huang, Weiting Guo, Xiang Yuan, Xiaojia Chen, Xiawei Hu, Wenzhi Sun, Xiele Wu, Xianshun Ren, Xiaoyan Yuan, Xiaoyue Mi, Yepeng Zhang, Yifu Sun, Yiting Lu, Yitong Li, You Huang, Yu Tang, Yixuan Li, Yuhang Deng, Yuan Zhou, Zhichao Hu, Zhiguang Liu, Zhihe Yang, Zilin Yang, Zhenzhi Lu, Zixiang Zhou, Zhao Zhong</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 发布轻量级视频生成模型HunyuanVideo 1.5（8.3B参数），采用SSTA、glyph-aware文本编码等技术实现高画质与运动一致性，开源降低视频生成研究门槛，属于原生多模态大模型的重要实践。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18870' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ReMatch: Boosting Representation through Matching for Multimodal Retrieval</h3>
<p><strong>Authors:</strong> Qianying Liu, Xiao Liang, Zhiqiang Zhang, Yibo Chen, Xu Tang, Zhongfei Qing, Fengfan Zhou, Yao Hu, Paul Henderson</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出ReMatch框架，利用MLLM的生成能力将多视图输入（原始数据+嵌入）用于多模态检索，结合对比损失与生成式匹配提升性能，属于原生多模态大模型的检索任务创新。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19278' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Syn-GRPO: Self-Evolving Data Synthesis for MLLM Perception Reasoning</h3>
<p><strong>Authors:</strong> Qihan Huang (), Haofei Zhang (), Rong Wei (), Yi Wang (), Rui Tang (), Mingli Song (), Jie Song ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对MLLM感知推理的RL数据质量问题，提出自进化数据合成框架，提升MLLM感知性能，属于原生多模态大模型的感知推理优化
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19343' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation</h3>
<p><strong>Authors:</strong> Zehong Ma (), Longhui Wei (), Shuai Wang (), Shiliang Zhang (), Qi Tian ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出频率解耦的像素扩散框架，将高频细节与低频语义生成解耦，提升图像生成的效率和质量，属于原生多模态大模型的图像生成技术
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19365' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens</h3>
<p><strong>Authors:</strong> Yiming Qin (), Bomin Wei (), Jiaxin Ge (), Konstantinos Kallidromitis (), Stephanie Fu (), Trevor Darrell (), Xudong Wang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出连续视觉token的Chain-of-Visual-Thought框架，提升VLMs的视觉推理能力，属于原生多模态大模型的视觉理解优化
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19418' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AnyExperts: On-Demand Expert Allocation for Multimodal Language Models with Mixture of Expert</h3>
<p><strong>Authors:</strong> Yuting Gao, Wang Lan, Hengyuan Zhao, Linjiang Huang, Si Liu, Qingpei Guo</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对多模态MoE模型的刚性路由问题，提出按需专家分配框架，优化计算资源分配，提升多模态大模型的效率与性能，属于原生多模态大模型方向的关键优化。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18314' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs</h3>
<p><strong>Authors:</strong> Yuting Gao, Weihao Chen, Lan Wang, Ruihan Xu, Qingpei Guo</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出OrdMoE框架用于多模态MoE LLM的偏好对齐，无需人工数据，提升多模态大模型的对齐性，属于原生多模态大模型范畴。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19023' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UniGame: Turning a Unified Multimodal Model Into Its Own Adversary</h3>
<p><strong>Authors:</strong> Zhaolong Su (), Wang Lu (), Hao Chen (), Sharon Li (), Jindong Wang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对统一多模态模型（UMMs）理解与生成的一致性问题，提出自对抗后训练框架UniGame，显著提升了模型的跨模态一致性、鲁棒性和整体性能，对多模态大模型的优化有重要意义。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19413' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints</h3>
<p><strong>Authors:</strong> Rui Xu, Dakuan Lu, Zicheng Zhao, Xiaoyu Tan, Xintao Wang, Siyu Yuan, Jiangjie Chen, Yinghui Xu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建新基准评估多模态LLM的多步空间推理能力，为多模态模型的开发与评估提供关键支撑
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18450' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Synthesizing Visual Concepts as Vision-Language Programs</h3>
<p><strong>Authors:</strong> Antonia Wüst, Wolfgang Stammer, Hikaru Shindo, Lukas Helff, Devendra Singh Dhami, Kristian Kersting</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 将视觉概念合成为视觉语言程序，结合VLM与程序合成，提升多模态推理的一致性与可解释性
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18964' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Reconstruction-Driven Multimodal Representation Learning for Automated Media Understanding</h3>
<p><strong>Authors:</strong> Yassir Benhammou, Suman Kalyan, Sujay Kumar</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出重建驱动的多模态自编码器（MMAE），学习文本、音频、视觉的统一表示，解决单模态模型跨模态关系理解局限，适用于媒体内容元数据提取和语义聚类，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17596' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ChineseVideoBench: Benchmarking Multi-modal Large Models for Chinese Video Question Answering</h3>
<p><strong>Authors:</strong> Yuxiang Nie (), Han Wang (), Yongjie Ye (), Haiyang Yu (), Weitao Jia (), Tao Zeng (), Hao Feng (), Xiang Fei (), Yang Li (), Xiaohui Lv (), Guozhi Tang (), Jingqun Tang (), Jinghui Lu (), Zehui Dai (), Jiacong Wang (), Dingkang Yang (), An-Lan Wang (), Can Huang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建ChineseVideoBench基准，评估中文MLLMs的视频QA能力，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18399' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EventBench: Towards Comprehensive Benchmarking of Event-based MLLMs</h3>
<p><strong>Authors:</strong> Shaoyu Liu (), Jianing Li (), Guanghui Zhao (), Yunjian Zhang (), Xiangyang Ji ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建EventBench基准，评估事件基MLLMs的能力，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18448' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Alternating Perception-Reasoning for Hallucination-Resistant Video Understanding</h3>
<p><strong>Authors:</strong> Bowei Pu, Chuanbin Liu, Yifan Ge, Peichen Zhou, Yiwei Sun, Zhiyin Lu, Jiankang Wang, Hongtao Xie</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出基于循环的感知-推理范式和事实感知评估器，解决视频推理大模型中的幻觉问题，直接关联原生多模态大模型（视频理解）的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18463' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives</h3>
<p><strong>Authors:</strong> Kai Jiang, Siqi Huang, Xiangyu Chen, Jiawei Shao, Hongyuan Zhang, Xuelong Li</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对多场景视觉任务中的多模态大模型灾难性遗忘问题，提出解耦特征学习框架，关联原生多模态大模型的持续学习研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18507' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Seeing What Matters: Visual Preference Policy Optimization for Visual Generation</h3>
<p><strong>Authors:</strong> Ziqi Ni, Yuanzhi Liang, Rui Li, Yi Zhou, Haibing Huang, Chi Zhang, Xuelong Li</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出视觉偏好策略优化方法，将标量反馈扩展为像素级优势，提升视觉生成模型的对齐效果，关联原生多模态大模型的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18719' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Thinking Ahead: Foresight Intelligence in MLLMs and World Models</h3>
<p><strong>Authors:</strong> Zhantao Gong, Liaoyuan Fan, Qing Guo, Xun Xu, Xulei Yang, Shijie Li</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建FSU-QA数据集评估多模态大模型的前瞻推理能力，关联原生多模态大模型的认知能力研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18735' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Any4D: Open-Prompt 4D Generation from Natural Language and Images</h3>
<p><strong>Authors:</strong> Hao Li, Qiao Sun</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Primitive Embodied World Models，实现从文本和图像到4D的开放prompt生成，关联原生多模态大模型的跨模态生成研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18746' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Understanding Task Transfer in Vision-Language Models</h3>
<p><strong>Authors:</strong> Bhuvan Sachdeva, Karan Uppal, Abhinav Java, Vineeth N. Balasubramanian</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 系统研究视觉语言模型的任务迁移性，提出PGF指标量化迁移效果，构建任务迁移图揭示任务间关系，对理解VLM泛化能力和指导高效训练有重要意义，属于原生多模态大模型的基础研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18787' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VideoPerceiver: Enhancing Fine-Grained Temporal Perception in Video Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Fufangchen Zhao, Liao Zhang, Daiqi Shi, Yuanjun Gao, Chen Ye, Yang Cai, Jian Gao, Danfeng Yan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出两阶段训练框架增强视频MLLM的细粒度时间感知，解决短片段短暂动作与长视频稀有事件推理问题，构建细粒度动作数据集，实验表明在细粒度任务上优于现有VMLLM，属于原生多模态大模型的性能提升研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18823' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Q-Save: Towards Scoring and Attribution for Generated Video Evaluation</h3>
<p><strong>Authors:</strong> Xiele Wu, Zicheng Zhang, Mingtao Chen, Yixian Liu, Yiming Liu, Shushi Wang, Zhichao Hu, Yuhong Liu, Guangtao Zhai, Xiaohong Liu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出AIGV评估基准Q-Save（10k视频，多维度标注）与统一模型，支持质量评分与归因解释，解决现有评估缺乏细粒度与可解释性的问题，实验表明模型性能优且可解释，属于原生多模态大模型的评估研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18825' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CLASH: A Benchmark for Cross-Modal Contradiction Detection</h3>
<p><strong>Authors:</strong> Teodora Popordanoska, Jiameng Li, Matthew B. Blaschko</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出跨模态矛盾检测基准CLASH，通过控制对象/属性级矛盾的图像-文本对，评估多模态模型的一致性推理能力，属于原生多模态大模型的核心能力评估研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19199' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Growing with the Generator: Self-Paced GRPO for Video Generation</h3>
<p><strong>Authors:</strong> Rui Li (), Yuanzhi Liang (), Ziqi Ni (), Haibing Huang (), Chi Zhang (), Xuelong Li ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出自步GRPO框架，让奖励随视频生成器进化，解决静态奖励的分布偏差问题，提升视频生成的语义对齐和质量，属于原生多模态大模型的视频生成优化
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.19356' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Binary BPE: A Family of Cross-Platform Tokenizers for Binary Analysis</h3>
<p><strong>Authors:</strong> Michael J. Bommarito II ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出跨平台的二进制BPE分词器，提升二进制分析的上下文效率，属于原生多模态大模型中的tokenizer设计
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17573' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PrismSSL: One Interface, Many Modalities; A Single-Interface Library for Multimodal Self-Supervised Learning</h3>
<p><strong>Authors:</strong> Melika Shirian, Kianoosh Vadaei, Kian Majlessi, Audrina Ebrahimi, Arshia Hemmat, Peyman Adibi, Hossein Karshenas</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出统一多模态自监督学习的库，支持音频、视觉、图和跨模态设置，对原生多模态大模型的自监督训练有帮助。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.17776' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Weakly-supervised Latent Models for Task-specific Visual-Language Control</h3>
<p><strong>Authors:</strong> Xian Yeow Lee, Lasitha Vidyaratne, Gregory Sin, Ahmed Farahat, Chetan Gupta</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出弱监督下的任务特定视觉语言控制模型，解决空间接地任务中的数据与计算瓶颈，提升多模态模型性能
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18319' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation</h3>
<p><strong>Authors:</strong> Yuyang Wanyan, Xiaoshan Yang, Weiming Dong, Changsheng Xu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对少样本视频域自适应问题，提出模态协作低秩分解器，关联原生多模态大模型的域自适应研究。
Score: 6
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.18711' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> FastMMoE: Accelerating Multimodal Large Language Models through Dynamic Expert Activation and Routing-Aware Token Pruning</h3>
<p><strong>Authors:</strong> Guoyang Xia, Yifeng Ding, Fengfa Li, Lei Ren, Wei Chen, Fangxiang Feng, Xiaojie Wang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出动态专家激活与路由感知token剪枝的FastMMoE框架，加速MoE-based MLLMs，减少FLOPs达55%同时保持95.5%性能，属于高效大模型训练与推理中的LLM infra方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17885' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Kitty: Accurate and Efficient 2-bit KV Cache Quantization with Dynamic Channel-wise Precision Boost</h3>
<p><strong>Authors:</strong> Haojun Xia, Xiaoxia Wu, Jisen Li, Robert Wu, Junxiong Wang, Jue Wang, Chenxi Li, Aman Singhal, Alay Dilipbhai Shah, Alpay Ariyak, Donglin Zhuang, Zhongzhu Zhou, Ben Athiwaratkun, Zhen Zheng, Shuaiwen Leon Song</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出KV缓存的2位量化框架Kitty，通过动态通道精度提升保持准确性，显著降低内存占用并提升推理效率，属于高效大模型训练与推理的关键优化。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18643' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models</h3>
<p><strong>Authors:</strong> Yonggan Fu, Xin Dong, Shizhe Diao, Matthijs Van keirsbilck, Hanrong Ye, Wonmin Byeon, Yashaswi Karnati, Lucas Liebenwein, Hannah Zhang, Nikolaus Binder, Maksim Khadkevich, Alexander Keller, Jan Kautz, Yingyan Celine Lin, Pavlo Molchanov</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Nemotron-Flash框架优化小语言模型的latency，通过深度-宽度比和算子选择提升效率，属于高效大模型训练与推理的关键优化。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18890' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> CDLM: Consistency Diffusion Language Models For Faster Sampling</h3>
<p><strong>Authors:</strong> Minseo Kim (), Chenfeng Xu (), Coleman Hooper (), Harman Singh (), Ben Athiwaratkun (), Ce Zhang (), Kurt Keutzer (), Amir Gholami ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对Diffusion Language Models推理慢的问题，结合一致性建模和KV缓存提出CDLM，实现了3.6x-14.5x的 latency降低，同时保持竞争力的 accuracy，有效解决了大模型推理效率瓶颈。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.19269' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Flow Map Distillation Without Data</h3>
<p><strong>Authors:</strong> Shangyuan Tong (), Nanye Ma (), Saining Xie (), Tommi Jaakkola ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出无数据的flow map蒸馏框架，通过从先验分布采样避免数据依赖问题，实现了比数据基方法更优的性能（ImageNet 256x256 FID 1.45），为大模型蒸馏提供了更稳健的范式。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.19428' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> NEZHA: A Zero-sacrifice and Hyperspeed Decoding Architecture for Generative Recommendations</h3>
<p><strong>Authors:</strong> Yejing Wang, Shengyu Zhou, Jinyu Lu, Ziwei Liu, Langming Liu, Maolin Wang, Wenlin Zhang, Feng Li, Wenbo Su, Pengjie Wang, Jian Xu, Xiangyu Zhao</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出零损失高速解码架构，解决生成式推荐的推理延迟问题，已部署到淘宝，工业应用价值高
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18793' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> AdaPerceiver: Transformers with Adaptive Width, Depth, and Tokens</h3>
<p><strong>Authors:</strong> Purvish Jajal, Nick John Eliopoulos, Benjamin Shiue-Hal Chou, George K. Thiruvathukal, Yung-Hsiang Lu, James C. Davis</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出AdaPerceiver，首次实现Transformer在宽度、深度和tokens上的统一自适应，通过联合训练保持多配置下的性能，在图像分类、分割等任务中提升效率（如FLOPs减少24-33%）和准确率，是Transformer效率优化的创新突破。
Score: 8.5
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18105' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rectifying Soft-Label Entangled Bias in Long-Tailed Dataset Distillation</h3>
<p><strong>Authors:</strong> Chenyang Jiang, Hang Zhao, Xinyu Zhang, Zhengcen Li, Qiben Shan, Shaocong Wu, Jingyong Su</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出ADSA模块修正长尾数据集蒸馏中的软标签偏差，提高尾类精度达11.8%，解决长尾数据蒸馏性能退化问题，属于高效大模型训练与推理中的数据集蒸馏方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17914' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Test-Time Temporal Sampling for Efficient MLLM Video Understanding</h3>
<p><strong>Authors:</strong> Kaibin Wang, Mingbao Lin</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对MLLM处理长视频时自注意力计算量过大的问题，提出训练-free的T3S框架，通过生成多短子序列并聚合预测，在提升准确率（最高+3.1%）的同时降低推理延迟（2.04×），有效解决长视频MLLM推理效率瓶颈。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17945' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Wencheng Ye, Tianshi Wang, Lei Zhu, Fengling Li, Guoli Yang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对VLA模型的计算开销问题，提出ActDistill框架，通过动作引导的自蒸馏将大VLA模型的能力转移到轻量模型，减少计算量超50%，提升推理速度（1.67×），同时保持性能，是VLA模型高效化的重要方法。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18082' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Uni-DAD: Unified Distillation and Adaptation of Diffusion Models for Few-step Few-shot Image Generation</h3>
<p><strong>Authors:</strong> Yara Bahram (), Melodie Desbos (), Mohammadhadi Shateri (), Eric Granger ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Uni-DAD统一蒸馏和适应框架，提升少样本扩散模型的生成效率和质量，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18281' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CrossJEPA: Cross-Modal Joint-Embedding Predictive Architecture for Efficient 3D Representation Learning from 2D Images</h3>
<p><strong>Authors:</strong> Avishka Perera (), Kumal Hewagamage (), Saeedha Nazar (), Kavishka Abeywardana (), Hasitha Gallella (), Ranga Rodrigo (), Mohamed Afham ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出CrossJEPA架构，从2D图像高效学习3D表示，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18424' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Extreme Model Compression for Edge Vision-Language Models: Sparse Temporal Token Fusion and Adaptive Neural Compression</h3>
<p><strong>Authors:</strong> Md Tasnin Tanvir, Soumitra Das, Sk Md Abidar Rahaman, Ali Shiri Sichani</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出稀疏时间令牌融合（STTF）和自适应神经压缩（ANC）两种算法，针对边缘设备视觉语言模型实现极致压缩，在减少参数和计算量的同时保持性能，符合高效大模型训练与推理的研究方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18504' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VideoCompressa: Data-Efficient Video Understanding via Joint Temporal Compression and Spatial Reconstruction</h3>
<p><strong>Authors:</strong> Shaobo Wang, Tianle Niu, Runkang Yang, Deshan Liu, Xu He, Zichen Wen, Conghui He, Xuming Hu, Linfeng Zhang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出动态 latent 压缩框架，通过关键帧选择与VAE压缩，用0.13%的数据超越全数据训练性能，在ConvNet与Qwen2.5-7B-VL上验证数据效率，属于高效大模型训练与推理的数据高效研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18831' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EventSTU: Event-Guided Efficient Spatio-Temporal Understanding for Video Large Language Models</h3>
<p><strong>Authors:</strong> Wenhao Xu, Xin Dong, Yue Li, Haodong Shi, Zhiwei Xiong</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出事件引导的训练-free框架，通过粗到细关键帧采样与自适应token pruning，实现3.01倍FLOPs reduction与3.10倍推理加速，构建EventBench基准，属于高效大模型训练与推理的推理优化研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18920' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ABM-LoRA: Activation Boundary Matching for Fast Convergence in Low-Rank Adaptation</h3>
<p><strong>Authors:</strong> Dongha Lee, Jinhee Park, Minjun Kim, Junseok Kwon</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出激活边界匹配的LoRA初始化策略，解决随机初始化导致的梯度空间不匹配问题，加速收敛并提升多任务性能，属于高效大模型训练与推理中的参数高效微调技术。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.19145' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GateRA: Token-Aware Modulation for Parameter-Efficient Fine-Tuning</h3>
<p><strong>Authors:</strong> Jie Ou (), Shuaihong Jiang (), Yingjun Du (), Cees G. M. Snoek ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出token-aware的参数高效微调框架，提升模型适应能力，属于高效大模型训练与推理中的PEFT技术
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17582' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Projection to Prediction: Beyond Logits for Scalable Language Models</h3>
<p><strong>Authors:</strong> Jianbing Dong (), Jianbin Chang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 整合输出投影和损失预测，减少LLM训练的内存和带宽消耗，提升训练效率，属于高效大模型训练与推理中的训练优化技术
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17599' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PocketLLM: Ultimate Compression of Large Language Models via Meta Networks</h3>
<p><strong>Authors:</strong> Ye Tian, Chengcheng Wang, Jing Han, Yehui Tang, Kai Han</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出通过元网络在 latent 空间压缩大模型的方法，实现 Llama 2-7B 10倍压缩且精度损失小，对高效大模型推理有重要价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17637' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Layer-Wise High-Impact Parameter Ratio Optimization in Post-Training Quantization for Large Language Models</h3>
<p><strong>Authors:</strong> Cuong Pham, Hoang Anh Dung, Cuong C. Nguyen, Trung Le, Gustavo Carneiro, Thanh-Toan Do</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出层特定的高影响参数比率优化，在低比特量化中保留更多关键参数，提升LLM量化精度，对高效大模型部署有价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17801' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Adaptive Layer-Wise Transformations for Post-Training Quantization of Large Language Models</h3>
<p><strong>Authors:</strong> Cuong Pham, Hoang Anh Dung, Cuong C. Nguyen, Trung Le, Gustavo Carneiro, Jianfei Cai, Thanh-Toan Do</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出自适应层变换选择，缓解量化中的异常值问题，在LLaMA模型上实现显著性能提升，对LLM量化有重要价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17809' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Deterministic Inference across Tensor Parallel Sizes That Eliminates Training-Inference Mismatch</h3>
<p><strong>Authors:</strong> Ziyang Zhang, Xinheng Ding, Jiayi Yuan, Rixin Liu, Huizi Mao, Jiarong Xing, Zirui Liu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出TP不变的内核，解决不同张量并行大小的推理确定性问题，消除训练与推理的不匹配，对LLM服务框架有重要价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17826' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning</h3>
<p><strong>Authors:</strong> Mengdi Wang, Efe Bozkir, Enkelejda Kasneci</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出聚合无关的split learning框架CycleSL，通过服务器-客户端循环更新提升分布式训练的scalability和性能，属于高效大模型训练与推理。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18611' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VLM in a flash: I/O-Efficient Sparsification of Vision-Language Model via Neuron Chunking</h3>
<p><strong>Authors:</strong> Kichang Yang, Seonjun Kim, Minjae Kim, Nairan Zhang, Chi Zhang, Youngki Lee</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Neuron Chunking方法稀疏化视觉语言模型（VLM），提升I/O效率和部署性能，属于高效大模型训练与推理。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18692' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> KernelBand: Boosting LLM-based Kernel Optimization with a Hierarchical and Hardware-aware Multi-armed Bandit</h3>
<p><strong>Authors:</strong> Dezhi Ran, Shuxiao Xie, Mingfang Ji, Ziyue Hua, Mengzhou Wu, Yuan Cao, Yuzhe Guo, Yu Hao, Linyi Li, Yitao Hu, Tao Xie</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出KernelBand框架优化LLM的kernel，通过分层多臂老虎机提升效率和硬件适配性，属于高效大模型训练与推理。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18868' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression</h3>
<p><strong>Authors:</strong> Santhosh G S, Saurav Prakash, Balaraman Ravindran</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出SWAN框架压缩KV缓存，无需解压缩提升推理效率，属于高效大模型训练与推理的关键优化。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18936' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FastForward Pruning: Efficient LLM Pruning via Single-Step Reinforcement Learning</h3>
<p><strong>Authors:</strong> Xin Yuan, Siqi Li, Jiateng Wei, Chengrui Zhu, Yanming Wu, Qingpeng Li, Jiajun Lv, Xiaoke Lan, Jun Chen, Yong Liu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出FastForward Pruning框架通过单步RL优化LLM剪枝，提升效率和性能，属于高效大模型训练与推理的关键优化。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18977' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions</h3>
<p><strong>Authors:</strong> Shaoyin Ma, Jie Song, Huiqiong Wang, Li Sun, Mingli Song</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出渐进推理框架优化模型选择，减少prompt膨胀与token消耗，显著提升大模型推理效率
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18715' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> BD-Net: Has Depth-Wise Convolution Ever Been Applied in Binary Neural Networks?</h3>
<p><strong>Authors:</strong> DoYoung Kim, Jin-Seop Lee, Noo-ri Kim, SungJoon Lee, Jee-Hyong Lee</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 首次将深度可分离卷积应用于二进制神经网络，通过1.58-bit卷积增强表达能力、预BN残差连接稳定训练，提升二进制网络性能与效率，属于高效大模型训练与推理中的模型压缩方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17633' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Attention Guided Alignment in Efficient Vision-Language Models</h3>
<p><strong>Authors:</strong> Shweta Mahajan, Hoang Le, Hyojin Park, Farzad Farhadzadeh, Munawar Hayat, Fatih Porikli</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出AGE-VLM框架，通过交叉注意力层与SAM空间知识蒸馏增强高效VLMs的视觉接地能力，减少对象幻觉，属于高效大模型训练与推理中的高效多模态模型方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17793' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Less is More: Data-Efficient Adaptation for Controllable Text-to-Video Generation</h3>
<p><strong>Authors:</strong> Shihan Cheng, Nilesh Kulkarni, David Hyde, Dmitriy Smirnov</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出数据高效微调策略，利用稀疏低质量合成数据训练可控文本到视频模型，解决高质量数据稀缺问题，属于高效大模型训练与推理中的高效适应方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17844' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> When Better Teachers Don't Make Better Students: Revisiting Knowledge Distillation for CLIP Models in VQA</h3>
<p><strong>Authors:</strong> Pume Tuchinda, Parinthapat Pengpun, Romrawin Chumpu, Sarana Nutanong, Peerat Limkonchotiwat</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 系统研究CLIP模型的知识蒸馏，发现更强教师模型不一定产生更好学生模型，挑战传统KD假设，为多模态模型蒸馏提供新 insights，属于高效大模型训练与推理中的知识蒸馏方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17886' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Decoupled Audio-Visual Dataset Distillation</h3>
<p><strong>Authors:</strong> Wenyuan Li, Guang Li, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出DAVDD框架，通过预训练银行和解耦器银行分离多模态公共与私有表示，解决多模态蒸馏的对齐与信息保留问题，属于高效大模型训练与推理中的数据集蒸馏方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17890' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Rethinking Long-tailed Dataset Distillation: A Uni-Level Framework with Unbiased Recovery and Relabeling</h3>
<p><strong>Authors:</strong> Xiao Cui, Yulei Qin, Xinyue Li, Wengang Zhou, Hongsheng Li, Houqiang Li</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出长尾数据集蒸馏统一框架，通过无偏恢复与重标记解决长尾巴分布偏差，在CIFAR-100-LT与Tiny-ImageNet-LT上提升 accuracy，属于高效大模型训练与推理的数据集蒸馏研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18858' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Parallel Vision Token Scheduling for Fast and Accurate Multimodal LMMs Inference</h3>
<p><strong>Authors:</strong> Wengyi Zhan, Mingbao Lin, Zhihang Lin, Rongrong Ji</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出视觉token并行调度框架，将token分为主题与非主题组，并行处理后丢弃非主题路径，实现1.77倍推理加速与70% FLOPs reduction，同时保持性能，属于高效大模型训练与推理的推理优化研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18875' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs</h3>
<p><strong>Authors:</strong> Huaming Ling, Ying Wang, Si Chen, Junfeng Fan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出一键微调策略将预训练CNN转换为FHE-friendly模型，结合广义 interleaved packing解决高分辨率问题，实现YOLO的FHE推理，属于高效大模型训练与推理的隐私计算研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18976' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Efficient Mathematical Reasoning Models via Dynamic Pruning and Knowledge Distillation</h3>
<p><strong>Authors:</strong> Fengming Yu (), Qingyu Meng (), Haiwei Pan (), Kejia Zhang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 通过动态剪枝和知识蒸馏提升数学推理模型的效率，属于高效大模型训练与推理中的模型压缩技术
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17577' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Comparative Analysis of Large Language Model Inference Serving Systems: A Performance Study of vLLM and HuggingFace TGI</h3>
<p><strong>Authors:</strong> Saicharan Kolluru ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 对比分析vLLM和TGI的推理性能，为LLM推理系统设计提供指导，属于高效大模型训练与推理中的LLM infra研究
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17593' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Model-to-Model Knowledge Transmission (M2KT): A Data-Free Framework for Cross-Model Understanding Transfer</h3>
<p><strong>Authors:</strong> Pratham Sorte</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出无数据的跨模型知识传输框架，通过概念流形对齐实现知识转移，减少数据依赖，提升大模型训练效率。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17638' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DeepCoT: Deep Continual Transformers for Real-Time Inference on Data Streams</h3>
<p><strong>Authors:</strong> Ginés Carreto Picón, Peng Yuan Zhou, Qi Zhang, Alexandros Iosifidis</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出深度持续Transformer，通过减少流数据推理的冗余计算，在音频、视频、文本任务上实现效率提升，对高效大模型推理有价值。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.17693' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ADF-LoRA: Alternating Low-Rank Aggregation for Decentralized Federated Fine-Tuning</h3>
<p><strong>Authors:</strong> Xiaoyu Wang, Xiaotian Li, Zhixiang Zhou, Chen Li, Yong Liu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出交替低秩聚合的LoRA变体，解决去中心化联邦微调中的相位不匹配问题，提升训练效率与稳定性，属于高效大模型训练与推理方向的联邦场景优化。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18291' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> QuantKAN: A Unified Quantization Framework for Kolmogorov Arnold Networks</h3>
<p><strong>Authors:</strong> Kazi Ahmed Asif Fuad, Lizhong Chen</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出QuantKAN框架量化Kolmogorov-Arnold Networks（KAN），在保持准确性的同时提升模型效率，属于高效大模型训练与推理。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18689' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Federated style aware transformer aggregation of representations</h3>
<p><strong>Authors:</strong> Mincheol Jeon, Euinam Huh</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出FedSTAR框架用于个性化联邦学习，通过风格感知聚合提升个性化和鲁棒性，属于高效大模型训练与推理。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18841' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Hi-SAFE: Hierarchical Secure Aggregation for Lightweight Federated Learning</h3>
<p><strong>Authors:</strong> Hyeong-Gun Joo, Songnam Hong, Seunghwan Lee, Dong-Joon Shin</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Hi-SAFE框架用于轻量级联邦学习的安全聚合，降低通信开销，属于高效大模型训练与推理。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18887' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Dynamic Mixture of Experts Against Severe Distribution Shifts</h3>
<p><strong>Authors:</strong> Donghu Kim</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出DynamicMoE方法解决分布偏移的MoE模型，提升持续学习性能，属于高效大模型训练与推理。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18987' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mitigating Participation Imbalance Bias in Asynchronous Federated Learning</h3>
<p><strong>Authors:</strong> Xiangyu Chang, Manyi Yao, Srikanth V. Krishnamurthy, Christian R. Shelton, Anirban Chakraborty, Ananthram Swami, Samet Oymak, Amit Roy-Chowdhury</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出ACE框架解决异步联邦学习的参与不平衡偏差，提升训练公平性和效率，属于高效大模型训练与推理。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.19066' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation</h3>
<p><strong>Authors:</strong> Juntao Gao, Feiyang Ye, Jing Zhang, Wenjing Qian</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对VLA模型视觉token冗余的计算瓶颈，提出指令引导的混合压缩框架，结合语义任务压缩与空间细化压缩保留任务关键信息，在LIBERO基准上减少59% FLOPs和3倍token数，同时保持竞争力，助力高效大模型的机器人实时部署。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18950' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Uncertainty-Aware Dual-Student Knowledge Distillation for Efficient Image Classification</h3>
<p><strong>Authors:</strong> Aakash Gore, Anoushka Dey, Aryan Mishra</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出不确定性感知双学生知识蒸馏框架，利用教师预测不确定性引导学习，结合peer-learning机制，在ImageNet-100上提升ResNet-18与MobileNetV2精度，属于高效大模型训练与推理的模型压缩研究。
Score: 6
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.18826' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Now You See It, Now You Don't - Instant Concept Erasure for Safe Text-to-Image and Video Generation</h3>
<p><strong>Authors:</strong> Shristi Das Biswas, Arani Roy, Kaushik Roy</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出即时概念擦除方法，实现文本到图像/视频生成的安全部署，无需重新训练即可精准消除目标概念，高度关联大模型安全与对齐的研究方向。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18684' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> BackdoorVLM: A Benchmark for Backdoor Attacks on Vision-Language Models</h3>
<p><strong>Authors:</strong> Juncheng Li, Yige Li, Hanxun Huang, Yunhao Chen, Xin Wang, Yixu Wang, Xingjun Ma, Yu-Gang Jiang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出首个VLM后门攻击基准，覆盖5类威胁与12种攻击方法，系统揭示VLM的后门脆弱性（1% poisoning rate达到90% success），属于大模型安全与对齐的关键基准研究。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18921' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Natural Emergent Misalignment from Reward Hacking in Production RL</h3>
<p><strong>Authors:</strong> Monte MacDiarmid, Benjamin Wright, Jonathan Uesato, Joe Benton, Jon Kutasov, Sara Price, Naia Bouscal, Sam Bowman, Trenton Bricken, Alex Cloud, Carson Denison, Johannes Gasteiger, Ryan Greenblatt, Jan Leike, Jack Lindsey, Vlad Mikulik, Ethan Perez, Alex Rodrigues, Drake Thomas, Albert Webson, Daniel Ziegler, Evan Hubinger</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 实证研究生产环境中RL的奖励hacking导致的自然涌现错位，提出缓解策略，对大模型安全与对齐有重要指导意义
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18397' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Bias Is a Subspace, Not a Coordinate: A Geometric Rethinking of Post-hoc Debiasing in Vision-Language Models</h3>
<p><strong>Authors:</strong> Dachuan Zhao, Weiyue Li, Zhenda Shen, Yushu Qiu, Bowen Xu, Haoyu Chen, Yongchao Chen</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对VLMs的偏差问题，提出几何视角的SPD框架，识别并去除偏差子空间，同时保留语义保真度，在零样本分类、检索等任务中提升公平性（公平性指标平均+18.5%），是大模型安全与对齐的重要进展。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18123' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MagicWand: A Universal Agent for Generation and Evaluation Aligned with User Preference</h3>
<p><strong>Authors:</strong> Zitong Xu (), Dake Shen (), Yaosong Du (), Kexiang Hao (), Jinghan Huang (), Xiande Huang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出MagicWand代理，利用UniPrefer-100K数据集提升生成内容与用户偏好的对齐，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18352' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SineProject: Machine Unlearning for Stable Vision Language Alignment</h3>
<p><strong>Authors:</strong> Arpit Garg (), Hemanth Saratchandran (), Simon Lucey ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出SineProject方法，解决机器遗忘中的视觉语言对齐问题，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18444' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Robust Physical Adversarial Patches Using Dynamically Optimized Clusters</h3>
<p><strong>Authors:</strong> Harrison Bagley, Will Meakin, Simon Lucey, Yee Wei Law, Tat-Jun Chin</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出超像素正则化方法生成鲁棒的物理对抗补丁，提升深度学习模型在真实场景中的安全性，关联大模型安全与对齐的研究方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18656' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection</h3>
<p><strong>Authors:</strong> Ruize Ma, Minghong Cai, Yilei Jiang, Jiaming Han, Yi Feng, Yingshui Tan, Xiaoyong Zhu, Bo Zhang, Bo Zheng, Xiangyu Yue</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对文本-图像到视频生成的多模态安全风险，提出主动检测与缓解框架，构建了ConceptRisk和T2VSafetyBench-TI2V基准数据集，解决现有方法单模态依赖、后处理局限等问题，在风险检测和安全生成上优于基线，是大模型安全与对齐的重要研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18780' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Benchmarking Corruption Robustness of LVLMs: A Discriminative Benchmark and Robustness Alignment Metric</h3>
<p><strong>Authors:</strong> Xiangjie Sui, Songyang Li, Hanwei Zhu, Baoliang Chen, Yuming Fang, Xin Sun</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对大视觉语言模型（LVLMs）视觉鲁棒性评估的不足，提出高判别性基准Bench-C和鲁棒性对齐指标RAS，揭示模型在视觉 corruption下的行为模式，属于大模型安全与对齐中的鲁棒性研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.19032' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond Reward Margin: Rethinking and Resolving Likelihood Displacement in Diffusion Models via Video Generation</h3>
<p><strong>Authors:</strong> Ruojun Xu, Yu Kai, Xuhua Ren, Jiaxiang Cheng, Bing Ma, Tianxiang Zheng, Qinhlin Lu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 分析Diffusion模型中Direct Preference Optimization（DPO）的likelihood displacement问题，提出Policy-Guided DPO（PG-DPO）解决优化冲突与次优最大化，提升视频生成的偏好对齐效果，属于大模型安全与对齐中的扩散模型对齐研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.19049' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BideDPO: Conditional Image Generation with Simultaneous Text and Condition Alignment</h3>
<p><strong>Authors:</strong> Dewei Zhou, Mingwei Li, Zongxin Yang, Yu Lu, Yunqiu Xu, Zhizhong Wang, Zeyi Huang, Yi Yang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出双向解耦的DPO框架，解决条件图像生成中文本与条件的冲突问题，通过自适应损失平衡与冲突感知数据生成提升对齐效果，属于大模型安全与对齐中的条件生成对齐研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.19268' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Multi-Value Alignment for LLMs via Value Decorrelation and Extrapolation</h3>
<p><strong>Authors:</strong> Hefei Xu (), Le Wu (), Chen Cheng (), Hao Liu ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出多值对齐框架，通过值解相关和外推解决LLM的多值冲突问题，属于大模型安全与对齐中的多值对齐研究
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17579' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems</h3>
<p><strong>Authors:</strong> Subramanyam Sahoo, Jared Junkin</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出机械可解释的任务分解框架MITD，检测并缓解具身AI的奖励hacking，提升大模型安全性与对齐性。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17869' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Curvature-Aware Safety Restoration In LLMs Fine-Tuning</h3>
<p><strong>Authors:</strong> Thong Bach, Thanh Nguyen-Tang, Dung Nguyen, Thao Minh Le, Truyen Tran</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出曲率感知的安全恢复方法，在LLM微调中平衡任务性能与安全对齐，属于大模型安全与对齐方向的实际应用研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18039' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Subtract the Corruption: Training-Data-Free Corrective Machine Unlearning using Task Arithmetic</h3>
<p><strong>Authors:</strong> Mostafa Mozafari, Farooq Ahmad Wani, Maria Sofia Bucarelli, Fabrizio Silvestri</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出CUTS方法解决无训练数据的纠正性机器遗忘，通过任务算术去除corruption影响，提升模型的安全性和对齐性，属于大模型安全与对齐。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18660' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM</h3>
<p><strong>Authors:</strong> Adarsh Kumarappan, Ayushi Mehrotra</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出(k,ε)-unstable框架为SmoothLLM提供概率安全认证，提升LLM的安全对齐和可信任性，属于大模型安全与对齐。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18721' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Alignment Faking - the Train -> Deploy Asymmetry: Through a Game-Theoretic Lens with Bayesian-Stackelberg Equilibria</h3>
<p><strong>Authors:</strong> Kartik Garg (), Shourya Mishra (), Kartikeya Sinha (), Ojaswi Pratap Singh (), Ayush Chopra (), Kanishk Rai (), Ammar Sheikh (), Raghav Maheshwari (), Aman Chadha (), Vinija Jain (), Amitava Das ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 用博弈论框架分析大模型的对齐伪造问题，评估了多种偏好优化方法的安全、无害和有用性表现，为大模型安全对齐的策略设计提供了理论和实证支持。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17937' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Steering Latent Traits, Not Learned Facts: An Empirical Study of Activation Control Limits</h3>
<p><strong>Authors:</strong> Tetiana Bas, Krystian Novak</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 研究激活引导在LLM行为控制中的有效性，分析不同行为类型的引导效果差异，为大模型对齐提供实证指导
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18284' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> When Generative Replay Meets Evolving Deepfakes: Domain-Aware Relative Weighting for Incremental Face Forgery Detection</h3>
<p><strong>Authors:</strong> Hao Shen (), Jikang Cheng (), Renye Yan (), Zhongyuan Wang (), Wei Peng (), Baojin Huang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出DARW策略，提升增量人脸伪造检测的性能，符合大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.18436' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Generative Adversarial Post-Training Mitigates Reward Hacking in Live Human-AI Music Interaction</h3>
<p><strong>Authors:</strong> Yusong Wu, Stephen Brade, Teng Ma, Tia-Jane Fowler, Enning Yang, Berker Banar, Aaron Courville, Natasha Jaques, Cheng-Zhi Anna Huang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 用对抗训练缓解RL后训练的奖励hacking，提升生成模型的多样性与安全性，对大模型对齐有帮助。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.17879' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Understanding, Accelerating, and Improving MeanFlow Training</h3>
<p><strong>Authors:</strong> Jin-Young Kim, Hyojun Go, Lea Bogensperger, Julius Erbach, Nikolai Kalischek, Federico Tombari, Konrad Schindler, Dominik Narnhofer</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 深入解析MeanFlow的训练动力学，提出分阶段训练策略加速瞬时与平均 velocity场的学习，显著提升few-step生成性能（DiT-XL在ImageNet 256x256上FID达2.87），属于深度学习理论中生成模型训练方法的创新。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.19065' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RNN as Linear Transformer: A Closer Investigation into Representational Potentials of Visual Mamba Models</h3>
<p><strong>Authors:</strong> Timing Yang (), Guoyizhe Wei (), Alan Yuille (), Feng Wang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 分析Visual Mamba的表示潜力，揭示其与Softmax/Linear Attention的关系，提出二进制分割 metric，符合深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18380' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EVCC: Enhanced Vision Transformer-ConvNeXt-CoAtNet Fusion for Classification</h3>
<p><strong>Authors:</strong> Kazi Reyazul Hasan, Md Nafiu Rahman, Wasif Jalal, Sadif Ahmed, Shahriar Raj, Mubasshira Musarrat, Muhammad Abdullah Adnan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出融合Vision Transformer、ConvNeXt和CoAtNet的多分支混合架构，结合自适应令牌剪枝等创新，推进网络架构设计，关联深度学习理论的研究方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18691' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Dendritic Convolution for Noise Image Recognition</h3>
<p><strong>Authors:</strong> Jiarui Xue, Dongjian Yang, Ye Sun, Gang Liu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 模拟生物神经元的树突结构，提出树突卷积操作，从神经元角度提升模型抗噪声能力，关联深度学习理论（网络架构）的研究方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18699' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> POUR: A Provably Optimal Method for Unlearning Representations via Neural Collapse</h3>
<p><strong>Authors:</strong> Anjie Le (), Can Peng (), Yuyuan Liu (), J. Alison Noble ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 结合神经崩溃理论提出可证明最优的表示遗忘方法，解决表示级机器学习遗忘问题，对深度学习理论中的表示学习有贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.19339' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Equivalence of Context and Parameter Updates in Modern Transformer Blocks</h3>
<p><strong>Authors:</strong> Adrian Goldwaser, Michael Munn, Javier Gonzalvo, Benoit Dherin</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 证明现代Transformer块中上下文效应与参数更新的等价性，提供统一框架理解prompt如何影响模型，对Transformer理论有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17864' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Escaping Optimization Stagnation: Taking Steps Beyond Task Arithmetic via Difference Vectors</h3>
<p><strong>Authors:</strong> Jinping Wang, Zhiqiang Gao, Dinggen Zhang, Zhiwu Xie</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对预训练模型编辑中的优化停滞问题，提出差异向量及DV-BASI算法，扩展任务算术的优化能力，属于深度学习理论中优化器方向的重要研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17987' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Deterministic Continuous Replacement: Fast and Stable Module Replacement in Pretrained Transformers</h3>
<p><strong>Authors:</strong> Rowan Bradbury, Aniket Srinivasan Ashok, Sai Ram Kasanagottu, Gunmay Jhingran, Shuai Meng</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出DCR方法解决预训练Transformer的模块替换稳定性问题，通过确定性连续替换提升替换效率和对齐，属于深度学习理论中的网络架构优化。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18670' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Doubly Wild Refitting: Model-Free Evaluation of High Dimensional Black-Box Predictions under Convex Losses</h3>
<p><strong>Authors:</strong> Haichen Hu, David Simchi-Levi</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Doubly Wild Refitting方法评估黑盒模型的excess risk，无需模型复杂度假设，属于深度学习理论中的模型评估研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18789' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> How Learning Rate Decay Wastes Your Best Data in Curriculum-Based LLM Pretraining</h3>
<p><strong>Authors:</strong> Kairong Luo, Zhenbo Sun, Haodong Wen, Xinyu Shi, Jiarui Cui, Chenyi Dang, Kaifeng Lyu, Wenguang Chen</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 分析学习率衰减在LLM课程预训练中的问题，提出改进策略提升数据利用效率，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18903' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Progressive Localisation in Localist LLMs</h3>
<p><strong>Authors:</strong> Joachim Diederich</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出LLM中注意力从分布式到局部化的渐进架构，平衡可解释性与性能，对深度学习网络架构设计有理论贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18375' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Scaling Implicit Fields via Hypernetwork-Driven Multiscale Coordinate Transformations</h3>
<p><strong>Authors:</strong> Plein Versace</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出HC-INR解决隐式神经表示的表示瓶颈与扩展性问题，结合理论证明与实验验证，推动深度学习理论发展
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18387' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> QAL: A Loss for Recall Precision Balance in 3D Reconstruction</h3>
<p><strong>Authors:</strong> Pranay Meshram, Yash Turkar, Kartikeya Singh, Praveen Raj Masilamani, Charuvahan Adhivarahan, Karthik Dantu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出QAL损失函数，通过覆盖加权最近邻与未覆盖真实吸引项平衡3D重建的召回与精度，解决传统损失函数忽视结构细节问题，属于深度学习理论中的损失函数方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17824' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian Splatting Generalization</h3>
<p><strong>Authors:</strong> Youngsik Yun, Dongjun Gu, Youngjung Uh</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出FASR正则化，结合图像局部频率调整正则化权重与半径，解决3DGS泛化差问题，避免SAM过度平滑细节，属于深度学习理论中的正则化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17918' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Exploring Weak-to-Strong Generalization for CLIP-based Classification</h3>
<p><strong>Authors:</strong> Jinhao Li (), Sarah M. Erfani (), Lei Feng (), James Bailey (), Feng Liu ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 探索CLIP的弱到强泛化能力，提出CPL方法，符合深度学习理论方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18396' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Dynamic Granularity Matters: Rethinking Vision Transformers Beyond Fixed Patch Splitting</h3>
<p><strong>Authors:</strong> Qiyang Yu, Yu Fang, Tianrui Li, Xuemei Cao, Yan Chen, Jianghao Li, Fan Min</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对Vision Transformers固定Patch分割的局限性，提出动态粒度调整的Grc-ViT框架，通过粗粒度评估和细粒度 refinement平衡全局推理与局部感知，属于深度学习理论中网络架构方向的创新研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.19021' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Enhancing Robustness of Offline Reinforcement Learning Under Data Corruption via Sharpness-Aware Minimization</h3>
<p><strong>Authors:</strong> Le Xu (), Jiayu Chen ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 将Sharpness-Aware Minimization（SAM）优化器应用于离线RL，提升数据 corruption下的鲁棒性，属于深度学习理论中的优化器研究
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17568' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Frugality in second-order optimization: floating-point approximations for Newton's method</h3>
<p><strong>Authors:</strong> Giuseppe Carrino, Elena Loli Piccolomini, Elisa Riccietti, Theo Mary</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 分析二阶优化中浮点运算的影响，提出混合精度牛顿法和广义高斯-牛顿法，提升二阶优化的效率与实用性，对优化算法设计有帮助。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17660' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Smoothed Agnostic Learning of Halfspaces over the Hypercube</h3>
<p><strong>Authors:</strong> Yiwen Kou, Raghu Meka</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出离散域的平滑agnostic学习框架，解决布尔超立方体上半空间的学习问题，对深度学习理论中的学习理论有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17782' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> High-Accuracy List-Decodable Mean Estimation</h3>
<p><strong>Authors:</strong> Ziyun Chen, Spencer Compton, Daniel Kane, Jerry Li</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出高精度列表可解码均值估计的算法与理论，解决鲁棒学习中的均值估计问题，对深度学习理论有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17822' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Internalizing Tools as Morphisms in Graded Transformers</h3>
<p><strong>Authors:</strong> Tony Shaska</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出分级Transformer的内部符号计算框架，将工具内化为morphisms，对Transformer架构设计有启发。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17840' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But Differently</h3>
<p><strong>Authors:</strong> Bochen Lyu, Yiyang Jia, Xiaohao Cai, Zhanxing Zhu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 分析RL和SFT在Transformer学习稀疏布尔函数中的差异，提供理论保证，深化对Transformer学习机制的理解。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17852' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Cost-Sensitive Conformal Training with Provably Controllable Learning Bounds</h3>
<p><strong>Authors:</strong> Xuesong Jia, Yuanjie Shi, Ziquan Liu, Yi Xu, Yan Yan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出成本敏感的conformal训练，通过秩加权最小化预测集大小，提供可控制的学习 bounds，对不确定性量化有帮助。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17861' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mitigating Catastrophic Forgetting in Streaming Generative and Predictive Learning via Stateful Replay</h3>
<p><strong>Authors:</strong> Wenzhang Du</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 研究流数据中的灾难性遗忘，提出状态重放机制，提升持续学习性能，对深度学习理论中的持续学习有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17936' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Controllability Analysis of State Space-based Language Model</h3>
<p><strong>Authors:</strong> Mohamed Mabrok, Yalda Zafari</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Influence Score分析Mamba模型的可控性，深化对SSM-based语言模型的理解，对架构可解释性有帮助。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17970' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Rate Scheduling with Matrix Factorization for Private Training</h3>
<p><strong>Authors:</strong> Nikita P. Kalinin, Joel Daniel Andersson</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 研究差分隐私训练中的学习率调度，结合矩阵分解推导上下界并提出优化方法，属于深度学习理论中优化器方向的关键问题。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17994' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> In Search of Goodness: Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorithm</h3>
<p><strong>Authors:</strong> Arya Shah, Vaibhav Tripathi</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 基准测试21种Forward-Forward算法的goodness函数，探索性能与效率的权衡，属于深度学习理论中网络架构与优化方向的重要实证研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18567' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> KAN vs LSTM Performance in Time Series Forecasting</h3>
<p><strong>Authors:</strong> Tabish Ali Rather, S M Mahmudul Hasan Joy, Nadezda Sukhorukova, Federico Frascoli</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 比较Kolmogorov-Arnold Networks（KAN）与LSTM在时间序列预测的性能，分析KAN的interpretability和效率，属于深度学习理论中的网络架构研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18613' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bayesian-based Online Label Shift Estimation with Dynamic Dirichlet Priors</h3>
<p><strong>Authors:</strong> Jiawei Hu, Javier A. Barria</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出贝叶斯框架FMAPLS解决在线标签偏移问题，改进估计的准确性和效率，属于深度学习理论中的泛化与分布偏移研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18615' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Sampling Control for Imbalanced Calibration in Semi-Supervised Learning</h3>
<p><strong>Authors:</strong> Senmao Tian, Xiang Wei, Shunli Zhang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出SC-SSL框架解决半监督学习的类不平衡问题，通过采样控制抑制模型偏差，属于深度学习理论中的泛化研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18773' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MIST: Mutual Information Via Supervised Training</h3>
<p><strong>Authors:</strong> German Gritsai, Megan Richards, Maxime Méloux, Kyunghyun Cho, Maxime Peyrard</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出MIST方法通过监督训练估计互信息，提升灵活性和效率，属于深度学习理论中的信息论研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.18945' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Resolving Node Identifiability in Graph Neural Processes via Laplacian Spectral Encodings</h3>
<p><strong>Authors:</strong> Zimo Yan, Zheng Xie, Chang Liu, Yuan Wang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出拉普拉斯谱编码解决图神经过程的节点可识别性，提升模型表达能力，属于深度学习理论中的图模型研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.19037' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Improved Sample Complexity for Full Coverage in Compact and Continuous Spaces</h3>
<p><strong>Authors:</strong> Lyu Yuhuan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 改进紧凑连续空间中覆盖问题的样本复杂度 bounds，减少保守性，对学习理论中的采样策略有帮助。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17784' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> On Transportability for Structural Causal Bandits</h3>
<p><strong>Authors:</strong> Min Woo Park, Sanghack Lee</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 分析结构因果Bandit的可迁移性，利用跨环境不变性提升学习效率，对因果学习与Bandit理论有贡献。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.17953' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Bringing Stability to Diffusion: Decomposing and Reducing Variance of Training Masked Diffusion Models</h3>
<p><strong>Authors:</strong> Mengni Jia, Mengyu Zhou, Yihao Liu, Xiaoxi Jiang, Guanjun Jiang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 分解掩码扩散模型训练方差的三个来源，提出多种方差减少方法提升训练稳定性，属于大模型新技术中扩散模型方向的重要理论与实践贡献。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18159' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> FeRA: Frequency-Energy Constrained Routing for Effective Diffusion Adaptation Fine-Tuning</h3>
<p><strong>Authors:</strong> Bo Yin, Xiaobin Hu, Xingyu Zhou, Peng-Tao Jiang, Yue Liao, Junwei Zhu, Jiangning Zhang, Ying Tai, Chengjie Wang, Shuicheng Yan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对扩散模型自适应微调的核心问题，提出频率能量驱动的FeRA框架，通过频率路由器和一致性正则对齐参数更新与扩散的内在机制，显著提升扩散模型的适应效果和鲁棒性，是扩散模型适应的创新技术。
Score: 8.5
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17979' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Efficient Score Pre-computation for Diffusion Models via Cross-Matrix Krylov Projection</h3>
<p><strong>Authors:</strong> Kaikwan Lau, Andrew S. Na, Justin W. L. Wan</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 将扩散模型转换为Fokker-Planck形式，利用交叉矩阵Krylov投影共享子空间加速分数预计算，解决扩散模型计算瓶颈，属于大模型新技术中的扩散模型方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17634' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Show Me: Unifying Instructional Image and Video Generation with Diffusion Models</h3>
<p><strong>Authors:</strong> Yujiang Pu, Zhanbo Huang, Vishnu Boddeti, Yu Kong</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出ShowMe框架，通过选择性激活视频扩散模型的空间与时间组件，统一 instructional图像与视频生成，解决单任务模型的局限性，属于大模型新技术中的扩散模型方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17839' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MINDiff: Mask-Integrated Negative Attention for Controlling Overfitting in Text-to-Image Personalization</h3>
<p><strong>Authors:</strong> Seulgi Jeong, Jaeil Kim</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出推理时负注意力机制MINDiff，解决文本到图像个性化的过拟合问题，无需重新训练即可平衡主题保真度与文本对齐，属于大模型新技术中的扩散模型方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17888' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ProxT2I: Efficient Reward-Guided Text-to-Image Generation via Proximal Diffusion</h3>
<p><strong>Authors:</strong> Zhenghan Fang, Jian Zheng, Qiaozi Gao, Xiaofeng Gao, Jeremias Sulam</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出近端扩散方法，实现高效的奖励引导文本到图像生成，提升生成效率与对齐效果，符合大模型新技术（扩散大模型）的研究方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18742' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DiP: Taming Diffusion Models in Pixel Space</h3>
<p><strong>Authors:</strong> Zhennan Chen, Junwei Zhu, Xu Chen, Jiangning Zhang, Xiaobin Hu, Hanzhen Zhao, Chengjie Wang, Jian Yang, Ying Tai</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出像素空间扩散框架，通过全局DiT与局部Patch Detailer Head协同，实现与LDM相当的效率且无需VAE，在ImageNet上达到1.90 FID和10倍推理加速，属于大模型新技术的扩散模型优化研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18822' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VeCoR - Velocity Contrastive Regularization for Flow Matching</h3>
<p><strong>Authors:</strong> Zong-Wei Hong, Jing-lun Li, Lin-Ze Li, Shen Zhang, Yao Tang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出速度对比正则化，为流匹配模型添加正负方向监督，提升生成稳定性与质量，在ImageNet-1K与MS-COCO上减少FID，属于大模型新技术的流匹配研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18942' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Generative Myopia: Why Diffusion Models Fail at Structure</h3>
<p><strong>Authors:</strong> Milad Siami</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 研究图扩散模型的“生成近视”问题，提出频谱加权扩散解决结构缺失，改进扩散模型的结构建模能力，属于大模型新技术范畴。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18593' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Majority of the Bests: Improving Best-of-N via Bootstrapping</h3>
<p><strong>Authors:</strong> Amin Rakhsha, Kanika Madan, Tianyu Zhang, Amir-massoud Farahmand, Amir Khasahmadi</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出MoB方法改进LLM的Best-of-N输出选择，通过bootstrapping估计输出分布的模式，提升准确性，属于大模型新技术。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18630' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EnfoPath: Energy-Informed Analysis of Generative Trajectories in Flow Matching</h3>
<p><strong>Authors:</strong> Ziyun Li, Ben Dai, Huancheng Hu, Henrik Boström, Soon Hoe Lim</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出EnfoPath方法分析流匹配的生成轨迹能量，揭示生成难度和样本特性，属于大模型新技术中的flow模型研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.19087' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Masked Diffusion Models are Secretly Learned-Order Autoregressive Models</h3>
<p><strong>Authors:</strong> Prateek Garg (), Bhavya Kohli (), Sunita Sarawagi ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 研究了Masked Diffusion Models作为学习顺序自回归模型的特性，揭示了其目标分解为加权自回归损失的本质，对diffusion类大模型的理论理解和设计优化有重要价值。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.19152' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Importance-Weighted Non-IID Sampling for Flow Matching Models</h3>
<p><strong>Authors:</strong> Xinshuang Liu, Runfa Blark Li, Shaoxiu Wei, Truong Nguyen</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出重要性加权非IID采样框架，结合得分正则化与残差速度场解决流匹配模型采样多样性与偏差问题，属于大模型新技术中的流匹配方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17812' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ArticFlow: Generative Simulation of Articulated Mechanisms</h3>
<p><strong>Authors:</strong> Jiong Lin, Jinchen Ruan, Hod Lipson</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出两阶段流匹配框架ArticFlow，学习动作控制的速度场，实现铰接机制的生成模拟，解决静态3D生成无法处理动作变形的问题，属于大模型新技术中的流匹配方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17883' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Sequence-Adaptive Video Prediction in Continuous Streams using Diffusion Noise Optimization</h3>
<p><strong>Authors:</strong> Sina Mokhtarzadeh Azar (), Emad Bahrami (), Enrico Pallotta (), Gianpiero Francesca (), Radu Timofte (), Juergen Gall ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出SAVi-DNO方法，通过扩散噪声优化适应连续视频流，提升视频预测性能，属于大模型新技术中的扩散模型应用。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18255' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Words and Pixels: A Benchmark for Implicit World Knowledge Reasoning in Generative Models</h3>
<p><strong>Authors:</strong> Tianyang Han (), Junhao Su (), Junjie Hu (), Peizhen Yang (), Hengyu Shi (), Junfeng Luo (), Jialin Gao ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出PicWorld基准，评估生成模型的隐式世界知识推理能力，属于大模型新技术中的评估方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18271' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Point-to-Point: Sparse Motion Guidance for Controllable Video Editing</h3>
<p><strong>Authors:</strong> Yeji Song (), Jaehyun Lee (), Mijin Koo (), JunHoo Lee (), Nojun Kwak ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出Point-to-Point方法，用锚点tokens捕捉运动，提升可控视频编辑性能，属于大模型新技术中的视频编辑应用。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18277' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FlowPortal: Residual-Corrected Flow for Training-Free Video Relighting and Background Replacement</h3>
<p><strong>Authors:</strong> Wenshuo Gao (), Junyi Fan (), Jiangyue Zeng (), Shuai Yang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出FlowPortal方法，用残差校正流实现无训练的视频重新打光和背景替换，属于大模型新技术中的视频处理应用。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18346' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Synthetic Curriculum Reinforces Compositional Text-to-Image Generation</h3>
<p><strong>Authors:</strong> Shijian Wang (), Runhao Fu (), Siyi Zhao (), Qingqin Zhan (), Xingjian Wang (), Jiarui Jin (), Yuan Lu (), Hanqian Wu (), Cunjian Chen ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出CompGen框架，用场景图和强化学习提升组合式文本到图像生成性能，属于大模型新技术中的生成模型优化。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18378' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Breaking Forgetting: Training-Free Few-Shot Class-Incremental Learning via Conditional Diffusion</h3>
<p><strong>Authors:</strong> Haidong Kang, Ketong Qian, Yi Lu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 利用条件扩散模型实现无训练的少样本类别增量学习，解决灾难性遗忘问题，符合大模型新技术（扩散大模型）的研究方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18516' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Edit2Perceive: Image Editing Diffusion Models Are Strong Dense Perceivers</h3>
<p><strong>Authors:</strong> Yiqing Shi, Yiren Song, Mike Zheng Shou</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 将图像编辑扩散模型应用于密集感知任务（深度、法线、抠图），拓展扩散模型的应用场景，符合大模型新技术（扩散大模型）的研究方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CoD: A Diffusion Foundation Model for Image Compression</h3>
<p><strong>Authors:</strong> Zhaoyang Jia, Zihan Zheng, Naifu Xue, Jiahao Li, Bin Li, Zongyu Guo, Xiaoyi Zhang, Houqiang Li, Yan Lu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出面向压缩的扩散基础模型CoD，从头训练以优化压缩与生成性能，符合大模型新技术（扩散大模型）的研究方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18706' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion</h3>
<p><strong>Authors:</strong> Yichen Yang, Hong Li, Haodong Zhu, Linin Yang, Guojun Lei, Sheng Xu, Baochang Zhang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出部分级离散扩散框架，通过语义分割和跨部分自回归+部分内并行扩散，解决3D mesh生成的全局一致性与局部细节问题，优于现有SOTA模型，属于大模型新技术的3D生成研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18801' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FlowSteer: Guiding Few-Step Image Synthesis with Authentic Trajectories</h3>
<p><strong>Authors:</strong> Lei Ke, Hubery Yin, Gongye Liu, Zhengyao Lv, Jingcai Guo, Chen Li, Wenhan Luo, Yujiu Yang, Jing Lyu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 改进ReFlow框架，提出Online Trajectory Alignment与对抗蒸馏，解决流匹配模型的分布 mismatch 问题，提升少步生成质量，在SD3上验证 efficacy，属于大模型新技术的流匹配研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18834' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction</h3>
<p><strong>Authors:</strong> Yiming Wang, Shaofei Wang, Marko Mihajlovic, Siyu Tang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出神经纹理 splatting 框架，用全局神经场预测每个3D高斯的局部外观与几何，提升3DGS的表达能力，在视图合成、几何重建等多任务上优于SOTA，属于大模型新技术的3D生成研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18873' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning What to Trust: Bayesian Prior-Guided Optimization for Visual Generation</h3>
<p><strong>Authors:</strong> Ruiying Liu, Yuanzhi Liang, Haibin Huang, Tianshu Yu, Chi Zhang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出贝叶斯先验引导优化框架，通过先验锚点调制GRPO的优化信任，解决文本-视觉对应模糊问题，提升生成的语义对齐与保真度，属于大模型新技术的生成优化研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.18919' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Plug-and-play Memory for Guiding Video Diffusion Models</h3>
<p><strong>Authors:</strong> Selena Song, Ziming Xu, Zijun Zhang, Kun Zhou, Jiaxian Guo, Lianhui Qin, Biwei Huang</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出可插拔的记忆编码器DiT-Mem，向扩散模型注入世界知识以改善物理规则遵循与视频保真度，属于大模型新技术中的扩散模型增强研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.19229' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Breaking the Likelihood-Quality Trade-off in Diffusion Models by Merging Pretrained Experts</h3>
<p><strong>Authors:</strong> Yasin Esfandiari (), Stefan Bauer (), Sebastian U. Stich (), Andrea Dittadi ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出专家合并方法解决扩散模型的likelihood-quality权衡问题，属于大模型新技术中的扩散模型优化
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.19434' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Straight Flows: Variational Flow Matching for Efficient Generation</h3>
<p><strong>Authors:</strong> Chenrui Ma (), Xi Xiao (), Tianyang Wang (), Xiao Wang (), Yanning Shen ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出直线流的变分流匹配方法，提升生成模型的效率，属于大模型新技术中的流模型优化
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17583' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Diffusion Models are Molecular Dynamics Simulators</h3>
<p><strong>Authors:</strong> Justin Diamond, Markus Lill</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 证明扩散模型与分子动力学模拟器的等价性，拓展扩散模型的应用场景，属于大模型新技术的研究。
Score: 6
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.17741' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Mixture of Horizons in Action Chunking</h3>
<p><strong>Authors:</strong> Dong Jing, Gang Wang, Jiaqi Liu, Weiliang Tang, Zelong Sun, Yunchao Yao, Zhenyu Wei, Yunhui Liu, Zhiwu Lu, Mingyu Ding</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对VLA（视觉-语言-动作）模型的动作块长度权衡问题，提出MoH混合视野策略，联合长短期优势提升机器人任务性能与泛化性，且具有即插即用和动态推理特性，对多模态智能体的动作建模有显著创新。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.19433' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SWITCH: Benchmarking Modeling and Handling of Tangible Interfaces in Long-horizon Embodied Scenarios</h3>
<p><strong>Authors:</strong> Jieru Lin, Zhiwei Yu, Börje F. Karlsson</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建SWITCH基准，评估多模态大语言模型在有形控制接口（如开关、家电面板）的处理能力，覆盖任务感知VQA、语义UI接地等能力，属于多模态智能体中的GUI grounding方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.17649' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ARIAL: An Agentic Framework for Document VQA with Precise Answer Localization</h3>
<p><strong>Authors:</strong> Ahmad Mohammadshirazi (), Pinaki Prasad Guha Neogi (), Dheeraj Kulshrestha (), Rajiv Ramnath ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出ARIAL框架，利用LLM-based规划代理协调工具，提升文档VQA的准确性和可解释性，性能超过现有方法，符合多模态智能体方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18192' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EgoVITA: Learning to Plan and Verify for Egocentric Video Reasoning</h3>
<p><strong>Authors:</strong> Yogesh Kulkarni (), Pooyan Fazli ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出EgoVITA强化学习框架，通过交替规划和验证提升第一视角视频推理性能，符合多模态智能体方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18242' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MASS: Motion-Aware Spatial-Temporal Grounding for Physics Reasoning and Comprehension in Vision-Language Models</h3>
<p><strong>Authors:</strong> Xiyang Wu (), Zongxia Li (), Jihui Jin (), Guangyao Shi (), Gouthaman KV (), Vishnu Raj (), Nilotpal Sinha (), Jingxi Chen (), Fan Du (), Dinesh Manocha ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出MASS方法，注入时空信号提升VLMs的物理推理能力，符合多模态智能体方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18373' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Perceptual-Evidence Anchored Reinforced Learning for Multimodal Reasoning</h3>
<p><strong>Authors:</strong> Chi Zhang (), Haibo Qiu (), Qiming Zhang (), Yufei Xu (), Zhixiong Zeng (), Siqi Yang (), Peng Shi (), Lin Ma (), Jing Zhang ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出PEARL框架，用感知证据锚定提升多模态推理能力，符合多模态智能体方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18437' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention</h3>
<p><strong>Authors:</strong> Lei Xiao, Jifeng Li, Juntao Gao, Feiyang Ye, Yan Jin, Jingjing Qian, Jing Zhang, Yong Wu, Xiaoyuan Yu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出AVA-VLA框架改进Vision-Language-Action（VLA）模型的主动视觉注意力，提升embodied AI性能，属于多模态智能体范畴。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18960' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Bridging Symbolic Control and Neural Reasoning in LLM Agents: The Structured Cognitive Loop</h3>
<p><strong>Authors:</strong> Myung Ho Kim ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出SCL架构分离LLM智能体的认知阶段，结合软符号控制实现神经灵活性与符号可控性的平衡，解决了现有智能体推理执行纠缠、记忆不稳定等问题，提升了可靠性和可解释性。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.17673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MergeVLA: Cross-Skill Model Merging Toward a Generalist Vision-Language-Action Agent</h3>
<p><strong>Authors:</strong> Yuxia Fu, Zhizhen Zhang, Yuqi Zhang, Zijian Wang, Zi Huang, Yadan Luo</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对VLA模型多技能难以合并的问题，提出MergeVLA架构，通过稀疏激活LoRA和跨注意力块保留参数一致性与模块可组合性，结合任务路由器实现无监督任务推理，在多个基准及真实机器人上性能优于单任务微调模型，对多模态智能体的泛化能力提升有重要价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18810' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control</h3>
<p><strong>Authors:</strong> Yuxuan Wang, Haobin Jiang, Shiqing Yao, Ziluo Ding, Zongqing Lu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出端到端语言-动作模型SENTINEL，直接映射语言指令与本体输入到低阶动作，通过flow matching生成动作块并结合残差头优化，在仿真与真实场景中实现稳定执行，支持多模态扩展，推进多模态智能体的端到端控制研究。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.19236' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Intermediate Representation for VLM-based Robot Manipulation</h3>
<p><strong>Authors:</strong> Weiliang Tang, Jialin Gao, Jia-Hui Pan, Gang Wang, Li Erran Li, Yunhui Liu, Mingyu Ding, Pheng-Ann Heng, Chi-Wing Fu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 聚焦VLM（视觉语言模型）驱动机器人操纵的中间表示设计，提出SEAM语义组装框架优化VLM可理解性与泛化性，结合少样本分割范式提升细粒度物体定位，对多模态智能体的表示学习有重要探索价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.19315' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DocPTBench: Benchmarking End-to-End Photographed Document Parsing and Translation</h3>
<p><strong>Authors:</strong> Yongkun Du (), Pinxuan Chen (), Xuye Ying (), Zhineng Chen ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建DocPTBench基准，评估拍摄文档的解析与翻译能力，涉及多模态处理，符合多模态智能体方向。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18434' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Description: Cognitively Benchmarking Fine-Grained Action for Embodied Agents</h3>
<p><strong>Authors:</strong> Dayong Liu, Chao Xu, Weihong Chen, Suyu Zhang, Juncheng Wang, Jiankang Deng, Baigui Sun, Yang Liu</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 构建评估具身智能体细粒度动作能力的基准数据集，关联多模态智能体的研究方向。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18685' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UISearch: Graph-Based Embeddings for Multimodal Enterprise UI Screenshots Retrieval</h3>
<p><strong>Authors:</strong> Maroun Ayli (), Youssef Bakouny (), Tushar Sharma (), Nader Jalloul (), Hani Seifeddine (), Rima Kilany ()</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 针对企业UI截图的多模态检索问题，提出图基表示学习框架，属于多模态智能体中的GUI相关任务
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.19380' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model</h3>
<p><strong>Authors:</strong> Changxin Huang, Lv Tang, Zhaohuan Zhan, Lisha Yu, Runhao Zeng, Zun Liu, Zhengjie Wang, Jianqiang Li</p>
<p><strong>Published:</strong> 2025-11-25</p>
<p><strong>Reason:</strong> 提出多模态世界模型协作框架，优化视觉推理与导航决策，提升多模态智能体的导航性能
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.18845' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>