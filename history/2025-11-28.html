<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-11-28</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>大模型新技术</a>
<a href='#' >多模态智能体</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >深度学习可解释性</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-11-28</h1>
<div class='meta-info'><p>更新于北京时间：2025-11-28 12:36:05</p>
<p>已自动阅读了 258 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：160890</p>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation</h3>
<p><strong>Authors:</strong> Inferix Team, Tianyu Feng, Yizeng Han, Jiahao He, Yuanyu He, Xi Lin, Teng Liu, Hanfeng Lu, Jiasheng Tang, Wei Wang, Zhiyuan Wang, Jichao Wu, Mingyang Yang, Yinghao Yu, Zeyu Zhang, Bohan Zhuang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出基于块扩散的下一代推理引擎，优化半自回归解码和KV Cache管理，支持高效、高质量的世界模拟，推动diffusion大模型的推理效率提升。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.20714' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Training-Free Diffusion Priors for Text-to-Image Generation via Optimization-based Visual Inversion</h3>
<p><strong>Authors:</strong> Samuele Dell'Erba, Andrew D. Bagdanov</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出优化-based视觉反转替代训练的扩散先验，避免传统先验的高计算成本，提升文本到图像生成的效率与质量。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.20821' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PG-ControlNet: A Physics-Guided ControlNet for Generative Spatially Varying Image Deblurring</h3>
<p><strong>Authors:</strong> Hakki Motorcu, Mujdat Cetin</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出物理引导的ControlNet，融合光传播的物理约束，提升生成式去模糊的准确性与鲁棒性，推动diffusion模型的物理一致性。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21043' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Solving Diffusion Inverse Problems with Restart Posterior Sampling</h3>
<p><strong>Authors:</strong> Bilal Ahmed, Joseph G. Makin</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出RePS框架解决扩散模型逆问题，提高收敛速度与重建质量，对扩散模型的实际应用有推动作用。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.20705' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> $\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion</h3>
<p><strong>Authors:</strong> Zhihao Zhan, Jiaying Zhou, Likui Zhang, Qinhan Lv, Hao Liu, Jusheng Zhang, Weizheng Li, Ziliang Chen, Tianshui Chen, Keze Wang, Liang Lin, Guangrun Wang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Continuized Discrete Diffusion框架以增强VLA模型的泛化能力与细粒度控制，该方法属于大模型新技术中的扩散模型应用，针对VLA模型的核心问题（泛化性、控制精度）提供了有效解决方案，实验在多机器人任务基准上取得SOTA性能，作者团队包含深度学习领域知名学者，对大模型新技术研究有较高价值。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21542' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Inversion-Free Style Transfer with Dual Rectified Flows</h3>
<p><strong>Authors:</strong> Yingying Deng, Xiangyu He, Fan Tang, Weiming Dong, Xucheng Yin</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出双整流流的无反转风格迁移，避免传统方法的计算开销与视觉失真，提升风格迁移的效率与质量。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.20986' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Diffusion to One-Step Generation: A Comparative Study of Flow-Based Models with Application to Image Inpainting</h3>
<p><strong>Authors:</strong> Umang Agarwal, Rudraksh Sangore, Sumit Laddha</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 对比扩散、CFM与MeanFlow模型，提出一步生成的MeanFlow框架，在CIFAR-10上实现FID 29.15（1步），并扩展至图像修复任务，属于大模型新技术中生成模型的关键研究，提升推理效率。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21215' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CaliTex: Geometry-Calibrated Attention for View-Coherent 3D Texture Generation</h3>
<p><strong>Authors:</strong> Chenyu Liu, Hongze Chen, Jingzhi Bao, Lingting Zhu, Runze Zhang, Weikai Chen, Zeyu Hu, Yingda Yin, Keyang Luo, Xin Wang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出几何校准的注意力机制，解决3D纹理生成的跨视图不一致问题，通过两阶段扩散Transformer实现一致纹理生成，实验优于开源与商业基线，属于大模型新技术中3D生成的创新研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21309' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DiverseVAR: Balancing Diversity and Quality of Next-Scale Visual Autoregressive Models</h3>
<p><strong>Authors:</strong> Mingue Park, Prin Phunyaphibarn, Phillip Y. Lee, Minhyuk Sung</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出文本嵌入噪声注入与scale-travel技术，提升视觉自回归模型的多样性（如文本到图像生成），在保持质量的同时实现帕累托最优，属于大模型新技术中自回归生成的创新研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21415' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Bits to Rounds: Parallel Decoding with Exploration for Diffusion Language Models</h3>
<p><strong>Authors:</strong> Hengyu Fu, Baihe Huang, Virginia Adams, Charles Wang, Venkat Srinivasan, Jiantao Jiao</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 针对扩散语言模型并行解码的效率问题，提出ETE策略通过探索高不确定性token最大化信息吞吐量，实验减少解码轮数且不损失生成质量，推动了扩散LM的实用化。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21103' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Masks Can Be Distracting: On Context Comprehension in Diffusion Language Models</h3>
<p><strong>Authors:</strong> Julianna Piskorz, Cristina Pinneri, Alvaro Correia, Motasem Alfarra, Risheek Garrepalli, Christos Louizos</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 揭示扩散语言模型中掩码干扰上下文理解的问题，提出mask-agnostic损失函数减少掩码负面影响，实验验证其提升模型上下文鲁棒性，为扩散LM训练优化提供新方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21338' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Escaping the Verifier: Learning to Reason via Demonstrations</h3>
<p><strong>Authors:</strong> Locke Cai, Ivan Provilkov</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出RARO方法通过逆强化学习从演示中学习推理，无需任务特定验证器，对大模型的推理能力学习有创新贡献。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21667' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Minimizing Hyperbolic Embedding Distortion with LLM-Guided Hierarchy Restructuring</h3>
<p><strong>Authors:</strong> Melika Ayoughi, Pascal Mettes, Paul Groth</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出LLM引导的层次结构重构方法优化双曲嵌入，结合prompt工程与已知嵌入 desiderata，对大模型在知识图谱嵌入中的应用有创新。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.20679' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> On the Limits of Innate Planning in Large Language Models</h3>
<p><strong>Authors:</strong> Charles Schepanowski, Charles Ling</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 分析LLM在8-puzzle任务中的规划能力限制，揭示状态表示与启发式规划的缺陷，对大模型的规划能力研究有重要意义。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21591' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> LongVT: Incentivizing "Thinking with Long Videos" via Native Tool Calling</h3>
<p><strong>Authors:</strong> Zuhao Yang, Sudong Wang, Kaichen Zhang, Keming Wu, Sicong Leng, Yifan Zhang, Chengwei Qin, Shijian Lu, Xingxuan Li, Lidong Bing</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出端到端代理框架，通过工具调用解决长视频推理的幻觉问题，构建多模态推理的闭环，推动长视频理解的落地。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.20785' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MIRA: Multimodal Iterative Reasoning Agent for Image Editing</h3>
<p><strong>Authors:</strong> Ziyun Zeng, Hang Hua, Jiebo Luo</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出迭代推理代理，通过感知-推理-动作循环提升图像编辑的语义准确性，解决传统方法的语义漂移问题。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.21087' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OpenApps: Simulating Environment Variations to Measure UI-Agent Reliability</h3>
<p><strong>Authors:</strong> Karen Ullrich, Jingtong Su, Claudia Shi, Arjun Subramonian, Amir Bar, Ivan Evtimov, Nikolaos Tsilivis, Randall Balestriero, Julia Kempe, Mark Ibrahim</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 构建UI agent的可靠性评估平台，通过模拟应用界面变化分析agent性能波动，解决GUI agent的鲁棒性问题，对多模态智能体的可靠性研究有重要价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.20766' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Agentic Learner with Grow-and-Refine Multimodal Semantic Memory</h3>
<p><strong>Authors:</strong> Weihao Bo, Shan Zhang, Yanpeng Sun, Jingjing Wu, Qunyi Xie, Xiao Tan, Kunbin Chen, Wei He, Xiaofan Li, Na Zhao, Jingdong Wang, Zechao Li</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出双流多模态语义记忆框架，分别编码视觉干扰与逻辑错误，通过grow-and-refine原则提升agent的终身学习能力，对多模态智能体的记忆管理有重要价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.21678' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CANVAS: A Benchmark for Vision-Language Models on Tool-Based User Interface Design</h3>
<p><strong>Authors:</strong> Daeheon Jeong, Seoyeon Byun, Kihoon Son, Dae Hyun Kim, Juho Kim</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出首个评估工具基UI设计的基准，涉及视觉语言模型的工具调用和UI交互，为GUI Agent的研究提供重要评测依据。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.20737' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> $A^2Flow:$ Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators</h3>
<p><strong>Authors:</strong> Mingming Zhao, Xiaokang Wei, Yuanqi Shao, Kaiwen Zhou, Lin Yang, Siwei Rao, Junhui Zhan, Zhitang Chen</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出自适应抽象算子的agent工作流生成框架，通过三阶段算子提取与记忆机制提升多任务性能和资源效率，对多模态智能体的workflow自动化有重要意义。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.20693' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ENACT: Evaluating Embodied Cognition with World Modeling of Egocentric Interaction</h3>
<p><strong>Authors:</strong> Qineng Wang, Wenlong Huang, Yu Zhou, Hang Yin, Tianwei Bao, Jianwen Lyu, Weiyu Liu, Ruohan Zhang, Jiajun Wu, Li Fei-Fei, Manling Li</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 构建具身认知的评估基准，通过前向/逆世界建模任务分析VLMs的具身能力，对多模态智能体的认知研究有重要价值。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.20937' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Prune4Web: DOM Tree Pruning Programming for Web Agent</h3>
<p><strong>Authors:</strong> Jiayuan Zhang, Kaiquan Chen, Zhihao Lu, Enshen Zhou, Qian Yu, Jing Zhang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Web agent的DOM树剪枝方法，通过LLM生成可执行脚本过滤冗余节点，提升网页导航效率，对GUI agent的性能优化有重要价值。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.21398' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MADRA: Multi-Agent Debate for Risk-Aware Embodied Planning</h3>
<p><strong>Authors:</strong> Junjian Wang, Lidan Zhao, Xi Sheryl Zhang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出多agent辩论框架提升具身规划的风险感知，通过迭代 deliberation减少错误拒绝，对多模态智能体的安全规划有重要意义。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.21460' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos</h3>
<p><strong>Authors:</strong> Seungjae Lee, Yoonkyo Jung, Inkook Chun, Yao-Chih Lee, Zikui Cai, Hongjia Huang, Aayush Talreja, Tan Dat Dao, Yongyuan Liang, Jia-Bin Huang, Furong Huang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出3D trace-space统一表示与TraceGen世界模型，实现从跨 embodiment（人类、不同机器人）视频中高效学习机器人任务，结合视觉、语言、动作多模态信息，解决小数据场景下的任务适应问题，实验验证了少样本与跨模态适应的有效性，对多模态智能体的泛化与迁移研究有重要参考价值。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.21690' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> OVOD-Agent: A Markov-Bandit Framework for Proactive Visual Reasoning and Self-Evolving Detection</h3>
<p><strong>Authors:</strong> Chujie Wang, Jianyu Lu, Zhiyuan Luo, Xi Chen, Chu He</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Markov-Bandit框架的开放词汇目标检测agent，实现主动视觉推理与自我进化，对多模态智能体的开放域检测能力有提升。
Score: 6
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.21064' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> GuardTrace-VL: Detecting Unsafe Multimodel Reasoning via Iterative Safety Supervision</h3>
<p><strong>Authors:</strong> Yuxiao Xiang, Junchi Chen, Zhenchao Jin, Changtao Miao, Haojie Yuan, Qi Chu, Tao Gong, Nenghai Yu</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 构建监控Question-Thinking-Answer pipeline的安全审计器，检测多模态推理中的不安全内容，提升大模型的推理安全性。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.20994' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Are Neuro-Inspired Multi-Modal Vision-Language Models Resilient to Membership Inference Privacy Leakage?</h3>
<p><strong>Authors:</strong> David Amebley, Sayanton Dibbo</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 研究多模态视觉语言模型的成员推理隐私泄漏问题，分析神经启发模型的隐私 resilience，为多模态大模型的隐私安全提供实验依据。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.20710' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Test-Time Alignment of Text-to-Image Diffusion Models via Null-Text Embedding Optimisation</h3>
<p><strong>Authors:</strong> Taehoon Kim, Henry Gouk, Timothy Hospedales</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Null-TTA方法，通过优化无条件嵌入实现扩散模型的测试时间对齐，避免reward hack，提升大模型的对齐可靠性。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.20889' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Hui Lu, Yi Yu, Yiming Yang, Chenyu Yi, Qixin Zhang, Bingquan Shen, Alex C. Kot (Nanyang Technological University), Xudong Jiang (Nanyang Technological University)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出通用可迁移的对抗补丁框架UPA-RFAS，针对视觉-语言-动作模型（VLA），揭示机器人系统的安全风险，实验验证跨模型、跨任务的迁移性，属于大模型安全与对齐的重要研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21192' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AVFakeBench: A Comprehensive Audio-Video Forgery Detection Benchmark for AV-LMMs</h3>
<p><strong>Authors:</strong> Shuhan Xia, Peipei Li, Xuannan Liu, Dongsen Zhang, Xinyu Guo, Zekun Li</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 构建首个音视频伪造检测基准AVFakeBench，覆盖7种伪造类型与4级标注，评估11个AV-LMMs的安全性能，揭示现有模型在细粒度感知与推理上的不足，属于大模型安全与对齐的重要资源。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21251' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Generalized Design Choices for Deepfake Detectors</h3>
<p><strong>Authors:</strong> Lorenzo Pellegrini, Serafino Pandolfini, Davide Maltoni, Matteo Ferrara, Marco Prati, Marco Ramilli</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 系统研究Deepfake检测器的设计选择（如数据预处理、增强策略），提出架构无关的最佳实践，在AI-GenBench上达到SOTA，属于大模型安全与对齐的重要研究，为检测器设计提供指导。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21507' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Video Generation Models Are Good Latent Reward Models</h3>
<p><strong>Authors:</strong> Xiaoyue Mi, Wenqing Yu, Jiesong Lian, Shibo Jie, Ruizhe Zhong, Zijun Liu, Guozhen Zhang, Zixiang Zhou, Zhiyong Xu, Yuan Zhou, Qinglin Lu, Fan Tang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出潜在奖励反馈学习框架PRFL，用视频生成模型作为奖励模型，在 latent 空间优化对齐，减少内存（~50%）与时间（~40%）开销，属于大模型安全与对齐中奖励模型设计的重要研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21541' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following</h3>
<p><strong>Authors:</strong> Tianyi Xiong (University of Illinois at Urbana-Champaign), Yi Ge (University of Illinois at Urbana-Champaign), Ming Li (University of Illinois at Urbana-Champaign), Zuolong Zhang (University of Illinois at Urbana-Champaign), Pranav Kulkarni (University of Illinois at Urbana-Champaign), Kaishen Wang (University of Illinois at Urbana-Champaign), Qi He (University of Illinois at Urbana-Champaign), Zeying Zhu (University of Illinois at Urbana-Champaign), Chenxi Liu (University of Illinois at Urbana-Champaign), Ruibo Chen (University of Illinois at Urbana-Champaign), Tong Zheng (University of Illinois at Urbana-Champaign), Yanshuo Chen (University of Illinois at Urbana-Champaign), Xiyao Wang (University of Illinois at Urbana-Champaign), Renrui Zhang (University of Illinois at Urbana-Champaign), Wenhu Chen (University of Illinois at Urbana-Champaign), Heng Huang (University of Illinois at Urbana-Champaign)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Multi-Crit基准评估多模态法官的多准则遵循能力，揭示现有模型的不足，对大模型安全与对齐中的评估体系有重要意义。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21662' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy</h3>
<p><strong>Authors:</strong> Teng Hu, Zhentao Yu, Guozhen Zhang, Zihan Su, Zhengguang Zhou, Youliang Zhang, Yuan Zhou, Qinglin Lu, Ran Yi</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 针对LLM微调中安全-能力权衡的核心问题，提出RLVR方法，通过理论推导安全漂移上界并结合多 adversarial 基准实验，证明其能同时提升推理能力与保持安全护栏，为大模型安全对齐提供了有效解决方案。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.2157' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Aligning LLMs Toward Multi-Turn Conversational Outcomes Using Iterative PPO</h3>
<p><strong>Authors:</strong> Daniel R. Jiang, Jalaj Bhandari, Yukai Yang, R\'emi Munos, Tyler Lu</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出迭代PPO方法解决多轮对话LLM的对齐问题，结合多轮Q函数与离线训练稳定性，对对话式LLM的安全对齐有实际价值。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21638' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Dataset Poisoning Attacks on Behavioral Cloning Policies</h3>
<p><strong>Authors:</strong> Akansha Kalra (University of California, Berkeley), Soumil Datta (University of California, Berkeley), Ethan Gilmore (University of California, Berkeley), Duc La (University of California, Berkeley), Guanhong Tao (University of California, Berkeley), Daniel S. Brown (University of California, Berkeley)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 分析行为克隆政策的数据集投毒攻击，提出熵基测试时触发方法，对大模型安全中的鲁棒性研究有实践价值。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.20992' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Naifu Zhang, Wei Tao, Xi Xiao, Qianpu Sun, Yuxin Zheng, Wentao Mo, Peiqiang Wang, Nan Zhang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出ADVLA框架对VLA模型进行稀疏对抗攻击，降低扰动的显著性与计算成本，对大模型安全中的鲁棒性研究有实践价值。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21663' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EvilGenie: A Reward Hacking Benchmark</h3>
<p><strong>Authors:</strong> Jonathan Gabor, Jayson Lynch, Jonathan Rosenfeld</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 构建奖励 hacking基准，评估LLM通过硬编码测试用例等方式攻击奖励函数的行为，为大模型安全研究提供重要测试工具。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21654' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Towards Trustworthy Legal AI through LLM Agents and Formal Reasoning</h3>
<p><strong>Authors:</strong> Linze Chen, Yufan Cai, Zhe Hou, Jinsong Dong</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出结合LLM agent与形式验证的法律AI框架，通过 adversarial agents与SMT求解器提升可靠性与可解释性，对大模型安全与对齐的法律应用有重要价值。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21033' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Self-Transparency Failures in Expert-Persona LLMs: A Large-Scale Behavioral Audit</h3>
<p><strong>Authors:</strong> Alex Diep</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 大规模审计专家角色LLM的自我透明度，揭示训练因素对透明度的影响，对大模型的透明度与安全有重要意义。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21569' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Active Slice Discovery in Large Language Models</h3>
<p><strong>Authors:</strong> Minhui Zhang (Stanford University), Prahar Ijner (Stanford University), Yoav Wald (Stanford University), Elliot Creager (Stanford University)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出主动切片发现方法识别LLM的错误切片，用少量标注数据提高错误检测效率，对大模型安全中的鲁棒性有帮助。
Score: 6
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.20713' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Pessimistic Verification for Open Ended Math Questions</h3>
<p><strong>Authors:</strong> Yanxing Huang, Zihan Tang, Zejin Lin, Peng Li, Yang Liu</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出悲观验证方法通过多平行验证提升数学问题的解释可靠性，对大模型的推理安全有重要价值。
Score: 6
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21522' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> LLaVA-UHD v3: Progressive Visual Compression for Efficient Native-Resolution Encoding in MLLMs</h3>
<p><strong>Authors:</strong> Shichu Sun, Yichen Zhang, Haolin Song, Zonghao Guo, Chi Chen, Yidan Zhang, Yuan Yao, Zhiyuan Liu (Tsinghua University), Maosong Sun (Tsinghua University)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出渐进式视觉压缩方法，优化多模态大模型的原生分辨率视觉编码，在保持性能的同时降低计算开销（TTFT 降低2.4×），作者团队来自清华大学（Zhiyuan Liu、Maosong Sun），研究结果对原生多模态大模型的视觉模块优化具有关键价值。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21150' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Monet: Reasoning in Latent Visual Space Beyond Images and Language</h3>
<p><strong>Authors:</strong> Qixun Wang, Yang Shi, Yifei Wang, Yuanxing Zhang, Pengfei Wan, Kun Gai, Xianghua Ying, Yisen Wang (Shanghai Jiao Tong University)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出训练框架让多模态大模型在潜在视觉空间推理，构建125K文本-图像 interleaved CoT数据集，提升视觉推理性能（如几何问题解决），作者团队包括上海交通大学的Yisen Wang，研究结果对原生多模态大模型的推理能力提升具有重要价值。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21395' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Qwen3-VL Technical Report</h3>
<p><strong>Authors:</strong> Shuai Bai (Alibaba Group), Yuxuan Cai (Alibaba Group), Ruizhe Chen (Alibaba Group), Keqin Chen (Alibaba Group), Xionghui Chen (Alibaba Group), Zesen Cheng (Alibaba Group), Lianghao Deng (Alibaba Group), Wei Ding (Alibaba Group), Chang Gao (Alibaba Group), Chunjiang Ge (Alibaba Group), Wenbin Ge (Alibaba Group), Zhifang Guo (Alibaba Group), Qidong Huang (Alibaba Group), Jie Huang (Alibaba Group), Fei Huang (Alibaba Group), Binyuan Hui (Alibaba Group), Shutong Jiang (Alibaba Group), Zhaohai Li (Alibaba Group), Mingsheng Li (Alibaba Group), Mei Li (Alibaba Group), Kaixin Li (Alibaba Group), Zicheng Lin (Alibaba Group), Junyang Lin (Alibaba Group), Xuejing Liu (Alibaba Group), Jiawei Liu (Alibaba Group), Chenglong Liu (Alibaba Group), Yang Liu (Alibaba Group), Dayiheng Liu (Alibaba Group), Shixuan Liu (Alibaba Group), Dunjie Lu (Alibaba Group), Ruilin Luo (Alibaba Group), Chenxu Lv (Alibaba Group), Rui Men (Alibaba Group), Lingchen Meng (Alibaba Group), Xuancheng Ren (Alibaba Group), Xingzhang Ren (Alibaba Group), Sibo Song (Alibaba Group), Yuchong Sun (Alibaba Group), Jun Tang (Alibaba Group), Jianhong Tu (Alibaba Group), Jianqiang Wan (Alibaba Group), Peng Wang (Alibaba Group), Pengfei Wang (Alibaba Group), Qiuyue Wang (Alibaba Group), Yuxuan Wang (Alibaba Group), Tianbao Xie (Alibaba Group), Yiheng Xu (Alibaba Group), Haiyang Xu (Alibaba Group), Jin Xu (Alibaba Group), Zhibo Yang (Alibaba Group), Mingkun Yang (Alibaba Group), Jianxin Yang (Alibaba Group), An Yang (Alibaba Group), Bowen Yu (Alibaba Group), Fei Zhang (Alibaba Group), Hang Zhang (Alibaba Group), Xi Zhang (Alibaba Group), Bo Zheng (Alibaba Group), Humen Zhong (Alibaba Group), Jingren Zhou (Alibaba Group), Fan Zhou (Alibaba Group), Jing Zhou (Alibaba Group), Yuanzhi Zhu (Alibaba Group), Ke Zhu (Alibaba Group)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 介绍Qwen3-VL原生多模态大模型，支持256K长上下文多模态推理，在MMMU等基准上表现优异，对原生多模态大模型的架构设计与应用有重要参考价值。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21631' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Text-Guided Semantic Image Encoder</h3>
<p><strong>Authors:</strong> Raghuveer Thirukovalluru, Xiaochuang Han, Bhuwan Dhingra, Emily Dinan, Maha Elbayad</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出文本引导的语义图像编码器，通过文本条件优化视觉表示，提升VLMs的任务性能和推理效率，改进多模态大模型的核心组件。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.20770' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Knowledge Completes the Vision: A Multimodal Entity-aware Retrieval-Augmented Generation Framework for News Image Captioning</h3>
<p><strong>Authors:</strong> Xiaoxing You, Qiang Huang, Lingyu Li, Chi Zhang, Xiaopeng Liu, Min Zhang, Jun Yu</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出MERGE框架，融合文本、视觉与结构化知识，提升新闻图像caption的质量与实体准确性，推动多模态生成的知识融合。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21002' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CameraMaster: Unified Camera Semantic-Parameter Control for Photography Retouching</h3>
<p><strong>Authors:</strong> Qirui Yang, Yang Yang, Ying Zeng, Xiaobin Hu, Bo Li, Huanjing Yue, Jingyu Yang, Peng-Tao Jiang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出统一框架，结合文本指令与相机参数，实现物理一致的摄影修图，提升多模态大模型的参数控制能力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21024' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MUSE: Manipulating Unified Framework for Synthesizing Emotions in Images via Test-Time Optimization</h3>
<p><strong>Authors:</strong> Yingjie Xia, Xi Wang, Jinglei Shi, Vicky Kalogeiton, Jian Yang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出统一框架，支持图像情感的生成与编辑，通过test-time优化提升情感准确性与内容一致性，推动多模态情感合成的落地。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21051' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CtrlVDiff: Controllable Video Generation via Unified Multimodal Video Diffusion</h3>
<p><strong>Authors:</strong> Dianbing Xi, Jiepeng Wang, Yuanzhi Liang, Xi Qiu, Jialun Liu, Hao Pan, Yuchi Huo, Rui Wang, Haibin Huang, Chi Zhang, Xuelong Li</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出统一多模态扩散模型，融合深度、法线、语义等多模态特征，支持可控视频生成与编辑，构建大规模多模态数据集MMVideo，实验验证在理解与生成任务上的优异性，属于原生多模态大模型的重要进展。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21129' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Thinking With Bounding Boxes: Enhancing Spatio-Temporal Video Grounding via Reinforcement Fine-Tuning</h3>
<p><strong>Authors:</strong> Xin Gu, Haoji Zhang, Qihang Fan, Jingxuan Niu, Zhipeng Zhang, Libo Zhang, Guang Chen, Fan Chen, Longyin Wen, Sijie Zhu</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出边界框链式思考机制，通过强化学习微调多模态大模型，提升时空视频接地（STVG）性能，在HCSTVG-v1上超越SOTA 7.3% m_tIoU，属于原生多模态大模型下游任务优化的关键研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21375' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning</h3>
<p><strong>Authors:</strong> Wenbo Hu, Jingli Lin, Yilin Long, Yunlong Ran, Lihan Jiang, Yifan Wang, Chenming Zhu, Runsen Xu, Tai Wang, Jiangmiao Pang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出G²VLM将3D重建与空间推理融入视觉语言模型，提高空间智能，对原生多模态大模型的空间理解能力有贡献。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21688' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SpatialBench: Benchmarking Multimodal Large Language Models for Spatial Cognition</h3>
<p><strong>Authors:</strong> Peiran Xu, Sudong Wang, Yao Zhu, Jianing Li, Yunjian Zhang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 构建多模态大模型的空间认知基准，分解为五个层次的空间能力，对原生多模态大模型的空间推理优化有参考价值。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21471' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Revisiting KRISP: A Lightweight Reproduction and Analysis of Knowledge-Enhanced Vision-Language Models</h3>
<p><strong>Authors:</strong> Souradeep Dutta, Keshav Bulia, Neena S Nair</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 复现并分析知识增强的视觉语言模型KRISP，指出设计缺陷并优化轻量级部署，为知识增强VLMs的研究提供实践参考。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.20795' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SPHINX: A Synthetic Environment for Visual Perception and Reasoning</h3>
<p><strong>Authors:</strong> Md Tanvirul Alam, Saksham Aggarwal, Justin Yang Chae, Nidhi Rastogi</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 构建合成视觉推理环境，评估大视觉语言模型的认知能力，为多模态大模型的推理性能提供精准评测。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.20814' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CaptionQA: Is Your Caption as Useful as the Image Itself?</h3>
<p><strong>Authors:</strong> Shijia Yang, Yunong Liu, Bohan Zhai, Ximeng Sun, Zicheng Liu, Emad Barsoum, Manling Li, Chenfeng Xu</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出效用-based基准，评估caption在下游任务的可用性，为多模态大模型的caption质量提供精准评测。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21025' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding</h3>
<p><strong>Authors:</strong> Yutao Tang, Cheng Zhao, Gaurav Mittal, Rohith Kukkala, Rama Chellappa (Johns Hopkins University), Cheng Peng, Mei Chen</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出多尺度正态分布变换tokenizer，用于3D视觉语言模型的场景编码，支持多种3D场景理解任务（如 referring segmentation、VQA），属于原生多模态大模型中3D tokenizer的创新研究，实验表现优于现有方法。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21191' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The More, the Merrier: Contrastive Fusion for Higher-Order Multimodal Alignment</h3>
<p><strong>Authors:</strong> Stefanos Koutoupis, Michaela Areti Zervou, Konstantinos Kontras, Maarten De Vos, Panagiotis Tsakalides, Grigorios Tsagatakis</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出对比融合框架ConFu，捕捉多模态的高阶依赖关系，同时保持pairwise对齐，支持单模态与多模态检索任务，属于原生多模态大模型中对齐机制的重要研究，实验验证在多个基准上的优异性。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21331' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FANoise: Singular Value-Adaptive Noise Modulation for Robust Multimodal Representation Learning</h3>
<p><strong>Authors:</strong> Jiaoyang Li, Jun Fang, Tianhao Gao, Xiaohui Zhang, Zhiyuan Liu, Chao Liu, Pengzhang Liu, Qixia Jiang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出FANoise策略自适应调制噪声，提高多模态表示的鲁棒性，对原生多模态大模型的表示学习有帮助。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.20997' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Canvas-to-Image: Compositional Image Generation with Multimodal Controls</h3>
<p><strong>Authors:</strong> Yusuf Dalva, Guocheng Gordon Qian, Maya Goldenberg, Tsai-Shien Chen, Kfir Aberman, Sergey Tulyakov, Pinar Yanardag, Kuan-Chieh Jackson Wang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Canvas-to-Image框架整合多模态控制生成图像，提高控制精度与身份保留，对多模态图像生成有实用价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21691' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Cross Domain Evaluation of Multimodal Chain-of-Thought Reasoning of different datasets into the Amazon CoT Framework</h3>
<p><strong>Authors:</strong> Nitya Tiwari, Parv Maheshwari, Vidisha Agarwal</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 评估多模态CoT在A-OKVQA、OKVQA等跨域任务的性能，分析视觉特征与推理质量的影响，对原生多模态大模型的推理能力优化有参考价值。
Score: 6
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.20701' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> On the Origin of Algorithmic Progress in AI</h3>
<p><strong>Authors:</strong> Hans Gundlach, Alex Fogelson, Jayson Lynch, Ana Trisovic, Jonathan Rosenfeld, Anmol Sandhu, Neil Thompson</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 系统分析2012-2023年AI算法进步来源，通过缩放实验发现算法效率提升与计算规模强相关（如LSTM到Transformer的转换），挑战了传统算法进步衡量方式，为深度学习理论中的算法-规模关系提供关键见解。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21622' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Intriguing Properties of Dynamic Sampling Networks</h3>
<p><strong>Authors:</strong> Dario Morle, Reid Zaffino</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 分析动态采样网络的理论特性，提出统一warping算子，揭示动态采样与传统卷积的正交性，推动深度学习理论的完善。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20800' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Smooth regularization for efficient video recognition</h3>
<p><strong>Authors:</strong> Gil Goldman, Raja Giryes, Mahadev Satyanarayanan</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出高斯随机游走平滑正则化，增强轻量级视频模型的时间 inductive bias，提升视频识别效率与性能。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20928' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MetaRank: Task-Aware Metric Selection for Model Transferability Estimation</h3>
<p><strong>Authors:</strong> Yuhang Liu, Wenjie Zhao, Yunhui Guo</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出元学习框架自动选择模型迁移性估计的metric，解决task-dependent的metric选择问题，提升迁移学习的效率。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21007' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AnchorOPT: Towards Optimizing Dynamic Anchors for Adaptive Prompt Learning</h3>
<p><strong>Authors:</strong> Zheng Li, Yibing Song, Xin Zhang, Lei Luo, Xiang Li, Jian Yang (Nanjing University of Science and Technology)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出动态锚点优化框架，通过学习数据驱动的锚点值与自适应位置矩阵，改进CLIP的prompt learning效果，解决静态锚点的局限性，属于深度学习理论中优化器方向的重要研究，实验验证在多个数据集上的性能提升。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21188' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> On the Role of Hidden States of Modern Hopfield Network in Transformer</h3>
<p><strong>Authors:</strong> Tsubasa Masumura (University of Tokyo), Masato Taki (University of Tokyo)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 深入分析现代Hopfield网络与Transformer的关系，提出MHN注意力机制改善Transformer的rank collapse和token uniformity问题，对网络架构设计有理论贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20698' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Gradient Descent Algorithm Survey</h3>
<p><strong>Authors:</strong> Deng Fucheng, Wang Wanjie, Gong Ao, Wang Xiaoqi, Wang Fan</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 系统综述SGD、Momentum、Adam等梯度下降算法的核心原理、优缺点及实践建议，对深度学习理论中的优化器研究有重要参考价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20725' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Gated KalmaNet: A Fading Memory Layer Through Test-Time Ridge Regression</h3>
<p><strong>Authors:</strong> Liangzu Peng (University of California, Los Angeles), Aditya Chattopadhyay (University of California, Los Angeles), Luca Zancato (University of California, Los Angeles), Elvis Nunez (University of California, Los Angeles), Wei Xia (University of California, Los Angeles), Stefano Soatto (University of California, Los Angeles)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Gated KalmaNet层通过在线ridge回归实现长上下文记忆，解决SSM的记忆损失问题，对网络架构设计有创新。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21016' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> G-Net: A Provably Easy Construction of High-Accuracy Random Binary Neural Networks</h3>
<p><strong>Authors:</strong> Alireza Aghasi, Nicholas Marshall, Saeid Pourmand, Wyatt Whiting</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 基于超维计算提出随机二进制神经网络G-Net，通过理论证明其能保持浮点网络精度，实验显示在CIFAR-10上精度远超现有HDC模型，为二进制网络设计提供了理论支撑与高效构造方法。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21063' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SUPN: Shallow Universal Polynomial Networks</h3>
<p><strong>Authors:</strong> Zachary Morrow, Michael Penwarden, Brian Chen, Aurya Javeed, Akil Narayan, John D. Jakeman</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出浅层通用多项式网络SUPN，理论证明其收敛率与最优多项式近似一致，实验显示低参数下近似误差与变异性优于DNN/KAN，为网络结构设计提供新方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21414' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Scale-Agnostic Kolmogorov-Arnold Geometry in Neural Networks</h3>
<p><strong>Authors:</strong> Mathew Vanherreweghe, Michael H. Freedman, Keith M. Adams</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 研究神经网络训练中自发形成的柯尔莫哥洛夫-阿诺德几何结构，揭示其在高维数据上的尺度不变性，对深度学习理论中网络架构与学习过程的几何机制有重要启发。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21626' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GaINeR: Geometry-Aware Implicit Network Representation</h3>
<p><strong>Authors:</strong> Weronika Jakubowska, Mikołaj Zieliński, Rafał Tobiasz, Krzysztof Byrski, Maciej Zięba, Dominik Belter, Przemysław Spurek</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 结合高斯分布与隐式神经表示，提出几何感知的图像表示框架，支持局部编辑和物理交互，推动INR的几何特性研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20924' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ST-PPO: Stabilized Off-Policy Proximal Policy Optimization for Multi-Turn Agents Training</h3>
<p><strong>Authors:</strong> Chenliang Li, Adel Elmahdy, Alex Boyd, Zhongruo Wang, Alfredo Garcia, Parminder Bhatia, Taha Kass-Hout, Cao Xiao (Google), Mingyi Hong (University of Minnesota)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出ST-PPO优化器解决多轮对话中PPO训练的不稳定性问题，改进token-level采样与优势估计，对优化器设计有实践意义。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20718' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Effects of Initialization Biases on Deep Neural Network Training Dynamics</h3>
<p><strong>Authors:</strong> Nicholas Pellegrino (University of Waterloo), David Szczecina (University of Waterloo), Paul W. Fieguth (University of Waterloo)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 分析初始化偏差对DNN训练动态的影响，探讨损失函数与初始化偏差的交互作用，对深度学习理论中的训练动力学研究有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20826' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Primal: A Unified Deterministic Framework for Quasi-Orthogonal Hashing and Manifold Learning</h3>
<p><strong>Authors:</strong> Vladimer Khasia</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Primal框架实现确定性特征映射，改善哈希与流形学习的正交性及分布紧凑性，对特征表示学习有理论意义。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.20839' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Controlling changes to attention logits</h3>
<p><strong>Authors:</strong> Ben Anson, Laurence Aitchison</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 针对Transformer查询/键权重的稳定性问题，提出参数依赖学习率控制注意力logits变化，实验证明提升训练稳定性与性能，为注意力机制优化提供新方法。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21377' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mechanisms of Non-Monotonic Scaling in Vision Transformers</h3>
<p><strong>Authors:</strong> Anantha Padmanaban Krishna Kumar (Boston University)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 分析视觉Transformer深度缩放的非单调现象，揭示表示演化的三阶段模式及[CLS] token的边缘化机制，对优化Transformer架构设计有重要意义。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21635' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Shift-Equivariant Complex-Valued Convolutional Neural Networks</h3>
<p><strong>Authors:</strong> Quentin Gabot, Teck-Yian Lim, Jérémie Fix, Joana Frontera-Pons, Chengfang Ren, Jean-Philippe Ovarlez</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出位移等变的复值卷积神经网络，改进传统CNN的位移不变性问题，通过复值运算与可学习多相采样实现等变，实验在极化SAR图像任务上验证有效，属于深度学习理论中网络架构的创新研究。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21250' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Representation Interventions Enable Lifelong Unstructured Knowledge Control</h3>
<p><strong>Authors:</strong> Xuyuan Liu, Zhengzhang Chen, Xinshuai Dong, Yanchi Liu, Xujiang Zhao, Shengyu Chen, Haoyu Wang, Yujun Yan, Haifeng Chen</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出表示干预方法实现LLM的终身知识更新，通过低维子空间干预避免重训练与跨编辑干扰，对高效大模型知识管理有重要贡献。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.20892' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Foundry: Distilling 3D Foundation Models for the Edge</h3>
<p><strong>Authors:</strong> Guillaume Letellier (IIT Delhi), Siddharth Srivastava (IIT Delhi), Frédéric Jurie (IIT Kanpur), Gaurav Sharma (IIT Kanpur)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Foundation Model Distillation范式，将3D基础模型蒸馏为紧凑代理模型，保持通用性并支持边缘部署，属于大模型压缩的重要探索。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.20721' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EM-KD: Distilling Efficient Multimodal Large Language Model with Unbalanced Vision Tokens</h3>
<p><strong>Authors:</strong> Ze Feng, Sen Yang, Boqiang Duan, Wankou Yang, Jingdong Wang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 针对多模态大模型的知识蒸馏问题，提出解决视觉token不平衡的对齐策略与双蒸馏模块，有效提升高效多模态大模型的精度与效率，属于高效大模型训练与推理的重要研究，作者团队具有行业影响力。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21106' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MobileI2V: Fast and High-Resolution Image-to-Video on Mobile Devices</h3>
<p><strong>Authors:</strong> Shuai Zhang, Bao Tang, Siyuan Yu, Yueting Zhu, Jingfeng Yao, Ya Zou, Shanglin Yuan, Li Yu, Wenyu Liu (Huazhong University of Science and Technology), Xinggang Wang (Huazhong University of Science and Technology)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出轻量扩散模型MobileI2V，实现移动设备上的快速720p图像到视频生成（每帧<100ms），通过线性混合架构与时间步蒸馏提升效率，属于高效大模型推理在移动场景的重要应用。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21475' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MLPMoE: Zero-Shot Architectural Metamorphosis of Dense LLM MLPs into Static Mixture-of-Experts</h3>
<p><strong>Authors:</strong> Ivan Novikov</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出零-shot将LLM密集MLP转换为静态MoE的方法，无需训练即可保持性能，通过结构化稀疏减少计算开销，有效提升了LLM推理效率，为高效大模型部署提供了新思路。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21089' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> IntAttention: A Fully Integer Attention Pipeline for Efficient Edge Inference</h3>
<p><strong>Authors:</strong> Wanli Zhong, Haibo Feng, Zirui Zhou, Hanyang Peng, Shiqi Yu</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 针对Transformer边缘推理的softmax浮点瓶颈，提出全整数注意力流水线，通过IndexSoftmax消除浮点操作，实现端到端整数数据流，显著提升边缘设备推理效率且无需重训练。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21513' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DSD: A Distributed Speculative Decoding Solution for Edge-Cloud Agile Large Model Serving</h3>
<p><strong>Authors:</strong> Fengze Yu, Leshu Li, Brad McDanel, Saiqian Zhang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出分布式推测解码框架，通过边缘-云协同与自适应窗口控制提升LLM推理的延迟和吞吐量，对高效大模型推理的边缘场景应用有实际贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21669' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Which Layer Causes Distribution Deviation? Entropy-Guided Adaptive Pruning for Diffusion and Flow Models</h3>
<p><strong>Authors:</strong> Changlin Li, Jiawei Zhang, Zeyi Shi, Zongxin Yang, Zhihui Li, Xiaojun Chang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出熵引导的自适应剪枝框架，针对扩散与流模型的参数冗余问题，通过条件熵偏差 metric 优先剪枝不重要模块，实现推理加速同时保持生成质量，属于高效大模型推理的关键技术。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21122' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Efficient Training for Human Video Generation with Entropy-Guided Prioritized Progressive Learning</h3>
<p><strong>Authors:</strong> Changlin Li, Jiawei Zhang, Shuhao Liu, Sihao Lin, Zeyi Shi, Zhihui Li, Xiaojun Chang</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出熵引导的优先渐进学习框架，通过条件熵膨胀评估模型组件重要性，自适应调整训练复杂度，实现人类视频生成的训练加速（2.2×）与内存 reduction（2.4×），属于高效大模型训练的核心研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21136' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Do Reasoning Vision-Language Models Inversely Scale in Test-Time Compute? A Distractor-centric Empirical Analysis</h3>
<p><strong>Authors:</strong> Jiyun Bae, Hyunjong Ok, Sangwoo Mo, Jaeho Lee</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 系统分析视觉语言模型的测试时缩放与干扰项影响，揭示视觉干扰项与文本干扰项的差异（如不增加推理长度但降低 accuracy），属于高效大模型推理的实证研究，为测试时策略优化提供指导。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21397' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CanKD: Cross-Attention-based Non-local operation for Feature-based Knowledge Distillation</h3>
<p><strong>Authors:</strong> Shizhe Sun, Wataru Ohyama</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出跨注意力的非局部知识蒸馏框架，通过跨模态注意力捕捉特征依赖，提升学生模型的特征表示能力，实验在目标检测（如COCO）与分割（如Cityscapes）上表现优异，属于高效大模型训练的关键技术。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21503' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Post-Pruning Accuracy Recovery via Data-Free Knowledge Distillation</h3>
<p><strong>Authors:</strong> Chinmay Tripurwar, Utkarsh Maurya, Dishant</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出无数据知识蒸馏方法恢复模型剪枝后的精度，解决隐私敏感场景下的模型压缩问题，对高效大模型训练有实用价值。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.20702' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Probabilistic Hash Embeddings for Online Learning of Categorical Features</h3>
<p><strong>Authors:</strong> Aodong Li, Abishek Sankararaman, Balakrishnan Narayanaswamy</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出概率哈希嵌入解决在线学习中的类别特征问题，保持内存效率与顺序无关性，对高效大模型推理有帮助。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.20893' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Unified Understanding of Offline Data Selection and Online Self-refining Generation for Post-training LLMs</h3>
<p><strong>Authors:</strong> Quan Xiao, Tianyi Chen</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 从优化角度统一LLM后训练的离线数据选择与在线自精炼生成，理论证明双级数据选择有效性，实验验证其在质量提升与安全微调中的效果，为高效训练提供了统一框架。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21056' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Subjective Depth and Timescale Transformers: Learning Where and When to Compute</h3>
<p><strong>Authors:</strong> Frederico Wieser, Martin Benfeghoul, Haitham Bou Ammar, Jun Wang, Zafeirios Fountas</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出SDT/STT结构通过贝叶斯 surprise信号动态路由计算，减少自注意力计算（75%）与KV缓存需求（50%），有效提升Transformer推理效率。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21408' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning When to Stop: Adaptive Latent Reasoning via Reinforcement Learning</h3>
<p><strong>Authors:</strong> Alex Ning, Yen-Ling Kuo, Gabe Gomes</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出自适应长度潜在推理模型，通过强化学习优化推理长度，在保持精度的同时减少52%推理长度，有效提升LLM推理效率。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21581' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Pre-train to Gain: Robust Learning Without Clean Labels</h3>
<p><strong>Authors:</strong> David Szczecina (University of Waterloo), Nicholas Pellegrino (University of Waterloo), Paul W. Fieguth (University of Waterloo)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 通过自监督预训练提高带噪声标签模型的鲁棒性，无需干净数据，对高效大模型训练有实用价值。
Score: 6
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.20844' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Staggered Environment Resets Improve Massively Parallel On-Policy Reinforcement Learning</h3>
<p><strong>Authors:</strong> Sid Bharthulwar (University of California, San Diego), Stone Tao (University of California, San Diego), Hao Su (University of California, San Diego)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出交错环境重置提高并行RL训练的稳定性与样本效率，对高效大模型训练有实践价值。
Score: 6
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.21011' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Causality Without Causal Models</h3>
<p><strong>Authors:</strong> Joseph Y. Halpern (Cornell University), Rafael Pass (Cornell University)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出不依赖因果模型的因果性抽象定义，扩展因果解释至包含嵌套反事实与信念的场景，对深度学习可解释性的因果理论有重要贡献。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.21260' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Open Vocabulary Compositional Explanations for Neuron Alignment</h3>
<p><strong>Authors:</strong> Biagio La Rosa, Leilani H. Gilpin</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出开放词汇的组合解释框架，支持任意概念的神经元对齐解释，解决传统方法依赖人工标注的局限性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.20931' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Physics Steering: Causal Control of Cross-Domain Concepts in a Physics Foundation Model</h3>
<p><strong>Authors:</strong> Rio Alexa Fear (University of Cambridge), Payel Mukhopadhyay (University of Cambridge), Michael McCabe (University of Cambridge), Alberto Bietti (University of Cambridge), Miles Cranmer (University of Cambridge)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 研究物理基础模型的内部表示，通过因果控制操纵跨域物理概念，对可解释性中的mechanistic interpretability有理论价值。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.20798' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Operationalizing Quantized Disentanglement</h3>
<p><strong>Authors:</strong> Vitoria Barin-Pacela (Mila), Kartik Ahuja (Mila), Simon Lacoste-Julien (Mila), Pascal Vincent (Mila)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出Cliff方法通过轴对齐不连续性实现无监督解纠缠，提高解纠缠表示质量，对可解释性中的disentanglement研究有推进作用。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.20927' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Directed Prediction Change - Efficient and Trustworthy Fidelity Assessment for Local Feature Attribution Methods</h3>
<p><strong>Authors:</strong> Kevin Iselborn, David Dembinsky, Adriano Lucieri, Andreas Dengel</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 针对现有局部特征归因保真度评估的计算低效与随机性问题，提出DPC指标，通过整合扰动与归因方向实现近10倍速度提升及确定性结果，为可解释性评估提供了更可靠工具。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.21363' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Guaranteed Optimal Compositional Explanations for Neurons</h3>
<p><strong>Authors:</strong> Biagio La Rosa, Leilani H. Gilpin</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出神经元的最优组合解释框架，通过分解空间对齐因素与启发式搜索实现理论最优解释，解决现有方法的次优问题，对深度学习可解释性的理论与实践有重要意义。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.20934' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CHiQPM: Calibrated Hierarchical Interpretable Image Classification</h3>
<p><strong>Authors:</strong> Thomas Norrenbrock (University of Maryland), Timo Kaiser (University of Maryland), Sovan Biswas (University of Maryland), Neslihan Kose (University of Maryland), Ramesh Manuvinakurike (University of Maryland), Bodo Rosenhahn (University of Maryland)</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出CHiQPM框架实现分层可解释性与conformal预测，在保持精度的同时提高模型可解释性，对可解释性研究有实践贡献。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.20779' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling</h3>
<p><strong>Authors:</strong> Peter S. Hovmand, Kari O'Donnell, Callie Ogland-Hand, Brian Biroscak, Douglas D. Gunzler</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 提出比较因果模型的框架，结合系统动力学与结构方程模型，对深度学习可解释性的因果分析有重要贡献。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.21636' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Improving Procedural Skill Explanations via Constrained Generation: A Symbolic-LLM Hybrid Architecture</h3>
<p><strong>Authors:</strong> Rahul Dass, Thomas Bowlin, Zebing Li, Xiao Jin, Ashok Goel</p>
<p><strong>Published:</strong> 2025-11-27</p>
<p><strong>Reason:</strong> 结合符号Task-Method-Knowledge模型与LLM生成结构化技能解释，提升解释的因果与目标导向逻辑，对深度学习可解释性的教育应用有重要意义。
Score: 6
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.20942' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>