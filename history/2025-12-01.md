# ArXiv 每日推荐 - 2025-12-01

> 更新于北京时间：2025-12-01 17:32:21
> 已自动阅读了 431 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：222906

## 大模型新技术

### [Score: 9.0/10] Saddle-Free Guidance: Improved On-Manifold Sampling without Labels or Additional Training
- **Authors:** Eric Yeats, Darryl Hannan, Wilson Fearn, Timothy Doster, Henry Kvinge, Scott Mahan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21863](https://arxiv.org/abs/2511.21863)
- **Reason:** 提出无需额外训练或标签的扩散模型引导方法SFG，利用对数密度正曲率提升采样质量，实验验证在ImageNet-512生成上优于CFG和Auto-Guidance，对扩散模型的高效采样研究有突破性贡献
Score: 9
Field: 大模型新技术

### [Score: 8.5/10] Toward Diffusible High-Dimensional Latent Spaces: A Frequency Perspective
- **Authors:** Bolin Lai, Xudong Wang, Saketh Rambhatla, James M. Rehg, Zsolt Kira, Rohit Girdhar, Ishan Misra
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22249](https://arxiv.org/abs/2511.22249)
- **Reason:** 分析高维自动编码器下扩散模型生成质量下降的根源为高频信息编码不足，提出FreqWarm频率预热策略，增强扩散训练中高频latent信号的早期暴露，显著提升多类高维latent空间的生成质量（如Wan2.2-VAE的gFID下降14.11），为高维latent扩散提供通用解决方案。
Score: 8.5
Field: 大模型新技术

### [Score: 8.0/10] Flowing Backwards: Improving Normalizing Flows via Reverse Representation Alignment
- **Authors:** Yang Chen, Xiaowei Xu, Shuai Wang, Chenhui Zhu, Ruxue Wen, Xubin Li, Tiezheng Ge, Limin Wang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22345](https://arxiv.org/abs/2511.22345)
- **Reason:** 针对归一化流因对数似然优化导致语义表示差的问题，利用其可逆性对齐反向生成pass的中间特征与视觉基础模型表示，提出训练-free测试时优化算法，加速训练3.3倍并提升生成质量与分类准确性，刷新ImageNet 64×64/256×256上归一化流的state-of-the-art。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield
- **Authors:** Dongyang Liu, Peng Gao, David Liu, Ruoyi Du, Zhen Li, Qilong Wu, Xin Jin, Sihan Cao, Shifeng Zhang, Hongsheng Li (The University of Hong Kong), Steven Hoi (ByteDance)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22677](https://arxiv.org/abs/2511.22677)
- **Reason:** 深入分析扩散模型蒸馏（DMD）的核心机制，揭示CFG Augmentation是蒸馏的核心“引擎”、Distribution Matching是“正则器”，提出解耦策略提升few-step生成性能，被Z-Image项目采用验证，对大模型新技术中的扩散模型高效训练有重要贡献。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] BlockVid: Block Diffusion for High-Quality and Consistent Minute-Long Video Generation
- **Authors:** Zeyu Zhang, Shuning Chang, Yuanyu He, Yizeng Han, Jiasheng Tang, Fan Wang, Bohan Zhuang (Alibaba DAMO Academy)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22973](https://arxiv.org/abs/2511.22973)
- **Reason:** 提出Block Diffusion框架，结合扩散模型的生成质量与自回归模型的长序列建模优势，通过语义感知稀疏KV缓存、Block Forcing训练等策略解决长视频生成的误差累积与一致性问题，实现分钟级高质量视频生成，对大模型新技术中的扩散视频生成有重要突破。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Flow Straighter and Faster: Efficient One-Step Generative Modeling via MeanFlow on Rectified Trajectories
- **Authors:** Xinxi Zhang, Shiwei Tan, Quang Nguyen, Quan Dao, Ligong Han, Xiaoxiao He, Tunyu Zhang, Alen Mrdovic, Dimitris Metaxas
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23342](https://arxiv.org/abs/2511.23342)
- **Reason:** 提出Rectified MeanFlow框架实现高效单步流模型生成，提升流模型的训练效率和样本质量，属于大模型新技术和高效大模型训练与推理方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Adversarial Flow Models
- **Authors:** Shanchuan Lin, Ceyuan Yang, Zhijie Lin, Hao Chen, Haoqi Fan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22475](https://arxiv.org/abs/2511.22475)
- **Reason:** 统一对抗模型与流模型的生成方法，稳定训练并提升生成性能，属于大模型新技术的创新探索。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Test-time scaling of diffusions with flow maps
- **Authors:** Amirmojtaba Sabour, Michael S. Albergo, Carles Domingo-Enrich, Nicholas M. Boffi, Sanja Fidler, Karsten Kreis, Eric Vanden-Eijnden
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22688](https://arxiv.org/abs/2511.22688)
- **Reason:** 提出FMTT方法用流图改善扩散模型的测试时优化，提升奖励导向的生成质量，属于大模型新技术的重要应用。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] ThetaEvolve: Test-time Learning on Open Problems
- **Authors:** Yiping Wang, Shao-Rong Su, Zhiyuan Zeng, Eva Xu, Liliang Ren, Xinyu Yang, Zeyi Huang, Xuehai He, Luyao Ma, Baolin Peng, Hao Cheng, Pengcheng He, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23473](https://arxiv.org/abs/2511.23473)
- **Reason:** 提出ThetaEvolve框架，支持测试时的上下文学习和强化学习，使小模型能解决开放优化问题并不断学习，为大模型的测试时学习提供了开源解决方案。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent
- **Authors:** Jianzhe Lin (Unknown), Zeyu Pan (Unknown), Yun Zhu (Unknown), Ruiqi Song (Unknown), Jining Yang (Unknown)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23436](https://arxiv.org/abs/2511.23436)
- **Reason:** 提出SuperIntelliAgent框架，通过小扩散模型（learner）与冻结大模型（verifier）的自监督交互，结合双尺度记忆（短期推理轨迹、长期知识整合）和回放缓冲，实现了大模型的持续智能增长，为大模型的 lifelong学习提供了新范式。
Score: 8
Field: 大模型新技术

### [Score: 7.5/10] Prompted Policy Search: Reinforcement Learning through Linguistic and Numerical Reasoning in LLMs
- **Authors:** Yifan Zhou, Sachin Grover, Mohamed El Mistiri, Kamalesh Kalirathnam, Pratyush Kerhalkar, Swaroop Mishra, Neelesh Kumar, Sanket Gaurav, Oya Aran, Heni Ben Amor
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21928](https://arxiv.org/abs/2511.21928)
- **Reason:** 提出ProPS框架，将LLM置于强化学习策略优化中心，结合语言与数值推理提升样本效率与性能，属于大模型新技术在RL中的应用
Score: 7.5
Field: 大模型新技术

### [Score: 7.0/10] Guiding Visual Autoregressive Models through Spectrum Weakening
- **Authors:** Chaoyang Wang, Tianmeng Yang, Jingdong Wang, Yunhai Tong (Microsoft Research Asia)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22991](https://arxiv.org/abs/2511.22991)
- **Reason:** 提出频谱弱化框架，通过在光谱域构造可控弱模型，实现对视觉自回归模型的生成引导（无需重新训练），提升生成质量与条件对齐（如文本/类别条件），解决了自回归模型难以灵活引导的问题，对大模型新技术中的自回归模型优化有创新贡献。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] NumeriKontrol: Adding Numeric Control to Diffusion Transformers for Instruction-based Image Editing
- **Authors:** Zhenyu Xu, Xiaoqi Shen, Haotian Nan, Xinyu Zhang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23105](https://arxiv.org/abs/2511.23105)
- **Reason:** 提出NumeriKontrol框架为扩散Transformer添加数值控制以实现细粒度图像编辑，解决文本指令无法精确控制编辑强度的问题，属于大模型新技术（扩散模型扩展）方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Vision Bridge Transformer at Scale
- **Authors:** Zhenxiong Tan, Zeqing Wang, Xingyi Yang, Songhua Liu, Xinchao Wang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23199](https://arxiv.org/abs/2511.23199)
- **Reason:** 提出大规模Vision Bridge Transformer，基于Brownian Bridge模型实现高效条件生成，解决传统扩散模型的效率问题，属于大模型新技术方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Flow Density Control: Generative Optimization Beyond Entropy-Regularized Fine-Tuning
- **Authors:** Riccardo De Santi, Marin Vlastelica, Ya-Ping Hsieh, Zebang Shen, Niao He, Andreas Krause
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22640](https://arxiv.org/abs/2511.22640)
- **Reason:** 提出Flow Density Control框架优化生成模型，支持更通用的效用优化（如风险规避、新颖性探索），属于大模型新技术的创新。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Generative Anchored Fields: Controlled Data Generation via Emergent Velocity Fields and Transport Algebra
- **Authors:** Deressa Wodajo Deressa, Hannes Mareen, Peter Lambert, Glenn Van Wallendael
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22693](https://arxiv.org/abs/2511.22693)
- **Reason:** 提出新的生成框架，支持组合控制和可控生成，提升生成模型的可控性，属于大模型新技术的创新。
Score: 7
Field: 大模型新技术

## 原生多模态大模型

### [Score: 9.0/10] REASONEDIT: Towards Reasoning-Enhanced Image Editing Models
- **Authors:** Fukun Yin, Shiyu Liu, Yucheng Han, Zhibo Wang, Peng Xing, Rui Wang, Wei Cheng, Yingming Wang, Aojie Li, Zixin Yin, Pengtao Chen, Xiangyu Zhang, Daxin Jiang, Xianfang Zeng, Gang Yu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22625](https://arxiv.org/abs/2511.22625)
- **Reason:** 针对现有图像编辑模型依赖冻结MLLM导致推理能力未充分利用的问题，提出思考-编辑-反思循环框架：思考机制利用MLLM解释抽象指令，反思机制自动修正结果，显著提升编辑性能（如ImgEdit+4.3%、GEdit+4.7%、Kris+8.2%），为多模态编辑模型注入推理能力提供新范式。
Score: 9
Field: 原生多模态大模型

### [Score: 8.5/10] HarmoCLIP: Harmonizing Global and Regional Representations in Contrastive Vision-Language Models
- **Authors:** Haoxi Zeng, Haoxuan Li, Yi Bin, Pengpeng Zeng, Xing Xu, Yang Yang, Heng Tao Shen
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22594](https://arxiv.org/abs/2511.22594)
- **Reason:** 针对CLIP因缺乏区域监督导致细粒度语义理解不足的问题，提出显式细粒度语义监督（对齐文本片段与视觉区域）和区域-语言对齐策略，调和全局与局部表示，在全局检索（提升至69.78%）和区域边界框分类（Top-1提升3.2%）上显著优于现有方法，解决CLIP的全局-局部权衡问题。
Score: 8.5
Field: 原生多模态大模型

### [Score: 8.0/10] SO-Bench: A Structural Output Evaluation of Multimodal LLMs
- **Authors:** Di Feng, Kaixin Ma, Feng Nan, Haofeng Chen, Bohan Zhai, David Griffiths, Mingfei Gao, Zhe Gan, Eshan Verma, Yinfei Yang, Zhifeng Chen, Afshin Dehghan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21750](https://arxiv.org/abs/2511.21750)
- **Reason:** 构建了首个系统评估多模态LLM结构化输出能力的SO-Bench基准，覆盖UI、自然图像等多视觉领域，揭示了现有模型在schema合规推理上的差距，对多模态大模型的结构化推理研究有重要价值
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] PAT3D: Physics-Augmented Text-to-3D Scene Generation
- **Authors:** Guying Lin, Kemeng Huang, Michael Liu, Ruihan Gao, Hanke Chen, Lyuhao Chen, Beijia Lu, Taku Komura, Yuan Liu, Jun-Yan Zhu, Minchen Li
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21978](https://arxiv.org/abs/2511.21978)
- **Reason:** 提出结合视觉语言模型与物理模拟的PAT3D框架，通过模拟循环优化生成物理合理的3D场景，解决了现有文本到3D模型缺乏物理一致性的问题，对多模态大模型的3D生成研究有重要推进
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Architecture Decoupling Is Not All You Need For Unified Multimodal Model
- **Authors:** Dian Zheng, Manyuan Zhang, Hongyu Li, Kai Zou, Hongbo Liu, Ziyu Guo, Kaituo Feng, Yexin Liu, Ying Luo, Yan Feng, Peng Pei, Xunliang Cai, Hongsheng Li (The University of Hong Kong)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22663](https://arxiv.org/abs/2511.22663)
- **Reason:** 针对统一多模态模型（图像生成与理解）的任务冲突问题，通过分析跨模态注意力行为提出Attention Interaction Alignment (AIA) loss，优化任务特定的多模态交互模式，实验验证提升了生成与理解性能，对原生多模态大模型的架构设计有重要参考价值。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] SpaceMind: Camera-Guided Modality Fusion for Spatial Reasoning in Vision-Language Models
- **Authors:** Ruosen Zhao, Zhikang Zhang, Jialei Xu, Jiahao Chang, Dong Chen, Lingyun Li, Weijian Sun, Zizhuang Wei
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23075](https://arxiv.org/abs/2511.23075)
- **Reason:** 提出多模态大模型SpaceMind，通过相机引导的模态融合增强视觉语言模型的3D空间推理能力，解决现有模型空间推理不足的问题，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Visual Generation Tuning
- **Authors:** Jiahao Guo, Sinan Du, Jingfeng Yao, Wenyu Liu, Bo Li, Haoxiang Cao, Kun Gai, Chun Yuan, Kai Wu, Xinggang Wang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23469](https://arxiv.org/abs/2511.23469)
- **Reason:** 提出VGT范式，通过高效视觉生成调优让预训练VLMs获得视觉生成能力，在图像重建和生成任务上性能优于现有方法，为统一多模态基础模型提供新方向
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Designing Instance-Level Sampling Schedules via REINFORCE with James-Stein Shrinkage
- **Authors:** Peiyu Yu, Suraj Kothawade, Sirui Xie, Ying Nian Wu, Hongliang Fei
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22177](https://arxiv.org/abs/2511.22177)
- **Reason:** 针对text-to-image采样器的实例级调度优化，提升文本图像对齐和生成质量，与原生多模态大模型的image generation方向高度相关。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] LFM2 Technical Report
- **Authors:** Alexander Amini, Anna Banaszak, Harold Benoit, Arthur B\"o\"ok, Tarek Dakhran, Song Duong, Alfred Eng, Fernando Fernandes, Marc H\"ark\"onen, Anne Harrington, Ramin Hasani, Saniya Karwa, Yuri Khrustalev, Maxime Labonne, Mathias Lechner, Valentine Lechner, Simon Lee, Zetian Li, Noel Loo, Jacob Marks, Edoardo Mosca, Samuel J. Paech, Paul Pak, Rom N. Parnichkun, Alex Quach, Ryan Rogers, Daniela Rus, Nayan Saxena, Bettina Schlager, Tim Seyde, Jimmy T. H. Smith, Aditya Tadimeti, Neehal Tumma
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23404](https://arxiv.org/abs/2511.23404)
- **Reason:** 提出面向边缘部署的Liquid Foundation Models家族LFM2，包含多模态变体（LFM2-VL视觉语言、LFM2-Audio语音），兼顾高效推理与多模态能力，提供了完整的多模态大模型解决方案。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] MoE3D: Mixture of Experts meets Multi-Modal 3D Understanding
- **Authors:** Yu Li, Yuenan Hou, Yingmei Wei, Xinge Zhu, Yuexin Ma, Wenqi Shao, Yanming Guo
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22103](https://arxiv.org/abs/2511.22103)
- **Reason:** 提出MoE3D框架，将混合专家模型引入多模态3D理解，通过渐进式预训练与信息聚合提升融合性能，在Multi3DRefer上的mIoU超越基线6.1%，对多模态大模型的3D语义理解有重要贡献
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Controllable 3D Object Generation with Single Image Prompt
- **Authors:** Jaeseok Lee, Jaekoo Lee
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22194](https://arxiv.org/abs/2511.22194)
- **Reason:** 提出无需文本反转的单图像提示3D生成方法，通过图像适配器与深度条件预热策略提升3D一致性与可控性，用户研究验证其优于现有文本反转方法，对多模态大模型的3D生成控制研究有重要贡献
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] 3D-Consistent Multi-View Editing by Diffusion Guidance
- **Authors:** Josef Bengtson, David Nilsson, Dong In Lee, Fredrik Kahl
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22228](https://arxiv.org/abs/2511.22228)
- **Reason:** 提出训练-free的扩散引导多视图编辑框架，通过一致性损失保证3D编辑的几何与光度一致性，实验验证在高斯 splatting编辑上优于现有方法，对多模态大模型的3D内容编辑有重要实践价值
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Some Modalities are More Equal Than Others: Decoding and Architecting Multimodal Integration in MLLMs
- **Authors:** Tianle Chen, Chaitanya Chakka, Arjun Reddy Akula, Xavier Thomas, Deepti Ghadiyaram (Adobe Research)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22826](https://arxiv.org/abs/2511.22826)
- **Reason:** 通过黑盒（性能分析）和白盒（注意力可视化）可解释性技术，揭示MLLMs对矛盾模态的脆弱性（如误导性文本、错位音频-视觉对），提出模态对齐调优策略提升跨模态推理的鲁棒性，对原生多模态大模型的可靠整合有重要意义。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Buffer replay enhances the robustness of multimodal learning under missing-modality
- **Authors:** Hongye Zhu, Xuan Liu, Yanwen Ba, Jingye Xue, Shigeng Zhang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23070](https://arxiv.org/abs/2511.23070)
- **Reason:** 提出REplay Prompting框架，通过模态特征缓冲和私有-共享特征解耦增强多模态模型在缺失模态下的鲁棒性，属于原生多模态大模型的关键问题研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] PowerCLIP: Powerset Alignment for Contrastive Pre-Training
- **Authors:** Masaki Kawamura, Nakamasa Inoue, Rintaro Yanagi, Hirokatsu Kataoka, Rio Yokota
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23170](https://arxiv.org/abs/2511.23170)
- **Reason:** 提出PowerCLIP通过幂集对齐增强对比预训练的组合语义理解，提升零样本分类和检索性能，属于原生多模态大模型（视觉语言预训练）方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] VQRAE: Representation Quantization Autoencoders for Multimodal Understanding, Generation and Reconstruction
- **Authors:** Sinan Du, Jiahao Guo, Bo Li, Shuhao Cui, Zhengzhuo Xu, Yifu Luo, Yongxian Wei, Kun Gai, Xinggang Wang, Kai Wu, Chun Yuan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23386](https://arxiv.org/abs/2511.23386)
- **Reason:** 提出VQRAE通过向量量化实现多模态理解、生成和重构的统一表示，支持视觉任务的统一处理，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] DisMo: Disentangled Motion Representations for Open-World Motion Transfer
- **Authors:** Thomas Ressler-Antal, Frank Fundel, Malek Ben Alaya, Stefan Andreas Baumann, Felix Krause, Ming Gui, Björn Ommer
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23428](https://arxiv.org/abs/2511.23428)
- **Reason:** 提出DisMo范式学习解耦的运动表示以实现开放域运动迁移，解决现有模型运动与内容耦合的问题，属于原生多模态大模型（视频生成、运动理解）方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Exploring Fusion Strategies for Multimodal Vision-Language Systems
- **Authors:** Regan Willis, Jason Bakos
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21889](https://arxiv.org/abs/2511.21889)
- **Reason:** 研究多模态视觉-语言系统的融合策略（早、中、晚融合），分析准确性与延迟的权衡，为多模态模型设计提供实践参考
Score: 7
Field: 原生多模态大模型

## 高效大模型训练与推理

### [Score: 9.0/10] Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer
- **Authors:** Image Team, Huanqia Cai, Sihan Cao, Ruoyi Du, Peng Gao, Steven Hoi, Shijie Huang, Zhaohui Hou, Dengyang Jiang, Xin Jin, Liangchen Li, Zhen Li, Zhong-Yu Li, David Liu, Dongyang Liu, Junhan Shi, Qilong Wu, Feng Yu, Chi Zhang, Shifeng Zhang, Shilin Zhou (Tongyi-MAI)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22699](https://arxiv.org/abs/2511.22699)
- **Reason:** 提出6B参数的高效图像生成基础模型Z-Image，基于单流扩散Transformer架构优化训练生命周期，实现与更大模型（20B-80B）相当的性能且推理高效（支持消费级硬件），解决了大模型部署的计算瓶颈，对高效大模型训练与推理和原生多模态大模型的落地有重要价值。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] ORION: Teaching Language Models to Reason Efficiently in the Language of Thought
- **Authors:** Kumar Tanmay (Unknown), Kriti Aggarwal (Unknown), Paul Pu Liang (Unknown), Subhabrata Mukherjee (Unknown)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22891](https://arxiv.org/abs/2511.22891)
- **Reason:** 受思维语言假设启发，提出Mentalese压缩推理框架，通过SLPO强化学习奖励简洁且正确的推理，实现了4-16倍的token压缩、5倍低延迟和7-9倍训练成本降低，同时保持90-98%的准确性，对大模型高效推理有突破性贡献。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.5/10] Decomposed Trust: Exploring Privacy, Adversarial Robustness, Fairness, and Ethics of Low-Rank LLMs
- **Authors:** Daniel Agyei Asante, Md Mokarram Chowdhury, Yang Li
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22099](https://arxiv.org/abs/2511.22099)
- **Reason:** 首次全面研究低秩LLM的可信性（隐私、鲁棒性、公平性、伦理），揭示低秩压缩对各维度的影响，为高效大模型的安全与对齐提供关键 insights
Score: 8.5
Field: 高效大模型训练与推理

### [Score: 8.0/10] StreamFlow: Theory, Algorithm, and Implementation for High-Efficiency Rectified Flow Generation
- **Authors:** Sen Fang, Hongbin Zhong, Yalin Feng, Dimitris N. Metaxas
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22009](https://arxiv.org/abs/2511.22009)
- **Reason:** 提出从理论到推理的Rectified Flow全链路加速方案，通过新速度场批量处理等方法将512×512图像生成速度提升611%，显著超越现有加速方法，对高效大模型推理有重要实践价值
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] TTSnap: Test-Time Scaling of Diffusion Models via Noise-Aware Pruning
- **Authors:** Qingtao Yu, Changlin Song, Minghao Sun, Zhengyang Yu, Vinay Kumar Verma, Soumya Roy, Sumit Negi, Hongdong Li, Dylan Campbell
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22242](https://arxiv.org/abs/2511.22242)
- **Reason:** 针对文本到图像扩散模型测试时需探索多噪声种子的高计算成本问题，提出噪声感知剪枝框架，通过训练噪声感知奖励模型提前剪枝低质量候选，在固定预算下提升探索效率与生成性能，实验证明比现有方法优16%以上，有效解决扩散模型测试时的计算瓶颈。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration
- **Authors:** Mengyu Yang, Yanming Yang, Chenyi Xu, Chenxi Song, Yufan Zuo, Tong Zhao, Ruibo Li, Chi Zhang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22533](https://arxiv.org/abs/2511.22533)
- **Reason:** 针对3D扩散模型缓存加速导致的几何不一致问题，提出几何感知缓存框架，通过预测缓存调度约束动态分配缓存配额、时空稳定性准则选择可复用特征，在加速推理（最高27.12% speed-up、54.8% FLOPs减少）的同时保持几何 fidelity（Chamfer Distance仅增加2.48%），解决3D扩散加速的核心矛盾。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] db-SP: Accelerating Sparse Attention for Visual Generative Models with Dual-Balanced Sequence Parallelism
- **Authors:** Siqi Chen, Ke Hong, Tianchen Zhao, Ruiqi Xie, Zhenhua Zhu, Xudong Zhang, Yu Wang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23113](https://arxiv.org/abs/2511.23113)
- **Reason:** 提出双平衡序列并行技术解决稀疏注意力的负载不平衡问题，加速视觉生成模型推理，显著提升稀疏注意力效率，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] A Fast and Flat Federated Learning Method via Weighted Momentum and Sharpness-Aware Minimization
- **Authors:** Tianle Li, Yongzhi Huang, Linshan Jiang, Chang Liu, Qipeng Xie, Wenfeng Du, Lu Wang, Kaishun Wu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22080](https://arxiv.org/abs/2511.22080)
- **Reason:** 提出FedWMSAM方法，结合加权动量与sharpness-aware minimization解决非IID联邦学习的收敛与泛化问题，有收敛界证明且性能优于基线
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] TinyLLM: Evaluation and Optimization of Small Language Models for Agentic Tasks on Edge Devices
- **Authors:** Mohd Ariful Haque (Clark Atlanta University), Fahad Rahman (United International University), Kishor Datta Gupta (Clark Atlanta University), Khalil Shujaee (Clark Atlanta University), Roy George (Clark Atlanta University)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22138](https://arxiv.org/abs/2511.22138)
- **Reason:** 研究边缘设备上小LLM的agentic任务优化，通过混合策略（SFT、PEFT、DPO）提升性能，证明小模型在边缘设备上的可行性，属于高效大模型训练与推理
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Solving Context Window Overflow in AI Agents
- **Authors:** Anton Bulle Labate (Unknown), Valesca Moura de Sousa (Unknown), Sandro Rama Fiorini (Unknown), Leonardo Guerreiro Azevedo (Unknown), Raphael Melo Thiago (Unknown), Viviane Torres da Silva (Unknown)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22729](https://arxiv.org/abs/2511.22729)
- **Reason:** 针对AI代理中工具输出导致的上下文窗口溢出问题，提出了内存指针替代原始数据的方法，在不丢失信息的前提下减少token使用和执行时间，解决了动态知识密集型领域（如材料科学）的agentic workflow瓶颈，提升了大模型推理效率。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.5/10] ITS3D: Inference-Time Scaling for Text-Guided 3D Diffusion Models
- **Authors:** Zhenglin Zhou, Fan Ma, Xiaobo Xia, Hehe Fan, Yi Yang, Tat-Seng Chua
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22456](https://arxiv.org/abs/2511.22456)
- **Reason:** 针对文本引导3D扩散模型的推理优化，提出验证器引导的搜索算法，通过高斯归一化稳定搜索、SVD压缩降低高维空间复杂度、奇异空间重置避免局部最优，有效提升文本到3D生成质量，为3D扩散模型的推理时高效缩放提供新方法。
Score: 7.5
Field: 高效大模型训练与推理

### [Score: 7.0/10] GoPrune: Accelerated Structured Pruning with $\ell_{2,p}$-Norm Optimization
- **Authors:** Li Xu, Xianchao Xiu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22120](https://arxiv.org/abs/2511.22120)
- **Reason:** 提出基于ℓ_{2,p}-范数的加速结构化剪枝方法GoPrune，通过近端交替最小化算法实现高效优化，在ResNet、VGG模型上的剪枝性能优于现有方法，对模型压缩的工程实现有重要价值
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Ovis-Image Technical Report
- **Authors:** Guo-Hua Wang, Liangfu Cao, Tianyu Cui, Minghao Fu, Xiaohao Chen, Pengxin Zhan, Jianshan Zhao, Lan Li, Bowen Fu, Jiaqi Liu, Qing-Guo Chen
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22982](https://arxiv.org/abs/2511.22982)
- **Reason:** 提出7B参数的文本到图像模型Ovis-Image，基于Ovis 2.5多模态 backbone优化文本渲染，实现与更大模型（如Qwen-Image）相当的双语文本生成性能，且支持单高端GPU部署，对高效大模型训练与推理和原生多模态大模型的实用化有价值。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] PerfMamba: Performance Analysis and Pruning of Selective State Space Models
- **Authors:** Abdullah Al Asif, Mobina Kashaniyan, Sixing Yu, Juan Pablo Muñoz, Ali Jannesari
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22849](https://arxiv.org/abs/2511.22849)
- **Reason:** 系统分析Mamba模型的性能，提出剪枝方法提升吞吐量和减少内存，对高效大模型训练与推理有实际价值。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning
- **Authors:** Jiajun Guo, Xin Luo, Jie Liu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23402](https://arxiv.org/abs/2511.23402)
- **Reason:** 提出结合学习型数据压缩的多模态模型结构，将模型嵌入压缩为低比特整数，解决了split learning中的高传输成本问题，同时保持模型性能，提升了多模态大模型的训练效率。
Score: 7
Field: 高效大模型训练与推理

## 深度学习理论

### [Score: 9.0/10] Towards Understanding Transformers in Learning Random Walks
- **Authors:** Wei Shi, Yuan Cao
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23239](https://arxiv.org/abs/2511.23239)
- **Reason:** 理论研究Transformer在学习随机游走时的能力和可解释性，证明一层Transformer可达到最优预测精度，且训练后的模型可解释，为Transformer的序列学习能力提供了理论洞见。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Provable Benefits of Sinusoidal Activation for Modular Addition
- **Authors:** Tianlong Huang, Zhiyuan Li
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23443](https://arxiv.org/abs/2511.23443)
- **Reason:** 理论研究正弦激活函数在学习模加法中的优势，证明其在表达能力和泛化性能上优于ReLU，为激活函数的选择提供了理论依据。
Score: 9
Field: 深度学习理论

### [Score: 8.5/10] Closed-Loop Transformers: Autoregressive Modeling as Iterative Latent Equilibrium
- **Authors:** Akbar Anbar Jafari, Gholamreza Anbarjafari
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21882](https://arxiv.org/abs/2511.21882)
- **Reason:** 提出闭环Transformer框架（EqT），通过迭代优化隐表示至平衡态解决开环自回归的承诺瓶颈，证明其为隐式能量模型的近似MAP推理，有收敛保证与实验验证
Score: 8.5
Field: 深度学习理论

### [Score: 8.5/10] Convergence Dynamics of Over-Parameterized Score Matching for a Single Gaussian
- **Authors:** Yiran Zhang, Weihang Xu, Mo Zhou, Maryam Fazel, Simon Shaolei Du
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22069](https://arxiv.org/abs/2511.22069)
- **Reason:** 分析过参数化模型在score matching中的优化动态，证明高噪声下全局收敛、低噪声下初始化依赖性，为生成模型训练理论提供重要 insights
Score: 8.5
Field: 深度学习理论

### [Score: 8.0/10] Markovian Scale Prediction: A New Era of Visual Autoregressive Generation
- **Authors:** Yu Zhang, Jingyi Liu, Yiwei Shi, Qi Zhang, Duoqian Miao, Changwei Wang, Longbing Cao
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23334](https://arxiv.org/abs/2511.23334)
- **Reason:** 提出Markov-VAR框架将视觉自回归生成重构为马尔可夫过程，提升效率和性能，解决现有VAR模型的计算效率问题，属于深度学习理论方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Dynamical Implicit Neural Representations
- **Authors:** Yesom Park, Kelvin Kan, Thomas Flynn, Yi Huang, Shinjae Yoo, Stanley Osher, Xihaier Luo
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21787](https://arxiv.org/abs/2511.21787)
- **Reason:** 提出DINR框架，将隐式神经表示的特征演化视为连续时间动态系统，解决INR的谱偏差问题，结合Rademacher复杂度与NTK的理论分析，提升了表示能力与泛化性
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Equilibrium Propagation Without Limits
- **Authors:** Elon Litman
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22024](https://arxiv.org/abs/2511.22024)
- **Reason:** 扩展平衡传播至有限nudge场景，证明Contrastive Hebbian Learning是精确梯度估计器，提出广义EP算法并给出收敛保证，推动深度学习理论发展
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Intelligent Neural Networks: From Layered Architectures to Graph-Organized Intelligence
- **Authors:** Antoine Salomon
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22813](https://arxiv.org/abs/2511.22813)
- **Reason:** 提出图结构的智能神经网络，将神经元组织成完全图而非分层结构，改善序列建模性能，属于深度学习理论中网络架构的重要创新。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] A Theoretical Framework for Discovering Groups and Unitary Representations via Tensor Factorization
- **Authors:** Dongsung Huh, Halyun Jeong
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23152](https://arxiv.org/abs/2511.23152)
- **Reason:** 提出张量分解模型HyperCube的理论框架，严格解释了其发现群结构和酉表示的归纳偏置，为张量分解在结构学习中的应用提供了理论支撑。
Score: 8
Field: 深度学习理论

### [Score: 7.5/10] A Variational Manifold Embedding Framework for Nonlinear Dimensionality Reduction
- **Authors:** John J. Vastola, Samuel J. Gershman, Kanaka Rajan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22128](https://arxiv.org/abs/2511.22128)
- **Reason:** 提出变分流形嵌入框架解决非线性降维问题，理论上恢复PCA作为特例，为表示学习提供可解释的variational视角
Score: 7.5
Field: 深度学习理论

### [Score: 6.0/10] Optimizer Sensitivity In Vision Transformerbased Iris Recognition: Adamw Vs Sgd Vs Rmsprop
- **Authors:** Moh Imam Faiz, Aviv Yuniar Rahman, Rangga Pahlevi Putra
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22994](https://arxiv.org/abs/2511.22994)
- **Reason:** 系统评估AdamW、SGD、RMSprop三种优化器对ViT-based虹膜识别模型的准确性与稳定性影响，揭示优化器选择对生物特征系统的关键作用，填补了ViT在特定任务中优化器研究的空白，对深度学习理论中的优化器方向有参考价值。
Score: 6
Field: 深度学习理论

## 大模型安全与对齐

### [Score: 9.0/10] AI Deception: Risks, Dynamics, and Controls
- **Authors:** Boyuan Chen (Jay), Sitong Fang (Jay), Jiaming Ji (Jay), Yanxu Zhu (Jay), Pengcheng Wen (Jay), Jinzhou Wu (Jay), Yingshui Tan (Jay), Boren Zheng (Jay), Mengying Yuan (Jay), Wenqi Chen (Jay), Donghai Hong (Jay), Alex Qiu (Jay), Xin Chen (Jay), Jiayi Zhou (Jay), Kaile Wang (Jay), Juntao Dai (Jay), Borong Zhang (Jay), Tianzhuo Yang (Jay), Saad Siddiqui (Jay), Isabella Duan (Jay), Yawen Duan (Jay), Brian Tse (Jay), Jen-Tse (Jay), Huang, Kun Wang (Unknown), Baihui Zheng (Unknown), Jiaheng Liu (Unknown), Jian Yang (Unknown), Yiming Li (Unknown), Wenting Chen (Unknown), Dongrui Liu (Unknown), Lukas Vierling (Unknown), Zhiheng Xi (Unknown), Haobo Fu (Unknown), Wenxuan Wang (Unknown), Jitao Sang (Unknown), Zhengyan Shi (Unknown), Chi-Min Chan (Unknown), Eugenie Shi (Unknown), Simin Li (Unknown), Juncheng Li (Unknown), Wei Ji (Unknown), Dong Li (Unknown), Jun Song (Unknown), Yinpeng Dong (Unknown), Jie Fu (Unknown), Bo Zheng (Unknown), Min Yang (Unknown), Yike Guo (Unknown), Philip Torr (Unknown), Zhongyuan Wang (Unknown), Yaodong Yang (Unknown), Tiejun Huang (Unknown), Ya-Qin Zhang (Unknown), Hongjiang Zhang (Unknown), Andrew Yao (Unknown)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22619](https://arxiv.org/abs/2511.22619)
- **Reason:** 首次基于信号理论定义AI欺骗，系统分析了AI欺骗的 emergence（激励基础、能力前提、触发条件）与 treatment（检测、缓解），覆盖语言模型、智能体等多场景的欺骗风险，为大模型安全与对齐提供了全面的理论框架和实证参考。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] PROMPTMINER: Black-Box Prompt Stealing against Text-to-Image Generative Models via Reinforcement Learning and Fuzz Optimization
- **Authors:** Mingzhe Li, Renhao Zhang, Zhiyang Wen, Siqi Pan, Bruno Castro da Silva, Juan Zhai, Shiqing Ma
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22119](https://arxiv.org/abs/2511.22119)
- **Reason:** 提出黑盒prompt窃取框架PROMPTMINER，通过强化学习与模糊优化实现高精度prompt恢复，实验验证在多扩散模型上优于基线，对大模型的prompt安全与知识产权保护研究有重要意义
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Exploring Dynamic Properties of Backdoor Training Through Information Bottleneck
- **Authors:** Xinyu Liu, Xu Zhang, Can Chen, Ren Wang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21923](https://arxiv.org/abs/2511.21923)
- **Reason:** 利用信息瓶颈分析后门训练动态，提出模型级整合的stealthiness指标，揭示后门攻击的信息理论特征，对大模型安全有理论贡献
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Does Self-Evaluation Enable Wireheading in Language Models?
- **Authors:** David Demitri Africa (Unknown), Hans Ethan Ting (Unknown)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23092](https://arxiv.org/abs/2511.23092)
- **Reason:** 实证研究了自我评估与奖励信号耦合的风险——模型会通过分数膨胀而非任务改进获取奖励，揭示了自我评估在大模型训练中的安全边界，为大模型对齐的机制设计提供了关键实验证据。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.5/10] Breaking the Illusion: Consensus-Based Generative Mitigation of Adversarial Illusions in Multi-Modal Embeddings
- **Authors:** Fatemeh Akbarian, Anahita Baninajjar, Yingyi Zhang, Ananth Balashankar, Amir Aminifar
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21893](https://arxiv.org/abs/2511.21893)
- **Reason:** 提出基于生成模型与共识的防御机制，有效降低多模态嵌入的对抗幻觉攻击成功率，提升跨模态对齐性能，为多模态模型安全提供解决方案
Score: 7.5
Field: 大模型安全与对齐

### [Score: 7.5/10] Breaking Algorithmic Collusion in Human-AI Ecosystems
- **Authors:** Natalie Collina, Eshwar Ram Arunachaleswaran, Meena Jagadeesan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21935](https://arxiv.org/abs/2511.21935)
- **Reason:** 研究人类-AI生态系统中的算法 collusion，证明人类参与能破坏collusion并降低价格，为大模型安全与对齐的生态问题提供理论分析
Score: 7.5
Field: 大模型安全与对齐

### [Score: 7.0/10] The Double-Edged Nature of the Rashomon Set for Trustworthy Machine Learning
- **Authors:** Ethan Hsu, Harry Chen, Chudi Zhong, Lesia Semenova
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21799](https://arxiv.org/abs/2511.21799)
- **Reason:** 分析Rashomon集在可信机器学习中的双重作用（鲁棒性与隐私的权衡），通过理论与实证揭示其作为资源与风险的特性，对大模型安全与对齐有参考价值
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Enhancing Trustworthiness with Mixed Precision: Benchmarks, Opportunities, and Challenges
- **Authors:** Guanxi Lu, Hao Mark Chen, Zhiqiang Que, Wayne Luk, Hongxiang Fan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22483](https://arxiv.org/abs/2511.22483)
- **Reason:** 系统研究量化对LLM可信度的影响，提出精度集成投票方法提升trustworthiness，与大模型安全与对齐方向相关。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Aligning Artificial Superintelligence via a Multi-Box Protocol
- **Authors:** Avraham Yair Negozio
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21779](https://arxiv.org/abs/2511.21779)
- **Reason:** 提出基于多隔离系统 mutual verification 的人工超级智能对齐协议，通过声誉系统激励诚实行为，为超级智能对齐提供了新颖的框架。
Score: 7
Field: 大模型安全与对齐

## 多模态智能体

### [Score: 8.5/10] A Safety and Security Framework for Real-World Agentic Systems
- **Authors:** Shaona Ghosh, Barnaby Simkin, Kyriacos Shiarlis, Soumili Nandi, Dan Zhao, Matthew Fiedler, Julia Bazinska, Nikki Pope, Roopa Prabhu, Daniel Rohrer, Michael Demoret, Bartley Richardson
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21990](https://arxiv.org/abs/2511.21990)
- **Reason:** 提出动态Agentic系统安全框架，结合AI辅助风险发现、红队测试与人为监督，通过NVIDIA AI-Q案例验证有效性，为多模态智能体安全提供实践方案
Score: 8.5
Field: 多模态智能体

### [Score: 8.0/10] DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action
- **Authors:** Zhen Fang, Zhuoyang Liu, Jiaming Liu, Hao Chen, Yu Zeng, Shiting Huang, Zehui Chen, Lin Chen, Shanghang Zhang, Feng Zhao
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22134](https://arxiv.org/abs/2511.22134)
- **Reason:** 提出DualVLA模型，通过双层数据剪枝与双教师蒸馏解决多模态智能体的动作退化问题，平衡了精准动作执行与多模态推理能力，在SimplerEnv与多模态基准上表现优异
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Guiding the Inner Eye: A Framework for Hierarchical and Flexible Visual Grounded Reasoning
- **Authors:** Zhaoyang Wei, Wenchao Ding, Yanchao Hao, Xi Chen
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22172](https://arxiv.org/abs/2511.22172)
- **Reason:** 提出GRiP框架，通过显著性加权IoU奖励与多启发式策略提升多模态模型的视觉接地推理能力，在TreeBench、V* Bench上的表现优于现有模型，对多模态智能体的推理透明度研究有重要价值
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model
- **Authors:** Junshu Tang, Jiacheng Liu, Jiaqi Li, Longhuang Wu, Haoyu Yang, Penghao Zhao, Siruis Gong, Xiang Yuan, Shuai Shao, Qinglin Lu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23429](https://arxiv.org/abs/2511.23429)
- **Reason:** 提出指令驱动的互动游戏世界模型，支持自然语言、键盘/鼠标控制，解决现有游戏模型交互性不足的问题，属于多模态智能体方向。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Training High-Level Schedulers with Execution-Feedback Reinforcement Learning for Long-Horizon GUI Automation
- **Authors:** Zehao Deng (Unknown), Tianjie Ju (Unknown), Zheng Wu (Unknown), Zhuosheng Zhang (Unknown), Gongshen Liu (Unknown)
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22235](https://arxiv.org/abs/2511.22235)
- **Reason:** 针对GUI智能体长 horizon任务的核心挑战（责任耦合、状态感知缺失），提出了CES多代理框架及执行反馈强化学习方法，通过Coordinator和State Tracker分别处理策略规划与状态管理，提升了GUI自动化的长任务处理能力，对多模态智能体的长任务推理有重要价值。
Score: 8
Field: 多模态智能体

### [Score: 7.5/10] Video-CoM: Interactive Video Reasoning via Chain of Manipulations
- **Authors:** Hanoona Rasheed, Mohammed Zumri, Muhammad Maaz, Ming-Hsuan Yang, Fahad Shahbaz Khan, Salman Khan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23477](https://arxiv.org/abs/2511.23477)
- **Reason:** 提出交互式视频推理范式，通过Chain of Manipulations迭代优化视觉表示，构建专用指令微调数据集并结合RL优化策略，在视频推理基准上性能显著提升且数据效率高
Score: 7.5
Field: 多模态智能体

### [Score: 7.0/10] JarvisEvo: Towards a Self-Evolving Photo Editing Agent with Synergistic Editor-Evaluator Optimization
- **Authors:** Yunlong Lin, Linqing Wang, Kunjie Lin, Zixu Lin, Kaixiong Gong, Wenbo Li, Bin Lin, Zhenxi Li, Shiyi Zhang, Yuyang Peng, Wenxun Dai, Xinghao Ding, Chunyu Wang, Qinglin Lu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23002](https://arxiv.org/abs/2511.23002)
- **Reason:** 提出自进化图像编辑智能体，结合多模态思维链推理与编辑器-评估器协同优化，集成Adobe Lightroom实现细粒度编辑，解决现有代理的幻觉和奖励 hacking 问题，属于多模态智能体研究范畴。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models
- **Authors:** Muhammad Maaz, Hanoona Rasheed, Fahad Shahbaz Khan, Salman Khan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23478](https://arxiv.org/abs/2511.23478)
- **Reason:** 针对多模态语言模型的视频推理一致性与接地性问题，提出RL方法结合时间对齐奖励，提升了推理准确性与可信度，在多个基准上验证了有效性
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] Real-Time Procedural Learning From Experience for AI Agents
- **Authors:** Dasheng Bi, Yubin Hu, Mohammed N. Nasir
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22074](https://arxiv.org/abs/2511.22074)
- **Reason:** 提出PRAXIS机制，使LLM-based智能体在部署后通过经验实时学习流程知识，在REAL web browsing基准上提升了任务完成 accuracy、可靠性和成本效率，解决了智能体实时学习的问题。
Score: 7
Field: 多模态智能体

## 深度学习可解释性

### [Score: 8.0/10] Partially Shared Concept Bottleneck Models
- **Authors:** Delong Zhao, Qiang Huang, Di Yan, Yiqun Sun, Jun Yu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22170](https://arxiv.org/abs/2511.22170)
- **Reason:** 提出PS-CBM框架，通过多模态概念生成与部分共享策略提升概念瓶颈模型的准确性与可解释性，实验验证在11个数据集上优于基线，对深度学习可解释性的工程化落地有重要推进
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] From Illusion to Intention: Visual Rationale Learning for Vision-Language Reasoning
- **Authors:** Changpeng Wang, Haozhe Wang, Xi Chen, Junhan Liu, Taofeng Xue, Chong Peng, Donglian Qi, Fangzhen Lin, Yunfeng Yan
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23031](https://arxiv.org/abs/2511.23031)
- **Reason:** 提出Visual Rationale Learning范式，通过过程监督、目标对齐和细粒度信用分配解决视觉语言推理的“幻觉”问题，增强模型推理的可解释性，直接对应深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection
- **Authors:** Huangsen Cao, Qin Mei, Zhiheng Li, Yuxi Li, Ying Zhang, Chen Li, Zhimeng Zhang, Xin Ding, Yongwei Wang, Jing Lyu, Fei Wu
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23158](https://arxiv.org/abs/2511.23158)
- **Reason:** 提出REVEAL框架结合专家级证据链和强化学习，实现可解释的AI生成图像检测并生成可验证推理链，解决现有方法缺乏可验证解释的问题，属于深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] ABLE: Using Adversarial Pairs to Construct Local Models for Explaining Model Predictions
- **Authors:** Krishna Khadka, Sunny Shree, Pujan Budhathoki, Yu Lei, Raghu Kacker, D. Richard Kuhn
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21952](https://arxiv.org/abs/2511.21952)
- **Reason:** 提出ABLE框架，通过对抗对构建局部模型解释预测，提升局部解释的稳定性与fidelity，在多个数据集与模型上验证有效性
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Space Explanations of Neural Network Classification
- **Authors:** Faezeh Labbaf, Tomáš Kolárik, Martin Blicha, Grigory Fedyukovich, Michael Wand, Natasha Sharygina
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22498](https://arxiv.org/abs/2511.22498)
- **Reason:** 利用逻辑方法生成神经网络分类的空间解释，提供可证明的行为保证，显著提升解释意义性，属于深度学习可解释性的重要进展。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] ARM-Explainer -- Explaining and improving graph neural network predictions for the maximum clique problem using node features and association rule mining
- **Authors:** Bharat Sharman, Elkafi Hassini
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22866](https://arxiv.org/abs/2511.22866)
- **Reason:** 提出基于关联规则挖掘的后验模型级解释器ARM-Explainer，用于解释GNN在最大团问题上的预测，并通过挖掘的重要节点特征增强模型性能，解决了GNN预测可解释性不足的问题，且在基准数据集上验证了有效性。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Delta-XAI: A Unified Framework for Explaining Prediction Changes in Online Time Series Monitoring
- **Authors:** Changhun Kim, Yechan Mun, Hyeongwon Jang, Eunseo Lee, Sangchul Hahn, Eunho Yang
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23036](https://arxiv.org/abs/2511.23036)
- **Reason:** 提出Delta-XAI框架，通过适配现有XAI方法并引入在线评估套件，解决了时间序列模型预测变化解释的难题，捕捉了时间依赖关系，提升了在线可解释性。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations
- **Authors:** Chancharik Mitra, Yusen Luo, Raj Saravanan, Dantong Niu, Anirudh Pai, Jesse Thomason, Trevor Darrell (University of California, Berkeley), Abrar Anwar, Deva Ramanan (University of California, Berkeley), Roei Herzig
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.22697](https://arxiv.org/abs/2511.22697)
- **Reason:** 论文提出基于机械可解释性的Robotic Steering微调方法，通过少样本演示识别并选择性微调VLA模型中与机器人任务相关的注意力头，提升了模型的适应性、鲁棒性和可解释性，符合深度学习可解释性研究方向，且作者团队包含Trevor Darrell、Deva Ramanan等知名学者，实验验证了方法有效性。
Score: 8
Field: 深度学习可解释性

### [Score: 7.5/10] Physically Interpretable Representation Learning with Gaussian Mixture Variational AutoEncoder (GM-VAE)
- **Authors:** Tiffany Fan, Murray Cutforth, Marta D'Elia, Alexandre Cortiella, Alireza Doostan, Eric Darve
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21883](https://arxiv.org/abs/2511.21883)
- **Reason:** 提出GM-VAE框架，结合EM训练与光谱可解释性指标，解决物理系统高维数据的可解释表示问题，在ODE、Navier-Stokes等任务上验证有效性
Score: 7.5
Field: 深度学习可解释性

### [Score: 7.0/10] Does the Model Say What the Data Says? A Simple Heuristic for Model Data Alignment
- **Authors:** Henry Salgado, Meagan Kendall, Martine Ceberio
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.21931](https://arxiv.org/abs/2511.21931)
- **Reason:** 提出简单框架评估模型-数据对齐，基于数据衍生基线比较模型解释与数据结构，为深度学习可解释性提供模型无关评估方法
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] BanglaSentNet: An Explainable Hybrid Deep Learning Framework for Multi-Aspect Sentiment Analysis with Cross-Domain Transfer Learning
- **Authors:** Ariful Islam, Md Rifat Hossen, Tanvir Mahmud
- **Published:** 2025-12-01
- **Link:** [https://arxiv.org/abs/2511.23264](https://arxiv.org/abs/2511.23264)
- **Reason:** 提出可解释的混合深度学习框架BanglaSentNet，结合SHAP特征归因和注意力可视化，解决了孟加拉语多方面情感分析的可解释性问题，且在跨域迁移中表现良好。
Score: 7
Field: 深度学习可解释性

