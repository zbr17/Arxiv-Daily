<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-02</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>高效大模型训练与推理</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习理论</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >大模型新技术</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-02</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-02 12:47:24</p>
<p>已自动阅读了 431 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：233082</p>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> StreamFlow: Theory, Algorithm, and Implementation for High-Efficiency Rectified Flow Generation</h3>
<p><strong>Authors:</strong> Sen Fang, Hongbin Zhong, Yalin Feng, Dimitris N. Metaxas</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出从理论到实现的Rectified Flow生成加速 pipeline，通过批量处理、向量化和动态编译等技术将512*512图像生成速度提升611%，属于高效大模型训练与推理中的生成模型加速技术。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22009' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Z-Image: An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer</h3>
<p><strong>Authors:</strong> Image Team, Huanqia Cai, Sihan Cao, Ruoyi Du, Peng Gao, Steven Hoi, Shijie Huang, Zhaohui Hou, Dengyang Jiang, Xin Jin, Liangchen Li, Zhen Li, Zhong-Yu Li, David Liu, Dongyang Liu, Junhan Shi, Qilong Wu, Feng Yu, Chi Zhang, Shifeng Zhang, Shilin Zhou</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出基于单流扩散Transformer的高效图像生成基础模型，通过优化数据基础设施与训练流程，实现6B参数模型在性能上媲美20B-80B参数竞品，同时支持低资源部署，为高效大模型设计提供实践范例。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22699' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> db-SP: Accelerating Sparse Attention for Visual Generative Models with Dual-Balanced Sequence Parallelism</h3>
<p><strong>Authors:</strong> Siqi Chen, Ke Hong, Tianchen Zhao, Ruiqi Xie, Zhenhua Zhu, Xudong Zhang, Yu Wang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出双级划分序列并行技术解决稀疏注意力负载不平衡问题，加速视觉生成模型推理，稀疏注意力加速 1.40x、端到端加速 1.25x，显著提升效率。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23113' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SingleQuant: Efficient Quantization of Large Language Models in a Single Pass</h3>
<p><strong>Authors:</strong> Jinying Xiao, Bin Ji, Shasha Li, Xiaodong Liu, Ma Jun, Ye Zhong, Wei Li, Xuan Xie, Qingbo Wu, Jie Yu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出单遍LLM量化框架，大幅提升量化速度与性能，符合高效大模型训练与推理的high compression方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22316' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Experts are all you need: A Composable Framework for Large Language Model Inference</h3>
<p><strong>Authors:</strong> Shrihari Sridharan, Sourjya Roy, Anand Raghunathan, Kaushik Roy</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出可组合LLM推理框架Comp-LLM，通过子查询依赖图与并行处理实现模型压缩（1.67x-3.56x）与延迟降低（1.1x-1.7x），同时提升准确性，完全匹配高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22955' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> LFM2 Technical Report</h3>
<p><strong>Authors:</strong> Alexander Amini, Anna Banaszak, Harold Benoit, Arthur B\"o\"ok, Tarek Dakhran, Song Duong, Alfred Eng, Fernando Fernandes, Marc H\"ark\"onen, Anne Harrington, Ramin Hasani, Saniya Karwa, Yuri Khrustalev, Maxime Labonne, Mathias Lechner, Valentine Lechner, Simon Lee, Zetian Li, Noel Loo, Jacob Marks, Edoardo Mosca, Samuel J. Paech, Paul Pak, Rom N. Parnichkun, Alex Quach, Ryan Rogers, Daniela Rus, Nayan Saxena, Bettina Schlager, Tim Seyde, Jimmy T. H. Smith, Aditya Tadimeti, Neehal Tumma</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出高效边缘部署的液体基础模型LFM2，通过硬件在环架构搜索、知识蒸馏与模型合并实现边缘推理加速（2x faster prefill/decode），是高效大模型训练与推理的典型实践。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23404' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ORION: Teaching Language Models to Reason Efficiently in the Language of Thought</h3>
<p><strong>Authors:</strong> Kumar Tanmay, Kriti Aggarwal, Paul Pu Liang, Subhabrata Mukherjee</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出Mentalese风格压缩推理框架，通过强化学习奖励简洁正确路径，实现推理token数4-16倍压缩、延迟5倍降低，对高效大模型推理的理论与实践均有重要价值。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22891' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GoPrune: Accelerated Structured Pruning with $\ell_{2,p}$-Norm Optimization</h3>
<p><strong>Authors:</strong> Li Xu, Xianchao Xiu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出基于ℓ_{2,p}-norm的结构化剪枝方法，通过 proximal交替最小化算法实现高效优化，提升模型压缩效率和推理速度，属于高效大模型训练与推理中的模型压缩技术。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22120' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DocVAL: Validated Chain-of-Thought Distillation for Grounded Document VQA</h3>
<p><strong>Authors:</strong> Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Dheeraj Kulshrestha, Rajiv Ramnath</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 用验证的Chain-of-Thought蒸馏将大模型推理能力转移到小模型，提升document VQA准确性与效率，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22521' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration</h3>
<p><strong>Authors:</strong> Mengyu Yang, Yanming Yang, Chenyi Xu, Chenxi Song, Yufan Zuo, Tong Zhao, Ruibo Li, Chi Zhang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出几何感知缓存框架加速3D扩散推理，保持几何一致性，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22533' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AutoTailor: Automatic and Efficient Adaptive Model Deployment for Diverse Edge Devices</h3>
<p><strong>Authors:</strong> Mengyang Liu, Chenyu Lu, Haodong Tian, Fang Dong, Ruiting Zhou, Wei Wang, Dian Shen, Guangtong Li, Ye Wan, Li Li</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出自动SuperNet-based自适应部署框架，降低边缘设备模型部署成本，符合高效大模型训练与推理的LLM infra方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22355' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PerfMamba: Performance Analysis and Pruning of Selective State Space Models</h3>
<p><strong>Authors:</strong> Abdullah Al Asif, Mobina Kashaniyan, Sixing Yu, Juan Pablo Muñoz, Ali Jannesari</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 对Mamba模型进行性能分析与状态剪枝，提升效率，符合高效大模型训练与推理的high compression方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22849' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Closing the Generalization Gap in Parameter-efficient Federated Edge Learning</h3>
<p><strong>Authors:</strong> Xinnong Du, Zhonghao Lyu, Xiaowen Cao, Chunyang Wen, Shuguang Cui, Jie Xu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出参数高效联邦边缘学习框架，通过泛化感知的剪枝与客户端选择优化，解决有限异质数据下的泛化 gap，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23282' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation</h3>
<p><strong>Authors:</strong> Bernhard Klein, Falk Selker, Hendrik Borras, Sophie Steger, Franz Pernkopf, Holger Fr\"oning</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出概率前向传播（PFP）与TVM代码生成结合的BNN加速方案，将推理速度提升4200x，对应高效大模型训练与推理中的加速需求。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23440' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Solving Context Window Overflow in AI Agents</h3>
<p><strong>Authors:</strong> Anton Bulle Labate, Valesca Moura de Sousa, Sandro Rama Fiorini, Leonardo Guerreiro Azevedo, Raphael Melo Thiago, Viviane Torres da Silva</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 针对AI智能体中LLM工具输出导致的上下文溢出问题，提出内存指针替代法，保留完整信息的同时降低token消耗与延迟，对高效大模型推理有实践指导意义。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22729' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent</h3>
<p><strong>Authors:</strong> Jianzhe Lin, Zeyu Pan, Yun Zhu, Ruiqi Song, Jining Yang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出SuperIntelliAgent框架，通过小模型与大模型的自我监督交互实现持续智能增长，降低训练成本并提升适应性，对高效大模型训练有参考价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23436' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Thinking by Doing: Building Efficient World Model Reasoning in LLMs via Multi-turn Interaction</h3>
<p><strong>Authors:</strong> Bao Shu, Yan Cai, Jianjian Sun, Chunrui Han, En Yu, Liang Zhao, Jingcheng Hu, Yinmin Zhang, Haoran Lv, Yuang Peng, Zheng Ge, Xiangyu Zhang, Daxin Jiang, Xiangyu Yue</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出WMAct框架，通过奖励调整与交互频率退火提升LLM世界模型推理效率，减少冗余交互并内化环境动态，对高效大模型推理实践有重要意义。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23476' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TinyLLM: Evaluation and Optimization of Small Language Models for Agentic Tasks on Edge Devices</h3>
<p><strong>Authors:</strong> Mohd Ariful Haque (Clark Atlanta University), Fahad Rahman (United International University), Kishor Datta Gupta (Clark Atlanta University), Khalil Shujaee (Clark Atlanta University), Roy George (Clark Atlanta University)</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 针对边缘设备agentic任务评估小模型（TinyAgent、TinyLlama等），提出混合优化策略（SFT+PEFT+DPO）， medium-sized模型（1-3B）实现65.74%总准确率、55.62%多轮准确率，为高效大模型推理及边缘部署提供实践参考。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.22138' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Energy-Efficient Vision Transformer Inference for Edge-AI Deployment</h3>
<p><strong>Authors:</strong> Nursultan Amanzhol, Jurn-Gyu Park</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出两阶段 pipeline（设备无关模型筛选+设备相关能效评估）优化ViT边缘推理能效，对应高效大模型训练与推理中的边缘部署需求。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23166' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning</h3>
<p><strong>Authors:</strong> Jiajun Guo, Xin Luo, Jie Liu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出多模态模型Quantized-Tinyllava，通过学习型低比特量化压缩模型嵌入，减少分裂学习中的传输成本，对应高效大模型训练与推理中的压缩需求。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23402' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Price of Progress: Algorithmic Efficiency and the Falling Cost of AI Inference</h3>
<p><strong>Authors:</strong> Hans Gundlach, Jayson Lynch, Matthias Mertens, Neil Thompson</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 量化分析算法效率提升对AI推理成本下降的贡献（5x-10x/年），为高效大模型训练与推理提供成本量化依据。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2511.23455' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> PROMPTMINER: Black-Box Prompt Stealing against Text-to-Image Generative Models via Reinforcement Learning and Fuzz Optimization</h3>
<p><strong>Authors:</strong> Mingzhe Li, Renhao Zhang, Zhiyang Wen, Siqi Pan, Bruno Castro da Silva, Juan Zhai, Shiqing Ma</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出黑盒prompt窃取框架，通过强化学习恢复主物体描述、模糊搜索恢复风格修饰，实现高准确率的prompt提取，评估生成模型的prompt安全风险，属于大模型安全与对齐中的安全攻击研究。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22119' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Aligning Artificial Superintelligence via a Multi-Box Protocol</h3>
<p><strong>Authors:</strong> Avraham Yair Negozio</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出多盒协议解决ASI对齐问题，通过隔离系统的互验证与声誉机制确保对齐，直接对应大模型安全与对齐方向。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21779' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> AI Deception: Risks, Dynamics, and Controls</h3>
<p><strong>Authors:</strong> Boyuan Chen (Jay), Sitong Fang (Jay), Jiaming Ji (Jay), Yanxu Zhu (Jay), Pengcheng Wen (Jay), Jinzhou Wu (Jay), Yingshui Tan (Jay), Boren Zheng (Jay), Mengying Yuan (Jay), Wenqi Chen (Jay), Donghai Hong (Jay), Alex Qiu (Jay), Xin Chen (Jay), Jiayi Zhou (Jay), Kaile Wang (Jay), Juntao Dai (Jay), Borong Zhang (Jay), Tianzhuo Yang (Jay), Saad Siddiqui (Jay), Isabella Duan (Jay), Yawen Duan (Jay), Brian Tse (Jay), Jen-Tse Huang, Kun Wang, Baihui Zheng, Jiaheng Liu, Jian Yang, Yiming Li, Wenting Chen, Dongrui Liu, Lukas Vierling, Zhiheng Xi, Haobo Fu, Wenxuan Wang, Jitao Sang, Zhengyan Shi, Chi-Min Chan, Eugenie Shi, Simin Li, Juncheng Li, Wei Ji, Dong Li, Jun Song, Yinpeng Dong, Jie Fu, Bo Zheng, Min Yang, Yike Guo, Philip Torr, Zhongyuan Wang, Yaodong Yang, Tiejun Huang, Ya-Qin Zhang, Hongjiang Zhang, Andrew Yao</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 系统综述AI欺骗的概念、机制与缓解策略，结合信号理论定义AI欺骗，分析其激励基础与触发条件，对大模型安全与对齐中的欺骗风险研究有全面参考价值。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22619' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond Real versus Fake Towards Intent-Aware Video Analysis</h3>
<p><strong>Authors:</strong> Saurabh Atreya, Nabyl Quignon, Baptiste Chopin, Abhijit Das, Antitza Dantcheva</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出IntentHQ基准从真实性验证转向意图分析，提升视频contextual understanding，属于大模型安全与对齐的意图识别研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22455' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Cross-Generator Image Forgery Detection through DINOv3</h3>
<p><strong>Authors:</strong> Zhenglin Huang, Jason Li, Haiquan Wen, Tianxiao Li, Xi Yang, Lu Qi, Bei Peng, Xiaowei Huang, Ming-Hsuan Yang, Guangliang Cheng</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 用DINOv3实现跨生成器图像伪造检测，发现基础模型的transferable cues并提升性能，属于大模型安全与对齐的伪造检测研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22471' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Safety and Security Framework for Real-World Agentic Systems</h3>
<p><strong>Authors:</strong> Shaona Ghosh, Barnaby Simkin, Kyriacos Shiarlis, Soumili Nandi, Dan Zhao, Matthew Fiedler, Julia Bazinska, Nikki Pope, Roopa Prabhu, Daniel Rohrer, Michael Demoret, Bartley Richardson (NVIDIA)</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出动态agentic安全框架，统一传统安全与agentic特有的风险（如工具误用、 cascading action chains），通过NVIDIA AI-Q Research Assistant案例验证有效性，释放10,000+条攻击防御轨迹数据集，对企业级agentic系统安全有实际指导价值。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.21990' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Does Self-Evaluation Enable Wireheading in Language Models?</h3>
<p><strong>Authors:</strong> David Demitri Africa, Hans Ethan Ting</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 实证研究自我评估与奖励耦合的wireheading风险，发现模型分数膨胀但精度未提升，对大模型安全与对齐中的奖励设计有关键启示。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.23092' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RemedyGS: Defend 3D Gaussian Splatting against Computation Cost Attacks</h3>
<p><strong>Authors:</strong> Yanping Li, Zhening Liu, Zijian Li, Zehong Lin, Jun Zhang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出针对3D Gaussian Splatting的计算成本攻击的防御框架，通过检测器识别 poisoned图像、净化器恢复良性图像，提升生成模型的安全性，属于大模型安全与对齐中的防御技术。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22147' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Decomposed Trust: Exploring Privacy, Adversarial Robustness, Fairness, and Ethics of Low-Rank LLMs</h3>
<p><strong>Authors:</strong> Daniel Agyei Asante, Md Mokarram Chowdhury, Yang Li</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 首次全面研究低秩因子分解对LLM可信度的影响（涵盖隐私、对抗鲁棒性、公平性、伦理对齐），发现压缩可提升隐私但削弱PII保护、增强鲁棒性但降低公平性，为可信模型压缩策略提供关键 insights。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22099' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Enhancing Trustworthiness with Mixed Precision: Benchmarks, Opportunities, and Challenges</h3>
<p><strong>Authors:</strong> Guanxi Lu, Hao Mark Chen, Zhiqiang Que, Wayne Luk, Hongxiang Fan</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 研究量化对LLM可信度的影响，提出精度集成方法提升可信度，符合大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22483' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Difficulties with Evaluating a Deception Detector for AIs</h3>
<p><strong>Authors:</strong> Lewis Smith, Bilal Chughtai, Neel Nanda</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 分析AI欺骗检测器的评估困难，属于大模型安全与对齐的LLM safety方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2511.22662' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> The Collapse of Patches</h3>
<p><strong>Authors:</strong> Wei Guo, Shunqi Mao, Zhuonan Liang, Heng Wang, Weidong Cai</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 发现图像patch的collapse现象，提出基于PageRank的patch顺序方法改善掩码图像建模，对深度学习理论中的网络结构与掩码模型研究有重要价值。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.22281' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> The Hidden Cost of Approximation in Online Mirror Descent</h3>
<p><strong>Authors:</strong> Ofir Schlisselberg, Uri Sherman, Tomer Koren, Yishay Mansour</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 系统分析在线镜像下降的近似误差影响，属于深度学习理论中的优化器方向。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.22283' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Intelligent Neural Networks: From Layered Architectures to Graph-Organized Intelligence</h3>
<p><strong>Authors:</strong> Antoine Salomon</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出图结构智能神经网络，实现范式转移并提升性能，属于深度学习理论的network architecture方向。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.22813' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Provable Benefits of Sinusoidal Activation for Modular Addition</h3>
<p><strong>Authors:</strong> Tianlong Huang, Zhiyuan Li</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 理论证明正弦激活在模加法学习中的优势（宽度2即可精确实现，而ReLU需线性宽度），并推导泛化边界，直接对应深度学习理论中的激活函数与网络架构研究。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.23443' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Markovian Scale Prediction: A New Era of Visual Autoregressive Generation</h3>
<p><strong>Authors:</strong> Yu Zhang, Jingyi Liu, Yiwei Shi, Qi Zhang, Duoqian Miao, Changwei Wang, Longbing Cao</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 将视觉自回归模型重构为马尔可夫过程，提出 Markov-VAR 减少内存消耗 83.8% 并降低 FID 10.5%，为自回归模型结构设计提供新范式。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.23334' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Exact Learning of Arithmetic with Differentiable Agents</h3>
<p><strong>Authors:</strong> Hristo Papazov, Francesco D'Angelo, Nicolas Flammarion</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 用可微分有限状态 transducer框架学习精确算术，属于深度学习理论的network architecture方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.22751' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Unified and Stable Risk Minimization Framework for Weakly Supervised Learning with Theoretical Guarantees</h3>
<p><strong>Authors:</strong> Miao Zhang, Junpeng Li, Changchun Hua, Yana Yang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出弱监督学习的统一风险最小化框架并提供理论保证，属于深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.22823' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Understanding Transformers in Learning Random Walks</h3>
<p><strong>Authors:</strong> Wei Shi, Yuan Cao</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 理论分析Transformer学习随机游走的能力边界，揭示训练后模型的注意力机制可解释性（聚焦父节点+概率转移），直接对应深度学习理论方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.23239' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Vision Bridge Transformer at Scale</h3>
<p><strong>Authors:</strong> Zhenxiong Tan, Zeqing Wang, Xingyi Yang, Songhua Liu, Xinchao Wang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出大规模 Brownian Bridge Transformer（ViBT），采用方差稳定速度匹配目标实现高效条件生成，为视觉 Transformer 架构设计提供新视角。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.23199' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Closed-Loop Transformers: Autoregressive Modeling as Iterative Latent Equilibrium</h3>
<p><strong>Authors:</strong> Akbar Anbar Jafari, Gholamreza Anbarjafari</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出闭环预测原理及EqT模型，通过迭代优化潜在表示解决open-loop autoregression的commitment瓶颈，理论证明其为近似MAP推理、线性收敛，并在二进制奇偶任务上验证了 deliberation 对难例的性能提升（+8.07%），是transformer架构的基础改进。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2511.21882' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> INSIGHT: An Interpretable Neural Vision-Language Framework for Reasoning of Generative Artifacts</h3>
<p><strong>Authors:</strong> Anshul Bagaria</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出可解释多模态框架，结合超分辨率、Grad-CAM和CLIP解释AI生成图像的artifacts，提升检测鲁棒性与解释质量，符合深度学习可解释性方向。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22351' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Revisiting the Necessity of Lengthy Chain-of-Thought in Vision-centric Reasoning Generalization</h3>
<p><strong>Authors:</strong> Yifan Du, Kun Zhou, Yingqian Min, Yue Ling, Wayne Xin Zhao, Youbin Wu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 系统研究视觉推理中Chain-of-Thought设计对泛化的影响，发现简洁CoT更利于泛化，为可解释性推理提供实践指导，属于深度学习可解释性方向。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22586' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Cue3D: Quantifying the Role of Image Cues in Single-Image 3D Generation</h3>
<p><strong>Authors:</strong> Xiang Li, Zirui Wang, Zixuan Huang, James M. Rehg</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出Cue3D框架量化单图像3D生成模型对阴影、纹理、轮廓等图像cues的依赖，揭示模型的推理逻辑，提升模型透明度，属于深度学习可解释性中的模型行为分析。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22121' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Partially Shared Concept Bottleneck Models</h3>
<p><strong>Authors:</strong> Delong Zhao, Qiang Huang, Di Yan, Yiqun Sun, Jun Yu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出PS-CBM框架，通过多模态概念生成、部分共享概念策略解决概念瓶颈模型的视觉 grounding和冗余问题，提升可解释性和分类 accuracy，属于深度学习可解释性中的模型改进。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22170' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Illusion to Intention: Visual Rationale Learning for Vision-Language Reasoning</h3>
<p><strong>Authors:</strong> Changpeng Wang, Haozhe Wang, Xi Chen, Junhan Liu, Taofeng Xue, Chong Peng, Donglian Qi, Fangzhen Lin, Yunfeng Yan</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出视觉理据学习范式，将视觉动作作为推理原语，通过过程监督与细粒度 credit assignment 实现透明可验证的视觉推理，直接解决“推理幻觉”问题，提升模型可解释性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.23031' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Space Explanations of Neural Network Classification</h3>
<p><strong>Authors:</strong> Faezeh Labbaf, Tomáš Kolárik, Martin Blicha, Grigory Fedyukovich, Michael Wand, Natasha Sharygina</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出逻辑-based空间解释方法，提供神经网络分类的可证明解释，符合深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22498' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ARM-Explainer -- Explaining and improving graph neural network predictions for the maximum clique problem using node features and association rule mining</h3>
<p><strong>Authors:</strong> Bharat Sharman, Elkafi Hassini</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出基于关联规则挖掘的后验解释框架ARM-Explainer，可识别影响GNN预测的关键节点特征并通过特征增强提升GNN性能，直接对应深度学习可解释性研究方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22866' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Delta-XAI: A Unified Framework for Explaining Prediction Changes in Online Time Series Monitoring</h3>
<p><strong>Authors:</strong> Changhun Kim, Yechan Mun, Hyeongwon Jang, Eunseo Lee, Sangchul Hahn, Eunho Yang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出统一框架Delta-XAI解决在线时间序列模型的预测变化解释问题，评估现有XAI方法并提出SWING增强时间依赖捕捉能力，符合深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.23036' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Intra-Class Probabilistic Embeddings for Uncertainty Estimation in Vision-Language Models</h3>
<p><strong>Authors:</strong> Zhenxiang Lin, Maryam Haghighat, Will Browne, Dimity Miller</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出训练-free的类内概率嵌入方法，通过建模视觉特征的类内一致性估计VLM的不确定性，提升模型在安全关键场景的可靠性，属于深度学习可解释性中的不确定性分析。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22019' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Topology to Retrieval: Decoding Embedding Spaces with Unified Signatures</h3>
<p><strong>Authors:</strong> Florian Rottach, William Rudman, Bastain Rieck, Harrisen Scells, Carsten Eickhoff</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 研究嵌入空间的拓扑与几何特征，通过统一拓扑签名增强模型可解释性，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22150' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mechanistic Finetuning of Vision-Language-Action Models via Few-Shot Demonstrations</h3>
<p><strong>Authors:</strong> Chancharik Mitra, Yusen Luo, Raj Saravanan, Dantong Niu, Anirudh Pai, Jesse Thomason, Trevor Darrell (University of California, Berkeley), Abrar Anwar, Deva Ramanan (Carnegie Mellon University), Roei Herzig</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出基于机械可解释性的Robotic Steering微调方法，通过少样本演示识别并选择性微调VLAs模型中与机器人任务物理、视觉和语言需求对齐的任务特定注意力头，提升了模型适应性与可解释性，作者团队包含Trevor Darrell等领域权威，与深度学习可解释性方向高度相关。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2511.22697' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Decoupled DMD: CFG Augmentation as the Spear, Distribution Matching as the Shield</h3>
<p><strong>Authors:</strong> Dongyang Liu, Peng Gao, David Liu, Ruoyi Du, Zhen Li, Qilong Wu, Xin Jin, Sihan Cao, Shifeng Zhang, Hongsheng Li, Steven Hoi</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 深入分解扩散模型蒸馏（DMD）的训练目标，揭示CFG增强是少步蒸馏的核心动力、分布匹配为正则化器，并提出解耦策略提升性能，该方法被Z-Image项目采用构建高效图像生成模型，理论与实践结合紧密。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22677' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Saddle-Free Guidance: Improved On-Manifold Sampling without Labels or Additional Training</h3>
<p><strong>Authors:</strong> Eric Yeats, Darryl Hannan, Wilson Fearn, Timothy Doster, Henry Kvinge, Scott Mahan</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出无需额外训练或标签的saddle-free引导方法，通过利用对数密度的正曲率提升score-based生成模型（如diffusion）的采样质量和多样性，属于大模型新技术中的生成模型改进。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21863' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Toward Diffusible High-Dimensional Latent Spaces: A Frequency Perspective</h3>
<p><strong>Authors:</strong> Bolin Lai, Xudong Wang, Saketh Rambhatla, James M. Rehg, Zsolt Kira, Rohit Girdhar, Ishan Misra</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 分析扩散模型高维latent的高频问题，提出FreqWarm方法提升高维latent生成质量，属于大模型新技术的diffusion相关研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22249' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TTSnap: Test-Time Scaling of Diffusion Models via Noise-Aware Pruning</h3>
<p><strong>Authors:</strong> Qingtao Yu, Changlin Song, Minghao Sun, Zhengyang Yu, Vinay Kumar Verma, Soumya Roy, Sumit Negi, Hongdong Li, Dylan Campbell</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出噪声感知剪枝的测试时缩放方法，加速扩散模型推理并提升生成性能，属于大模型新技术的diffusion推理优化研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22242' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Flowing Backwards: Improving Normalizing Flows via Reverse Representation Alignment</h3>
<p><strong>Authors:</strong> Yang Chen, Xiaowei Xu, Shuai Wang, Chenhui Zhu, Ruxue Wen, Xubin Li, Tiezheng Ge, Limin Wang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 利用归一化流的可逆性对齐逆向生成特征，提升生成质量与分类准确性，属于大模型新技术的flow模型研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22345' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AnchorFlow: Training-Free 3D Editing via Latent Anchor-Aligned Flows</h3>
<p><strong>Authors:</strong> Zhenglin Zhou, Fan Ma, Chengzhuo Gui, Xiaobo Xia, Hehe Fan, Yi Yang, Tat-Seng Chua</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出训练-free 3D编辑框架，用latent anchor对齐流提升编辑稳定性与语义忠实度，属于大模型新技术的3D diffusion/flow研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22357' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BlockVid: Block Diffusion for High-Quality and Consistent Minute-Long Video Generation</h3>
<p><strong>Authors:</strong> Zeyu Zhang, Shuning Chang, Yuanyu He, Yizeng Han, Jiasheng Tang, Fan Wang, Bohan Zhuang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出块扩散框架解决长视频生成的误差积累与一致性问题，通过语义感知稀疏KV缓存、块强制训练等策略生成高质量分钟级视频，构建LV-Bench基准评估长视频连贯性，推动长视频生成技术进步。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22973' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> NumeriKontrol: Adding Numeric Control to Diffusion Transformers for Instruction-based Image Editing</h3>
<p><strong>Authors:</strong> Zhenyu Xu, Xiaoqi Shen, Haotian Nan, Xinyu Zhang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出数值适配器与 CAT 数据集，实现扩散模型的精确数值控制图像编辑，支持零-shot 多条件编辑，提升指令驱动编辑的精度与可控性。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.23105' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Flow Straighter and Faster: Efficient One-Step Generative Modeling via MeanFlow on Rectified Trajectories</h3>
<p><strong>Authors:</strong> Xinxi Zhang, Shiwei Tan, Quang Nguyen, Quan Dao, Ligong Han, Xiaoxiao He, Tunyu Zhang, Alen Mrdovic, Dimitris Metaxas</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出 Rectified MeanFlow 结合整流轨迹与均值流，改进 flow-based 模型的训练效率与采样质量，在 ImageNet 多分辨率上超过现有单步生成方法。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.23342' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DisMo: Disentangled Motion Representations for Open-World Motion Transfer</h3>
<p><strong>Authors:</strong> Thomas Ressler-Antal, Frank Fundel, Malek Ben Alaya, Stefan Andreas Baumann, Felix Krause, Ming Gui, Björn Ommer</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出 DisMo 通过图像空间重建学习分离的运动表示，实现开放世界运动迁移，提升视频生成与运动理解性能，零-shot 动作分类超过 V-JEPA。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.23428' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Adversarial Flow Models</h3>
<p><strong>Authors:</strong> Shanchuan Lin, Ceyuan Yang, Zhijie Lin, Hao Chen, Haoqi Fan</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 统一对抗模型与流模型，稳定生成训练并提升性能，属于大模型新技术方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22475' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Test-time scaling of diffusions with flow maps</h3>
<p><strong>Authors:</strong> Amirmojtaba Sabour, Michael S. Albergo, Carles Domingo-Enrich, Nicholas M. Boffi, Sanja Fidler, Karsten Kreis, Eric Vanden-Eijnden</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 用流图改进扩散模型的测试时间奖励优化，属于大模型新技术的diffusion LLM方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22688' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Masked Diffusion for Generative Recommendation</h3>
<p><strong>Authors:</strong> Kulin Shah, Bhuvesh Kumar, Neil Shah, Liam Collins</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 将masked diffusion引入生成式推荐，替代自回归建模实现并行解码，提升推理效率与性能，属于大模型新技术中的diffusion应用方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.23021' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ThetaEvolve: Test-time Learning on Open Problems</h3>
<p><strong>Authors:</strong> Yiping Wang, Shao-Rong Su, Zhiyuan Zeng, Eva Xu, Liliang Ren, Xinyu Yang, Zeyi Huang, Xuehai He, Luyao Ma, Baolin Peng, Hao Cheng, Pengcheng He, Weizhu Chen, Shuohang Wang, Simon Shaolei Du, Yelong Shen</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出ThetaEvolve框架，通过测试时RL优化让小模型（如DeepSeek-R1-0528-Qwen3-8B）实现开放问题的新边界突破，属于大模型新技术中的测试时学习方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.23473' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UniArt: Unified 3D Representation for Generating 3D Articulated Objects with Open-Set Articulation</h3>
<p><strong>Authors:</strong> Bu Jin, Weize Li, Songen Gu, Yupeng Zheng, Yuhang Zheng, Zhengyi Zhou, Yao Yao</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出基于diffusion的端到端框架，统一编码3D铰接物体的几何、纹理、分割和运动参数，实现开放集铰接的3D物体生成，属于大模型新技术中的3D生成改进。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.21887' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> BrepGPT: Autoregressive B-rep Generation with Voronoi Half-Patch</h3>
<p><strong>Authors:</strong> Pu Li, Wenhao Zhang, Weize Quan, Biao Zhang, Peter Wonka, Dong-Ming Yan</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出单阶段自回归框架，用Voronoi Half-Patch表示统一B-rep的几何与拓扑信息，实现高效的CAD B-rep模型生成，属于大模型新技术中的CAD生成改进。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22171' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Controllable 3D Object Generation with Single Image Prompt</h3>
<p><strong>Authors:</strong> Jaeseok Lee, Jaekoo Lee</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出无需textual inversion的单图像 prompt 3D生成方法，通过image adapter和depth条件预热策略提升控制能力和3D一致性，属于大模型新技术中的3D生成改进。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22194' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> 3D-Consistent Multi-View Editing by Diffusion Guidance</h3>
<p><strong>Authors:</strong> Josef Bengtson, David Nilsson, Dong In Lee, Fredrik Kahl</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出训练-free的diffusion框架，通过一致性损失引导多视图一致的图像编辑，提升3D模型（如Gaussian Splat）的编辑质量，属于大模型新技术中的diffusion应用改进。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22228' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Guiding Visual Autoregressive Models through Spectrum Weakening</h3>
<p><strong>Authors:</strong> Chaoyang Wang, Tianmeng Yang, Jingdong Wang, Yunhai Tong</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出频谱弱化框架改进视觉自回归模型的生成质量，通过在谱域构建可控弱模型，无需重新训练或修改架构，实现无条件生成质量提升与条件生成的prompt对齐，理论分析与实验验证结合。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22991' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Adversarial Training for Process Reward Models</h3>
<p><strong>Authors:</strong> Gurusha Juneja, Deepak Nathani, William Yang Wang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出对抗训练的过程奖励模型APRM，通过生成推理错误样本提升PRM的鲁棒性与泛化能力，增强LLM数学推理性能，属于大模型新技术范畴。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2511.22888' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SpaceMind: Camera-Guided Modality Fusion for Spatial Reasoning in Vision-Language Models</h3>
<p><strong>Authors:</strong> Ruosen Zhao, Zhikang Zhang, Jialei Xu, Jiahao Chang, Dong Chen, Lingyun Li, Weijian Sun, Zizhuang Wei</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出双编码器架构与相机引导模态融合模块，将相机表示作为主动引导模态增强 VLMs 的 3D 空间推理能力，在多个空间推理基准上取得 SOTA 性能。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.23075' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> VQRAE: Representation Quantization Autoencoders for Multimodal Understanding, Generation and Reconstruction</h3>
<p><strong>Authors:</strong> Sinan Du, Jiahao Guo, Bo Li, Shuhao Cui, Zhengzhuo Xu, Yifu Luo, Yongxian Wei, Kun Gai, Xinggang Wang, Kai Wu, Chun Yuan</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出 VQRAE 统一多模态理解、生成与重建的表示，通过向量量化与两阶段训练实现连续语义特征与离散生成 tokens 的统一，在多任务上取得 competitive 性能。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.23386' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SO-Bench: A Structural Output Evaluation of Multimodal LLMs</h3>
<p><strong>Authors:</strong> Di Feng, Kaixin Ma, Feng Nan, Haofeng Chen, Bohan Zhai, David Griffiths, Mingfei Gao, Zhe Gan, Eshan Verma, Yinfei Yang, Zhifeng Chen, Afshin Dehghan</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 构建SO-Bench基准系统评估多模态LLM的结构输出能力，揭示其在视觉结构化推理中的性能差距，为原生多模态大模型的结构化推理研究提供重要参考。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21750' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PAT3D: Physics-Augmented Text-to-3D Scene Generation</h3>
<p><strong>Authors:</strong> Guying Lin, Kemeng Huang, Michael Liu, Ruihan Gao, Hanke Chen, Lyuhao Chen, Beijia Lu, Taku Komura, Yuan Liu, Jun-Yan Zhu, Minchen Li</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 结合视觉-语言模型与物理模拟，提出物理增强的文本到3D场景生成框架，生成物理合理、 simulation-ready的3D场景，属于原生多模态大模型中的文本到3D生成任务。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21978' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MoE3D: Mixture of Experts meets Multi-Modal 3D Understanding</h3>
<p><strong>Authors:</strong> Yu Li, Yuenan Hou, Yingmei Wei, Xinge Zhu, Yuexin Ma, Wenqi Shao, Yanming Guo</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 将MoE架构引入多模态3D理解，通过专家网络处理不同模态和交叉模态交互，提升多模态特征融合性能，属于原生多模态大模型的结构改进。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22103' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Semantic Anchoring for Robust Personalization in Text-to-Image Diffusion Models</h3>
<p><strong>Authors:</strong> Seoyun Yang, Gihoon Kim, Taesup Kim</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出语义锚定方法解决文本到图像扩散模型个性化的过拟合与先验保留问题，提升subject fidelity与text-image对齐，属于原生多模态大模型的image generation方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22245' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HarmoCLIP: Harmonizing Global and Regional Representations in Contrastive Vision-Language Models</h3>
<p><strong>Authors:</strong> Haoxi Zeng, Haoxuan Li, Yi Bin, Pengpeng Zeng, Xing Xu, Yang Yang, Heng Tao Shen</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 调和CLIP的全局与局部表示，解决global-local trade-off并提升检索与区域任务性能，属于原生多模态大模型的VL model研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22594' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> REASONEDIT: Towards Reasoning-Enhanced Image Editing Models</h3>
<p><strong>Authors:</strong> Fukun Yin, Shiyu Liu, Yucheng Han, Zhibo Wang, Peng Xing, Rui Wang, Wei Cheng, Yingming Wang, Aojie Li, Zixin Yin, Pengtao Chen, Xiangyu Zhang, Daxin Jiang, Xianfang Zeng, Gang Yu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 结合MLLM的thinking与reflection机制提升图像编辑准确性，属于原生多模态大模型的image editing研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22625' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Architecture Decoupling Is Not All You Need For Unified Multimodal Model</h3>
<p><strong>Authors:</strong> Dian Zheng, Manyuan Zhang, Hongyu Li, Kai Zou, Hongbo Liu, Ziyu Guo, Kaituo Feng, Yexin Liu, Ying Luo, Yan Feng, Peng Pei, Xunliang Cai, Hongsheng Li</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 针对统一多模态模型（图像生成与理解）的任务冲突问题，分析模型解耦的局限性并提出注意力交互对齐（AIA）损失，以学习任务特定的多模态交互模式，有效提升生成与理解性能，作者团队在多模态领域有深厚积累。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22663' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Some Modalities are More Equal Than Others: Decoding and Architecting Multimodal Integration in MLLMs</h3>
<p><strong>Authors:</strong> Tianle Chen, Chaitanya Chakka, Arjun Reddy Akula, Xavier Thomas, Deepti Ghadiyaram</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 研究多模态大模型（MLLMs）对矛盾模态的鲁棒性问题，构建MMA-Bench基准分析模型缺陷，并提出模态对齐调优策略提升跨模态推理可靠性，结合黑盒与白盒可解释性分析，对多模态模型设计有重要指导意义。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22826' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Ovis-Image Technical Report</h3>
<p><strong>Authors:</strong> Guo-Hua Wang, Liangfu Cao, Tianyu Cui, Minghao Fu, Xiaohao Chen, Pengxin Zhan, Jianshan Zhao, Lan Li, Bowen Fu, Jiaqi Liu, Qing-Guo Chen</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出针对高质量文本渲染优化的7B参数文本到图像模型，基于Ovis 2.5多模态 backbone与文本中心训练 pipeline，在单GPU上实现部署，性能媲美更大规模模型，为高效多模态生成模型设计提供参考。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22982' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Buffer replay enhances the robustness of multimodal learning under missing-modality</h3>
<p><strong>Authors:</strong> Hongye Zhu, Xuan Liu, Yanwen Ba, Jingye Xue, Shigeng Zhang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出轻量级 REP 框架，通过模态特征缓冲与私有-共享特征解耦提升多模态模型在缺失模态下的鲁棒性，适用于多种多模态基准且仅引入可忽略参数 overhead。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.23070' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PowerCLIP: Powerset Alignment for Contrastive Pre-Training</h3>
<p><strong>Authors:</strong> Masaki Kawamura, Nakamasa Inoue, Rintaro Yanagi, Hirokatsu Kataoka, Rio Yokota</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出幂集对齐增强 CLIP 的组合语义理解，通过非线性能量聚合近似幂集，提升视觉语言预训练模型的零-shot 分类与检索性能。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.23170' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unlocking Multilingual Reasoning Capability of LLMs and LVLMs through Representation Engineering</h3>
<p><strong>Authors:</strong> Qiming Li, Xiaocheng Feng, Yixuan Ma, Zekai Ye, Ruihan Chen, Xiachong Feng, Bing Qin</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出训练-free 表示工程方法（MRRE），通过跨语言推理增强向量与目标语言锚定向量提升 LLMs/LVLMs 的多语言推理能力，低资源语言性能提升显著。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.23231' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Visual Generation Tuning</h3>
<p><strong>Authors:</strong> Jiahao Guo (hustvl), Sinan Du, Jingfeng Yao, Wenyu Liu, Bo Li, Haoxiang Cao, Kun Gai, Chun Yuan, Kai Wu, Xinggang Wang (hustvl)</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出VGT范式，通过高效视觉生成微调使预训练VLMs获得视觉生成能力，在图像重建（26.67 PSNR、0.50 rFID）和生成任务（GenEval 0.77、DPG-Bench 78.73）上优于专用模型，为探索下一代统一多模态基础模型提供新路径。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.23469' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Designing Instance-Level Sampling Schedules via REINFORCE with James-Stein Shrinkage</h3>
<p><strong>Authors:</strong> Peiyu Yu, Suraj Kothawade, Sirui Xie, Ying Nian Wu, Hongliang Fei</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 针对文本到图像生成的实例级采样调度优化，提升生成质量与对齐度，符合原生多模态大模型的image generation方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22177' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TIM-PRM: Verifying multimodal reasoning with Tool-Integrated PRM</h3>
<p><strong>Authors:</strong> Peng Kuang, Xiangxiang Wang, Wentao Liu, Jian Dong, Kaidi Xu, Haohan Wang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 针对多模态LLM的视觉幻觉与逻辑不一致问题，提出工具集成的PRM框架，通过主动工具查询验证推理步骤，提升多模态推理准确性与可解释性，对原生多模态大模型研究有推动作用。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22998' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DialBench: Towards Accurate Reading Recognition of Pointer Meter using Large Foundation Models</h3>
<p><strong>Authors:</strong> Futian Wang, Chaoliu Weng, Xiao Wang, Zhen Chen, Zhicheng Zhao, Jin Tang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 构建RPM-10K指针仪表数据集，提出基于物理关系注入的视觉-语言模型MRLM，提升仪表读数的准确性和物理推理能力，属于原生多模态大模型的视觉-语言推理应用。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.21982' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Layover or Direct Flight: Rethinking Audio-Guided Image Segmentation</h3>
<p><strong>Authors:</strong> Joel Alberto Santos, Zongwei Wu, Xavier Alameda-Pineda, Radu Timofte</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 挑战传统转录-文本-视觉的 pipeline，研究直接音频-视觉对齐的物体 grounding，提升多模态理解对 linguistic variability的鲁棒性，属于原生多模态大模型的音频-视觉融合改进。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22025' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> WorldWander: Bridging Egocentric and Exocentric Worlds in Video Generation</h3>
<p><strong>Authors:</strong> Quanjian Song, Yiren Song, Kelly Peng, Yuan Gao, Mike Zheng Shou</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出WorldWander框架和EgoExo-8K数据集，通过视角对齐和协作位置编码桥接第一人称与第三人称视频生成，提升多视角视频的一致性，属于原生多模态大模型的视频生成任务。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22098' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GA2-CLIP: Generic Attribute Anchor for Efficient Prompt Tuningin Video-Language Models</h3>
<p><strong>Authors:</strong> Bin Wang, Ruotong Hu, Wenqian Wang, Wentong Li, Mingliang Gao, Runmin Cong, Wei Zhang</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出通用属性锚点的prompt tuning方法，通过外部监督信号缓解语义空间 narrowing，提升视频-语言模型对 unseen类的泛化性，属于原生多模态大模型的prompt优化技术。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22125' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> IMTalker: Efficient Audio-driven Talking Face Generation with Implicit Motion Transfer</h3>
<p><strong>Authors:</strong> Bo Chen, Tao Liu, Qi Chen, Xie Chen, Zilong Zheng</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出隐式运动转移的框架，通过交叉注意力机制建模运动差异与身份对齐，提升音频驱动的说话人脸生成效率和质量，属于原生多模态大模型的音频-视觉生成改进。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22167' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Match-and-Fuse: Consistent Generation from Unstructured Image Sets</h3>
<p><strong>Authors:</strong> Kate Feingold, Omri Kaduri, Tali Dekel</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 用图模型与特征融合解决非结构化图像集的一致生成问题，提升跨图像一致性与视觉质量，属于原生多模态大模型的image generation方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22287' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Generative Anchored Fields: Controlled Data Generation via Emergent Velocity Fields and Transport Algebra</h3>
<p><strong>Authors:</strong> Deressa Wodajo Deressa, Hannes Mareen, Peter Lambert, Glenn Van Wallendael</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出生成锚定场框架实现可控数据生成，符合原生多模态大模型的image generation方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.22693' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> LatBot: Distilling Universal Latent Actions for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Zuolei Li, Xingyu Gao, Xiaofan Wang, Jianlong Fu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出Universal Latent Action Learning框架，从大规模物体操作视频中学习可转移的潜在动作，分解为运动和场景token以过滤无关动态，通过蒸馏提升VLA模型的泛化能力，在模拟和真实机器人任务中表现优异，与原生多模态大模型方向中的多模态大模型改进高度相关。
Score: 6
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2511.23034' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Can Multi-Modal LLMs Provide Live Step-by-Step Task Guidance?</h3>
<p><strong>Authors:</strong> Apratim Bhattacharyya, Bicheng Xu, Sanjay Haresh, Reza Pourreza, Litian Liu, Sunny Panchal, Pulkit Madan, Leonid Sigal, Roland Memisevic</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出Qualcomm Interactive Cooking基准和LiveMamba模型，研究多模态LLM的实时分步任务引导能力，解决现有模型无法异步响应视频流的问题，属于多模态智能体的交互任务改进。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.21998' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action</h3>
<p><strong>Authors:</strong> Zhen Fang, Zhuoyang Liu, Jiaming Liu, Hao Chen, Yu Zeng, Shiting Huang, Zehui Chen, Lin Chen, Shanghang Zhang, Feng Zhao</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出DualVLA框架，通过双层数据剪枝和双教师自适应蒸馏解决VLA模型的action degeneration问题，提升智能体的动作执行与多模态推理平衡能力，属于多模态智能体的改进。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.22134' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Guiding the Inner Eye: A Framework for Hierarchical and Flexible Visual Grounded Reasoning</h3>
<p><strong>Authors:</strong> Zhaoyang Wei, Wenchao Ding, Yanchao Hao, Xi Chen</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出GRiP框架，通过认知增强的RL和多启发式奖励提升视觉接地推理的鲁棒性和灵活性，解决现有模型推理路径僵化的问题，属于多模态智能体的推理改进。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.22172' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SkeletonAgent: An Agentic Interaction Framework for Skeleton-based Action Recognition</h3>
<p><strong>Authors:</strong> Hongda Liu, Yunfan Liu, Changlu Wang, Yunlong Wang, Zhenan Sun</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出Questioner与Selector双agent交互框架，结合LLM与动作识别模型提升骨架动作识别准确性，属于多模态智能体方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.22433' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MG-Nav: Dual-Scale Visual Navigation via Sparse Spatial Memory</h3>
<p><strong>Authors:</strong> Bo Wang, Jiehong Lin, Chenzhi Liu, Xinting Hu, Yifei Yu, Tianjia Liu, Zhongrui Wang, Xiaojuan Qi</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出双尺度视觉导航框架，用稀疏空间记忆提升零样本性能与鲁棒性，属于多模态智能体的GUI navigation方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.22609' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> JarvisEvo: Towards a Self-Evolving Photo Editing Agent with Synergistic Editor-Evaluator Optimization</h3>
<p><strong>Authors:</strong> Yunlong Lin, Linqing Wang, Kunjie Lin, Zixu Lin, Kaixiong Gong, Wenbo Li, Bin Lin, Zhenxi Li, Shiyi Zhang, Yuyang Peng, Wenxun Dai, Xinghao Ding, Chunyu Wang, Qinglin Lu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出自进化图像编辑智能体，通过多模态 interleaved CoT 推理与协同 editor-evaluator 优化解决指令幻觉和奖励攻击问题，在图像编辑基准上显著超越现有模型，属于多模态智能体的典型改进。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.23002' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Real-Time Procedural Learning From Experience for AI Agents</h3>
<p><strong>Authors:</strong> Dasheng Bi, Yubin Hu, Mohammed N. Nasir</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 提出PRAXIS框架让AI Agent实时从经验中学习程序知识，提升web浏览任务的完成度与效率，对应多模态智能体中的Agent学习需求。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.22074' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Training High-Level Schedulers with Execution-Feedback Reinforcement Learning for Long-Horizon GUI Automation</h3>
<p><strong>Authors:</strong> Zehao Deng, Tianjie Ju, Zheng Wu, Zhuosheng Zhang, Gongshen Liu</p>
<p><strong>Published:</strong> 2025-12-01</p>
<p><strong>Reason:</strong> 针对GUI智能体长程任务的责任耦合与状态感知缺失问题，提出CES多代理框架，通过训练高层调度模型提升规划与状态管理能力，对多模态智能体中的GUI Agent研究有重要实践价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2511.22235' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>