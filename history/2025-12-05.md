# ArXiv 每日推荐 - 2025-12-05

> 更新于北京时间：2025-12-05 12:34:57
> 已自动阅读了 285 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：143186

## 高效大模型训练与推理

### [Score: 9.0/10] ConvRot: Rotation-Based Plug-and-Play 4-bit Quantization for Diffusion Transformers
- **Authors:** Feice Huang, Zuliang Han, Xing Zhou, Yihuang Chen, Lifei Zhu, Haoqian Wang
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03673](https://arxiv.org/abs/2512.03673)
- **Reason:** 提出基于旋转的即插即用4位量化方法，显著提升扩散Transformer推理速度与内存效率，对扩散模型高效部署有重要实用价值
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] GalaxyDiT: Efficient Video Generation with Guidance Alignment and Adaptive Proxy in Diffusion Transformers
- **Authors:** Zhiye Song, Steve Dai, Ben Keller, Brucek Khailany
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03451](https://arxiv.org/abs/2512.03451)
- **Reason:** 提出GalaxyDiT通过引导对齐和自适应代理加速视频生成，属于高效大模型训练与推理中diffusion模型的加速方法，实验验证Wan2.1模型上1.87-2.37倍加速且质量损失小。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] NAS-LoRA: Empowering Parameter-Efficient Fine-Tuning for Visual Foundation Models with Searchable Adaptation
- **Authors:** Renqi Chen, Haoyang Su, Shixiang Tang
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03499](https://arxiv.org/abs/2512.03499)
- **Reason:** 提出NAS-LoRA结合NAS与LoRA，增强视觉基础模型的参数高效微调，属于高效大模型训练与推理中的PEFT改进，实验显示比现有方法更优且训练成本降低24.14%。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition
- **Authors:** Zichuan Lin, Yicheng Liu, Yang Yang, Lvfang Tao, Deheng Ye
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03794](https://arxiv.org/abs/2512.03794)
- **Reason:** 基于主动视觉机制实现自适应视觉token获取，大幅降低视觉-语言模型的计算开销，符合高效大模型研究方向
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Cache What Lasts: Token Retention for Memory-Bounded KV Cache in LLMs
- **Authors:** Ngoc Bui, Shubham Sharma, Simran Lamba, Saumitra Mishra, Rex Ying
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03324](https://arxiv.org/abs/2512.03324)
- **Reason:** 针对LLM长上下文推理的KV缓存内存瓶颈，提出学习型token保留策略TRIM-KV，通过轻量级retention gate和蒸馏训练优化token eviction，性能优于现有启发式或学习型方法，还提供了layer和head层面的可解释性 insights，对高效大模型推理有重要价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] UniQL: Unified Quantization and Low-rank Compression for Adaptive Edge LLMs
- **Authors:** Hung-Yueh Chiang, Chi-Chih Chang, Yu-Chen Lu, Chien-Yu Lin, Kai-Chiang Wu, Mohamed S. Abdelfattah, Diana Marculescu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03383](https://arxiv.org/abs/2512.03383)
- **Reason:** 提出统一的量化与低秩压缩框架，支持Transformer、SSM及混合模型在边缘设备的部署，通过weight-sorting、量化感知SVD等技术实现内存减少4x-5.7x、吞吐量提升2.7x-3.4x，同时保持精度，是高效大模型边缘部署的重要进展。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training
- **Authors:** Dingwei Zhu, Zhiheng Xi, Shihan Dou, Yuhui Wang, Sixian Li, Junjie Ye, Honglin Guo, Shichun Liu, Chenhao Huang, Yajie Yang, Junlin Shang, Senjie Jin, Ming Zhang, Jiazheng Zhang, Caishuang Huang, Yunke Zhang, Demei Yan, Yuran Wang, Tao Gui
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03847](https://arxiv.org/abs/2512.03847)
- **Reason:** 提出DVPO框架，将条件风险理论与分布值建模结合，优化LLM的post-training，解决噪声监督下的鲁棒性与泛化性平衡问题，在多轮对话、数学推理等任务中优于现有RL方法，对高效大模型训练中的post-training阶段有重要价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Optical Context Compression Is Just (Bad) Autoencoding
- **Authors:** Ivan Yee Lee, Cheng Yang, Taylor Berg-Kirkpatrick
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03643](https://arxiv.org/abs/2512.03643)
- **Reason:** 研究视觉上下文压缩的有效性，对比不同压缩方法对语言建模的影响，为高效视觉-语言模型设计提供关键启示
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation
- **Authors:** Letian Zhou, Songhua Liu, Xinchao Wang
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03844](https://arxiv.org/abs/2512.03844)
- **Reason:** 提出无训练数据集蒸馏方法，利用文本-图像扩散模型生成高质量蒸馏数据，显著提升模型训练的数据效率
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing
- **Authors:** Roman Rausch, David Jansen, Sukhbinder Singh, Román Orús
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03062](https://arxiv.org/abs/2512.03062)
- **Reason:** 提出基于费米函数的秩选择和规范固定方法，实现LLM的全局优化SVD压缩，解决了层内秩选择和参数冗余问题，提升了大模型压缩效率，属于高效大模型训练与推理中的高压缩方向。
Score: 7
Field: 高效大模型训练与推理

## 原生多模态大模型

### [Score: 9.0/10] Thinking with Programming Vision: Towards a Unified View for Thinking with Images
- **Authors:** Zirun Guo, Minjie Hong, Feng Zhang, Kai Jia, Tao Jin
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03746](https://arxiv.org/abs/2512.03746)
- **Reason:** 提出CodeVision框架，以代码为通用工具整合语言与视觉能力，提升多模态大模型的鲁棒性与工具使用灵活性
Score: 9
Field: 原生多模态大模型

### [Score: 9.0/10] UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework
- **Authors:** Youxin Pang, Yong Zhang, Ruizhi Shao, Xiang Deng, Feng Gao, Xu Xiaoming, Xiaoming Wei, Yebin Liu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03918](https://arxiv.org/abs/2512.03918)
- **Reason:** 提出统一2D视频与3D人体运动的自回归模型，实现多模态数据的联合生成与理解，是原生多模态大模型的关键创新
Score: 9
Field: 原生多模态大模型

### [Score: 8.0/10] OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation
- **Authors:** Zhishan Zhou, Siyuan Wei, Zengran Wang, Chunjie Wang, Xiaosheng Yan, Xiao Liu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03532](https://arxiv.org/abs/2512.03532)
- **Reason:** 提出OpenTrack3D开放词汇3D实例分割框架，结合视觉-空间 tracker与MLLM，属于原生多模态大模型中3D与语言的开放词汇任务，实验验证多个基准上SOTA。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Rethinking Prompt Design for Inference-time Scaling in Text-to-Visual Generation
- **Authors:** Subin Kim, Sangwoo Mo, Mamshad Nayeem Rizve, Yiran Xu, Difan Liu, Jinwoo Shin, Tobias Hinz
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03534](https://arxiv.org/abs/2512.03534)
- **Reason:** 提出PRIS框架在推理时自适应修改prompt，提升文本到视觉生成的对齐，属于原生多模态大模型中的prompt工程，实验验证VBench 2.0上提升15%。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning
- **Authors:** Tao Wu, Li Yang, Gen Zhan, Yiting Liao, Junlin Li, Deliang Fu, Li Zhang, Limin Wang
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03963](https://arxiv.org/abs/2512.03963)
- **Reason:** 通过时间感知多任务强化学习增强多模态大模型的时间推理能力，支持长视频分析等复杂任务，推动多模态理解向时间维度延伸
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models
- **Authors:** Xiwen Wei, Mustafa Munir, Radu Marculescu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03125](https://arxiv.org/abs/2512.03125)
- **Reason:** 研究统一多模态生成模型持续学习中的模态内和模态间遗忘问题，提出模态解耦专家架构，有效缓解了模态间梯度冲突，属于原生多模态大模型的持续学习优化，对多模态模型的长期迭代学习有重要价值。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval
- **Authors:** Constantin Venhoff, Ashkan Khakzar, Sonia Joseph, Philip Torr, Neel Nanda
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03276](https://arxiv.org/abs/2512.03276)
- **Reason:** 分析视觉语言模型（VLMs）事实召回的“两跳问题”（视觉输入到实体表示、实体表示到知识召回），通过机制分析解释了性能退化原因并提出改进方法，属于原生多模态大模型中的知识对齐与检索关键问题研究。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] Object Counting with GPT-4o and GPT-5: A Comparative Study
- **Authors:** Richard Füzesséry, Kaziwa Saleh, Sándor Szénási, Zoltán Vámossy
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03233](https://arxiv.org/abs/2512.03233)
- **Reason:** 比较GPT-4o与GPT-5的零样本目标计数能力，涉及多模态大模型的视觉-语言对齐，结果显示其性能接近或超越现有零样本方法，对原生多模态大模型的视觉能力评估有参考价值。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] LLM-Guided Material Inference for 3D Point Clouds
- **Authors:** Nafiseh Izadyar, Teseo Schneider
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03237](https://arxiv.org/abs/2512.03237)
- **Reason:** 提出LLM引导的3D点云材料推理方法，将LLM的语言先验与3D几何信息结合，实现零样本材料分配，属于原生多模态大模型中3D与语言的跨模态对齐研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] ViDiC: Video Difference Captioning
- **Authors:** Jiangtao Wu, Shihao Li, Zhaozhou Bian, Yuanxing Zhang, Jialu Chen, Runzhe Wen, An Ping, Yiwen He, Jiakai Wang, Jiaheng Liu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03405](https://arxiv.org/abs/2512.03405)
- **Reason:** 提出视频差异captioning任务及ViDiC-1K数据集，评估MLLM的视频-文本差异描述能力，属于原生多模态大模型中视频与文本的细粒度对齐研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Text-Printed Image: Bridging the Image-Text Modality Gap for Text-centric Training of Large Vision-Language Models
- **Authors:** Shojiro Yamabe, Futa Waseda, Daiki Shiono, Tsubasa Takahashi
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03463](https://arxiv.org/abs/2512.03463)
- **Reason:** 提出Text-Printed Image将文本渲染为图像，桥接图像-文本模态gap，属于原生多模态大模型中的模态对齐研究，实验显示比扩散生成的合成图像更有效。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] CookAnything: A Framework for Flexible and Consistent Multi-Step Recipe Image Generation
- **Authors:** Ruoxuan Zhang, Bin Wen, Hongxia Xie, Yi Yao, Songhan Zuo, Jian-Yu Jiang-Lin, Hong-Han Shuai, Wen-Huang Cheng
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03540](https://arxiv.org/abs/2512.03540)
- **Reason:** 提出CookAnything框架处理任意长度的食谱指令生成图像序列，属于原生多模态大模型中的多步指令视觉生成，实验验证优于现有方法。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding
- **Authors:** Huy Quang Ung, Guillaume Habault, Yasutaka Nishimura, Hao Niu, Roberto Legaspi, Tomoki Oya, Ryoichi Kojima, Masato Taya, Chihiro Ono, Atsunori Minamikawa, Yan Liu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03558](https://arxiv.org/abs/2512.03558)
- **Reason:** 提出CartoMapQA基准评估VLM的地图理解能力，属于原生多模态大模型中的地图-文本任务，实验暴露VLM在地图语义和地理推理的不足。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models
- **Authors:** Hao Sun, Lei Fan, Donglin Di, Shaohui Liu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03566](https://arxiv.org/abs/2512.03566)
- **Reason:** 提出GAOT框架通过文本引导的diffusion模型生成articulated物体，属于原生多模态大模型中的文本到3D生成，实验验证PartNet-Mobility上优于现有方法。
Score: 7
Field: 原生多模态大模型

## 深度学习可解释性

### [Score: 9.0/10] Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability
- **Authors:** Jialai She
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03112](https://arxiv.org/abs/2512.03112)
- **Reason:** 针对Shapley值的加性假设缺陷，提出稀疏等渗Shapley回归框架，同时解决了非线性转化估计和高维特征稀疏性问题，属于深度学习可解释性中Shapley值方法的关键改进，对非线性场景下的特征归因有重要意义。
Score: 9
Field: 深度学习可解释性

### [Score: 7.0/10] A Framework for Causal Concept-based Model Explanations
- **Authors:** Anna Rodum Bjørru, Jacob Lysnæs-Larsen, Oskar Jørgensen, Inga Strümke, Helge Langseth
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.02735](https://arxiv.org/abs/2512.02735)
- **Reason:** 构建了基于因果概念的模型解释框架，通过概念干预的充分性概率生成局部和全局解释，兼顾解释的可理解性与对模型的忠实性，属于深度学习可解释性中的概念级解释研究。
Score: 7
Field: 深度学习可解释性

## 大模型安全与对齐

### [Score: 9.0/10] Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value
- **Authors:** Joe Edelman, Tan Zhi-Xuan, Ryan Lowe, Oliver Klingefjord, Vincent Wang-Mascianica, Matija Franklin, Ryan Othniel Kearns, Ellie Hain, Atrisha Sarkar, Michiel Bakker, Fazl Barez, David Duvenaud, Jakob Foerster, Iason Gabriel, Joseph Gubbels, Bryce Goodman, Andreas Haupt, Jobst Heitzig, Julian Jara-Ettinger, Atoosa Kasirzadeh, James Ravi Kirkpatrick, Andrew Koh, W. Bradley Knox, Philipp Koralus, Joel Lehman, Sydney Levine, Samuele Marro, Manon Revel, Toby Shorin, Morgan Sutherland, Michael Henry Tessler, Ivan Vendrov, James Wilken-Smith
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03399](https://arxiv.org/abs/2512.03399)
- **Reason:** 从全栈视角提出AI与机构协同对齐的框架，指出现有价值模型的不足并提出“thick models of value”，涵盖AI系统与制度层面的对齐，作者团队包含多位大模型对齐领域的关键研究者，对大模型安全与对齐的理论与实践有重要指导意义。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] V-ITI: Mitigating Hallucinations in Multimodal Large Language Models via Visual Inference-Time Intervention
- **Authors:** Nan Sun, Zhenyu Zhang, Xixun Lin, Kun Wang, Yanmin Shang, Naibin Gu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang, Yanan Cao
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03542](https://arxiv.org/abs/2512.03542)
- **Reason:** 提出V-ITI通过视觉推理时干预减轻MLLM的幻觉，属于大模型安全与对齐中的幻觉问题解决，实验验证多个基准上减少幻觉且保持性能。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] FeatureLens: A Highly Generalizable and Interpretable Framework for Detecting Adversarial Examples Based on Image Features
- **Authors:** Zhigang Yang, Yuan Liu, Jiawei Zhang, Puning Zhang, Xinqiang Ma
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03625](https://arxiv.org/abs/2512.03625)
- **Reason:** 提出轻量级、高可解释性的对抗样本检测框架，兼顾检测精度、泛化性与计算效率，对大模型对抗防御研究有重要贡献
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Out-of-the-box: Black-box Causal Attacks on Object Detectors
- **Authors:** Melane Navaratnarajah, David A. Kelly, Hana Chockler
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03730](https://arxiv.org/abs/2512.03730)
- **Reason:** 提出黑盒因果攻击方法，生成可解释、不可察觉的对抗攻击，有效评估目标检测器安全性，对大模型安全研究有重要意义
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models
- **Authors:** Korada Sri Vardhana, Shrikrishna Lolla, Soma Biswas
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03749](https://arxiv.org/abs/2512.03749)
- **Reason:** 提出无监督去偏方法，减少扩散模型的偏见问题，提升生成结果的公平性与可靠性，对大模型对齐研究有重要贡献
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Grokked Models are Better Unlearners
- **Authors:** Yuanbang Liang, Yang Li
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03437](https://arxiv.org/abs/2512.03437)
- **Reason:** 发现grokked模型（延迟泛化的模型）在机器 unlearning 中比早期停止模型更高效、 collateral damage 更小，通过特征和曲率分析揭示其模块化表示的优势，为改进unlearning方法提供了新的思路，对大模型安全中的数据遗忘问题有重要价值。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Towards Irreversible Machine Unlearning for Diffusion Models
- **Authors:** Xun Yuan, Zilong Zhao, Jiayu Li, Aryan Pasikhani, Prosanta Gope, Biplab Sikdar
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03564](https://arxiv.org/abs/2512.03564)
- **Reason:** 针对扩散模型的finetuning-based unlearning方法提出DiMRA攻击，揭示其可逆漏洞，并提出DiMUM方法通过记忆替代数据实现不可逆unlearning，提升了扩散模型unlearning的鲁棒性，对大模型安全中的生成式模型遗忘问题有重要贡献。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] OmniGuard: Unified Omni-Modal Guardrails with Deliberate Reasoning
- **Authors:** Boyu Zhu, Xiaofei Wen, Wenjie Jacky Mo, Tinghui Zhu, Yanan Xie, Peng Qi, Muhao Chen
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.02306](https://arxiv.org/abs/2512.02306)
- **Reason:** 提出多模态大模型的统一安全护栏框架，通过多模态安全数据集和 deliberate reasoning 提升安全防护能力，解决了多模态场景下的大模型安全与对齐问题。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Invasive Context Engineering to Control Large Language Models
- **Authors:** Thomas Rivasseau
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03001](https://arxiv.org/abs/2512.03001)
- **Reason:** Introduces a novel control method (invasive context engineering) to enhance LLM security by inserting control sentences into the context, addressing long-context jailbreak issues without retraining, which is highly relevant to LLM safety.
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation
- **Authors:** Zexin Lin, Hawen Wan, Yebin Zhong, Xiaoqiang
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03992](https://arxiv.org/abs/2512.03992)
- **Reason:** 构建基准评估多模态大模型在时间视觉退化下的幻觉持久性，为安全关键场景的模型可靠性验证提供重要工具
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Dynamically Scaled Activation Steering
- **Authors:** Alex Ferrando, Xavier Suau, Jordi Gonz\`alez, Pau Rodriguez
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03661](https://arxiv.org/abs/2512.03661)
- **Reason:** 提出动态缩放的激活引导框架DSAS，自适应调整引导强度以解决现有方法uniform应用导致的性能下降，提升了毒性 mitigation 等对齐任务的效果，同时保持模型 utility，是大模型对齐中激活引导技术的重要改进。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Martingale Score: An Unsupervised Metric for Bayesian Rationality in LLM Reasoning
- **Authors:** Zhonghao He, Tianyi Qiu, Hirokazu Shirado, Maarten Sap
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.02914](https://arxiv.org/abs/2512.02914)
- **Reason:** Proposes an unsupervised Martingale Score to measure belief entrenchment in LLM reasoning, which helps assess the truth-seeking ability of LLMs and is critical for ensuring their rationality and reliability, aligning with LLM safety and alignment goals.
Score: 7
Field: 大模型安全与对齐

## 深度学习理论

### [Score: 9.0/10] Deep Unfolding: Recent Developments, Theory, and Design Guidelines
- **Authors:** Nir Shlezinger, Santiago Segarra, Yi Zhang, Dvir Avrahami, Zohar Davidov, Tirza Routtenberg, Yonina C. Eldar
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03768](https://arxiv.org/abs/2512.03768)
- **Reason:** 系统综述深度展开的理论、设计范式与训练方法，连接传统优化算法与深度学习架构，涵盖收敛性和泛化性理论，对深度学习理论中优化与学习的结合有重要参考价值，作者团队在信号处理与深度学习理论领域有影响力。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] Drainage: A Unifying Framework for Addressing Class Uncertainty
- **Authors:** Yasser Taha, Grégoire Montavon, Nils Körber
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03182](https://arxiv.org/abs/2512.03182)
- **Reason:** 提出通过输出层添加drainage node的统一框架，解决标签噪声、分布外样本等类不确定性问题，属于深度学习理论中模型架构与鲁棒性的重要改进，实验验证高噪声场景下准确率提升9%。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] DM3D: Deformable Mamba via Offset-Guided Gaussian Sequencing for Point Cloud Understanding
- **Authors:** Bin Liu, Chunyang Wang, Xuelian Liu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03424](https://arxiv.org/abs/2512.03424)
- **Reason:** 提出DM3D deformable Mamba架构，通过偏移引导的高斯排序处理点云不规则性，属于深度学习理论中Mamba模型在点云理解的应用，实验验证分类、分割等任务SOTA。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding
- **Authors:** Duy-Tung Pham, An The Nguyen, Viet-Hoang Tran, Nhan-Phu Chung, Xin T. Tong, Tan M. Nguyen, Thieu N. Vo
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03058](https://arxiv.org/abs/2512.03058)
- **Reason:** 研究Transformer中tokens的动态特性及位置编码对其的影响，分析了连续时间极限下动力系统的渐近行为，提出改进Transformer架构的方法，属于深度学习理论的核心研究内容，对理解Transformer工作机制和优化架构有重要价值。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($\lambda$,$\lambda$))-GA
- **Authors:** Tai Nguyen, Phong Le, Andr\'e Biedenkapp, Carola Doerr, Nguyen Dang
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03805](https://arxiv.org/abs/2512.03805)
- **Reason:** 系统研究深度RL在动态算法配置中的应用，发现并解决DDQN和PPO的 scalability degradation与学习不稳定性问题，提出自适应奖励移位策略，实现与理论最优策略相当的性能且样本效率更高，对深度学习理论中RL与优化算法的结合有重要贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics
- **Authors:** Connall Garrod, Jonathan P. Keating, Christos Thrampoulidis
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.04006](https://arxiv.org/abs/2512.04006)
- **Reason:** 聚焦交叉熵训练损失的优化动力学分析，通过Hadamard初始化对角化softmax，证明两层线性神经网络的梯度流可收敛到神经崩塌几何，为深度学习理论中优化与初始化方法提供了可追踪的分析框架。
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] KeyPointDiffuser: Unsupervised 3D Keypoint Learning via Latent Diffusion Models
- **Authors:** Rhys Newbury, Juyan Zhang, Tin Tran, Hanna Kurniawati, Dana Kulić
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03450](https://arxiv.org/abs/2512.03450)
- **Reason:** 提出KeyPointDiffuser无监督3D关键点学习框架，通过latent diffusion模型，属于深度学习理论中无监督3D表示学习的改进，实验显示关键点一致性优于现有方法。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Exploiting Domain Properties in Language-Driven Domain Generalization for Semantic Segmentation
- **Authors:** Seogkyu Jeon, Kibeom Hong, Hyeran Byun
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03508](https://arxiv.org/abs/2512.03508)
- **Reason:** 提出DPMFormer结合领域感知prompt学习与对比学习，提升语义分割的领域泛化，属于深度学习理论中的领域泛化研究，实验验证多个基准上SOTA。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Robust Tabular Foundation Models
- **Authors:** Matthew Peroni, Franck Le, Vadim Sheinin
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03307](https://arxiv.org/abs/2512.03307)
- **Reason:** 提出模型无关的对抗训练框架RTFM，通过优化合成数据生成器强调模型挑战数据集，提升表格基础模型TabPFN V2的基准性能，为深度学习理论中基础模型的鲁棒训练提供了新方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Modal Logical Neural Networks
- **Authors:** Antonin Sulc
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03491](https://arxiv.org/abs/2512.03491)
- **Reason:** 提出模态逻辑神经网络MLNNs，将深度学习与模态逻辑语义结合，设计$\Box$和$\Diamond$算子神经元，支持必要性与可能性推理，是神经符号深度学习架构的重要创新，对深度学习理论中的逻辑推理整合有价值。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Convergence for Discrete Parameter Updates
- **Authors:** Paul Wilson, Fabio Zanasi, George Constantinides
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.04051](https://arxiv.org/abs/2512.04051)
- **Reason:** 针对低精度训练中的离散参数更新规则，建立了通用类离散方案的收敛保证，并通过多项式更新规则验证，为深度学习理论中离散优化方法提供了理论支撑。
Score: 7
Field: 深度学习理论

## 大模型新技术

### [Score: 8.0/10] PixPerfect: Seamless Latent Diffusion Local Editing with Discriminative Pixel-Space Refinement
- **Authors:** Haitian Zheng, Yuan Yao, Yongsheng Yu, Yuqian Zhou, Jiebo Luo, Zhe Lin
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03247](https://arxiv.org/abs/2512.03247)
- **Reason:** 针对latent diffusion局部编辑的像素不一致问题，提出像素空间细化框架，提升感知保真度，属于大模型新技术中diffusion模型的实用改进，实验验证在多个基准上优于现有方法。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation
- **Authors:** Yiyi Cai, Yuhan Wu, Kunhang Li, You Zhou, Bo Zheng, Haiyang Liu
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03520](https://arxiv.org/abs/2512.03520)
- **Reason:** 提出FloodDiffusion通过定制diffusion forcing处理流式运动生成，属于大模型新技术中diffusion模型在时间序列生成的应用，实验验证HumanML3D上FID 0.057。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] BlurDM: A Blur Diffusion Model for Image Deblurring
- **Authors:** Jin-Ting He, Fu-Jen Tsai, Yan-Tsung Peng, Min-Hung Chen, Chia-Wen Lin, Yen-Yu Lin
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03979](https://arxiv.org/abs/2512.03979)
- **Reason:** 将模糊形成过程整合到扩散模型中，提出新型去模糊扩散架构，属于扩散类大模型的关键技术创新
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] GeoVideo: Introducing Geometric Regularization into Video Generation Model
- **Authors:** Yunpeng Bai, Shaoheng Fang, Chaohui Yu, Fan Wang, Qixing Huang
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03453](https://arxiv.org/abs/2512.03453)
- **Reason:** 提出GeoVideo将几何正则化引入视频生成，解决2D生成的3D结构不一致问题，属于大模型新技术中视频diffusion模型的几何改进，实验显示结构一致性优于基线。
Score: 7
Field: 大模型新技术

## 多模态智能体

### [Score: 8.0/10] SpatialReasoner: Active Perception for Large-Scale 3D Scene Understanding
- **Authors:** Hongpei Zheng, Shijie Li, Yanran Li, Hujun Yin
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03284](https://arxiv.org/abs/2512.03284)
- **Reason:** 提出主动感知框架SpatialReasoner，通过LLM引导的空间工具探索大规模3D场景，属于多模态智能体中3D场景理解的主动推理，实验显示优于GPT-4o和Gemini-2.5-Pro。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] YOLOA: Real-Time Affordance Detection via LLM Adapter
- **Authors:** Yuqi Ji, Junjie Ke, Lihuo He, Jun Liu, Kaifan Zhang, Yu-Kun Lai, Guiguang Ding, Xinbo Gao
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03418](https://arxiv.org/abs/2512.03418)
- **Reason:** 提出YOLOA实时affordance检测模型，通过LLM adapter结合目标检测与affordance学习，属于多模态智能体中embodied AI的affordance能力研究，实验验证多个基准上达到SOTA。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention
- **Authors:** Ziwen Li, Xin Wang, Hanlue Zhang, Runnan Chen, Runqi Lin, Xiao He, Han Huang, Yandong Guo, Fakhri Karray, Tongliang Liu, Mingming Gong
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03724](https://arxiv.org/abs/2512.03724)
- **Reason:** 通过姿态条件锚定注意力提升VLA模型动作生成精度，针对机器人操纵等embodied任务，符合多模态智能体研究方向
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] Step-by-step Layered Design Generation
- **Authors:** Faizan Farooq Khan, K J Joseph, Koustava Goswami, Mohamed Elhoseiny, Balaji Vasan Srinivasan
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03335](https://arxiv.org/abs/2512.03335)
- **Reason:** 提出分步分层设计生成框架SLEDGE，处理设计师的分步指令，属于多模态智能体中设计任务的分步推理，实验验证优于现有方法。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] Procedural Mistake Detection via Action Effect Modeling
- **Authors:** Wenliang Guo, Yujiang Pu, Yu Kong
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03474](https://arxiv.org/abs/2512.03474)
- **Reason:** 提出AEM框架通过动作效果建模检测操作错误，属于多模态智能体中操作任务的错误检测，实验验证EgoPER和CaptainCook4D上SOTA。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] Towards Object-centric Understanding for Instructional Videos
- **Authors:** Wenliang Guo, Yu Kong
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03479](https://arxiv.org/abs/2512.03479)
- **Reason:** 提出目标中心的instructional视频理解框架，通过agent orchestration工具实现多跳推理，属于多模态智能体中视频理解的目标推理，实验显示优于现有MLLM。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] EEA: Exploration-Exploitation Agent for Long Video Understanding
- **Authors:** Te Yang, Xiangyu Zhu, Bo Wang, Quan Chen, Peng Jiang, Zhen Lei
- **Published:** 2025-12-04
- **Link:** [https://arxiv.org/abs/2512.03500](https://arxiv.org/abs/2512.03500)
- **Reason:** 提出EEA agent通过语义引导的分层树搜索平衡探索与利用，处理长视频理解，属于多模态智能体中长视频的主动理解，实验验证优于现有方法。
Score: 7
Field: 多模态智能体

