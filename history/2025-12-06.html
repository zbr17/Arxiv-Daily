<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-06</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >大模型新技术</a>
<a href='#' >深度学习理论</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >多模态智能体</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习可解释性</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-06</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-06 12:29:36</p>
<p>已自动阅读了 226 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：129822</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> DeRA: Decoupled Representation Alignment for Video Tokenization</h3>
<p><strong>Authors:</strong> Pengbo Guo, Junke Wang, Zhen Xing, Chengxu Liu, Daoguo Dong, Xueming Qian, Zuxuan Wu</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出解耦空间-时间表示的1D视频tokenizer DeRA，通过对称对齐冲突投影解决异质监督的梯度冲突，显著提升视频生成性能，符合原生多模态大模型中的tokenizer研究方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04483' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> PhyVLLM: Physics-Guided Video Language Model with Motion-Appearance Disentanglement</h3>
<p><strong>Authors:</strong> Yu-Wei Zhan, Xin Wang, Hong Chen, Tongtong Feng, Wei Feng, Ren Wang, Guangyao Li, Qing Li, Wenwu Zhu</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出物理引导的视频语言模型，通过双分支编码器解耦运动与外观，结合Neural ODE建模物理动态，提升多模态视频理解与物理推理能力，属于原生多模态大模型研究。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04532' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SAM3-I: Segment Anything with Instructions</h3>
<p><strong>Authors:</strong> Jingjing Li, Yue Feng, Yuchen Guo, Jincai Huang, Yongri Piao, Qi Bi, Miao Zhang, Xiaoqi Zhao, Qiang Chen, Shihao Zou, Wei Ji, Huchuan Lu, Li Cheng</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对SAM3无法处理复杂自然语言指令的问题，提出SAM3-I框架，引入指令感知的级联适应机制，实现直接遵循指令的分割任务，在保持概念 grounding的同时扩展SAM3的能力，相关于原生多模态大模型的图像理解方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04585' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</h3>
<p><strong>Authors:</strong> Yubo Huang, Hailong Guo, Fangtai Wu, Shifeng Zhang, Shijie Huang, Qijun Gan, Lin Liu, Sirui Zhao, Enhong Chen, Jiaming Liu, Steven Hoi</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对扩散模型在实时音频驱动Avatar生成中的序列计算与一致性问题，提出Live Avatar框架，用TPP并行化去噪步骤并结合RSFM保持一致性，实现20 FPS的实时生成，相关于原生多模态大模型的图像生成方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04677' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> EMMA: Efficient Multimodal Understanding, Generation, and Editing with a Unified Architecture</h3>
<p><strong>Authors:</strong> Xin He, Longhui Wei, Jianbo Ouyang, Lingxi Xie, Qi Tian</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对多模态模型的效率与统一问题，提出EMMA架构，用高效自动编码器与共享-解耦网络，实现理解、生成、编辑的统一，超越BAGEL-7B等模型，相关于原生多模态大模型的统一架构方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04810' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Refa\c{c}ade: Editing Object with Given Reference Texture</h3>
<p><strong>Authors:</strong> Youze Huang (University of Electronic Science and Technology of China), Penghui Ruan (The Hong Kong Polytechnic University), Bojia Zi (The Chinese University of Hong Kong), Xianbiao Qi (IntelliFusion Inc), Jianan Wang (Astribot Inc), Rong Xiao (IntelliFusion Inc)</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对图像/视频物体纹理编辑任务，提出Refa\c{c}ade方法解决ControlNet依赖原始参考图像带来的结构干扰和纹理-结构解耦不足问题，通过纹理去除器和拼图置换提升视觉质量与可控性，在定量和人类评估中超过基线，相关于原生多模态大模型的图像生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04534' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> COOPER: A Unified Model for Cooperative Perception and Reasoning in Spatial Intelligence</h3>
<p><strong>Authors:</strong> Zefeng Zhang, Xiangzhao Hao, Hengzhu Tang, Zhenyu Zhang, Jiawei Sheng, Xiaodong Li, Zhenyang Li, Li Gao, Daiting Shi, Dawei Yin, Tingwen Liu</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对MLLM的空间推理能力不足问题，提出COOPER框架，融合深度和分割作为辅助模态，通过两阶段训练提升空间感知与推理能力，在空间推理任务上平均提升6.91%，相关于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04563' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> I2I-Bench: A Comprehensive Benchmark Suite for Image-to-Image Editing Models</h3>
<p><strong>Authors:</strong> Juntong Wang, Jiarui Wang, Huiyu Duan, Jiaxiang Kang, Guangtao Zhai, Xiongkuo Min</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对图像编辑模型缺乏综合评估的问题，提出I2I-Bench基准，涵盖10个任务类别和30个评估维度，结合自动化工具与LMM实现多维度评估，相关于原生多模态大模型的图像编辑方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04660' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Cross-View Point Correspondence in Vision-Language Models</h3>
<p><strong>Authors:</strong> Yipu Wang, Yuheng Ji, Yuyang Liu, Enshen Zhou, Ziqiang Yang, Yuxuan Tian, Ziheng Qin, Yue Liu, Huajie Tan, Cheng Chi, Zhiyuan Ma, Daniel Dajun Zeng, Xiaolong Zheng</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对VLM的跨视图点对应能力不足问题，提出CVPC任务与CrossPoint-Bench基准，构建CrossPoint-378K数据集训练CroPond模型，超越Gemini-2.5-Pro 39.7%，相关于原生多模态大模型的跨模态空间理解方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04686' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Order Matters: 3D Shape Generation from Sequential VR Sketches</h3>
<p><strong>Authors:</strong> Yizi Chen, Sidi Wu, Tianyi Xiao, Nina Wiedemann, Loic Landrieu</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对VR草图3D形状生成忽略笔画顺序的问题，提出VRSketch2Shape框架与数据集，用顺序感知的编码器与扩散生成器提升几何保真度，相关于原生多模态大模型的3D内容生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04761' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LaFiTe: A Generative Latent Field for 3D Native Texturing</h3>
<p><strong>Authors:</strong> Chia-Hao Chen, Zi-Xin Zou, Yan-Pei Cao, Ze Yuan, Guan Luo, Xiaojuan Qi, Ding Liang, Song-Hai Zhang, Yuan-Chen Guo</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对3D原生纹理生成的表示 gap问题，提出LaFiTe框架，用VAE编码成稀疏 latent空间，提升纹理保真度（PSNR超10dB），支持材质合成等下游任务，相关于原生多模态大模型的3D内容生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04786' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> 4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer</h3>
<p><strong>Authors:</strong> Xianfeng Wu, Yajing Bai, Minghan Li, Xianzu Wu, Xueqi Zhao, Zhongyuan Lai, Wenyu Liu, Xinggang Wang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出首个Transformer-based的4D语言-视觉几何接地框架，联合几何感知和语言对齐，对原生多模态大模型中的多模态融合有重要贡献。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05060' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation</h3>
<p><strong>Authors:</strong> Dongzhi Jiang, Renrui Zhang, Haodong Li, Zhuofan Zong, Ziyu Guo, Jun He, Claire Guo, Junyan Ye, Rongyao Fang, Weijia Li, Rui Liu, Hongsheng Li</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出Draft-as-CoT范式，通过低分辨率草稿引导文本到图像生成，解决稀有概念生成问题，对原生多模态大模型中的text-to-image生成有重要改进。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05112' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TV2TV: A Unified Framework for Interleaved Language and Video Generation</h3>
<p><strong>Authors:</strong> Xiaochuang Han, Youssef Emad, Melissa Hall, John Nguyen, Karthik Padthe, Liam Robbins, Amir Bar, Delong Chen, Michal Drozdzal, Maha Elbayad, Yushi Hu, Shang-Wen Li, Sreya Dutta Roy, Jakob Verbeek, XuDong Wang, Marjan Ghazvininejad, Luke Zettlemoyer, Emily Dinan</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出TV2TV统一框架，通过Mixture-of-Transformers联合学习语言建模与视频流匹配，实现文本与视频的 interleaved 生成，提升视频生成的可控性和prompt对齐度，属于原生多模态大模型研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05103' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models</h3>
<p><strong>Authors:</strong> Lei Zhang, Ju Dong, Kaixin Bai, Minheng Ni, Zoltan-Csaba Marton, Zhaopeng Chen, Jianwei Zhang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 该论文提出ResponsibleRobotBench基准，基于多模态大模型评估负责任机器人操作，为多模态大模型在机器人领域的应用提供系统评估框架，直接关联原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04308' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization</h3>
<p><strong>Authors:</strong> Hong Kuang, Jianchen Liu</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对3D Gaussian Splatting在野外语境中的表面重建精度和渲染质量问题，提出GEF框架，通过熵驱动建模、自适应正则化和跨尺度对齐提升几何精度与 photometric保真度，相关于原生多模态大模型的3D内容生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04542' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> OmniScaleSR: Unleashing Scale-Controlled Diffusion Prior for Faithful and Realistic Arbitrary-Scale Image Super-Resolution</h3>
<p><strong>Authors:</strong> Xinning Chai, Zhengxue Cheng, Yuhong Zhang, Hengsheng Zhang, Yingsheng Qin, Yucai Yang, Rong Xie, Li Song</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对任意尺度超分辨率的真实性与保真度权衡问题，提出OmniScaleSR框架，结合显式与隐式尺度控制，提升大倍数放大的视觉质量，相关于原生多模态大模型的图像生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04699' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS</h3>
<p><strong>Authors:</strong> Chuanyu Fu, Guanying Chen, Yuqi Zhang, Kunbin Yao, Yuan Xiong, Chuan Huang, Shuguang Cui, Yasuyuki Matsushita, Xiaochun Cao</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对3DGS在野外语境中的 transient对象与光照问题，提出RobustSplat++，用延迟高斯增长与掩码引导，提升渲染质量，相关于原生多模态大模型的3D内容生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.04815' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> UltraImage: Rethinking Resolution Extrapolation in Image Diffusion Transformers</h3>
<p><strong>Authors:</strong> Min Zhao, Bokai Yan, Xue Yang, Hongzhou Zhu, Jintao Zhang, Shilong Liu, Chongxuan Li, Jun Zhu</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出扩散Transformer的分辨率外推框架，通过递归主频率校正和熵引导注意力集中解决高分辨率生成的重复与退化问题，支持6K*6K图像生成，属于大模型新技术中的diffusion LLM研究。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.04504' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> dVLM-AD: Enhance Diffusion Vision-Language-Model for Driving via Controllable Reasoning</h3>
<p><strong>Authors:</strong> Yingzi Ma, Yulong Cao, Wenhao Ding, Shuibai Zhang, Yan Wang, Boris Ivanovic, Ming Jiang, Marco Pavone, Chaowei Xiao</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出扩散基视觉语言模型dVLM-AD，通过双向注意力提升自动驾驶中的推理可控性与一致性，属于大模型新技术中的diffusion LLM研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.04459' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> NeuralRemaster: Phase-Preserving Diffusion for Structure-Aligned Generation</h3>
<p><strong>Authors:</strong> Yu Zeng, Charles Ochoa, Mingyuan Zhou, Vishal M. Patel, Vitor Guizilini, Rowan McAllister</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出相位保持扩散模型，保留输入相位以实现结构对齐生成，对大模型新技术中的diffusion模型改进有重要价值。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.05106' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Decoding Large Language Diffusion Models with Foreseeing Movement</h3>
<p><strong>Authors:</strong> Yichuan Mo, Quan Chen, Mingjie Li, Zeming Wei, Yisen Wang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出FDM方法，通过预见解码优化大语言扩散模型的推理，对大模型新技术中的LLDM解码有重要贡献。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.04135' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies</h3>
<p><strong>Authors:</strong> Jonne Van Haastregt, Bastian Orthmann, Michael C. Welle, Yuchong Zhang, Danica Kragic</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出Hybrid-Diffusion模型，结合开环程序与视觉运动扩散政策，创新融合扩散模型与传统控制，属于大模型新技术中的diffusion相关方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.04960' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence</h3>
<p><strong>Authors:</strong> Tianyu Yuan, Yuanbo Yang, Lin-Zhuo Chen, Yao Yao, Zhuzhong Qian</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对视频跟踪的对应关系鲁棒性问题，提出HeFT框架，分析VDiT的内部表示，利用头和频率感知的特征选择提升零样本跟踪性能，相关于大模型新技术中的扩散模型应用方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.04619' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PaCo-RL: Advancing Reinforcement Learning for Consistent Image Generation with Pairwise Reward Modeling</h3>
<p><strong>Authors:</strong> Bowen Ping, Chengyou Jia, Minnan Luo, Changliang Xia, Xin Shen, Zhuohang Dang, Hangwei Qian</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对一致图像生成的监督训练限制问题，提出PaCo-RL框架，用PaCo-Reward评估一致性，结合PaCo-GRPO提升训练效率与稳定性，相关于大模型新技术中的RL与生成模型结合方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.04784' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting</h3>
<p><strong>Authors:</strong> Jian Tang, Pu Pang, Haowen Sun, Chengzhong Ma, Xingyu Chen, Hua Huang, Xuguang Lan</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出S2GS语义表示方法，结合Diffusion Policy作为下游算法，解决机器人操作跨域迁移问题，关联大模型新技术中的diffusion方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.04731' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> BEP: A Binary Error Propagation Algorithm for Binary Neural Networks Training</h3>
<p><strong>Authors:</strong> Luca Colombo, Fabrizio Pittorino, Daniele Zambon, Carlo Baldassi, Manuel Roveri, Cesare Alippi</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出首个适用于二进制神经网络的端到端二进制训练算法，解决传统量化感知训练需浮点运算的问题，支持递归网络二进制训练，对深度学习理论中的网络架构和优化器研究有重要贡献。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04189' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DisentangleFormer: Spatial-Channel Decoupling for Multi-Channel Vision</h3>
<p><strong>Authors:</strong> Jiashu Liao, Pietro Liò, Marc de Kamps, Duygu Sarikaya</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出空间-通道解耦的Transformer架构，通过并行解缠模块和自适应校准解决多通道特征纠缠问题，提升多通道视觉任务性能，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04314' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Autoregressive Image Generation Needs Only a Few Lines of C</h3>
<p><strong>Authors:</strong> Noa Rubin, Orit Davidovich, Zohar Ringel</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对深度学习中特征学习和样本复杂度的缩放问题提出启发式分析方法，复现已知结果并预测复杂架构行为，对深度学习理论中的特征学习机制研究有重要价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04165' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Network of Theseus (like the ship)</h3>
<p><strong>Authors:</strong> Vighnesh Subramaniam, Colin Conwell, Boris Katz, Andrei Barbu, Brian Cheung</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出渐进式转换网络架构的方法，打破“训练架构即部署架构”的假设，对深度学习理论中的网络架构设计有重要启发。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04198' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Initialization Determines Whether In-Context Learning Is Gradient Descent</h3>
<p><strong>Authors:</strong> Shifeng Xie, Rui Yuan, Simone Rossi, Thomas Hannagan</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 研究上下文学习与梯度下降的关系，指出初始化的关键作用，扩展了上下文学习的理论理解，对深度学习理论中的上下文学习机制有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04268' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> When do spectral gradient updates help in deep learning?</h3>
<p><strong>Authors:</strong> Damek Davis, Dmitriy Drusvyatskiy</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 分析谱梯度方法（如Muon优化器）在深度学习中的有效性条件，提出层wise判断条件，对深度学习理论中的优化器设计有重要指导意义。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04299' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Continuous-Time Approximations for Stochastic Gradient Descent without Replacement</h3>
<p><strong>Authors:</strong> Stefan Perko</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 研究随机梯度下降无替换（SGDo）的连续时间近似，提出epoched Brownian运动驱动的Young微分方程模型，证明强凸目标下的几乎必然收敛性及收敛速率上界，对深度学习优化器理论有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04703' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Universal Weight Subspace Hypothesis</h3>
<p><strong>Authors:</strong> Prakhar Kaushik, Shravan Chaudhari, Ankit Vaidya, Rama Chellappa, Alan Yuille</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 大规模实验发现不同任务、初始化的深度网络收敛到相似低维权重子空间，揭示深度网络权重的内在组织规律，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.05117' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MT-Depth: Multi-task Instance feature analysis for the Depth Completion</h3>
<p><strong>Authors:</strong> Abdul Haseeb Nizamani, Dandi Zhou, Xinhai Sun</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对深度补全的对象级理解不足问题，提出instance-aware框架，结合YOLO的实例分割与U-Net的深度补全，提升边界与薄结构的深度准确性，相关于深度学习理论的网络架构设计方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04734' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Tokenizing Buildings: A Transformer for Layout Synthesis</h3>
<p><strong>Authors:</strong> Manuel Ladron de Guevara, Jinmo Rhee, Ardavan Bidgoli, Vaidas Razgaitis, Michael Bergin</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对建筑布局合成的tokenization问题，提出SBM Transformer架构，用稀疏属性-特征矩阵与统一嵌入，提升布局生成的功能合理性与导航性，相关于深度学习理论的网络架构设计方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04832' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Studying Various Activation Functions and Non-IID Data for Machine Learning Model Robustness</h3>
<p><strong>Authors:</strong> Long Dang, Thushari Hapuarachchi, Kaiqi Xiong, Jing Lin</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 研究十种激活函数在对抗训练和联邦学习（非IID数据）中的鲁棒性，提出改进的对抗训练方法，对深度学习理论中的模型鲁棒性和训练方法有重要参考价值。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04264' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RNNs perform task computations by dynamically warping neural representations</h3>
<p><strong>Authors:</strong> Arthur Pellegrino, Angus Chadwick</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出RNN通过动态扭曲神经表示进行计算的假设，开发黎曼几何框架分析，对深度学习理论中的RNN计算机制有重要理解。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.04310' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems</h3>
<p><strong>Authors:</strong> Zehao Fan, Zhenyu Liu, Yunzhen Liu, Yayue Hou, Hadjer Benmeziane, Kaoutar El Maghraoui, Liu Liu</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出上下文感知的MoE推理方法，结合CXL-NDP系统优化专家放置，对高效大模型推理中的MoE优化有重要价值。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.04476' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management</h3>
<p><strong>Authors:</strong> Hongbo Jin, Qingyuan Wang, Wenhao Zhang, Yang Liu, Sijie Cheng</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对超长视频理解的上下文长度限制和内存低效问题，提出VideoMem框架，通过动态更新全局内存缓冲区保留关键信息，并结合PRPO算法提升训练效率，在多个基准测试中显著超越现有模型，相关于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.04540' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Reward Forcing: Efficient Streaming Video Generation with Rewarded Distribution Matching Distillation</h3>
<p><strong>Authors:</strong> Yunhong Lu, Yanhong Zeng, Haobo Li, Hao Ouyang, Qiuyu Wang, Ka Leong Cheng, Jiapeng Zhu, Hengyuan Cao, Zhipeng Zhang, Xing Zhu, Yujun Shen, Min Zhang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对流式视频生成的初始帧复制与运动动态不足问题，提出Reward Forcing框架，用EMA-Sink保持长时一致性，结合Re-DMD提升运动质量，在单H100上达到23.1 FPS，相关于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.04678' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Deep Forcing: Training-Free Long Video Generation with Deep Sink and Participative Compression</h3>
<p><strong>Authors:</strong> Jung Yi, Wooseok Jang, Paul Hyunbin Cho, Jisu Nam, Heeji Yoon, Seungryong Kim</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出Deep Forcing方法，通过Deep Sink和Participative Compression实现无训练的长视频生成，对高效大模型推理中的长序列生成优化有重要价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05081' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GRASP: GRouped Activation Shared Parameterization for Parameter-Efficient Fine-Tuning and Robust Inference of Transformers</h3>
<p><strong>Authors:</strong> Malyaban Bal, Abhronil Sengupta</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出GRASP方法，通过分组激活共享参数实现参数高效微调，同时提高推理鲁棒性，对高效大模型训练中的参数高效微调有重要贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.04296' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> On the Limits of Test-Time Compute: Sequential Reward Filtering for Better Inference</h3>
<p><strong>Authors:</strong> Yue Yu, Qiwei Di, Quanquan Gu, Dongruo Zhou</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 分析测试时计算的限制，提出奖励过滤的顺序推理方法，对高效大模型推理中的测试时计算优化有重要参考价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.04558' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RLHFSpec: Breaking the Efficiency Bottleneck in RLHF Training via Adaptive Drafting</h3>
<p><strong>Authors:</strong> Siqi Wang, Hailong Yang, Junjie Zhu, Xuezhu Wang, Yufan Xu, Depei Qian</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对RLHF生成阶段瓶颈，集成推测解码提出RLHFSpec，通过workload-aware策略选择和样本重分配提升生成吞吐量，有效缓解RLHF整体执行瓶颈，属于高效大模型训练与推理优化。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.04752' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Single-Image Super-Resolution in the JPEG Compressed Domain</h3>
<p><strong>Authors:</strong> Sruthi Srinivasan, Elham Shakibapour, Rajy Rawther, Mehdi Saeedi</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出JPEG压缩域单图超分方法，直接在DCT系数上训练，实现2.6倍数据加载加速和2.5倍训练加速，属于高效大模型训练与推理中的高效训练研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.04284' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ARM-Thinker: Reinforcing Multimodal Generative Reward Models with Agentic Tool Use and Visual Reasoning</h3>
<p><strong>Authors:</strong> Shengyuan Ding, Xinyu Fang, Ziyu Liu, Yuhang Zang, Yuhang Cao, Xiangyu Zhao, Haodong Duan, Xiaoyi Dong, Jianze Liang, Bin Wang, Conghui He, Dahua Lin, Jiaqi Wang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出ARM-Thinker，通过智能体工具使用增强多模态生成奖励模型，解决幻觉和弱接地问题，对多模态智能体中的工具使用有重要贡献。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.05111' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MindDrive: An All-in-One Framework Bridging World Models and Vision-Language Model for End-to-End Autonomous Driving</h3>
<p><strong>Authors:</strong> Bin Suna, Yaoguang Caob, Yan Wanga, Rui Wanga, Jiachen Shanga, Xiejie Fenga, Jiayi Lu, Jia Shi, Shichun Yang, Xiaoyu Yane, Ziying Song</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出端到端自动驾驶框架，结合世界模型与VLM实现感知、推理与规划的统一，属于多模态智能体中的embodied agent研究。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.04441' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Evaluating Long-Context Reasoning in LLM-Based WebAgents</h3>
<p><strong>Authors:</strong> Andy Chung, Yichi Zhang, Kaixiang Lin, Aditya Rawal, Qiaozi Gao, Joyce Chai</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 评估WebAgents的长上下文推理能力，发现性能退化问题并提出改进方法，对多模态智能体中的WebAgent设计有重要参考价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.04307' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Learning to Orchestrate Agents in Natural Language with the Conductor</h3>
<p><strong>Authors:</strong> Stefan Nielsen, Edoardo Cetin, Peter Schwendeman, Qi Sun, Jinglue Xu, Yujin Tang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出Conductor模型，通过RL学习编排自然语言中的智能体，实现多智能体协作，对多模态智能体中的智能体编排有重要贡献。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.04388' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space</h3>
<p><strong>Authors:</strong> Joey Hong, Kang Liu, Zhan Ling, Jiecao Chen, Sergey Levine</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出NLAC，用自然语言critic训练LLM agents，解决长 horizon任务的样本复杂度与稳定性问题，属于多模态智能体的高效训练研究。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.04601' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Feng Xu, Guangyao Zhai, Xin Kong, Tingzhong Fu, Daniel F. N. Gordon, Xueli An, Benjamin Busam</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出STARE-VLA方法，通过阶段感知强化微调视觉-语言-动作模型，在SimplerEnv和ManiSkill3上取得state-of-the-art结果，关联多模态智能体方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.05107' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> StreamEQA: Towards Streaming Video Understanding for Embodied Scenarios</h3>
<p><strong>Authors:</strong> Yifei Wang, Zhenkai Li, Tianwen Qian, Huanran Zheng, Zheng Wang, Yuqian Fu, Xiaoling Wang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 构建首个embodied场景流视频QA基准，评估模型在感知、交互、规划等维度的流视频理解能力，推动多模态智能体研究。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.04451' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> When Robots Should Say "I Don't Know": Benchmarking Abstention in Embodied Question Answering</h3>
<p><strong>Authors:</strong> Tao Wu, Chuhao Zhou, Guangyu Zhao, Haozhi Cao, Yewen Pu, Jianfei Yang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对Embodied QA agents缺乏“不知道”能力的问题，提出AbstainEQA数据集和评估框架，分析现有模型在五种 abstention场景下的性能，发现模型远落后于人类，为可靠的embodied交互提供基础，相关于多模态智能体方向。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.04597' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination</h3>
<p><strong>Authors:</strong> Chengyang He, Ge Sun, Yue Bai, Junkai Lu, Jiadong Zhao, Guillaume Sartoretti</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出FALCON框架，结合视觉语言基础模型协调 locomotion与manipulation的多模态智能体，解决单一政策融合异质观测的问题，提升了具身协调能力。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.04381' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Data-regularized Reinforcement Learning for Diffusion Models at Scale</h3>
<p><strong>Authors:</strong> Haotian Ye, Kaiwen Zheng, Jiashu Xu, Puheng Li, Huayu Chen, Jiaqi Han, Sheng Liu, Qinsheng Zhang, Hanzi Mao, Zekun Hao, Prithvijit Chattopadhyay, Dinghao Yang, Liang Feng, Maosheng Liao, Junjie Bai, Ming-Yu Liu, James Zou, Stefano Ermon</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出DDRL方法，通过数据正则化解决扩散模型RL对齐中的奖励hacking问题，有大量实验支持，对大模型安全与对齐中的扩散模型对齐有重要贡献。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04332' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment</h3>
<p><strong>Authors:</strong> Kai-Po Chang, Wei-Yuan Cheng, Chi-Pin Huang, Fu-En Yang, Yu-Chiang Frank Wang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出SANTA框架，通过自增强对比对齐和轨迹-短语对比缓解MLLM的物体与动作幻觉，提升事实一致性，属于大模型安全与对齐中的alignment研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04356' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot</h3>
<p><strong>Authors:</strong> Sheng Hang, Chaoxiang He, Hongsheng Hu, Hanqing Hu, Bin Benjamin Zhu, Shi-Feng Sun, Dawu Gu, Shuo Wang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对恶意图像的细粒度检测需求，提出零样本 pipeline，结合分割模型与VLM的开放词汇提示，实现检测、元素识别与定位的一体化，在新标注数据集上超过现有方法，相关于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04599' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SEASON: Mitigating Temporal Hallucination in Video Large Language Models via Self-Diagnostic Contrastive Decoding</h3>
<p><strong>Authors:</strong> Chang-Hsun Wu, Kai-Po Chang, Yu-Yang Sheng, Hung-Kai Chung, Kuei-Chun Wang, Yu-Chiang Frank Wang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对VideoLLMs的时间幻觉问题，提出SEASON方法，动态诊断token的幻觉倾向并应用对比解码，在三个幻觉基准测试中超过现有方法，同时提升视频理解性能，相关于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04643' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Diffusion Fine-Tuning via Reparameterized Policy Gradient of the Soft Q-Function</h3>
<p><strong>Authors:</strong> Hyeongyu Kang, Jaewoo Lee, Woocheol Shin, Kiyoung Om, Jinkyoo Park</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出SQDF方法，通过软Q函数的重参数化策略梯度微调扩散模型，平衡奖励和多样性，对大模型安全与对齐中的扩散模型对齐有重要改进。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04559' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Value Gradient Guidance for Flow Matching Alignment</h3>
<p><strong>Authors:</strong> Zhen Liu, Tim Z. Xiao, Carles Domingo-Enrich, Weiyang Liu, Dinghuai Zhang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 基于最优控制理论提出VGG-Flow，通过价值函数梯度匹配优化预训练flow matching模型，实现高效且保留先验的对齐，解决现有flow matching对齐方法的效率与先验保留矛盾。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05116' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI</h3>
<p><strong>Authors:</strong> Hu Keyi</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出Weight-Calculatism认知架构，通过逻辑原子与权重计算实现可解释决策，价值对齐可追溯，解决现有AI的可解释性与对齐难题。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.03072' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Counterfeit Answers: Adversarial Forgery against OCR-Free Document Visual Question Answering</h3>
<p><strong>Authors:</strong> Marco Pintore, Maura Pintor, Dimosthenis Karatzas, Battista Biggio</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对OCR-Free DocVQA模型的对抗攻击漏洞，提出伪造文档内容的攻击算法，通过生成视觉不可感知但语义定向的伪造内容诱导模型错误回答，揭示现有系统的安全风险，相关于大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04554' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Sanity Check for Multi-In-Domain Face Forgery Detection in the Real World</h3>
<p><strong>Authors:</strong> Jikang Cheng, Renye Yan, Zhiyuan Yan, Yaozhong Gan, Xueyi Zhang, Zhongyuan Wang, Wei Peng, Ling Liang</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 针对多域深度伪造检测的domain主导问题，提出DevDet框架，通过FFDev与DAFT放大real/fake差异，提升domain-unspecified场景下的判断准确性，相关于大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04837' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bootstrapped Mixed Rewards for RL Post-Training: Injecting Canonical Action Order</h3>
<p><strong>Authors:</strong> Prakhar Gupta, Vaibhav Gupta</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出混合奖励的RL后训练方法，注入规范动作顺序，改进模型性能，对大模型安全与对齐中的RL微调有重要价值。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.04277' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation</h3>
<p><strong>Authors:</strong> Austin Spizzirri</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 从哲学角度重新构思AI对齐，提出syntropic框架分析内容-based价值指定的“specification trap”，为大模型安全与对齐提供新理论视角。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.03048' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models</h3>
<p><strong>Authors:</strong> Manar Alnaasan, Md Selim Sarowar, Sungho Kim</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 结合RGB-D多模态特征与LLM，将视觉嵌入转换为临床可解释的文本，提升帕金森步态识别的可解释性，符合深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.04425' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Distance Is All You Need: Radial Dispersion for Uncertainty Estimation in Large Language Models</h3>
<p><strong>Authors:</strong> Manh Nguyen, Sunil Gupta, Hung Le</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出简单、模型无关的不确定性度量RDS，用于LLM幻觉检测和答案选择，对深度学习可解释性中的不确定性估计有重要应用价值。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.04351' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SuperActivators: Only the Tail of the Distribution Contains Reliable Concept Signals</h3>
<p><strong>Authors:</strong> Cassandra Goldberg, Chaehyeon Kim, Adam Stein, Eric Wong</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出SuperActivator机制，发现概念激活分布的高尾token提供可靠概念信号，显著提升多模态概念检测和特征归因性能，对深度学习可解释性的概念向量研究有重要推进。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05038' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Explainable Graph Representation Learning via Graph Pattern Analysis</h3>
<p><strong>Authors:</strong> Xudong Wang, Ziheng Sun, Chris Ding, Jicong Fan</p>
<p><strong>Published:</strong> 2025-12-05</p>
<p><strong>Reason:</strong> 提出通过图模式分析学习可解释的图表示，结合子结构采样和权重和，对深度学习可解释性中的图表示学习有重要贡献。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.04530' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>