<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-09</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>高效大模型训练与推理</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >深度学习理论</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >多模态智能体</a>
<a href='#' >大模型新技术</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-09</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-09 12:28:53</p>
<p>已自动阅读了 202 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：98564</p>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows</h3>
<p><strong>Authors:</strong> Zhenglin Cheng, Peng Sun, Jianguo Li, Tao Lin</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出无需预训练教师模型的1-step生成模型，解决扩散模型多步推理效率低的问题，在文本到图像任务上实现1-NFE下的高性能，符合高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05150' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> InvarDiff: Cross-Scale Invariance Caching for Accelerated Diffusion Models</h3>
<p><strong>Authors:</strong> Zihao Wu</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出训练-free的扩散模型加速方法，利用跨时间步和层的不变性缓存减少冗余计算，在保持生成质量的同时实现2-3倍推理加速，与高效大模型训练与推理方向高度相关。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05134' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HQ-DM: Single Hadamard Transformation-Based Quantization-Aware Training for Low-Bit Diffusion Models</h3>
<p><strong>Authors:</strong> Shizhuo Mao, Hongtao Zou, Qihu Xie, Song Chen, Yi Kang</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出HQ-DM量化感知训练框架，通过单Hadamard变换解决扩散模型低比特量化的激活离群值问题，显著提升量化后性能，对高效扩散模型训练有关键贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05746' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> USV: Unified Sparsification for Accelerating Video Diffusion Models</h3>
<p><strong>Authors:</strong> Xinjian Wu, Hongmei Wang, Yuan Zhou, Qinglin Lu</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出USV统一稀疏化框架，联合优化视频扩散模型的内部计算与采样过程，实现83.3%去噪加速和22.7%端到端加速，为高效视频生成提供了可行路径。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05754' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws</h3>
<p><strong>Authors:</strong> Zhengquan Luo, Zhiqiang Xu</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 建立数据集蒸馏的统一理论框架，推导了scaling law与configuration-coverage law，提升了蒸馏数据的有效性与鲁棒性，属于高效大模型训练与推理研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05817' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity</h3>
<p><strong>Authors:</strong> Damien Lesens, Beheshteh T. Rakhshan, Guillaume Rabusseau</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出KV缓存压缩方法，通过直接分解注意力矩阵保证 fidelity，解决了长序列推理的内存瓶颈，属于高效大模型训练与推理中的推理优化研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05916' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Training-Time Action Conditioning for Efficient Real-Time Chunking</h3>
<p><strong>Authors:</strong> Kevin Black, Allen Z. Ren, Michael Equi, Sergey Levine</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出训练时动作条件化方法，消除实时分块的推理开销，提升视觉语言动作模型的推理效率，方法简单且在模拟与真实任务中验证效果
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05964' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ShaRP: SHAllow-LayeR Pruning for Video Large Language Models Acceleration</h3>
<p><strong>Authors:</strong> Yingjie Xia, Tao Liu, Jinglei Shi, Qingsong Xie, Heng Guo, Jian Yang, Xi Wang</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 针对视频大语言模型预填充阶段计算量大的问题，提出浅层层剪枝框架减少冗余，提升推理速度，属于高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05385' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction</h3>
<p><strong>Authors:</strong> Ruihong Yin, Xuepeng Shi, Oleksandr Bailo, Marco Manfredi, Theo Gevers</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出多token预测加速结构化语言模型推理，解决自回归速度慢的问题，同时保持准确性，属于高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05597' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack</h3>
<p><strong>Authors:</strong> Shiji Zhao, Shukun Xiong, Yao Huang, Yan Jin, Zhenyu Wu, Jiyang Guan, Ranjie Duan, Jialing Tao, Hui Xue, Xingxing Wei</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出视觉推理序列攻击方法VRSA，针对多模态大模型的安全漏洞实现越狱，评估了对GPT-4o、Claude-4.5-Sonnet等模型的攻击效果，对大模型安全与对齐研究有重要警示意义。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05853' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> BEAVER: An Efficient Deterministic LLM Verifier</h3>
<p><strong>Authors:</strong> Tarun Suresh, Nalin Wadhwa, Debangshu Banerjee, Gagandeep Singh</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出首个实用的LLM确定性验证框架，针对约束满足问题计算可靠概率边界，在正确性、隐私和安全代码生成任务上显著优于基线方法，为大模型安全部署提供关键工具，属于大模型安全与对齐方向。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05439' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Taxonomy-Adaptive Moderation Model with Robust Guardrails for Large Language Models</h3>
<p><strong>Authors:</strong> Mahesh Kumar Nandwana, Youngwan Lim, Joseph Liu, Alex Yang, Varun Notibala, Nishchaie Khanna</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出基于Llama-3.1的安全 moderation模型Roblox Guard 1.0，通过指令微调适应新安全 taxonomy，并发布评估基准，属于大模型安全与对齐研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05339' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs</h3>
<p><strong>Authors:</strong> Igor Shilov, Alex Cloud, Aryo Pradipta Gema, Jacob Goldman-Wetzler, Nina Panickssery, Henry Sleight, Erik Jones, Cem Anil</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出SGTM方法，将目标知识定位到特定参数子集以实现移除，提升了标签噪声下的 retain/forget 权衡与对抗鲁棒性，属于大模型安全与对齐研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05648' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations</h3>
<p><strong>Authors:</strong> Igor Halperin</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出基于信息论和热力学的语义忠实性（SF）和语义熵产生（SEP）指标，用于LLM幻觉控制和忠实性评估，在SEC 10-K文件总结任务上验证有效性，属于大模型安全与对齐中的幻觉管理方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05156' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation</h3>
<p><strong>Authors:</strong> Yiwen Liang, Qiufeng Li, Shikai Wang, Weidong Cao</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 针对LLM硬件代码生成中的IP记忆、污染数据等问题，提出语法保留的unlearning框架，提升了生成可靠性，属于大模型安全与对齐中的知识移除研究。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05341' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems</h3>
<p><strong>Authors:</strong> Robert Yang</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 引入哲学中的“意志薄弱（akrasia）”概念分析智能体的不一致和目标漂移问题，提出Akrasia Benchmark量化模型“自我控制”能力，连接哲学与AI安全，为大模型对齐研究提供新视角。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.05449' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Interaction Tensor Shap</h3>
<p><strong>Authors:</strong> Hiroki Hasegawa, Yukihiko Okada</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 将高阶Shapley交互表示为张量网络收缩，解决了现有方法的指数计算瓶颈，为高维模型的交互分析提供了可扩展框架，属于深度学习可解释性中的Shapley值研究。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05338' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models</h3>
<p><strong>Authors:</strong> Weijue Bu, Guan Yuan, Guixian Zhang</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出自适应注意力机制解决VLM的幻觉问题，提升边缘细节捕捉和空间连续性建模，属于深度学习可解释性方向的重要进展。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05546' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces</h3>
<p><strong>Authors:</strong> Na Li, Hangguan Shan, Wei Ni, Wenjie Zhang, Xinyu Li</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出RSA2C算法将SHAP归因与Actor-Critic优化结合，理论推导收敛界并实证提升强化学习性能，为深度学习可解释性与优化的融合研究提供了新范式。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05291' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability</h3>
<p><strong>Authors:</strong> Yiming Tang, Harshvardhan Saini, Yizhen Liao, Dianbo Liu</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 建立了稀疏字典学习在机制可解释性中的理论基础，解释了feature absorption等实证现象，属于深度学习可解释性中的白盒解释研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05534' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Sparse Attention Post-Training for Mechanistic Interpretability</h3>
<p><strong>Authors:</strong> Florent Draye, Anson Lei, Ingmar Posner, Bernhard Schölkopf</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 通过稀疏注意力后训练简化Transformer的电路结构，提升了机制可解释性，属于深度学习可解释性中的白盒解释研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05865' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution</h3>
<p><strong>Authors:</strong> Sara Patel, Mingxun Zhou, Giulia Fanti</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 结合Shapley值解决生成式搜索中的公平归因问题，针对检索增强生成（RAG）管道提出高效算法，在多跳QA数据集上实现与精确Shapley计算相当的归因质量且资源消耗显著降低，与深度学习可解释性方向高度相关。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05958' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception</h3>
<p><strong>Authors:</strong> Anne Sielemann, Valentin Barner, Stefan Wolf, Masoud Roschani, Jens Ziehn, Juergen Beyerer</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 利用SHAP、GradCAM等方法系统研究背景对自动驾驶感知模型的影响，量化了背景相关性的作用，对深度学习可解释性中的特征重要性分析有参考价值。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.05937' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Learnability Window in Gated Recurrent Neural Networks</h3>
<p><strong>Authors:</strong> Lorenzo Livi</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出可学习窗口理论框架，通过有效学习率解释门控RNN的长程依赖学习能力，深化了对RNN训练机制的理解，属于深度学习理论中的网络架构研究。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.05790' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Non-Convex Federated Optimization under Cost-Aware Client Selection</h3>
<p><strong>Authors:</strong> Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 针对联邦优化中不同客户端选择策略的通信成本差异问题，提出新模型和算法，改进了非凸优化下的通信与局部计算复杂度，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.05327' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RevoNAD: Reflective Evolutionary Exploration for Neural Architecture Design</h3>
<p><strong>Authors:</strong> Gyusam Chang, Jeongyoon Yoon, Shin han yi, JaeHyeok Lee, Sujin Jang, Sangpil Kim</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 结合LLM推理与进化搜索，提出反射式神经架构设计框架，提升了架构的可靠性与性能，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.05403' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hyperparameter Transfer Enables Consistent Gains of Matrix-Preconditioned Optimizers Across Scales</h3>
<p><strong>Authors:</strong> Shikai Qiu, Zixi Chen, Hoang Phan, Qi Lei, Andrew Gordon Wilson</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 研究矩阵预处理优化器的超参数迁移，解决了跨尺度性能一致性问题，提升了优化器的 scalability，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.05620' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Your Latent Mask is Wrong: Pixel-Equivalent Latent Compositing for Diffusion Models</h3>
<p><strong>Authors:</strong> Rowan Bradbury, Dazhi Zhong</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出像素等价的潜在合成方法，解决扩散模型潜在空间合成的 artifacts问题，提升inpainting等任务的边界和结构建模能力，属于原生多模态大模型方向的改进。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05198' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Delving into Latent Spectral Biasing of Video VAEs for Superior Diffusability</h3>
<p><strong>Authors:</strong> Shizhan Liu, Xinran Deng, Zhuoyi Yang, Jiayan Teng, Xiaotao Gu, Jie Tang</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 分析视频VAE的潜在谱偏置问题，提出正则化方法提升扩散模型的训练效率和生成质量，属于原生多模态大模型方向的改进。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05394' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models</h3>
<p><strong>Authors:</strong> Chuang Yu, Jinmiao Zhao, Mingxuan Zhao, Yunpeng Liu, Xiujun Shu, Yuanhao Feng, Bo Wang, Xiangyu Yue</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 针对多模态大模型（MLLMs）推理中的多 rationale 语义建模不足、逻辑鲁棒性差等问题，提出“理解-反思-纠正”的判别式推理框架，在多个公开数据集上实现SOTA性能，属于原生多模态大模型的推理增强方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05530' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bring Your Dreams to Life: Continual Text-to-Video Customization</h3>
<p><strong>Authors:</strong> Jiahua Dong, Xudong Wang, Wenqi Liang, Zongyan Han, Meng Cao, Duzhen Zhang, Hanbin Zhao, Zhi Han, Salman Khan, Fahad Shahbaz Khan</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出CCVD模型解决文本到视频持续定制中的遗忘与概念忽视问题，提升了持续学习性能，对原生多模态大模型的文本-视频生成研究有推动作用。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05802' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty</h3>
<p><strong>Authors:</strong> Zhiting Mei, Tenny Yin, Micah Baker, Ola Shorinwa, Anirudha Majumdar</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出C3不确定性量化方法，为可控视频模型提供校准的子patch级置信估计，解决视频生成幻觉问题，提升了多模态大模型的生成可靠性。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.05927' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding</h3>
<p><strong>Authors:</strong> Zhiyuan Jiang, Shenghao Xie, Wenyi Li, Wenqiang Zu, Peihang Li, Jiahao Qiu, Siqi Pei, Lei Ma, Tiejun Huang, Mengdi Wang, Shilong Liu</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 研究Zoom操作对GUI接地的作用，提出训练-free的ZoomClick方法提升GUI接地模型性能，构建GUIZoom-Bench基准，为多模态智能体中的GUI相关研究提供了新视角与工具。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.05941' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models</h3>
<p><strong>Authors:</strong> Haowen Liu, Shaoxiong Yao, Haonan Chen, Jiawei Gao, Jiayuan Mao, Jia-Bin Huang, Yilun Du</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 结合视觉语言模型（多模态）与模拟实现物理接地的动作规划，针对多模态智能体的物理推理能力提升，方法创新且在真实世界机器人任务中验证效果
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.05955' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity</h3>
<p><strong>Authors:</strong> Germán Kruszewski, Pierre Erbacher, Jos Rozen, Marc Dymetman</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出基于过滤正确答案的推理优化方法，针对RL导致的LLM多样性损失问题，利用α-divergence家族统一现有方法并控制precision-diversity权衡，在定理证明基准上实现帕累托前沿性能提升，属于大模型推理优化的新技术。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.05962' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Self-Improving VLM Judges Without Human Annotations</h3>
<p><strong>Authors:</strong> Inna Wanyin Lin, Yushi Hu, Shuyue Stella Li, Scott Geng, Pang Wei Koh, Luke Zettlemoyer, Tim Althoff, Marjan Ghazvininejad</p>
<p><strong>Published:</strong> 2025-12-08</p>
<p><strong>Reason:</strong> 提出无需人类标注的VLM评判器自训练框架，通过迭代生成-评判-优化提升正确性、推理和安全性能，属于大模型新技术方向的重要进展。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.05145' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>