# ArXiv 每日推荐 - 2025-12-09

> 更新于北京时间：2025-12-09 12:28:53
> 已自动阅读了 202 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：98564

## 高效大模型训练与推理

### [Score: 9.0/10] TwinFlow: Realizing One-step Generation on Large Models with Self-adversarial Flows
- **Authors:** Zhenglin Cheng, Peng Sun, Jianguo Li, Tao Lin
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05150](https://arxiv.org/abs/2512.05150)
- **Reason:** 提出无需预训练教师模型的1-step生成模型，解决扩散模型多步推理效率低的问题，在文本到图像任务上实现1-NFE下的高性能，符合高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] InvarDiff: Cross-Scale Invariance Caching for Accelerated Diffusion Models
- **Authors:** Zihao Wu
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05134](https://arxiv.org/abs/2512.05134)
- **Reason:** 提出训练-free的扩散模型加速方法，利用跨时间步和层的不变性缓存减少冗余计算，在保持生成质量的同时实现2-3倍推理加速，与高效大模型训练与推理方向高度相关。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] HQ-DM: Single Hadamard Transformation-Based Quantization-Aware Training for Low-Bit Diffusion Models
- **Authors:** Shizhuo Mao, Hongtao Zou, Qihu Xie, Song Chen, Yi Kang
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05746](https://arxiv.org/abs/2512.05746)
- **Reason:** 提出HQ-DM量化感知训练框架，通过单Hadamard变换解决扩散模型低比特量化的激活离群值问题，显著提升量化后性能，对高效扩散模型训练有关键贡献。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] USV: Unified Sparsification for Accelerating Video Diffusion Models
- **Authors:** Xinjian Wu, Hongmei Wang, Yuan Zhou, Qinglin Lu
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05754](https://arxiv.org/abs/2512.05754)
- **Reason:** 提出USV统一稀疏化框架，联合优化视频扩散模型的内部计算与采样过程，实现83.3%去噪加速和22.7%端到端加速，为高效视频生成提供了可行路径。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws
- **Authors:** Zhengquan Luo, Zhiqiang Xu
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05817](https://arxiv.org/abs/2512.05817)
- **Reason:** 建立数据集蒸馏的统一理论框架，推导了scaling law与configuration-coverage law，提升了蒸馏数据的有效性与鲁棒性，属于高效大模型训练与推理研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity
- **Authors:** Damien Lesens, Beheshteh T. Rakhshan, Guillaume Rabusseau
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05916](https://arxiv.org/abs/2512.05916)
- **Reason:** 提出KV缓存压缩方法，通过直接分解注意力矩阵保证 fidelity，解决了长序列推理的内存瓶颈，属于高效大模型训练与推理中的推理优化研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Training-Time Action Conditioning for Efficient Real-Time Chunking
- **Authors:** Kevin Black, Allen Z. Ren, Michael Equi, Sergey Levine
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05964](https://arxiv.org/abs/2512.05964)
- **Reason:** 提出训练时动作条件化方法，消除实时分块的推理开销，提升视觉语言动作模型的推理效率，方法简单且在模拟与真实任务中验证效果
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] ShaRP: SHAllow-LayeR Pruning for Video Large Language Models Acceleration
- **Authors:** Yingjie Xia, Tao Liu, Jinglei Shi, Qingsong Xie, Heng Guo, Jian Yang, Xi Wang
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05385](https://arxiv.org/abs/2512.05385)
- **Reason:** 针对视频大语言模型预填充阶段计算量大的问题，提出浅层层剪枝框架减少冗余，提升推理速度，属于高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction
- **Authors:** Ruihong Yin, Xuepeng Shi, Oleksandr Bailo, Marco Manfredi, Theo Gevers
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05597](https://arxiv.org/abs/2512.05597)
- **Reason:** 提出多token预测加速结构化语言模型推理，解决自回归速度慢的问题，同时保持准确性，属于高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理

## 大模型安全与对齐

### [Score: 9.0/10] VRSA: Jailbreaking Multimodal Large Language Models through Visual Reasoning Sequential Attack
- **Authors:** Shiji Zhao, Shukun Xiong, Yao Huang, Yan Jin, Zhenyu Wu, Jiyang Guan, Ranjie Duan, Jialing Tao, Hui Xue, Xingxing Wei
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05853](https://arxiv.org/abs/2512.05853)
- **Reason:** 提出视觉推理序列攻击方法VRSA，针对多模态大模型的安全漏洞实现越狱，评估了对GPT-4o、Claude-4.5-Sonnet等模型的攻击效果，对大模型安全与对齐研究有重要警示意义。
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] BEAVER: An Efficient Deterministic LLM Verifier
- **Authors:** Tarun Suresh, Nalin Wadhwa, Debangshu Banerjee, Gagandeep Singh
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05439](https://arxiv.org/abs/2512.05439)
- **Reason:** 提出首个实用的LLM确定性验证框架，针对约束满足问题计算可靠概率边界，在正确性、隐私和安全代码生成任务上显著优于基线方法，为大模型安全部署提供关键工具，属于大模型安全与对齐方向。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] Taxonomy-Adaptive Moderation Model with Robust Guardrails for Large Language Models
- **Authors:** Mahesh Kumar Nandwana, Youngwan Lim, Joseph Liu, Alex Yang, Varun Notibala, Nishchaie Khanna
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05339](https://arxiv.org/abs/2512.05339)
- **Reason:** 提出基于Llama-3.1的安全 moderation模型Roblox Guard 1.0，通过指令微调适应新安全 taxonomy，并发布评估基准，属于大模型安全与对齐研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs
- **Authors:** Igor Shilov, Alex Cloud, Aryo Pradipta Gema, Jacob Goldman-Wetzler, Nina Panickssery, Henry Sleight, Erik Jones, Cem Anil
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05648](https://arxiv.org/abs/2512.05648)
- **Reason:** 提出SGTM方法，将目标知识定位到特定参数子集以实现移除，提升了标签噪声下的 retain/forget 权衡与对抗鲁棒性，属于大模型安全与对齐研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations
- **Authors:** Igor Halperin
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05156](https://arxiv.org/abs/2512.05156)
- **Reason:** 提出基于信息论和热力学的语义忠实性（SF）和语义熵产生（SEP）指标，用于LLM幻觉控制和忠实性评估，在SEC 10-K文件总结任务上验证有效性，属于大模型安全与对齐中的幻觉管理方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation
- **Authors:** Yiwen Liang, Qiufeng Li, Shikai Wang, Weidong Cao
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05341](https://arxiv.org/abs/2512.05341)
- **Reason:** 针对LLM硬件代码生成中的IP记忆、污染数据等问题，提出语法保留的unlearning框架，提升了生成可靠性，属于大模型安全与对齐中的知识移除研究。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems
- **Authors:** Robert Yang
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05449](https://arxiv.org/abs/2512.05449)
- **Reason:** 引入哲学中的“意志薄弱（akrasia）”概念分析智能体的不一致和目标漂移问题，提出Akrasia Benchmark量化模型“自我控制”能力，连接哲学与AI安全，为大模型对齐研究提供新视角。
Score: 7
Field: 大模型安全与对齐

## 深度学习可解释性

### [Score: 9.0/10] Interaction Tensor Shap
- **Authors:** Hiroki Hasegawa, Yukihiko Okada
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05338](https://arxiv.org/abs/2512.05338)
- **Reason:** 将高阶Shapley交互表示为张量网络收缩，解决了现有方法的指数计算瓶颈，为高维模型的交互分析提供了可扩展框架，属于深度学习可解释性中的Shapley值研究。
Score: 9
Field: 深度学习可解释性

### [Score: 8.0/10] Conscious Gaze: Adaptive Attention Mechanisms for Hallucination Mitigation in Vision-Language Models
- **Authors:** Weijue Bu, Guan Yuan, Guixian Zhang
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05546](https://arxiv.org/abs/2512.05546)
- **Reason:** 提出自适应注意力机制解决VLM的幻觉问题，提升边缘细节捕捉和空间连续性建模，属于深度学习可解释性方向的重要进展。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces
- **Authors:** Na Li, Hangguan Shan, Wei Ni, Wenjie Zhang, Xinyu Li
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05291](https://arxiv.org/abs/2512.05291)
- **Reason:** 提出RSA2C算法将SHAP归因与Actor-Critic优化结合，理论推导收敛界并实证提升强化学习性能，为深度学习可解释性与优化的融合研究提供了新范式。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability
- **Authors:** Yiming Tang, Harshvardhan Saini, Yizhen Liao, Dianbo Liu
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05534](https://arxiv.org/abs/2512.05534)
- **Reason:** 建立了稀疏字典学习在机制可解释性中的理论基础，解释了feature absorption等实证现象，属于深度学习可解释性中的白盒解释研究。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Sparse Attention Post-Training for Mechanistic Interpretability
- **Authors:** Florent Draye, Anson Lei, Ingmar Posner, Bernhard Schölkopf
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05865](https://arxiv.org/abs/2512.05865)
- **Reason:** 通过稀疏注意力后训练简化Transformer的电路结构，提升了机制可解释性，属于深度学习可解释性中的白盒解释研究。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution
- **Authors:** Sara Patel, Mingxun Zhou, Giulia Fanti
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05958](https://arxiv.org/abs/2512.05958)
- **Reason:** 结合Shapley值解决生成式搜索中的公平归因问题，针对检索增强生成（RAG）管道提出高效算法，在多跳QA数据集上实现与精确Shapley计算相当的归因质量且资源消耗显著降低，与深度学习可解释性方向高度相关。
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Measuring the Effect of Background on Classification and Feature Importance in Deep Learning for AV Perception
- **Authors:** Anne Sielemann, Valentin Barner, Stefan Wolf, Masoud Roschani, Jens Ziehn, Juergen Beyerer
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05937](https://arxiv.org/abs/2512.05937)
- **Reason:** 利用SHAP、GradCAM等方法系统研究背景对自动驾驶感知模型的影响，量化了背景相关性的作用，对深度学习可解释性中的特征重要性分析有参考价值。
Score: 7
Field: 深度学习可解释性

## 深度学习理论

### [Score: 9.0/10] Learnability Window in Gated Recurrent Neural Networks
- **Authors:** Lorenzo Livi
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05790](https://arxiv.org/abs/2512.05790)
- **Reason:** 提出可学习窗口理论框架，通过有效学习率解释门控RNN的长程依赖学习能力，深化了对RNN训练机制的理解，属于深度学习理论中的网络架构研究。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] Non-Convex Federated Optimization under Cost-Aware Client Selection
- **Authors:** Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05327](https://arxiv.org/abs/2512.05327)
- **Reason:** 针对联邦优化中不同客户端选择策略的通信成本差异问题，提出新模型和算法，改进了非凸优化下的通信与局部计算复杂度，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] RevoNAD: Reflective Evolutionary Exploration for Neural Architecture Design
- **Authors:** Gyusam Chang, Jeongyoon Yoon, Shin han yi, JaeHyeok Lee, Sujin Jang, Sangpil Kim
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05403](https://arxiv.org/abs/2512.05403)
- **Reason:** 结合LLM推理与进化搜索，提出反射式神经架构设计框架，提升了架构的可靠性与性能，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Hyperparameter Transfer Enables Consistent Gains of Matrix-Preconditioned Optimizers Across Scales
- **Authors:** Shikai Qiu, Zixi Chen, Hoang Phan, Qi Lei, Andrew Gordon Wilson
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05620](https://arxiv.org/abs/2512.05620)
- **Reason:** 研究矩阵预处理优化器的超参数迁移，解决了跨尺度性能一致性问题，提升了优化器的 scalability，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论

## 原生多模态大模型

### [Score: 8.0/10] Your Latent Mask is Wrong: Pixel-Equivalent Latent Compositing for Diffusion Models
- **Authors:** Rowan Bradbury, Dazhi Zhong
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05198](https://arxiv.org/abs/2512.05198)
- **Reason:** 提出像素等价的潜在合成方法，解决扩散模型潜在空间合成的 artifacts问题，提升inpainting等任务的边界和结构建模能力，属于原生多模态大模型方向的改进。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Delving into Latent Spectral Biasing of Video VAEs for Superior Diffusability
- **Authors:** Shizhan Liu, Xinran Deng, Zhuoyi Yang, Jiayan Teng, Xiaotao Gu, Jie Tang
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05394](https://arxiv.org/abs/2512.05394)
- **Reason:** 分析视频VAE的潜在谱偏置问题，提出正则化方法提升扩散模型的训练效率和生成质量，属于原生多模态大模型方向的改进。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models
- **Authors:** Chuang Yu, Jinmiao Zhao, Mingxuan Zhao, Yunpeng Liu, Xiujun Shu, Yuanhao Feng, Bo Wang, Xiangyu Yue
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05530](https://arxiv.org/abs/2512.05530)
- **Reason:** 针对多模态大模型（MLLMs）推理中的多 rationale 语义建模不足、逻辑鲁棒性差等问题，提出“理解-反思-纠正”的判别式推理框架，在多个公开数据集上实现SOTA性能，属于原生多模态大模型的推理增强方向。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] Bring Your Dreams to Life: Continual Text-to-Video Customization
- **Authors:** Jiahua Dong, Xudong Wang, Wenqi Liang, Zongyan Han, Meng Cao, Duzhen Zhang, Hanbin Zhao, Zhi Han, Salman Khan, Fahad Shahbaz Khan
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05802](https://arxiv.org/abs/2512.05802)
- **Reason:** 提出CCVD模型解决文本到视频持续定制中的遗忘与概念忽视问题，提升了持续学习性能，对原生多模态大模型的文本-视频生成研究有推动作用。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty
- **Authors:** Zhiting Mei, Tenny Yin, Micah Baker, Ola Shorinwa, Anirudha Majumdar
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05927](https://arxiv.org/abs/2512.05927)
- **Reason:** 提出C3不确定性量化方法，为可控视频模型提供校准的子patch级置信估计，解决视频生成幻觉问题，提升了多模态大模型的生成可靠性。
Score: 7
Field: 原生多模态大模型

## 多模态智能体

### [Score: 8.0/10] Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding
- **Authors:** Zhiyuan Jiang, Shenghao Xie, Wenyi Li, Wenqiang Zu, Peihang Li, Jiahao Qiu, Siqi Pei, Lei Ma, Tiejun Huang, Mengdi Wang, Shilong Liu
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05941](https://arxiv.org/abs/2512.05941)
- **Reason:** 研究Zoom操作对GUI接地的作用，提出训练-free的ZoomClick方法提升GUI接地模型性能，构建GUIZoom-Bench基准，为多模态智能体中的GUI相关研究提供了新视角与工具。
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models
- **Authors:** Haowen Liu, Shaoxiong Yao, Haonan Chen, Jiawei Gao, Jiayuan Mao, Jia-Bin Huang, Yilun Du
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05955](https://arxiv.org/abs/2512.05955)
- **Reason:** 结合视觉语言模型（多模态）与模拟实现物理接地的动作规划，针对多模态智能体的物理推理能力提升，方法创新且在真实世界机器人任务中验证效果
Score: 7
Field: 多模态智能体

## 大模型新技术

### [Score: 8.0/10] Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity
- **Authors:** Germán Kruszewski, Pierre Erbacher, Jos Rozen, Marc Dymetman
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05962](https://arxiv.org/abs/2512.05962)
- **Reason:** 提出基于过滤正确答案的推理优化方法，针对RL导致的LLM多样性损失问题，利用α-divergence家族统一现有方法并控制precision-diversity权衡，在定理证明基准上实现帕累托前沿性能提升，属于大模型推理优化的新技术。
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] Self-Improving VLM Judges Without Human Annotations
- **Authors:** Inna Wanyin Lin, Yushi Hu, Shuyue Stella Li, Scott Geng, Pang Wei Koh, Luke Zettlemoyer, Tim Althoff, Marjan Ghazvininejad
- **Published:** 2025-12-08
- **Link:** [https://arxiv.org/abs/2512.05145](https://arxiv.org/abs/2512.05145)
- **Reason:** 提出无需人类标注的VLM评判器自训练框架，通过迭代生成-评判-优化提升正确性、推理和安全性能，属于大模型新技术方向的重要进展。
Score: 7
Field: 大模型新技术

