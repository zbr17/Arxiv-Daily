<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-10</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>大模型安全与对齐</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >大模型新技术</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >深度学习理论</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-10</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-10 12:51:07</p>
<p>已自动阅读了 474 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：258969</p>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs</h3>
<p><strong>Authors:</strong> Chaoyang Wang, Yangfan He, Yiyang Zhou, Yixuan Wang, Jiaqi Liu, Peng Xia, Zhengzhong Tu, Mohit Bansal, Huaxiu Yao</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 揭示大视觉语言模型（LVLM）的推理路径错误问题，提出PSO两阶段框架优化推理路径选择，提升模型推理的稳定性与准确性，对大模型安全与对齐中的推理对齐有重要价值
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06258' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> RunawayEvil: Jailbreaking the Image-to-Video Generative Models</h3>
<p><strong>Authors:</strong> Songping Wang, Rufan Qian, Yueming Lyu, Qinglong Liu, Linzhuang Zou, Jie Qin, Songhua Liu, Caifeng Shan</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出首个多模态越狱框架研究图像到视频生成模型的安全漏洞，属于大模型安全与对齐的恶意攻击防御方向，创新性高。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06674' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models</h3>
<p><strong>Authors:</strong> Fenghua Weng, Chaochao Lu, Xia Hu, Wenqi Shao, Wenjie Wang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对大视觉语言模型（LVLM）的安全对齐问题，提出三阶段反思框架TRR，构建ReSafe数据集，通过强化学习强化政策引导的自我反思，将安全响应率从42.8%提升至87.7%，同时保持通用任务性能，有效增强LVLM的安全性。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07141' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models</h3>
<p><strong>Authors:</strong> Tong Xie, Andrew Bai, Yuanhao Ban, Yunqi Hong, Haoyu Li, Cho-jui Hsieh</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 分析RLHF中BT损失的表示距离偏差，提出NormBT优化奖励模型，属于大模型对齐的关键改进。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06343' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> GSAE: Graph-Regularized Sparse Autoencoders for Robust LLM Safety Steering</h3>
<p><strong>Authors:</strong> Jehyeok Yeon, Federico Cinus, Yifan Wu, Luca Luceri</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出GSAE用于LLM安全引导，增强拒绝有害内容的能力，提升安全与对齐性能。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06655' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities</h3>
<p><strong>Authors:</strong> Dung Thuy Nguyen, Quang Nguyen, Preston K. Robinette, Eli Jiang, Taylor T. Johnson, Kevin Leach</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出生成式遗忘框架解决3D生成模型的身份移除问题，聚焦大模型安全与对齐中的隐私保护需求。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06562' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection</h3>
<p><strong>Authors:</strong> Ruoxin Chen, Jiahui Gao, Kaiqing Lin, Keyue Zhang, Yandan Zhao, Isabel Guan, Taiping Yao, Shouhong Ding</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出任务-模型对齐原则构建双分支检测器，解决AI生成图像检测的泛化性问题，属于大模型安全与对齐的内容真实性验证方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06746' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting</h3>
<p><strong>Authors:</strong> Longjie Zhao, Ziming Hong, Zhenyang Ren, Runnan Chen, Mingming Gong, Tongliang Liu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出3D Gaussian Splatting的鲁棒水印方法，解决扩散编辑下的版权保护问题，属于大模型安全与对齐的产权保护方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06774' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing</h3>
<p><strong>Authors:</strong> Ziming Hong, Tianyu Huang, Runnan Chen, Shanshan Ye, Mingming Gong, Bo Han, Tongliang Liu (University of Sydney)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出AdLift框架，通过将2D对抗扰动提升到3D高斯表示，保护3D资产免受指令驱动编辑，属于大模型安全与对齐中的对抗性保护方向，作者和机构具有影响力。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07247' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models</h3>
<p><strong>Authors:</strong> Kassoum Sanogo, Renzo Ardiccioni (Institutions not specified)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出无训练自校正框架，通过不确定性引导的视觉再注意减少视觉语言模型的幻觉，属于大模型安全与对齐中的可靠性提升方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07564' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Quantization Blindspots: How Model Compression Breaks Backdoor Defenses</h3>
<p><strong>Authors:</strong> Rohan Pandey, Eric Ye</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 发现INT8量化使所有后门防御的检测率降至0%，揭示部署环境（量化模型）与防御评估（全精度模型）的 mismatch，属于大模型安全与对齐中的量化鲁棒性方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06243' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning</h3>
<p><strong>Authors:</strong> Yezi Liu, Hanning Chen, Wenjun Huang, Yang Ni, Mohsen Imani</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出R2F框架，通过LoRA的梯度重建实现LLM高效遗忘，无需全模型微调或原始数据访问，理论分析了跨模型泛化性，实证显示有效性与效率优于现有方法，属于大模型安全与对齐中的unlearning方向，解决了LLM安全调整的计算成本问题。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07374' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples</h3>
<p><strong>Authors:</strong> Yezi Liu, Hanning Chen, Wenjun Huang, Yang Ni, Mohsen Imani</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出LUNE方法，通过LoRA的负样本微调实现LLM高效遗忘，仅更新低秩适配器，计算成本比全微调低一个数量级，实证显示效果与全微调相当，属于大模型安全与对齐中的unlearning方向，提升了LLM安全调整的效率。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07375' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents</h3>
<p><strong>Authors:</strong> Zhibo Liang, Tianze Hu, Zaiye Chen, Mingjie Tang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出CCA认知控制架构，通过Intent Graph和Tiered Adjudicator实现全生命周期认知监督，抵御间接提示注入（IPI）攻击，提升AI代理的对齐鲁棒性，属于大模型安全与对齐中的安全框架。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06716' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection</h3>
<p><strong>Authors:</strong> Sayeem Been Zaman, Wasimul Karim, Arefin Ittesafun Abian, Reem E. Mohamed, Md Rafiqul Islam, Asif Karim, Sami Azam (Institutions not specified)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出DeepAgent框架，通过双流多agent融合实现鲁棒多模态Deepfake检测，属于大模型安全与对齐中的虚假内容检测方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07351' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> When Privacy Isn't Synthetic: Hidden Data Leakage in Generative AI Models</h3>
<p><strong>Authors:</strong> S. M. Mustaqim, Anantaa Kotal, Paul H. Yi</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 揭示生成模型的分布邻域隐私泄漏问题，提出基于聚类的黑盒成员推理攻击，即使模型用差分隐私训练仍存在泄漏，属于大模型安全与对齐中的隐私保护方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06062' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Depth-Wise Activation Steering for Honest Language Models</h3>
<p><strong>Authors:</strong> Gracjan G\'oral, Marysia Winkels, Steven Basart</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出深度激活引导方法，通过高斯调度加权网络深度的引导强度，提升语言模型的诚实性（减少虚假陈述），属于大模型安全与对齐中的诚实性研究。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07667' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment</h3>
<p><strong>Authors:</strong> Charlie Masters, Marta Grze\'skiewicz, Stefano V. Albrecht</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出ARCANE多代理框架，将对齐转化为多代理协作问题，用自然语言规则动态表示 stakeholder偏好，实现可解释和可配置对齐，属于大模型安全与对齐中的对齐框架。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.06196' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models</h3>
<p><strong>Authors:</strong> Xiqiao Xiong, Ouxiang Li, Zhuo Liu, Moxin Li, Wentao Shi, Fuli Feng, Xiangnan He</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对大模型黑盒多轮jailbreak问题，用强化学习优化攻击策略，提升了攻击成功率，为大模型安全防御和评估提供了重要参考。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07761' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Auditing Games for Sandbagging</h3>
<p><strong>Authors:</strong> Jordan Taylor, Sid Black, Dillon Bowen, Thomas Read, Satvik Golechha, Alex Zelenka-Martin, Oliver Makins, Connor Kissane, Kola Ayonrinde, Jacob Merizian, Samuel Marks, Chris Cundy, Joseph Bloom</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 研究AI系统的sandbagging行为（隐藏能力），通过红队蓝队博弈测试检测方法，对大模型安全审计和可靠性评估有重要意义。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.07810' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Unleashing the Intrinsic Visual Representation Capability of Multimodal Large Language Models</h3>
<p><strong>Authors:</strong> Hengzhuang Li, Xinsong Zhang, Qiming Peng, Bin Luo, Han Hu, Dengyang Jiang, Han-Jia Ye, Teng Zhang, Hai Jin</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对多模态大语言模型（MLLM）的模态不平衡问题，提出LaVer框架通过掩码图像建模增强视觉表示，显著提升多模态任务性能，对原生多模态大模型的表示学习有关键贡献
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06281' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation</h3>
<p><strong>Authors:</strong> Wenyi Mo, Tianyu Zhang, Yalong Bai, Ligong Han, Ying Ba, Dimitris N. Metaxas</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出多模态偏好学习框架，利用多模态大语言模型提取用户偏好表示并注入扩散模型，实现偏好条件下的图像生成，对原生多模态大模型的应用拓展有重要意义
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06020' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation</h3>
<p><strong>Authors:</strong> Su Sun, Cheng Zhao, Himangi Mittal, Gaurav Mittal, Rohith Kukkala, Yingjie Victor Chen, Mei Chen</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出Track4DGen框架，结合多视图视频扩散模型与基础点跟踪器，注入运动先验提升4D动态对象生成的一致性与 fidelity，对原生多模态大模型的4D生成任务有创新贡献
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06158' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension</h3>
<p><strong>Authors:</strong> Tianyi Gao, Hao Li, Han Fang, Xin Wei, Xiaodong Dong, Hongbo Sun, Ye Yuan, Zhongjiang He, Jinglin Xu, Jingmin Xin, Hao Sun</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 构建RefBench-PRO基准，分解指代表达理解任务为感知与推理维度，提出RL-based方法提升复杂推理下的定位精度，对原生多模态大模型的可解释性评估与优化有重要意义
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06276' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models</h3>
<p><strong>Authors:</strong> Jiahao Li, Yusheng Luo, Yunzhong Lou, Xiangdong Zhou</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出ReCAD框架，结合强化学习与视觉语言模型生成精确的参数化CAD模型，提升几何 accuracy与泛化性，对原生多模态大模型在CAD领域的应用有重要突破
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06328' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Training Dynamics in Scale-wise Autoregressive Generation</h3>
<p><strong>Authors:</strong> Gengze Zhou, Chongjian Ge, Hao Tan, Feng Liu, Yicong Hong</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 分析尺度自回归生成的训练动态，提出SAR方法改善暴露偏差，提升图像生成质量，属于原生多模态大模型的图像生成方向研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06421' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DragMesh: Interactive 3D Generation Made Easy</h3>
<p><strong>Authors:</strong> Tianshan Zhang, Zeyu Zhang, Hao Tang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出解耦运动学推理与生成的3D交互框架，实现实时可动画3D生成，推动原生多模态大模型的3D智能发展。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06424' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars</h3>
<p><strong>Authors:</strong> Ramazan Fazylov, Sergey Zagoruyko, Aleksandr Parkin, Stamatis Lefkimmiatis, Ivan Laptev</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 结合3D Gaussian Splatting与GAN生成实时可动画头像，属于原生多模态大模型的3D生成方向重要成果。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06438' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CoT4Det: A Chain-of-Thought Framework for Perception-Oriented Vision-Language Tasks</h3>
<p><strong>Authors:</strong> Yu Qi, Yumeng Zhang, Chenting Gong, Xiao Tan, Weiming Zhang, Wei Zhang, Jingdong Wang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 将思维链引入感知导向视觉语言任务，提升大模型目标检测性能，属于原生多模态大模型的感知推理优化研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06663' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> 1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning</h3>
<p><strong>Authors:</strong> Shida Gao, Feng Xue, Xiangfeng Wang, Anlong Ming, Teng Long, Yihua Shao, Haozhe Wang, Zhaowen Lin, Wei Wang, Nicu Sebe</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 结合视频大模型与开放词汇检测器解决时空接地问题，推动原生多模态大模型的视频理解能力提升。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Scaling Zero-Shot Reference-to-Video Generation</h3>
<p><strong>Authors:</strong> Zijian Zhou, Shikun Liu, Haozhe Liu, Haonan Qiu, Zhaochong An, Weiming Ren, Zhiheng Liu, Xiaoke Huang, Kam Woh Ng, Tian Xie, Xiao Han, Yuren Cong, Hang Li, Chuyan Zhu, Aditya Patel, Tao Xiang, Sen He</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 解决参考到视频（R2V）生成依赖昂贵图像-视频-文本三元组的问题，提出零-shot框架Saber，仅用视频-文本对训练，通过masked训练和attention设计学习身份一致的参考感知表示，在基准上超过现有方法，提升R2V的 scalability。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06905' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning</h3>
<p><strong>Authors:</strong> Xuhui Zheng, Kang An, Ziliang Wang, Yuhang Wang, Faqiang Qian, Yichao Wu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对多模态预训练的图像-标题对描述偏差问题，首次将强化学习融入MLLM预训练，提出MMRPT框架，mask视觉依赖的文本片段，用语义-视觉奖励引导重构，增强模型的视觉接地推理能力，实验显示零-shot性能提升和鲁棒性增强。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07203' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unified Camera Positional Encoding for Controlled Video Generation</h3>
<p><strong>Authors:</strong> Cheng Zhang, Boying Li, Meng Wei, Yan-Pei Cao, Camilo Cruz Gambardella, Dinh Phung, Jianfei Cai (Monash University, Nanyang Technological University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出统一相机位置编码UCPE，整合6-DoF姿态、内参和畸变信息，提升文本到视频生成的相机可控性，属于原生多模态大模型中的视频生成方向，机构和方法具有优势。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07237' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition</h3>
<p><strong>Authors:</strong> Xinyu Wei, Kangrui Cen, Hongyang Wei, Zhen Guo, Bairui Li, Zeqing Wang, Jinrui Zhang, Lei Zhang (Hong Kong University of Science and Technology)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 构建MICo-150K多图像合成数据集，支持任意多图像输入的一致性生成，属于原生多模态大模型中的多图像合成方向，作者和机构具有影响力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07348' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects</h3>
<p><strong>Authors:</strong> Shuohan Tao, Boyao Zhou, Hanzhang Tu, Yuwang Wang, Yebin Liu (Tsinghua University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出Tessellation GS框架，通过神经网格高斯实现动态物体的单目重建，提升鲁棒性和精度，属于原生多模态大模型中的3D重建方向，作者和机构具有强影响力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07381' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer</h3>
<p><strong>Authors:</strong> Penghui Liu, Jiangshan Wang, Yutong Shen, Shanhui Mo, Chenyang Qi, Yue Ma (Tsinghua University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出MultiMotion框架，通过Video Diffusion Transformer实现多主体视频动作迁移，属于原生多模态大模型中的视频生成方向，作者和机构具有强影响力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07500' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MeshRipple: Structured Autoregressive Generation of Artist-Meshes</h3>
<p><strong>Authors:</strong> Junkai Lin, Hang Long, Huipeng Guo, Jielei Zhang, JiaYi Yang, Tianle Guo, Yang Yang, Jianwen Li, Wenxiao Zhang, Matthias Nie{\ss}ner, Wei Yang (Technical University of Munich, Tsinghua University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出MeshRipple框架，通过结构化自回归生成艺术家风格3D网格，属于原生多模态大模型中的3D生成方向，作者和机构具有强影响力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07514' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Orbit to Ground: Generative City Photogrammetry from Extreme Off-Nadir Satellite Images</h3>
<p><strong>Authors:</strong> Fei Yu, Yu Liu, Luyang Tang, Mingchao Sun, Zengye Ge, Rui Bu, Yuchao Jin, Haisen Zhao, He Sun, Yangyan Li, Mu Xu, Wenzheng Chen, Baoquan Chen (Tsinghua University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出从卫星图像生成地面视图的框架，通过2.5D高度图和生成纹理恢复实现城市级3D重建，属于原生多模态大模型中的图像生成方向，作者和机构具有强影响力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07527' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LongCat-Image Technical Report</h3>
<p><strong>Authors:</strong> Meituan LongCat Team, Hanghang Ma, Haoxian Tan, Jiale Huang, Junqiang Wu, Jun-Yan He, Lishuai Gao, Songlin Xiao, Xiaoming Wei, Xiaoqi Ma, Xunliang Cai, Yayong Guan, Jie Hu (Meituan)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 发布LongCat-Image多语言图像生成模型，提升文本渲染和图像编辑能力，属于原生多模态大模型中的图像生成方向，企业团队具有实践影响力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07584' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation</h3>
<p><strong>Authors:</strong> Zhiqi Li, Wenhuan Li, Tengfei Wang, Zhenwei Wang, Junta Wu, Haoyuan Wang, Yunhan Yang, Zehuan Huang, Yang Li, Peidong Liu, Chunchao Guo (Tsinghua University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出MoCA框架，通过混合组件注意力实现可扩展的组合式3D生成，属于原生多模态大模型中的3D生成方向，作者和机构具有强影响力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07628' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment</h3>
<p><strong>Authors:</strong> Sangha Park, Eunji Kim, Yeongtak Oh, Jooyoung Choi, Sungroh Yoon</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对文本-图像生成中的对齐难题，提出自动化负向提示 pipeline（NPC），通过分析交叉注意力模式识别非预期内容并生成负向提示，在GenEval++和Imagine-Bench上显著优于基线，属于原生多模态大模型中文本-图像对齐的关键优化方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07702' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination</h3>
<p><strong>Authors:</strong> Sangha Park, Seungryong Yoo, Jisoo Mok, Sungroh Yoon</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对多模态大模型的物体幻觉问题，通过稀疏自编码器识别视觉理解特征并引导模型，在CHAIR_S、POPE等基准上实现10%+性能提升，属于原生多模态大模型中的幻觉缓解方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07730' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation</h3>
<p><strong>Authors:</strong> Shihao Zhao, Yitong Chen, Zeyinzi Jiang, Bojia Zi, Shaozhe Hao, Yu Liu, Chaojie Mao, Kwan-Yee K. Wong</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出低成本多模态统一框架，支持文本/图像/视频的理解与生成，自动解析用户意图和任务类型，无需人工干预，属于原生多模态大模型中的统一化方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07747' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing</h3>
<p><strong>Authors:</strong> Haoyang He, Jie Wang, Jiangning Zhang, Zhucun Xue, Xingyuan Bu, Qiangpeng Yang, Shilei Wen, Lei Xie</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 构建包含8种编辑类型的300万级指令引导视频编辑数据集，配套431条基准测试，训练的OpenVE-Edit模型优于现有开源模型，属于原生多模态大模型中的数据集与视频编辑方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07826' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Vector Quantization using Gaussian Variational Autoencoder</h3>
<p><strong>Authors:</strong> Tongda Xu, Wendi Zheng, Jiajun He, Jose Miguel Hernandez-Lobato, Yan Wang, Ya-Qin Zhang, Jie Tang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出Gaussian Quant改进VQ-VAE的向量量化，生成离散token，属于原生多模态大模型的tokenizer方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06609' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VideoVLA: Video Generators Can Be Generalizable Robot Manipulators</h3>
<p><strong>Authors:</strong> Yichao Shen, Fangyun Wei, Zhiying Du, Yaobo Liang, Yan Lu, Jiaolong Yang, Nanning Zheng, Baining Guo</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出VideoVLA，将视频生成模型转化为通用机器人操纵器，联合建模视频、语言和动作模态，利用预训练视频生成模型实现视觉想象与动作预测，属于原生多模态大模型的创新应用。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06963' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Personalized Image Descriptions from Attention Sequences</h3>
<p><strong>Authors:</strong> Ruoyu Xue, Hieu Le, Jingyi Xu, Sounak Mondal, Abe Leite, Gregory Zelinsky, Minh Hoai, Dimitris Samaras</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 结合个性化注意力序列生成图像描述，改进视觉语言模型的个性化理解能力，属于原生多模态大模型的多模态交互研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06662' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Role of Entropy in Visual Grounding: Analysis and Optimization</h3>
<p><strong>Authors:</strong> Shuo Li, Jiajun Sun, Zhihao Zhang, Xiaoran Fan, Senjie Jin, Hui Li, Yuming Yang, Junjie Ye, Lixing Shen, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 分析熵在视觉接地中的作用并提出ECVGPO优化策略，提升多模态大模型的视觉推理稳定性，属于原生多模态大模型的感知优化研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06726' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding</h3>
<p><strong>Authors:</strong> Hang Yin, Xiaomin He, PeiWen Yuan, Yiwei Li, Jiayi Shi, Wenxiao Fan, Shaoxiong Feng, Kan Li</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 通过结构化数据增强注入空间监督，提升视觉语言模型的空间理解能力，属于原生多模态大模型的空间推理优化研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06769' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning</h3>
<p><strong>Authors:</strong> Yueqian Wang, Songxiang Liu, Disong Wang, Nuo Xu, Guanglu Wan, Huishuai Zhang, Dongyan Zhao</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 用多轮强化学习增强视频多模态大模型的主动交互能力，属于原生多模态大模型的视频交互优化研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06810' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models</h3>
<p><strong>Authors:</strong> Biao Chen, Lin Zuo, Mengmeng Jing, Kunbin He, Yuchen Wang (Institutions not specified)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出Dropout Prompt Learning方法，通过token级dropout和残差熵正则化提升视觉语言模型在低样本、长尾等场景的鲁棒性，与原生多模态大模型研究方向高度相关。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07234' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation</h3>
<p><strong>Authors:</strong> Zhi Rao, Yucheng Zhou, Benjia Zhou, Yiqing Huang, Sergio Escalera, Jun Wan (Polytechnic University of Catalonia, South China Normal University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出RVLF框架，结合视觉语言模型和强化学习优化无Gloss手语翻译，提升语义一致性和翻译质量，属于原生多模态大模型中的手语翻译方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07273' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation</h3>
<p><strong>Authors:</strong> Ziyang Mai, Yu-Wing Tai (The Chinese University of Hong Kong)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出ContextAnyone框架，通过Emphasize-Attention模块整合参考图像信息，提升文本到视频生成的角色一致性，属于原生多模态大模型中的视频生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07328' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery</h3>
<p><strong>Authors:</strong> Meng Cao, Xingyu Li, Xue Liu, Ian Reid, Xiaodan Liang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出强化学习框架，通过主动探索、视觉想象和证据推理提升多模态大模型的空间推理能力，解决复杂空间任务中的性能瓶颈，属于原生多模态大模型中的空间理解方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07733' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation</h3>
<p><strong>Authors:</strong> Fan Yang, Heyuan Li, Peihao Li, Weihao Yuan, Lingteng Qiu, Chaoyue Song, Cheng Chen, Yisheng He, Shifeng Zhang, Xiaoguang Han, Steven Hoi, Guosheng Lin</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 结合3D重建的结构/外观先验与实时视频扩散模型，生成高保真上半身3D avatar，解决现有方法的纹理模糊和运动僵硬问题，属于原生多模态大模型中的3D数字人生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07720' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory</h3>
<p><strong>Authors:</strong> Zhaochong An, Menglin Jia, Haonan Qiu, Zijian Zhou, Xiaoke Huang, Zhiheng Liu, Weiming Ren, Kumara Kahatapitiya, Ding Liu, Sen He, Chenyang Zhang, Tao Xiang, Fanny Yang, Serge Belongie, Tian Xie</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出自适应记忆框架，通过帧选择和条件器提升多镜头视频的叙事连贯性，解决现有方法的上下文建模缺陷，属于原生多模态大模型中的视频生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07802' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes</h3>
<p><strong>Authors:</strong> Shai Krakovsky, Gal Fiebelman, Sagie Benaim, Hadar Averbuch-Elor</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 将语言嵌入3D高斯表示，解决大场景语义特征对齐与效率问题，支持自然语言查询/编辑，属于原生多模态大模型中的语言-3D融合方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07807' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling</h3>
<p><strong>Authors:</strong> Shaoheng Fang, Hanwen Jiang, Yunpeng Bai, Niloy J. Mitra, Qixing Huang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 联合生成RGB帧与4D场景表示（点云、相机轨迹、光流），保证视频的几何与运动一致性，属于原生多模态大模型中的4D生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07821' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation</h3>
<p><strong>Authors:</strong> Jiehui Huang, Yuechen Zhang, Xu He, Yuan Gao, Zhi Cen, Bin Xia, Yan Zhou, Xin Tao, Pengfei Wan, Jiaya Jia</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 融合分割、骨骼、光流等多模态任务联合学习，提升视频生成的世界感知与一致性，属于原生多模态大模型中的多任务融合方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.07831' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning</h3>
<p><strong>Authors:</strong> Tingyu Li, Zheng Sun, Jingxuan Wei, Siyuan Li, Conghui He, Lijun Wu, Cheng Tan</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出DoGe框架，将视觉语言模型的学习过程解耦为Thinker（上下文探索）和Solver（任务解决），实现数据稀缺下的自进化学习，属于原生多模态大模型中的视觉语言推理研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06835' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models</h3>
<p><strong>Authors:</strong> Ce Chi, Xing Wang, Zhendong Wang, Xiaofan Liu, Ce Li, Zhiyan Song, Chen Zhao, Kexin Yang, Boshen Shi, Jingjing Yang, Chao Deng, Junlan Feng</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出JT-DA工具集成表格推理LLM，通过表中心数据蒸馏和工作流优化提升表格推理能力，属于原生多模态大模型中的表格-文本多模态研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06859' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment</h3>
<p><strong>Authors:</strong> Ruicheng Zhang, Mingyang Zhang, Jun Zhou, Zhangrui Guo, Xiaofan Liu, Zunnan Xu, Zhizhou Zhong, Puxin Yan, Haocheng Luo, Xiu Li</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出分层视频生成框架MIND-V，结合vision-language模型的语义推理和RL的物理对齐，用于机器人长视野操作的视频合成，属于原生多模态大模型在机器人领域的创新应用。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.06628' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search</h3>
<p><strong>Authors:</strong> Kaicheng Yang, Kaisen Yang, Baiting Wu, Xun Zhang, Qianrui Yang, Haotong Qin, He Zhang, Yulun Zhang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出TreeQ框架，针对扩散Transformer（DiT）设计树结构混合精度搜索与环境噪声引导，实现近无损4-bit量化，对大模型新技术中的扩散模型高效部署有重要创新
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.06353' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Improving the Throughput of Diffusion-based Large Language Models via a Training-Free Confidence-Aware Calibration</h3>
<p><strong>Authors:</strong> Jucheng Shen, Gaurav Sarkar, Yeonju Ro, Sharath Nittur Sridhar, Zhangyang Wang, Aditya Akella, Souvik Kundu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出CadLLM方法，通过置信度感知的动态块大小、步长调整与词汇子集采样，优化扩散LLM的推理吞吐量，实现2.28倍的吞吐量提升，属于大模型新技术中的diffusion LLM方向，提升了扩散LLM的实用效率。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.07173' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ReLaX: Reasoning with Latent Exploration for Large Reasoning Models</h3>
<p><strong>Authors:</strong> Shimin Zhang, Xianwei Chen, Yufan Shen, Ziyuan Ye, Jibin Wu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 利用Koopman算子线性化大推理模型（LRM）的潜在动态，提出ReLaX框架调节推理中的探索与利用，提升推理能力，属于大模型新技术中的推理优化。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.07558' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression</h3>
<p><strong>Authors:</strong> Qiming Bao, Xiaoxuan Fu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 研究LLM在逻辑规则扰动（如删除、改写、压缩）下的多步逻辑推理泛化能力，发现LLM对语义保留的逻辑变换稳定但对缺失/冲突证据脆弱，属于大模型新技术中的逻辑推理研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.06393' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy</h3>
<p><strong>Authors:</strong> Miguel Ingram, Arthur Joseph Merritt III</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出神经亲和力框架，通过9类任务分类诊断Transformer的组成 gap（局部模式与全局合成的性能差异），属于大模型新技术中的抽象推理研究。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.07109' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation</h3>
<p><strong>Authors:</strong> Yao Teng, Zhihuan Jiang, Han Shi, Xian Liu, Xuefei Ning, Guohao Dai, Yu Wang, Zhenguo Li, Xihui Liu (Microsoft Research Asia)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出SJD++框架，通过改进的推测Jacobi解码实现自回归文本到图像生成的无训练加速，属于高效大模型训练与推理中的推理加速方向，效果显著且机构具有强影响力。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07503' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> All You Need Are Random Visual Tokens? Demystifying Token Pruning in VLLMs</h3>
<p><strong>Authors:</strong> Yahong Wang, Juncheng Wu, Zhangkai Ni, Longzhen Yang, Yihang Liu, Chengmei Yang, Ying Wen, Xianfeng Tang, Hui Liu, Yuyin Zhou, Lianghua He (Institutions not specified)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 分析视觉大语言模型中的token pruning，提出“信息 horizon”概念，通过随机pruning提升推理效率，属于高效大模型训练与推理中的token压缩方向，实验验证充分。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07580' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> BitStopper: An Efficient Transformer Attention Accelerator via Stage-fusion and Early Termination</h3>
<p><strong>Authors:</strong> Huizheng Wang, Hongbin Wang, Shaojun Wei, Yang Hu, Shouyi Yin</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出BitStopper加速Transformer注意力，通过阶段融合和早停减少计算与内存开销。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06457' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models</h3>
<p><strong>Authors:</strong> Sourjya Roy, Shrihari Sridharan, Surya Selvam, Anand Raghunathan</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出KV-CAR压缩KV缓存，通过自动编码器与复用减少内存开销，提升LLM推理效率。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06727' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Adaptive Dataset Quantization: A New Direction for Dataset Pruning</h3>
<p><strong>Authors:</strong> Chenyue Yu, Jianyu Yu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出自适应数据集量化方法，通过减少样本内冗余解决大规模数据集的存储与通信成本问题，在保持模型训练性能的同时实现显著压缩率，对高效大模型训练具有重要价值
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.05987' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VDOT: Efficient Unified Video Creation via Optimal Transport Distillation</h3>
<p><strong>Authors:</strong> Yutong Wang, Haiyu Zhang, Tianfan Xue, Yu Qiao, Yaohui Wang, Chang Xu, Xinyuan Chen</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出最优传输蒸馏的高效统一视频生成模型，优化生成效率，属于高效大模型训练与推理的生成加速方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06802' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models</h3>
<p><strong>Authors:</strong> Xiang Lin, Weixin Li, Shu Guo, Lihong Wang, Di Huang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出重构基多模态适配器优化视觉语言模型的少样本适应，属于高效大模型训练与推理的参数高效微调方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06811' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior</h3>
<p><strong>Authors:</strong> Yulin Li, Haokun Gui, Ziyang Fan, Junjie Wang, Bin Kang, Bin Chen, Zhuotao Tian</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对视频大语言模型（VLLM）长视频视觉token序列的计算效率瓶颈，提出训练-free的动态token压缩框架DyToK，利用VLLM注意力机制的关键帧先验调整每帧token保留率，实现4.3x更快推理同时保持精度，兼容现有压缩方法，有效解决VLLM的长视频效率问题。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06866' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HVQ-CGIC: Enabling Hyperprior Entropy Modeling for VQ-Based Controllable Generative Image Compression</h3>
<p><strong>Authors:</strong> Niu Yi, Xu Tianyi, Ma Mingming, Wang Xinkun</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 解决VQ-based生成式图像压缩的熵模型非自适应问题，提出HVQ-CGIC引入hyperprior到VQ索引的熵模型，设计loss实现率失真（RD）平衡和控制，在Kodak数据集上比特率较现有方法减少61.3%，提升生成压缩的效率。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07192' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance</h3>
<p><strong>Authors:</strong> Naifu Xue, Zhaoyang Jia, Jiahao Li, Bin Li, Zihan Zheng, Yuan Zhang, Yan Lu (Singapore University of Technology and Design)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出S2VC框架，通过单步扩散和语义-时间引导实现高效视频编码，属于高效大模型训练与推理中的视频压缩方向，机构具有影响力。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07480' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> K2-V2: A 360-Open, Reasoning-Enhanced LLM</h3>
<p><strong>Authors:</strong> K2 Team, Zhengzhong Liu, Liping Tang, Linghao Jin, Haonan Li, Nikhil Ranjan, Desai Fan, Shaurya Rohatgi, Richard Fan, Omkar Pangarkar, Huijuan Wang, Zhoujun Cheng, Suqi Sun, Seungwook Han, Bowen Tan, Gurpreet Gosal, Xudong Han, Varad Pimpalkhute, Shibo Hao, Ming Shan Hee, Joel Hestness, Haolong Jia, Liqun Ma, Aaryamonvikram Singh, Daria Soboleva, Natalia Vassilieva, Renxi Wang, Yingquan Wu, Yuekai Sun, Taylor Killian, Alexander Moreno, John Maggs, Hector Ren, Guowei He, Hongyi Wang, Xuezhe Ma, Yuqi Wang, Mikhail Yurochkin, Eric P. Xing</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 推出开源推理增强LLM，通过注入领域知识、推理与长上下文能力，性能优于Qwen2.5-72B，属于高效大模型训练与推理中的开源模型方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06201' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Theoretical Compression Bounds for Wide Multilayer Perceptrons</h3>
<p><strong>Authors:</strong> Houssam El Cheairi, David Gamarnik, Rahul Mazumder</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出随机贪心压缩算法，理论分析宽MLP的剪枝与量化边界，揭示压缩性与网络宽度的权衡，属于高效大模型训练与推理中的压缩理论方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06288' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs</h3>
<p><strong>Authors:</strong> Runlong Zhou, Lefan Zhang, Shang-Chen Wu, Kelvin Zou, Hanzhi Zhou, Ke Ye, Yihao Feng, Dong Yin, Alex Guillen Garcia, Dmytro Babych, Rohit Chatterjee, Matthew Hopkins, Xiang Kong, Chang Lan, Lezhi Li, Yiping Ma, Daniele Molinari, Senyu Tong, Yanchao Sun, Thomas Voice, Jianyu Wang, Chong Wang, Simon Wang, Floris Weers, Yechen Xu, Guolin Yin, Muyang Yu, Yi Zhang, Zheng Zhou, Danyang Zhuo, Ruoming Pang, Cheng Leong</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出TPU上的大规模分布式RL框架RLAX，提升LLM训练效率，支持 preemptible 训练。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06392' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Neural expressiveness for beyond importance model compression</h3>
<p><strong>Authors:</strong> Angelos-Christos Maroudis, Sotirios Xydis</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出“Expressiveness”准则用于模型压缩，不依赖学习状态，提升压缩效率且保持性能。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06440' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Optimizing LLMs Using Quantization for Mobile Execution</h3>
<p><strong>Authors:</strong> Agatsya Yadav, Renta Chintala Bhargavi</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 研究LLM的4位后训练量化，将Llama 3.2 3B模型压缩用于移动设备，平衡模型大小与性能。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06490' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation</h3>
<p><strong>Authors:</strong> Xiaocan Li, Shiliang Wu, Zheng Shen</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出A-3PO加速异步LLM训练，通过近似 proximal policy 减少计算瓶颈，提升训练效率。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06547' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GradientSpace: Unsupervised Data Clustering for Improved Instruction Tuning</h3>
<p><strong>Authors:</strong> Shrihari Sridharan, Deepak Ravikumar, Anand Raghunathan, Kaushik Roy</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出GradientSpace用于指令微调的数据聚类，基于梯度空间分组，提升LLM训练效果。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06678' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FOAM: Blocked State Folding for Memory-Efficient LLM Training</h3>
<p><strong>Authors:</strong> Ziqing Wen, Jiahuan Wang, Ping Luo, Dongsheng Li, Tao Sun</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出FOAM方法通过块状状态折叠压缩优化器状态，结合残差校正恢复信息，理论证明收敛率与vanilla Adam相当，实证显示训练内存减少约50%，属于高效大模型训练与推理方向，解决了LLM训练中的内存瓶颈问题。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07112' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation</h3>
<p><strong>Authors:</strong> Muyu Xu, Fangneng Zhan, Xiaoqin Zhang, Ling Shao, Shijian Lu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 针对稀疏视角3D高斯 splatting的大模型训练计算负担问题，提出轻量级多尺度适配器的框架MuSASplat，实现ViT的高效fine-tune，大幅减少参数和训练资源需求，同时保持高质量渲染，解决稀疏视角GS的效率瓶颈。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07165' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting</h3>
<p><strong>Authors:</strong> Seokhyun Youn, Soohyun Lee, Geonho Kim, Weeyoung Kwon, Sung-Ho Bae, Jihyong Oh</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 首篇系统综述高效3D高斯 splatting（GS）的研究，将现有方法分类为参数压缩和重构压缩，总结数据集、评价指标和基准比较，为该领域的压缩与高效方法研究提供全面参考，对后续研究有指导价值。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07197' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PVeRA: Probabilistic Vector-Based Random Matrix Adaptation</h3>
<p><strong>Authors:</strong> Leo Fillioux, Enzo Ferrante, Paul-Henry Cournède, Maria Vakalopoulou, Stergios Christodoulidis</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出概率版VeRA适配器，通过概率修改低秩矩阵提升参数高效适应性能，在VTAB-1k基准上优于VeRA及其他主流适配器，属于高效大模型训练与推理中的参数高效微调方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07703' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FRWKV:Frequency-Domain Linear Attention for Long-Term Time Series Forecasting</h3>
<p><strong>Authors:</strong> Qingyuan Yang, Shizhuo, Dongyue Chen, Da Teng, Zehua Gan</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出频域线性注意力框架FRWKV，将线性注意力（O(T)复杂度）与频域分析结合，解决Transformer长序列时间序列预测的二次复杂度问题，属于高效大模型训练与推理中的高效注意力机制。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07539' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GatedFWA: Linear Flash Windowed Attention with Gated Associative Memory</h3>
<p><strong>Authors:</strong> Jiaxu Liu, Yuhe Bai, Christos-Savvas Bouganis</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出门控Flash窗口注意力（GatedFWA），结合滑动窗口注意力的效率和门控机制稳定记忆更新，线性时间复杂度，属于高效大模型训练与推理中的高效注意力机制。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07782' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LightSearcher: Efficient DeepSearch via Experiential Memory</h3>
<p><strong>Authors:</strong> Hengzhi Lan, Yue Yu, Li Qian, Li Peng, Jie Wu, Wei Liu, Jian Luan, Ting Bai</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出LightSearcher框架，通过对比推理轨迹学习文本经验记忆，自适应奖励 shaping减少冗余工具调用，平衡DeepSearch的 accuracy与效率，属于高效大模型训练与推理中的高效推理。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.06653' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Optimizing Optimizers for Fast Gradient-Based Learning</h3>
<p><strong>Authors:</strong> Jaerin Lee, Kyoung Mu Lee</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出优化器自动设计框架，基于贪心原则最大化损失下降，系统推导现有优化器并优化其超参数。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06370' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Deep Manifold Part 2: Neural Network Mathematics</h3>
<p><strong>Authors:</strong> Max Y. Ma, Gen-Hua Shi</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 用流形、不动点理论等研究神经网络的数学基础，解释模型 learnability 与复杂性。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06563' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics</h3>
<p><strong>Authors:</strong> Nikhil Verma, Joonas Linnosmaa, Espinosa-Leal Leonardo, Napat Vajragupta</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出ArcGD优化器，基于数学推导改进梯度下降，提升训练稳定性与泛化性能。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06737' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Inductive Bottleneck: Data-Driven Emergence of Representational Sparsity in Vision Transformers</h3>
<p><strong>Authors:</strong> Kanishk Awadhiya (Institutions not specified)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 分析Vision Transformers中“归纳瓶颈”现象，揭示表征稀疏性的data-driven机制，属于深度学习理论中的网络架构和表征学习方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07331' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Memory-Amortized Inference: A Topological Unification of Search, Closure, and Structure</h3>
<p><strong>Authors:</strong> Xin Li</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出基于拓扑的记忆摊销推理框架，统一搜索、闭合与结构，解释快速思考（直觉）从慢速思考（推理）的涌现，属于深度学习理论中的推理与记忆统一方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.05990' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ARC-AGI Without Pretraining</h3>
<p><strong>Authors:</strong> Isaac Liao, Albert Gu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出无预训练的CompressARC模型，基于最小描述长度（MDL）在极端数据限制下解决ARC-AGI谜题，属于深度学习理论中的无预训练智能方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06104' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Zero Generalization Error Theorem for Random Interpolators via Algebraic Geometry</h3>
<p><strong>Authors:</strong> Naoki Yoshida, Isao Ishikawa, Masaaki Imaizumi</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 用代数几何证明随机插值器的零泛化误差定理，深化深度学习泛化理论理解。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06347' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Comparing BFGS and OGR for Second-Order Optimization</h3>
<p><strong>Authors:</strong> Adrian Przybysz, Mikołaj Kołek, Franciszek Sobota, Jarek Duda</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 比较了BFGS与OGR两种二阶优化方法在神经网络训练中的表现，针对Hessian估计的高维度与高成本问题展开分析，提出OGR在非凸场景下的收敛速度与损失表现更优，属于深度学习理论中的优化器研究方向，对二阶优化的实际应用有参考价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06969' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search</h3>
<p><strong>Authors:</strong> Tanay Arora, Christof Teuscher</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出Concrete Ticket Search算法，通过Concrete松弛与梯度平衡方案实现子网络的组合优化，保留训练动态，解决了现有彩票假设方法的精度-稀疏性权衡问题，在高稀疏度下表现优于LTR等方法，属于深度学习理论中的网络架构方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07142' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Efficient Low-Tubal-Rank Tensor Estimation via Alternating Preconditioned Gradient Descent</h3>
<p><strong>Authors:</strong> Zhiyu Liu, Zhi Han, Yandong Tang, Jun Fan, Yao Wang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出交替预条件梯度下降（APGD）算法解决低张量秩估计的收敛问题，针对过参数化场景加速收敛并提供线性收敛理论保证，属于深度学习理论中的优化算法研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07490' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Mathematical Theory of Top-$k$ Sparse Attention via Total Variation Distance</h3>
<p><strong>Authors:</strong> Georgios Tzachristas, Lei Deng, Ioannis Tzachristas, Gong Zhang, Renhai Chen</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 建立Top-k稀疏注意力的数学理论，通过总变异距离分析近似误差，推导闭形式尾质量和渐近规则，属于深度学习理论中的注意力机制理论。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07647' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Bootstrap Perspective on Stochastic Gradient Descent</h3>
<p><strong>Authors:</strong> Hongjian Lan, Yucong Liu, Florian Sch\"afer</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 从bootstrap视角分析SGD的泛化能力，证明SGD通过隐式正则化梯度协方差矩阵的迹控制算法变异性，提升泛化，属于深度学习理论中的优化算法与泛化理论。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07676' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Group Representational Position Encoding</h3>
<p><strong>Authors:</strong> Yifan Zhang, Zixiang Chen, Yifeng Liu, Zhen Qin, Huizhuo Yuan, Kangping Xu, Yang Yuan, Quanquan Gu, Andrew Chi-Chih Yao</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出群表示位置编码（GRAPE）框架，统一 multiplicative rotations（如RoPE）和 additive logit biases（如ALiBi），属于深度学习理论中的位置编码理论。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07805' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Provable Long-Range Benefits of Next-Token Prediction</h3>
<p><strong>Authors:</strong> Xinyuan Cao, Santosh S. Vempala</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 证明下一个token预测对长程结构的学习能力，通过RNN优化下一个token预测可近似训练分布，属于深度学习理论中的预训练目标理论。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07818' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PrunedCaps: A Case For Primary Capsules Discrimination</h3>
<p><strong>Authors:</strong> Ramin Sharifi, Pouya Shiri, Amirali Baniasadi</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 研究胶囊网络（CapsNet）的初级胶囊剪枝方法，在不损失精度的前提下大幅提升模型速度并减少计算量，对深度学习理论中的网络结构优化有积极贡献
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06003' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Distribution Matching Variational AutoEncoder</h3>
<p><strong>Authors:</strong> Sen Ye, Jianning Pei, Mengde Xu, Shuyang Gu, Chunyu Wang, Liwei Wang, Han Hu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出DMVAE，通过分布匹配约束编码器潜在分布与SSL特征等参考分布，在ImageNet上用64 epochs达到3.2的gFID，属于深度学习理论中的生成模型潜在空间优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07778' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation</h3>
<p><strong>Authors:</strong> Yuan Gao, Chen Chen, Tianrong Chen, Jiatao Gu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出仅用一层注意力层适应预训练视觉编码器，结合特征重建与图像解码双解码器，在ImageNet上用80 epochs达到2.08的FID，属于深度学习理论中的视觉编码器适配方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07829' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Invariant Graph Representations Through Redundant Information</h3>
<p><strong>Authors:</strong> Barproda Halder, Pasan Dissanayake, Sanghamitra Dutta</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 利用部分信息分解（PID）识别冗余信息，提出多_level优化框架（RIG）学习不变图表示，提升OOD泛化性能，属于深度学习理论中的图表示学习方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06154' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Quantifying Memory Use in Reinforcement Learning with Temporal Range</h3>
<p><strong>Authors:</strong> Rodney Lafuente-Mercado, Daniela Rus, T. Konstantin Rusch</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出Temporal Range量化RL中的记忆使用，通过自动微分计算时间滞后的加权平均，对齐任务真实滞后与所需历史窗口，属于深度学习理论中的RL记忆量化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06204' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Entropic Confinement and Mode Connectivity in Overparameterized Neural Networks</h3>
<p><strong>Authors:</strong> Luca Di Carlo, Chase Goddard, David J. Schwab</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 研究过参数化网络的熵约束与模式连接，发现曲率变化产生的熵壁垒导致优化动态局限于单一盆地，解释损失景观的连接性与局限性，属于深度学习理论中的损失景观分析方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06297' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Average-reward reinforcement learning in semi-Markov decision processes via relative value iteration</h3>
<p><strong>Authors:</strong> Huizhen Yu, Yi Wan, Richard S. Sutton</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 将异步随机近似应用于半Markov决策过程的平均奖励RL，提出RVI Q-learning并证明其收敛性，属于深度学习理论中的RL算法方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06218' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Back to Author Console Empowering GNNs for Domain Adaptation via Denoising Target Graph</h3>
<p><strong>Authors:</strong> Haiyang Yu, Meng-Chieh Lee, Xiang song, Qi Zhu, Christos Faloutsos</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出GraphDeT框架，通过去噪目标图的辅助任务增强GNN的域适应性能，理论分析证明去噪可收紧泛化界，属于深度学习理论中的图域适应方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06236' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Auto-exploration for online reinforcement learning</h3>
<p><strong>Authors:</strong> Caleb Ju, Guanghui Lan</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出无参数自动探索的在线RL方法，在tabular和线性函数近似下达到O(ε^-2)样本复杂度，属于深度学习理论中的RL探索方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06244' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces</h3>
<p><strong>Authors:</strong> Nikita Gabdullin</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 研究预配置潜在空间的向量系统（如An根系统）加速神经网络训练，分析向量系统对潜在空间结构的影响，属于深度学习理论中的网络架构与潜在空间设计。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07509' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Formalized Hopfield Networks and Boltzmann Machines</h3>
<p><strong>Authors:</strong> Matteo Cipollina, Michail Karatarakis, Freek Wiedijk</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 在Lean 4中形式化验证Hopfield网络和玻尔兹曼机，证明Hebbian学习的正确性和玻尔兹曼机的遍历性，属于深度学习理论中的经典模型理论。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07766' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization</h3>
<p><strong>Authors:</strong> Xuan Xie, Xuan Wang, Wenjie Wang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出DaGRPO框架，通过序列级梯度修正和离线数据增强解决GRPO的梯度冲突问题，提升大模型推理的稳定性和样本效率，属于深度学习理论中的优化算法与推理优化。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.06337' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Improving action classification with brain-inspired deep networks</h3>
<p><strong>Authors:</strong> Aidas Aglinskas, Stefano Anzellotti</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 受大脑视觉通路中身体/场景选择性区域启发，设计分离流网络架构，提升动作分类性能并匹配人类认知模式，属于深度学习理论中的脑启发网络架构方向。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07729' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> RRAEDy: Adaptive Latent Linearization of Nonlinear Dynamical Systems</h3>
<p><strong>Authors:</strong> Jad Mounayer, Sebastian Rodriguez, Jerome Tomezyk, Chady Ghnatios, Francisco Chinesta</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出RRAEDy模型实现非线性动力系统的自适应潜在线性化，自动发现潜在维度并学习稳定的低维动力学，属于深度学习理论中的网络架构与动力系统建模。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07542' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Always Keep Your Promises: DynamicLRP, A Model-Agnostic Solution To Layer-Wise Relevance Propagation</h3>
<p><strong>Authors:</strong> Kevin Lee, Pablo Millan Arias</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出DynamicLRP框架，通过计算图的张量操作级分解与Promise System实现模型无关的LRP归因，保持了LRP的理论保证，解决了现有LRP依赖特定架构的问题，属于深度学习可解释性中的白盒解释方向，提升了可解释性方法的通用性与扩展性。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.07010' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LogicCBMs: Logic-Enhanced Concept-Based Learning</h3>
<p><strong>Authors:</strong> Deepika SN Vemuri, Gautham Bellamkonda, Aditya Pola, Vineeth N Balasubramanian (Indian Institute of Technology Madras)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出LogicCBMs框架，通过命题逻辑增强概念瓶颈模型，提升可解释性和表达能力，属于深度学习可解释性中的概念学习方向，机构具有影响力。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.07383' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Learning When</h3>
<p><strong>Authors:</strong> Ronald Katende</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出基于信息几何的解释效率度量，为深度学习可解释性提供理论基础，解决现有指标未量化数据对解释表示支持效果的问题。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.06341' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods</h3>
<p><strong>Authors:</strong> Panagiota Kiourti, Anu Singh, Preeti Duraipandian, Weichao Zhou, Wenchao Li</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 重新思考特征归因方法的鲁棒性评估，提出新指标与生成相似输入的方法，提升可解释性评估准确性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.06665' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data</h3>
<p><strong>Authors:</strong> Lin Yang, Xiang Li, Xin Ma, Xinxin Zhao</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 用SHAP分析增强EEG模型的可解释性，可视化特征贡献，属于深度学习可解释性的Shapley value方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.06730' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ContextualSHAP : Enhancing SHAP Explanations Through Contextual Language Generation</h3>
<p><strong>Authors:</strong> Latifa Dwiyanti, Sergio Ryan Wibisono, Hidetaka Nambo</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出ContextualSHAP，结合LLM生成上下文文本解释增强SHAP的可解释性，解决SHAP缺乏用户友好解释的问题，属于深度学习可解释性中的Shapley值解释研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.07178' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Geometric Unification of Concept Learning with Concept Cones</h3>
<p><strong>Authors:</strong> Alexandre Rocchi--Henry, Thomas Fel, Gianni Franchi</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出概念锥的几何框架，统一监督（CBMs）与无监督（SAEs）概念学习，为深度学习可解释性中的概念发现提供了 principled 几何视角，推动了可解释性理论的整合。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.07355' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Zero-Shot Textual Explanations via Translating Decision-Critical Features</h3>
<p><strong>Authors:</strong> Toshinori Yamauchi, Hiroshi Kera, Kazuhiko Kawamoto (Institutions not specified)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出TEXTER框架，通过分离决策关键特征并映射到CLIP空间生成零样本文本解释，提升模型决策的可解释性，符合深度学习可解释性研究方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.07245' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> On measuring grounding and generalizing grounding problems</h3>
<p><strong>Authors:</strong> Daniel Quigley, Eric Maynard</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出接地的评估框架，将接地从二元判断转化为多维度审计（如真实性、保真度、鲁棒性），属于深度学习可解释性中的符号接地问题研究。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.06205' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems</h3>
<p><strong>Authors:</strong> Xianzong Wu, Xiaohong Li, Lili Quan, Qiang Hu</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出UncertaintyZoo工具包，集成29种不确定性量化方法，统一接口评估深度学习系统的预测不确定性，属于深度学习可解释性中的不确定性量化研究。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.06406' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning</h3>
<p><strong>Authors:</strong> Yuji Wang, Wenlong Liu, Jingxuan Niu, Haoji Zhang, Yansong Tang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出工具优化的指代接地推理框架，结合智能体强化学习解决工具输出不可靠问题，聚焦多模态智能体的工具交互与推理能力提升。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.06373' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs</h3>
<p><strong>Authors:</strong> Bin Li, Ruichi Zhang, Han Liang, Jingyan Zhang, Juze Zhang, Xin Chen, Lan Xu, Jingyi Yu, Jingya Wang (Rutgers University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出InterAgent框架，通过交互图扩散实现基于物理的多agent命令执行，属于多模态智能体中的多agent控制方向，作者和机构具有影响力。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.07410' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Online Segment Any 3D Thing as Instance Tracking</h3>
<p><strong>Authors:</strong> Hanshi Wang, Zijian Cai, Jin Gao, Yiwei Zhang, Weiming Hu, Ke Wang, Zhipeng Zhang (Chinese Academy of Sciences)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出AutoSeg3D框架，通过实例跟踪实现在线3D分割，提升具身智能体的环境感知能力，属于多模态智能体中的3D感知方向，机构具有影响力。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.07599' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Optimization-Guided Diffusion for Interactive Scene Generation</h3>
<p><strong>Authors:</strong> Shiaho Li, Naisheng Ye, Tianyu Li, Kashyap Chitta, Tuo An, Peng Su, Boyang Wang, Haiou Liu, Chen Lv, Hongyang Li (Tsinghua University)</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出OMEGA框架，通过优化引导扩散实现交互式场景生成，提升自动驾驶场景的真实性和可控性，属于多模态智能体中的场景生成方向，作者和机构具有强影响力。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.07661' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge</h3>
<p><strong>Authors:</strong> Ilia Larchenko, Gleb Zarin, Akash Karnatak</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 基于Pi0.5架构的VLA模型任务适应方法，在2025 BEHAVIOR Challenge中获第一名，针对机器人长视野 household 任务，提升了多模态智能体的泛化能力。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.06951' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems</h3>
<p><strong>Authors:</strong> Bufang Yang, Lilin Xu, Liekang Zeng, Yunqi Guo, Siyang Jiang, Wenrui Lu, Kaiwei Liu, Hancheng Xiang, Xiaofan Jiang, Guoliang Xing, Zhenyu Yan</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出ProAgent主动LLM代理系统，利用按需感官上下文提取和上下文感知推理，实现主动 assistance，属于多模态智能体中的主动代理研究。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.06721' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DoVer: Intervention-Driven Auto Debugging for LLM Multi-Agent Systems</h3>
<p><strong>Authors:</strong> Ming Ma, Jue Zhang, Fangkai Yang, Yu Kang, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出DoVer干预驱动调试框架，通过目标干预验证故障假设，提升LLM多代理系统的可靠性，属于多模态智能体中的调试研究。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.06749' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VIGIL: A Reflective Runtime for Self-Healing Agents</h3>
<p><strong>Authors:</strong> Christopher Cruz</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 提出VIGIL反射 runtime，通过行为日志分析和情绪表示实现代理的自我修复，提升代理的鲁棒性，属于多模态智能体中的自我修复研究。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.07094' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> On Memory: A comparison of memory mechanisms in world models</h3>
<p><strong>Authors:</strong> Eli J. Laird, Corey Clark</p>
<p><strong>Published:</strong> 2025-12-09</p>
<p><strong>Reason:</strong> 比较世界模型中的记忆机制（如视觉Transformer的 residual stream），分析记忆跨度和残留流动态，属于多模态智能体中的记忆研究。
Score: 6
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.06983' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>