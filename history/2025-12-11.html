<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-11</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >多模态智能体</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >深度学习理论</a>
<a href='#' >大模型新技术</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >大模型安全与对齐</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-11</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-11 12:42:09</p>
<p>已自动阅读了 268 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：136931</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ContextDrag: Precise Drag-Based Image Editing via Context-Preserving Token Injection and Position-Consistent Attention</h3>
<p><strong>Authors:</strong> Huiguo He, Pengyu Yan, Ziqi Yi, Weizhi Zhong, Zheng Liu, Yejun Tang, Huan Yang, Kun Gai, Guanbin Li, Lianwen Jin</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出精确拖拽式图像编辑框架，利用上下文保留token注入和位置一致注意力提升编辑连贯性与保真度，属于原生多模态大模型的图像编辑方向。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08477' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Photo3D: Advancing Photorealistic 3D Generation through Structure-Aligned Detail Enhancement</h3>
<p><strong>Authors:</strong> Xinyue Liang, Zhinyuan Ma, Lingchen Sun, Yanjun Guo, Lei Zhang</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 结合GPT-4o-Image生成图像数据提升3D模型外观真实感，属于原生多模态大模型的3D生成方向，创新性高。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08535' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Chain-of-Image Generation: Toward Monitorable and Controllable Image Generation</h3>
<p><strong>Authors:</strong> Young Kyung Kim, Oded Schlesinger, Yuzhou Zhao, J. Matias Di Martino, Guillermo Sapiro</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 将CoT引入图像生成，分解为分步语义过程提升可监控性与可控性，属于原生多模态大模型的可控图像生成方向，创新性高。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08645' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance</h3>
<p><strong>Authors:</strong> Ruihang Chu, Yefei He, Zhekai Chen, Shiwei Zhang, Xiaogang Xu, Bin Xia, Dingdong Wang, Hongwei Yi, Xihui Liu, Hengshuang Zhao, Yu Liu, Yingya Zhang, Yujiu Yang</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出运动可控视频生成框架，通过latent轨迹引导提升运动控制精度，属于原生多模态大模型的视频生成方向，效果显著。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08765' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Unseen Bias: How Norm Discrepancy in Pre-Norm MLLMs Leads to Visual Information Loss</h3>
<p><strong>Authors:</strong> Bozhou Li (), Xinda Xue (), Sihan Yang (), Yang Shi (), Xinlong Chen (), Yushuo Guan (), Yuanxing Zhang (), Wentao Zhang ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 揭示了多模态大语言模型（MLLMs）中Pre-Norm架构导致的视觉与文本token范数差异及“不对称更新动态”问题，提出插入LayerNorm层的简单解决方案，实验验证在LLaVA-1.5上显著提升多模态及文本任务性能，直接关联原生多模态大模型的架构优化与跨模态融合问题。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08374' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond the Noise: Aligning Prompts with Latent Representations in Diffusion Models</h3>
<p><strong>Authors:</strong> Vasco Ramos, Regev Cohen, Idan Szpektor, Joao Magalhaes</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出NoisyCLIP在扩散模型noisy潜在空间测量prompt与表示对齐，提升生成语义保真度，属于原生多模态大模型的扩散模型prompt对齐方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08505' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PaintFlow: A Unified Framework for Interactive Oil Paintings Editing and Generation</h3>
<p><strong>Authors:</strong> Zhangli Hu, Ye Chen, Jiajun Yao, Bingbing Ni</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出统一油画交互编辑与生成框架，结合参考图像、素描和文本prompt，属于原生多模态大模型的图像生成/编辑方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08534' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning</h3>
<p><strong>Authors:</strong> Yi Zhang, Chun-Wun Cheng, Junyi He, Ke Yu, Yushun Tang, Carola-Bibiane Sch\"onlieb, Zhihai He, Angelica I. Aviles-Rivero</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出无训练双曲适配器提升跨模态推理性能，属于原生多模态大模型的跨模态对齐方向，有创新性。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08820' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs</h3>
<p><strong>Authors:</strong> Angela van Sprang, Laurens Samson, Ana Lucic, Erman Acar, Sennay Ghebreab, Yuki M. Asano (University of Amsterdam)</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出REST基准评测MLLMs的跨模态不一致性（图像/文本/混合模态），揭示多模态模型的“模态间隙”问题，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08923' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Tri-Bench: Stress-Testing VLM Reliability on Spatial Reasoning under Camera Tilt and Object Interference</h3>
<p><strong>Authors:</strong> Amit Bendkhale</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出Tri-Bench基准测试VLMs空间推理可靠性，为VLM评估提供实用基准，属于原生多模态大模型的VLM评估方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08860' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Siamese-Driven Optimization for Low-Resolution Image Latent Embedding in Image Captioning</h3>
<p><strong>Authors:</strong> Jing Jie Tan, Anissa Mokraoui, Ban-Hoe Kwan, Danny Wee-Kiat Ng, Yan-Chai Hum</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出Siamese驱动优化框架提升低分辨率图像 latent embedding用于图像captioning，属于原生多模态大模型的图像captioning方向，有应用价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08873' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CARLoS: Retrieval via Concise Assessment Representation of LoRAs at Scale</h3>
<p><strong>Authors:</strong> Shahar Sarfaty, Adi Haviv, Uri Hacohen, Niva Elkin-Koren, Roi Livni, Amit H. Bermano (Technion - Israel Institute of Technology)</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出CARLoS框架，利用CLIP嵌入表征LoRA的语义方向、强度与一致性，实现大规模LoRA语义检索，与原生多模态大模型（图像生成/理解）密切相关。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.08826' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MVP: Multiple View Prediction Improves GUI Grounding</h3>
<p><strong>Authors:</strong> Yunzhu Zhang, Zeyu Pan, Zhengwen Zeng, Shuheng Shen, Changhua Meng, Linchao Zhu</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出多视图预测框架提升GUI grounding稳定性与准确性，直接针对用户高优先级的GUI grounding问题，效果显著。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.08529' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Thinking with Images via Self-Calling Agent</h3>
<p><strong>Authors:</strong> Wenxi Yang, Yuzhong Zhao, Fang Wan, Qixiang Ye</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出Self-Calling Chain-of-Thought范式，将复杂视觉推理分解为原子子任务通过自调用agent解决，属于多模态智能体方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.08511' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm</h3>
<p><strong>Authors:</strong> Haoyu Zhao, Weizhong Ding, Yuhao Yang, Zheng Tian, Linyi Yang, Kun Shao, Jun Wang</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出See-Control多模态智能体框架，通过机械臂实现智能手机的物理交互（无需ADB），解决跨平台GUI交互问题，属于多模态智能体（GUI grounding/交互）方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.08629' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation</h3>
<p><strong>Authors:</strong> Meng Wei, Chenyang Wan, Jiaqi Peng, Xiqian Yu, Yuqiang Yang, Delin Feng, Wenzhe Cai, Chenming Zhu, Tai Wang, Jiangmiao Pang, Xihui Liu</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出DualVLN双系统模型（VLM全局规划+Diffusion Transformer局部策略），解决视觉-语言导航的泛化与实时控制问题，属于多模态智能体（导航）方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.08186' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models</h3>
<p><strong>Authors:</strong> Hongyuan Tao, Bencheng Liao, Shaoyu Chen, Haoran Yin, Qian Zhang, Wenyu Liu, Xinggang Wang</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 结合线性与稀疏注意力实现高效无限输入VLMs，解决VLMs长输入问题，提升推理效率，属于高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08829' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> LUNA: Linear Universal Neural Attention with Generalization Guarantees</h3>
<p><strong>Authors:</strong> Ashkan Shahbazi, Ping He, Ali Abbasi, Yikun Bai, Xinran Liu, Elaheh Akbari, Darian Salehi, Navid NaderiAlizadeh, Soheil Kolouri</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对线性注意力依赖固定特征图导致精度损失的问题，提出LUNA学习特征图的线性注意力机制，保持线性计算成本的同时匹配甚至超过二次注意力的精度，对高效大模型推理有突破性贡献
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08061' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones</h3>
<p><strong>Authors:</strong> Jiaxiang Geng (), Lunyu Zhao (), Yiyi Lu (), Bing Luo ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出首个手机端LLM微调框架，支持全参数与参数高效微调，通过参数分片、梯度累积、能耗感知调度解决内存与能耗限制，实验验证在GPT-2、Gemma 3等模型上的有效性。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08211' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HybridToken-VLM: Hybrid Token Compression for Vision-Language Models</h3>
<p><strong>Authors:</strong> Jusheng Zhang (), Xiaoyang Guo (), Kaitong Cai (), Qinhan Lv (), Yijia Fan (), Wenhao Chai (), Jian Wang (), Keze Wang ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对视觉语言模型（VLMs）中视觉patch token带来的 quadratic计算成本问题，提出混合token压缩框架，通过分离语义与外观的双通道设计，实现高效且接地的表示，实验表明在580-to-1压缩比下保持87.2%的性能，显著优于现有连续基线，直接关联高效大模型训练与推理方向的核心需求。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08240' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Effective and Efficient Long Video Understanding of Multimodal Large Language Models via One-shot Clip Retrieval</h3>
<p><strong>Authors:</strong> Tao Chen (), Shaobo Ju (), Qiong Wu (), Chenxin Fang (), Kun Zhang (), Jun Peng (), Hui Li (), Yiyi Zhou (), Rongrong Ji ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对多模态大模型（MLLMs）处理长视频的内存与效率痛点，提出OneClip-RAG范式，通过query引导的视频chunking与one-shot clip检索增强长视频理解，实验表明提升InternLV2、Qwen2-VL等模型的长视频任务性能，且高效（单4090 GPU处理1小时视频仅需2.2分钟），直接关联高效大模型训练与推理的长视频推理优化需求。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08410' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Repulsor: Accelerating Generative Modeling with a Contrastive Memory Bank</h3>
<p><strong>Authors:</strong> Shaofeng Zhang, Xuanqi Chen, Ning Liao, Haoxiang Zhao, Xiaoxing Wang, Haoru Tan, Sitong Wu, Xiaosong Jia, Qi Fan, Junchi Yan</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出对比记忆库加速生成模型训练，提升收敛速度与生成质量，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08648' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LoFA: Learning to Predict Personalized Priors for Fast Adaptation of Visual Generative Models</h3>
<p><strong>Authors:</strong> Yiming Hao, Mutian Xu, Chongjie Ye, Jie Qin, Shunlin Lu, Yipeng Qin, Xiaoguang Han</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出LoFA框架预测个性化先验快速适应视觉生成模型，解决生成模型个性化适应问题，提升效率。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08785' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ThreadWeaver: Adaptive Threading for Efficient Parallel Reasoning in Language Models</h3>
<p><strong>Authors:</strong> Long Lian, Sida Wang, Felix Juefei-Xu, Tsu-Jui Fu, Xiuyu Li, Adam Yala, Trevor Darrell, Alane Suhr, Yuandong Tian, Xi Victoria Lin</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对LLM推理时的顺序解码延迟问题，提出自适应并行推理框架ThreadWeaver，通过两阶段并行轨迹生成、前缀树训练推理协同设计和并行化感知强化学习，在保持推理精度的同时降低延迟，对高效大模型推理具有重要研究价值
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07843' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GSPN-2: Efficient Parallel Sequence Modeling</h3>
<p><strong>Authors:</strong> Hongjun Wang, Yitong Jiang, Collin McCarthy, David Wehr, Hanrong Ye, Xinhao Li, Ka Chun Cheung, Wonmin Byeon, Jinwei Gu, Ke Chen, Kai Han, Hongxu Yin, Pavlo Molchanov, Jan Kautz, Sifei Liu</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对GSPN的GPU内核开销、数据传输和计算冗余问题，提出GSPN-2的算法-系统联合设计，将数千次微内核启动合并为一个2D内核，引入紧凑通道传播策略，显著提升视觉Transformer的效率，对高效大模型训练与推理有重要价值
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07884' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LayerPipe2: Multistage Pipelining and Weight Recompute via Improved Exponential Moving Average for Training Neural Networks</h3>
<p><strong>Authors:</strong> Nanda K. Unnikrishnan (), Keshab K. Parhi ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对LayerPipe的梯度延迟与存储瓶颈问题，通过可变延迟梯度适应、重定时及流水线感知移动平均，解决流水线训练的理论与工程问题，提升神经网络训练效率。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08160' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents</h3>
<p><strong>Authors:</strong> Xiang Chen (), Yuling Shi (), Qizhen Lan (), Yuchao Qiu (), Xiaodong Gu ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出联邦自进化框架，通过局部高回报轨迹微调、全局低秩聚合解决异质任务与稀疏奖励的梯度冲突，实验验证跨5个环境的任务成功率比联邦基线高18%。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08870' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models</h3>
<p><strong>Authors:</strong> Jiayi Tian, Seyedarmin Azizi, Yequan Zhao, Erfan Baghaei Potraghloo, Sean McPherson, Sharath Nittur Sridhar, Zhengyang Wang, Zheng Zhang, Massoud Pedram (University of Southern California), Souvik Kundu</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出无训练的KV压缩方法SkipKV，通过句子级选择跳过KV生成与存储，解决大推理模型的KV缓存开销问题，提升推理准确性（+26.7%）和吞吐量（+1.7x），与高效大模型推理方向高度相关。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07993' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Real Weights: Hypercomplex Representations for Stable Quantization</h3>
<p><strong>Authors:</strong> Jawad Ibn Ahad, Maisha Rahman, Amrijit Biswas, Muhammad Rafsan Kabir, Robin Krambroeckers, Sifat Momen, Nabeel Mohammed, Shafin Rahman</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出超复数表示用于稳定量化，减少模型大小与延迟并保持性能，属于高效大模型训练与推理的压缩方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08524' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Skewness-Guided Pruning of Multimodal Swin Transformers for Federated Skin Lesion Classification on Edge Devices</h3>
<p><strong>Authors:</strong> Kuniko Paxton, Koorosh Aslansefat, Dhavalkumar Thakker, Yiannis Papadopoulos</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出偏度引导剪枝减少多模态Swin Transformer大小，适合边缘设备联邦学习，属于高效大模型训练与推理的压缩方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08751' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LAPA: Log-Domain Prediction-Driven Dynamic Sparsity Accelerator for Transformer Model</h3>
<p><strong>Authors:</strong> Huizheng Wang, Hongbin Wang, Shaojun Wei, Yang Hu, Shouyi Yin</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对Transformer动态稀疏加速的计算和能量开销问题，提出对数域注意力预测的加速器LAPA，通过非对称前导一计算、混合精度多轮移位累加和数据特征依赖过滤，显著提升能量效率，对高效大模型推理的硬件加速有重要价值
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.07855' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Generation is Required for Data-Efficient Perception</h3>
<p><strong>Authors:</strong> Jack Brady, Bernhard Sch\"olkopf, Thomas Kipf, Simon Buchholz, Wieland Brendel</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 理论证明生成模型对数据高效感知的必要性，有重要理论贡献，解决生成模型必要性问题。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.08854' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Dual-Branch Center-Surrounding Contrast: Rethinking Contrastive Learning for 3D Point Clouds</h3>
<p><strong>Authors:</strong> Shaofeng Zhang, Xuanqi Chen, Xiangdong Zhang, Sitong Wu, Junchi Yan</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出双分支中心-周围对比框架提升3D点云自监督对比学习性能，属于深度学习理论的对比学习方向，有理论创新。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.08673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Space Alignment Matters: The Missing Piece for Inducing Neural Collapse in Long-Tailed Learning</h3>
<p><strong>Authors:</strong> Jinping Wang, Zhiqiang Gao, Zhiwu Xie</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对长尾学习中神经崩溃现象缺失的问题，理论量化了特征与分类器权重空间错位的危害，并提出三种plug-and-play的对齐策略，显著提升了长尾模型的泛化性能，对深度学习理论中的神经崩溃和长尾学习研究有重要贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07844' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Softly Symbolifying Kolmogorov-Arnold Networks</h3>
<p><strong>Authors:</strong> James Bagrow, Josh Bongard</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对Kolmogorov-Arnold Networks（KAN）符号fidelity不足的问题，提出S2KAN将符号基元整合到训练中，通过可微分稀疏化和最小描述长度目标，在提升模型可解释性的同时保持精度，对深度学习理论中的可解释架构设计有重要贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07875' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Correction of Decoupled Weight Decay</h3>
<p><strong>Authors:</strong> Jason Chuan-Chih Chou ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对AdamW中解耦权重衰减与学习率的比例问题，推导得出权重衰减应与学习率平方成正比，理论与实验验证其提升模型性能与训练稳定性的效果。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.08217' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Mathematical Foundations of Neural Tangents and Infinite-Width Networks</h3>
<p><strong>Authors:</strong> Rachana Mysore (), Preksha Girish (), Kavitha Jayaram (), Shrey Kumar (), Preksha Girish (), Shravan Sanjeev Bagal (), Kavitha Jayaram (), Shreya Aravind Shastry ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 研究无限宽网络的神经切线核（NTK）理论，提出NTK-ECRN架构，分析NTK动态、谱特性与泛化的关系，桥接理论与实际深度学习架构，提升训练稳定性。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.08264' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Semi-Supervised Contrastive Learning with Orthonormal Prototypes</h3>
<p><strong>Authors:</strong> Huanran Li (Department of Electrical Engineering), Manh Nguyen (Statistics), Daniel Pimentel-Alarcón (Biostatistics, Wisconsin Institute of Discovery, University of Wisconsin-Madison)</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对对比学习中的维度塌陷问题，提出CLOP半监督损失函数，通过促进类嵌入的正交线性子空间，提升模型性能和跨学习率、批量大小的稳定性，对深度学习理论中的对比学习研究有重要贡献
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.07880' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Complexity of One-Dimensional ReLU DNNs</h3>
<p><strong>Authors:</strong> Jonathan Kogan, Hayden Jananthan, Jeremy Kepner</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 理论分析了一维ReLU深度神经网络的线性区域数量，提出函数自适应稀疏性概念，量化模型实际使用区域与近似目标所需最小区域的差异，对深度学习理论中的模型表达能力研究有重要贡献
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.08091' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models</h3>
<p><strong>Authors:</strong> Zheng Ding (), Weirui Ye ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 将扩散模型去噪过程转化为搜索树，提出TreeGRPO框架，通过共享前缀、多轨迹分支提升RL后训练的样本效率与计算效率，实验验证在扩散和流模型上比GRPO快2.4倍， Pareto前沿更优。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.08153' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Temporal Concept Dynamics in Diffusion Models via Prompt-Conditioned Interventions</h3>
<p><strong>Authors:</strong> Ada Gorgun, Fawaz Sammani, Nikos Deligiannis, Bernt Schiele, Jonas Fischer</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 研究扩散模型中时间概念动态，通过prompt条件干预分析概念形成时间特性，属于大模型新技术的扩散模型研究方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.08486' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fast-ARDiff: An Entropy-informed Acceleration Framework for Continuous Space Autoregressive Generation</h3>
<p><strong>Authors:</strong> Zhen Zou, Xiaoxiao Ma, Jie Huang, Zichao Yu, Feng Zhao</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出熵引导加速框架联合优化AR与扩散组件，提升生成速度，属于大模型新技术的AR-diffusion混合方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.08537' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> An Iteration-Free Fixed-Point Estimator for Diffusion Inversion</h3>
<p><strong>Authors:</strong> Yifei Chen, Kaiyu Song, Yan Pan, Jianxing Yu, Jian Yin, Hanjiang Lai</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出无迭代固定点估计器用于扩散反转，提升重建性能，属于大模型新技术的扩散模型研究方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.08547' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Refining Diffusion Models for Motion Synthesis with an Acceleration Loss to Generate Realistic IMU Data</h3>
<p><strong>Authors:</strong> Lars Ole H äusler (), Lena Uhlenberg (), G öran K öber (), Diyora Salimova (), Oliver Amft ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 引入加速度二阶损失微调扩散模型，优化IMU运动数据生成的时间一致性，实验验证生成数据更接近真实分布，提升人体活动识别性能（比基线高8.7%）。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.08859' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Model-Based Diffusion Sampling for Predictive Control in Offline Decision Making</h3>
<p><strong>Authors:</strong> Haldun Balim, Na Li, Yilun Du (Massachusetts Institute of Technology)</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出MPDiffuser模型，将扩散采样与动力学模型结合用于离线决策，属于大模型新技术（扩散LLM）方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.08280' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Uncertainty-Aware Subset Selection for Robust Visual Explainability under Distribution Shifts</h3>
<p><strong>Authors:</strong> Madhav Gupta, Vishak Prasad C, Ganesh Ramakrishnan</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对分布移位下视觉可解释性的子集选择方法，解决现有方法可靠性下降问题，属于深度学习可解释性重要研究方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.08445' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BrainExplore: Large-Scale Discovery of Interpretable Visual Representations in the Human Brain</h3>
<p><strong>Authors:</strong> Navve Wasserman, Matias Cosarinsky, Yuval Golbari, Aude Oliva, Antonio Torralba, Tamar Rott Shaham, Michal Irani</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出大规模自动化框架发现大脑中可解释视觉表示，结合神经科学与可解释AI，有交叉价值。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.08560' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Decoupling Template Bias in CLIP: Harnessing Empty Prompts for Enhanced Few-Shot Learning</h3>
<p><strong>Authors:</strong> Zhenyu Zhang, Guangyao Chen, Yixiong Zou, Zhimeng Huang, Yuhua Li</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 利用空prompt减少CLIP模板偏差，提升少样本学习性能，解决CLIP关键偏差问题，提升鲁棒性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.08606' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Refining Visual Artifacts in Diffusion Models via Explainable AI-based Flaw Activation Maps</h3>
<p><strong>Authors:</strong> Seoyeon Lee, Gwangyeol Yu, Chaewon Kim, Jonghyuk Park</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 利用XAI生成缺陷激活图改进扩散模型视觉 artifacts，将可解释性与模型改进结合，有实际意义。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.08774' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HOLE: Homological Observation of Latent Embeddings for Neural Network Interpretability</h3>
<p><strong>Authors:</strong> Sudhanva Manjunath Athreya, Paul Rosen</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出HOLE方法，通过持久同源性分析神经嵌入的拓扑特征，并用Sankey图、热图等可视化工具展示，揭示模型表示的结构、质量和鲁棒性，对深度学习可解释性研究有重要价值
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.07988' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CIP-Net: Continual Interpretable Prototype-based Network</h3>
<p><strong>Authors:</strong> Federico Di Valerio, Michela Proietti, Alessio Ragno, Roberto Capobianco</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对持续学习中的灾难性遗忘和可解释性问题，提出CIP-Net无样例自解释原型模型，在保持性能的同时提供可解释性，降低内存开销，对深度学习可解释性与持续学习的结合研究有重要贡献
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.07981' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Enhancing Explainability of Graph Neural Networks Through Conceptual and Structural Analyses and Their Extensions</h3>
<p><strong>Authors:</strong> Tien Cuong Bui</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对图神经网络（GNN）的可解释性问题，提出结合概念分析（后验解释）与结构分析（自解释设计）的方法，解决现有XAI方法难以解析图中复杂关系的痛点，属于深度学习可解释性研究范畴。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.08344' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Deconstructing the Dual Black Box:A Plug-and-Play Cognitive Framework for Human-AI Collaborative Enhancement and Its Implications for AI Governance</h3>
<p><strong>Authors:</strong> Yiming Lu</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出plug-and-play认知框架，通过元交互将人类“认知黑盒”（直觉）与AI“计算黑盒”转化为可解释的白盒系统，解决人机协作中的可解释性痛点，属于深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.08740' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models</h3>
<p><strong>Authors:</strong> Jiaming Zhang, Che Wang, Yang Cao, Longtao Huang, Wei Yang Bryan Lim</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对多模态推理模型的地理隐私问题，提出对抗框架破坏层次推理，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08503' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Training LLMs for Honesty via Confessions</h3>
<p><strong>Authors:</strong> Manas Joglekar, Jeremy Chen, Gabriel Wu, Jason Yosinski, Jasmine Wang, Boaz Barak, Amelia Glaese</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对LLM的不诚实问题（如幻觉、掩盖不当行为），提出通过自白机制训练模型诚实报告缺点，在多个场景中提升诚实性，对大模型安全与对齐研究有重要价值
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08093' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Improving the Sensitivity of Backdoor Detectors via Class Subspace Orthogonalization</h3>
<p><strong>Authors:</strong> Guangmingmei Yang (), David J. Miller (), George Kesidis ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对后门检测中现有方法对微妙后门和易区分非目标类的失效问题，提出Class Subspace Orthogonalization方法，通过抑制非目标类的内在特征、保留目标类的后门触发特征提升检测敏感性，实验验证对混合标签和自适应攻击有效。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08129' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Robust Agents in Open-Ended Worlds</h3>
<p><strong>Authors:</strong> Mikayel Samvelyan ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 研究开放世界中智能体的鲁棒性，结合多智能体学习与LLM对抗提示生成，提出MiniHack环境框架、Maestro对抗课程等方法，提升智能体对新环境、分布外输入及其他智能体交互的泛化能力。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08139' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fully Decentralized Certified Unlearning</h3>
<p><strong>Authors:</strong> Hithem Lamri (), Michail Maniatakos ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 针对去中心化设置下的认证遗忘问题，提出RR-DU方法，通过随机游走、梯度升降与高斯噪声实现(ε,δ)隐私保证，实验验证在MNIST、CIFAR-10上比去中心化DP基线更优。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08443' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search</h3>
<p><strong>Authors:</strong> Manos Plitsis (), Giorgos Bouritsas (), Vassilis Katsouros (), Yannis Panagakis ()</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出BGPS框架，通过LLM生成属性中性提示、结合属性分类器引导提示搜索，自动揭露文本到图像模型的隐藏偏见，实验验证在Stable Diffusion上发现未被记录的偏见。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08724' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change</h3>
<p><strong>Authors:</strong> Yong-Woon Kim</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出IDAIF框架，将变革理论（ToC）与AI系统设计结合，通过多目标帕累托优化、因果图、RLHF等方法实现AI与人类价值的对齐，解决AI部署中“技术性能与社会影响脱节”的问题，属于大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08449' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Principles2Plan: LLM-Guided System for Operationalising Ethical Principles into Plans</h3>
<p><strong>Authors:</strong> Tammy Zhong, Yang Song, Maurice Pagnucco (University of New South Wales)</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出Principles2Plan系统，利用LLM将抽象伦理原则转化为可执行的具体计划，解决自动规划中伦理支持缺失的问题，属于大模型安全与对齐研究内容。
Score: 6
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08536' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> The SMART+ Framework for AI Systems</h3>
<p><strong>Authors:</strong> Laxmiraju Kandikatla, Branislav Radeljic</p>
<p><strong>Published:</strong> 2025-12-10</p>
<p><strong>Reason:</strong> 提出SMART+框架（安全、监控、问责、可靠、透明+隐私安全、数据治理、公平性、护栏），用于跨行业AI治理，重点解决AI的安全性、合规性与可审计性问题，属于大模型安全与对齐方向。
Score: 6
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08592' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>