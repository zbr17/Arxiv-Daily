<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-12</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >深度学习理论</a>
<a href='#' >多模态智能体</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >大模型新技术</a>
<a href='#' >大模型安全与对齐</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-12</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-12 12:38:58</p>
<p>已自动阅读了 234 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：124368</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> AgentComp: From Agentic Reasoning to Compositional Mastery in Text-to-Image Models</h3>
<p><strong>Authors:</strong> Arman Zarei, Jiacheng Pan, Matthew Gwilliam, Soheil Feizi, Zhenheng Yang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 利用LLM推理与工具能力构建组合数据集，优化文本到图像模型的组合生成，涉及多模态大模型的agentic推理与组合能力。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09081' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> OmniPSD: Layered PSD Generation with Diffusion Transformer</h3>
<p><strong>Authors:</strong> Cheng Liu, Yiren Song, Haofan Wang, Mike Zheng Shou</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 基于Flux生态的扩散框架实现text-to-PSD和image-to-PSD生成，涉及多模态大模型的分层设计与diffusion技术。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09247' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VABench: A Comprehensive Benchmark for Audio-Video Generation</h3>
<p><strong>Authors:</strong> Daili Hua, Xizhi Wang, Bohan Zeng, Xinyi Huang, Hao Liang, Junbo Niu, Xinlong Chen, Quanqing Xu, Wentao Zhang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 构建音频-视频生成的综合基准，评估同步性、一致性等多模态指标，支持原生多模态大模型的评估与优化。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09299' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Chain-of-Thought Reasoning for Videos</h3>
<p><strong>Authors:</strong> Yiwu Zhong, Zi-Yuan Hu, Yin Li, Liwei Wang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出视频MLLM的高效CoT推理框架，通过压缩视觉tokens与简洁推理提升效率，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09616' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DynaIP: Dynamic Image Prompt Adapter for Scalable Zero-shot Personalized Text-to-Image Generation</h3>
<p><strong>Authors:</strong> Zhizhong Wang, Tianyi Chu, Zeyi Huang, Nanyang Wang, Kehan Li</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 针对个性化文本到图像生成的概念保真度、多主体扩展性等核心挑战，提出动态图像提示适配器DynaIP，通过动态解耦策略和分层特征融合显著提升模型性能，属于原生多模态大模型的重要改进方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09814' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Composing Concepts from Images and Videos via Concept-prompt Binding</h3>
<p><strong>Authors:</strong> Xianghao Kong, Zeyu Zhang, Yuwei Guo, Zhuoran Zhao, Songchun Zhang, Anyi Rao</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出Bind & Compose方法解决图像与视频的视觉概念组合问题，通过概念-提示绑定和时间解耦策略提升概念一致性与跨模态兼容性，是原生多模态大模型在视觉创意领域的关键研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09824' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning</h3>
<p><strong>Authors:</strong> Xinyu Liu, Hangjie Yuan, Yujie Wei, Jiazheng Xing, Yujin Han, Jiahao Pan, Yanbiao Ma, Chi-Min Chan, Kang Zhao, Shiwei Zhang, Wenhan Luo, Yike Guo</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 针对视频编辑的推理感知需求，提出ReViSE框架与RVE基准，通过自反思学习提升推理准确性与视觉保真度，是原生多模态大模型在视频编辑领域的重要应用。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09924' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GLaD: Geometric Latent Distillation for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Minghao Guo, Meng Cao, Jiachen Tao, Rongtao Xu, Yan Yan, Xiaodan Liang, Ivan Laptev, Xiaojun Chang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出几何 latent 蒸馏方法，将3D几何先验融入Vision-Language-Action模型预训练，提升模型空间推理能力和泛化性能，符合原生多模态大模型研究方向
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09619' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Minghui Lin, Pengxiang Ding, Shu Wang, Zifeng Zhuang, Yang Liu, Xinyang Tong, Wenxuan Song, Shangke Lyu, Siteng Huang, Donglin Wang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 利用运动表示进行双向时间推理，提出Hindsight、Insight、Foresight框架提升Vision-Language-Action模型的长horizon操纵性能，符合原生多模态大模型研究方向
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09928' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> IF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting</h3>
<p><strong>Authors:</strong> Tao Zhang, Yuyang Hong, Yang Xia, Kun Ding, Zeyu Zhang, Ying Wang, Shiming Xiang, Chunhong Pan</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 构建首个红外图像MLLM基准，提出生成式视觉提示提升性能，推动原生多模态大模型在红外理解中的应用。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.09663' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs</h3>
<p><strong>Authors:</strong> Isha Chaturvedi, Anjana Nair, Yushen Li, Adhitya Rajendra Kumar, Kevin Zhu, Sunishchal Dev, Ashwinee Panda, Vasu Sharma</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出Contrastive Region Masking方法，揭示MLLM推理过程中视觉区域的依赖关系，提升推理可解释性与忠实度，属于深度学习可解释性的重要进展。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.08976' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Natural Geometry of Robust Data Attribution: From Convex Models to Deep Networks</h3>
<p><strong>Authors:</strong> Shihao Li, Jiachen Li, Dongmei Chen</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出自然Wasserstein度量解决数据归因鲁棒性问题，提升Deep Learning模型归因稳定性与可靠性，属于深度学习可解释性的关键突破。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.09103' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> STACHE: Local Black-Box Explanations for Reinforcement Learning Policies</h3>
<p><strong>Authors:</strong> Andrew Elashkin, Orna Grumberg</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出STACHE框架，为RL策略生成局部黑盒解释（鲁棒性区域、最小反事实），帮助理解策略训练过程中的逻辑演变，提升RL模型可解释性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.09909' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Building Reasonable Inference for Vision-Language Models in Blind Image Quality Assessment</h3>
<p><strong>Authors:</strong> Yuan Li, Zitang Sun, Yen-ju Chen, Shin'ya Nishida</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 针对VLM推理不稳定、预测不接地问题，提出两阶段调优方法，提升推理可靠性与人类对齐性，属于深度学习可解释性研究。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.09555' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Investigate the Low-level Visual Perception in Vision-Language based Image Quality Assessment</h3>
<p><strong>Authors:</strong> Yuan Li, Zitang Sun, Yen-Ju Chen, Shin'ya Nishida</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 分析MLLM低层次视觉感知缺陷，通过增强视觉编码器对齐提升失真识别能力，属于深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.09573' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Understanding the Failure Modes of Transformers through the Lens of Graph Neural Networks</h3>
<p><strong>Authors:</strong> Hunjae Lee</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 用GNN理论分析Transformer信息传播瓶颈，统一现有解决方案并解释其有效性，属于深度学习理论中Transformer的关键理论理解。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09182' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Provably Learning from Modern Language Models via Low Logit Rank</h3>
<p><strong>Authors:</strong> Noah Golowich, Allen Liu, Abhishek Shetty</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 基于现代LLM的低logit秩实证观察，提出高效算法从LLM查询中学习，为现代LLM的可学习性提供首个端到端理论保证。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09892' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GS-KAN: Parameter-Efficient Kolmogorov-Arnold Networks via Sprecher-Type Shared Basis Functions</h3>
<p><strong>Authors:</strong> Oscar Eliasson</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出GS-KAN通过共享基函数提升Kolmogorov-Arnold Networks参数效率，属于深度学习理论中网络架构的创新研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09084' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Spectral Embedding via Chebyshev Bases for Robust DeepONet Approximation</h3>
<p><strong>Authors:</strong> Muhammad Abid, Omer San</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出谱嵌入的DeepONet改进SEDONet，提升PDE求解非周期特征捕捉能力，属于深度学习理论中网络架构的重要研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09165' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation</h3>
<p><strong>Authors:</strong> Ce Wang, Weihang Dai, Hanru Bai, Xiaomeng Li</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出基于谱排序的对比学习方法，提升半监督回归表示能力，属于深度学习理论中对比学习的创新研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09267' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Self-Supervised Learning with Gaussian Processes</h3>
<p><strong>Authors:</strong> Yunshan Duan, Sinead Williamson</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出GPSSL用高斯过程改进自监督学习不确定性量化，属于深度学习理论中自监督学习的创新方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09322' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rates and architectures for learning geometrically non-trivial operators</h3>
<p><strong>Authors:</strong> T. Mitchell Roddenberry, Leo Tzou, Ivan Dokmanić, Maarten V. de Hoop, Richard G. Baraniuk</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 扩展算子学习理论至几何积分算子（如广义Radon变换），证明其无维度灾难，提出类交叉注意力架构，为科学机器学习中的算子学习提供理论与架构支撑。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09376' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Drawback of Enforcing Equivariance and its Compensation via the Lens of Expressive Power</h3>
<p><strong>Authors:</strong> Yuzhu Chen, Tian Qin, Xinmei Tian, Fengxiang He, Dacheng Tao</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 分析等变约束对模型表达能力的限制，证明可通过增大模型规模补偿该缺陷，揭示等变网络泛化性与模型复杂度的关系，为等变网络设计提供理论指导。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Analysis of Dirichlet Energies as Over-smoothing Measures</h3>
<p><strong>Authors:</strong> Anna Bison, Alessandro Sperduti</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 分析两种Dirichlet能量（非归一化/归一化拉普拉斯）作为GNN过平滑度量的差异，指出归一化拉普拉斯的缺陷，为GNN动态监控提供理论指导。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09890' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Hands-on Evaluation of Visual Transformers for Object Recognition and Detection</h3>
<p><strong>Authors:</strong> Dimitrios N. Vlachogiannis, Dimitrios A. Koutsomitropoulos</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 对比ViT与CNN架构在目标任务中的性能，为深度学习理论中的网络架构设计提供实践依据。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09579' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Latent-Autoregressive GP-VAE Language Model</h3>
<p><strong>Authors:</strong> Yves Ruffenach</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 将高斯过程（GP）集成到变分自编码器（VAE）中，构建 latent-autoregressive 语言模型，研究序列动态在 latent 空间的表现，为语言模型结构设计提供新视角。
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.09535' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning</h3>
<p><strong>Authors:</strong> Kaichen He, Zihao Wang, Muyao Li, Anji Liu, Yitao Liang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出CrossAgent框架，统一处理异质动作空间（API、GUI、机器人指令），自适应选择交互粒度，在Minecraft环境中超越固定动作基线，显著提升智能体适应性与效率。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.09706' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VisualActBench: Can VLMs See and Act like a Human?</h3>
<p><strong>Authors:</strong> Daoan Zhang, Pai Liu, Xiaofei Zhou, Yuan Ge, Guangchen Lan, Jing Bi, Christopher Brinton, Ehsan Hoque, Jiebo Luo</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出VisualActBench基准评估VLM的视觉动作推理能力，聚焦多模态智能体的主动推理与人类决策对齐问题，为提升模型真实世界适用性提供了重要基础。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.09907' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Architectures for Building Agentic AI</h3>
<p><strong>Authors:</strong> Sławomir Nowaczyk</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 定义智能体系统架构（目标管理器、规划器、工具路由器等），分析组件化、接口设计对可靠性的影响，为多模态智能体设计提供系统性指导。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.09458' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Lossless Ultimate Vision Token Compression for VLMs</h3>
<p><strong>Authors:</strong> Dehua Zheng, Mouxiao Huang, Borui Jiang, Hailin Hu, Xinghao Chen</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 针对VLM视觉token冗余问题提出LUVC框架，实现2倍推理加速且训练-free，直接优化高效大模型推理中的token压缩。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09010' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Efficient Feature Compression for Machines with Global Statistics Preservation</h3>
<p><strong>Authors:</strong> Md Eimran Hossain Eimon, Hyomin Choi, Fabien Racapé, Mateen Ulhaq, Velibor Adzic, Hari Kalva, Borko Furht</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 用Z-score归一化改进FCM，减少比特率17.09%且不牺牲精度，属于高效大模型的特征压缩优化。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09235' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ROI-Packing: Efficient Region-Based Compression for Machine Vision</h3>
<p><strong>Authors:</strong> Md Eimran Hossain Eimon, Alena Krause, Ashan Perera, Juan Merlos, Hari Kalva, Velibor Adzic, Borko Furht</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出ROI-based图像压缩，比VVC减少44.1%比特率且不影响任务精度，优化高效大模型的视觉数据压缩。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09258' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces</h3>
<p><strong>Authors:</strong> Yueer Zhou, Yichen Wu, Ying Wei</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 针对LoRA在终身学习中的灾难性遗忘问题，提出PS-LoRA通过子空间对齐更新解决冲突，提升多领域适应稳定性，属于高效大模型训练与推理的关键改进。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08960' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> StructuredDNA: A Bio-Physical Framework for Energy-Aware Transformer Routing</h3>
<p><strong>Authors:</strong> Mustapha Hamdi</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 受生物启发提出StructuredDNA框架，通过能量感知路由提升Transformer能量效率与参数效率，属于高效大模型训练与推理的创新方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.08968' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Tensor-Compressed and Fully-Quantized Training of Neural PDE Solvers</h3>
<p><strong>Authors:</strong> Jinming Lu, Jiayi Tian, Yequan Zhao, Hai Li, Zheng Zhang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出全量化训练与张量分解框架，提升PINN边缘设备部署效率，属于高效大模型训练与推理的重要应用。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09202' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hetero-SplitEE: Split Learning of Neural Networks with Early Exits for Heterogeneous IoT Devices</h3>
<p><strong>Authors:</strong> Yuki Oda, Yuta Ono, Hiroshi Nakamura, Hideki Takase</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出Hetero-SplitEE框架支持异构IoT设备拆分学习，提升协作训练效率，属于高效大模型训练与推理的重要改进。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09313' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design</h3>
<p><strong>Authors:</strong> Amin Tavakoli, Raswanth Murugan, Ozan Gokdemir, Arvind Ramanathan, Frances Arnold, Anima Anandkumar</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出自蒸馏微调方法提升蛋白语言模型设计能力，属于高效大模型训练与推理的重要应用。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09329' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Knowledge Diversion for Efficient Morphology Control and Policy Transfer</h3>
<p><strong>Authors:</strong> Fu Feng, Ruixiao Shi, Yucheng Xie, Jianlu Shen, Jing Wang, Xin Geng</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出DivMorph，通过SVD分解Transformer权重为共享learngenes和特定tailors，动态门控调制，减少单智能体部署模型大小17×，提升跨任务迁移样本效率3×。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09796' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning</h3>
<p><strong>Authors:</strong> Khurram Khalil, Muhammad Mahad Khaliq, Khaza Anuarul Hoque</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出RIFT，用强化学习生成最小高影响故障场景，加速LLM加速器故障评估，减少测试向量99%，提升成本效益12.8×，支撑高效LLM硬件设计。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09829' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Yifan Ye, Jiaqi Ma, Jun Cen, Zhihe Lu</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出训练-free的Token扩展-合并方法，实现Vision-Language-Action模型的Token压缩，提升推理速度同时保持任务性能，符合高效大模型训练与推理研究方向
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09927' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Enabling Next-Generation Consumer Experience with Feature Coding for Machines</h3>
<p><strong>Authors:</strong> Md Eimran Hossain Eimon, Juan Merlos, Ashan Perera, Hari Kalva, Velibor Adzic, Borko Furht</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 介绍MPEG的FCM标准，通过压缩中间特征支持split-inference，减少比特率75.9%，优化高效大模型的特征传输。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09232' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs</h3>
<p><strong>Authors:</strong> Yezi Liu, William Youngwoo Chung, Hanning Chen, Calvin Yeung, Mohsen Imani</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出PathHD框架，通过超维计算替代神经路径编码，仅需单LLM调用完成知识图谱推理，有效降低推理 latency 和 GPU 内存占用，提升LLM推理效率。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09369' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mixture of Lookup Key-Value Experts</h3>
<p><strong>Authors:</strong> Zongcheng Wang</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 改进MoLE的上下文无关专家选择机制，提出MoLKV通过输入查询与缓存key-value专家交互，实现上下文感知专家输出，提升小模型性能，适用于资源受限设备。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09723' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression</h3>
<p><strong>Authors:</strong> Gustavo Coelho Haase, Paulo Henrique Dourado da Silva</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出HPM-KD知识蒸馏框架，通过自适应配置、渐进蒸馏链、多教师集成等组件，实现10-15×模型压缩，无需手动调参，提升压缩效率与实用性。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.09886' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TextGuider: Training-Free Guidance for Text Rendering via Attention Alignment</h3>
<p><strong>Authors:</strong> Kanghyun Baek, Sangyub Lee, Jin Young Choi, Jaewoo Song, Daemin Park, Jooyoung Choi, Chaehun Shin, Bohyung Han, Sungroh Yoon</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 针对扩散型文本到图像模型的文本渲染遗漏问题，提出无训练引导方法，通过注意力对齐提升文本完整性与准确性，属于大模型新技术中的扩散模型研究。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.09350' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Learning Unmasking Policies for Diffusion Language Models</h3>
<p><strong>Authors:</strong> Metod Jazbec, Theo X. Olausson, Louis Bétune, Pierre Ablin, Michael Kirchhof, Joao Monterio, Victor Turrisi, Jason Ramapuram, Marco Cuturi</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 针对扩散语言模型的解掩码策略，用强化学习训练提升生成质量与效率，属于大模型新技术中扩散LLM的重要改进。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.09106' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Color encoding in Latent Space of Stable Diffusion Models</h3>
<p><strong>Authors:</strong> Guillem Arias, Ariadna Solà, Martí Armengod, Maria Vanrell</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 系统分析Stable Diffusion潜在空间的颜色编码机制，揭示颜色信息的分布规律，为扩散模型的可解释性与编辑应用提供基础，属于大模型新技术方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.09477' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unconsciously Forget: Mitigating Memorization; Without Knowing What is being Memorized</h3>
<p><strong>Authors:</strong> Er Jin, Yang Zhang, Yongli Mou, Yanfei Dong, Stefan Decker, Kenji Kawaguchi, Johannes Stegmaier</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出剪枝方法缓解大模型记忆问题，无需针对特定概念，有效抑制 copyrighted内容生成，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.09687' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing</h3>
<p><strong>Authors:</strong> Zixia Wang, Gaojie Jin, Jia Hu, Ronghui Mu</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 提出聚类引导的去噪平滑方法CluCERT，解决LLM对抗鲁棒性认证问题，提升模型安全性与可靠性，属于大模型安全与对齐的重要研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.08967' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study</h3>
<p><strong>Authors:</strong> Adrian Ryser, Florian Allwein, Tim Schlippe</p>
<p><strong>Published:</strong> 2025-12-11</p>
<p><strong>Reason:</strong> 研究LLM幻觉对用户信任的影响，发现上下文敏感的信任校准机制，识别直觉等信任因素，为LLM安全使用提供实践建议。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.09088' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>