# ArXiv 每日推荐 - 2025-12-12

> 更新于北京时间：2025-12-12 12:38:58
> 已自动阅读了 234 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：124368

## 原生多模态大模型

### [Score: 9.0/10] AgentComp: From Agentic Reasoning to Compositional Mastery in Text-to-Image Models
- **Authors:** Arman Zarei, Jiacheng Pan, Matthew Gwilliam, Soheil Feizi, Zhenheng Yang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09081](https://arxiv.org/abs/2512.09081)
- **Reason:** 利用LLM推理与工具能力构建组合数据集，优化文本到图像模型的组合生成，涉及多模态大模型的agentic推理与组合能力。
Score: 9
Field: 原生多模态大模型

### [Score: 9.0/10] OmniPSD: Layered PSD Generation with Diffusion Transformer
- **Authors:** Cheng Liu, Yiren Song, Haofan Wang, Mike Zheng Shou
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09247](https://arxiv.org/abs/2512.09247)
- **Reason:** 基于Flux生态的扩散框架实现text-to-PSD和image-to-PSD生成，涉及多模态大模型的分层设计与diffusion技术。
Score: 9
Field: 原生多模态大模型

### [Score: 8.0/10] VABench: A Comprehensive Benchmark for Audio-Video Generation
- **Authors:** Daili Hua, Xizhi Wang, Bohan Zeng, Xinyi Huang, Hao Liang, Junbo Niu, Xinlong Chen, Quanqing Xu, Wentao Zhang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09299](https://arxiv.org/abs/2512.09299)
- **Reason:** 构建音频-视频生成的综合基准，评估同步性、一致性等多模态指标，支持原生多模态大模型的评估与优化。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Rethinking Chain-of-Thought Reasoning for Videos
- **Authors:** Yiwu Zhong, Zi-Yuan Hu, Yin Li, Liwei Wang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09616](https://arxiv.org/abs/2512.09616)
- **Reason:** 提出视频MLLM的高效CoT推理框架，通过压缩视觉tokens与简洁推理提升效率，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] DynaIP: Dynamic Image Prompt Adapter for Scalable Zero-shot Personalized Text-to-Image Generation
- **Authors:** Zhizhong Wang, Tianyi Chu, Zeyi Huang, Nanyang Wang, Kehan Li
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09814](https://arxiv.org/abs/2512.09814)
- **Reason:** 针对个性化文本到图像生成的概念保真度、多主体扩展性等核心挑战，提出动态图像提示适配器DynaIP，通过动态解耦策略和分层特征融合显著提升模型性能，属于原生多模态大模型的重要改进方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Composing Concepts from Images and Videos via Concept-prompt Binding
- **Authors:** Xianghao Kong, Zeyu Zhang, Yuwei Guo, Zhuoran Zhao, Songchun Zhang, Anyi Rao
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09824](https://arxiv.org/abs/2512.09824)
- **Reason:** 提出Bind & Compose方法解决图像与视频的视觉概念组合问题，通过概念-提示绑定和时间解耦策略提升概念一致性与跨模态兼容性，是原生多模态大模型在视觉创意领域的关键研究。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] ReViSE: Towards Reason-Informed Video Editing in Unified Models with Self-Reflective Learning
- **Authors:** Xinyu Liu, Hangjie Yuan, Yujie Wei, Jiazheng Xing, Yujin Han, Jiahao Pan, Yanbiao Ma, Chi-Min Chan, Kang Zhao, Shiwei Zhang, Wenhan Luo, Yike Guo
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09924](https://arxiv.org/abs/2512.09924)
- **Reason:** 针对视频编辑的推理感知需求，提出ReViSE框架与RVE基准，通过自反思学习提升推理准确性与视觉保真度，是原生多模态大模型在视频编辑领域的重要应用。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] GLaD: Geometric Latent Distillation for Vision-Language-Action Models
- **Authors:** Minghao Guo, Meng Cao, Jiachen Tao, Rongtao Xu, Yan Yan, Xiaodan Liang, Ivan Laptev, Xiaojun Chang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09619](https://arxiv.org/abs/2512.09619)
- **Reason:** 提出几何 latent 蒸馏方法，将3D几何先验融入Vision-Language-Action模型预训练，提升模型空间推理能力和泛化性能，符合原生多模态大模型研究方向
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models
- **Authors:** Minghui Lin, Pengxiang Ding, Shu Wang, Zifeng Zhuang, Yang Liu, Xinyang Tong, Wenxuan Song, Shangke Lyu, Siteng Huang, Donglin Wang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09928](https://arxiv.org/abs/2512.09928)
- **Reason:** 利用运动表示进行双向时间推理，提出Hindsight、Insight、Foresight框架提升Vision-Language-Action模型的长horizon操纵性能，符合原生多模态大模型研究方向
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] IF-Bench: Benchmarking and Enhancing MLLMs for Infrared Images with Generative Visual Prompting
- **Authors:** Tao Zhang, Yuyang Hong, Yang Xia, Kun Ding, Zeyu Zhang, Ying Wang, Shiming Xiang, Chunhong Pan
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09663](https://arxiv.org/abs/2512.09663)
- **Reason:** 构建首个红外图像MLLM基准，提出生成式视觉提示提升性能，推动原生多模态大模型在红外理解中的应用。
Score: 7
Field: 原生多模态大模型

## 深度学习可解释性

### [Score: 9.0/10] Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs
- **Authors:** Isha Chaturvedi, Anjana Nair, Yushen Li, Adhitya Rajendra Kumar, Kevin Zhu, Sunishchal Dev, Ashwinee Panda, Vasu Sharma
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.08976](https://arxiv.org/abs/2512.08976)
- **Reason:** 提出Contrastive Region Masking方法，揭示MLLM推理过程中视觉区域的依赖关系，提升推理可解释性与忠实度，属于深度学习可解释性的重要进展。
Score: 9
Field: 深度学习可解释性

### [Score: 9.0/10] Natural Geometry of Robust Data Attribution: From Convex Models to Deep Networks
- **Authors:** Shihao Li, Jiachen Li, Dongmei Chen
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09103](https://arxiv.org/abs/2512.09103)
- **Reason:** 提出自然Wasserstein度量解决数据归因鲁棒性问题，提升Deep Learning模型归因稳定性与可靠性，属于深度学习可解释性的关键突破。
Score: 9
Field: 深度学习可解释性

### [Score: 8.0/10] STACHE: Local Black-Box Explanations for Reinforcement Learning Policies
- **Authors:** Andrew Elashkin, Orna Grumberg
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09909](https://arxiv.org/abs/2512.09909)
- **Reason:** 提出STACHE框架，为RL策略生成局部黑盒解释（鲁棒性区域、最小反事实），帮助理解策略训练过程中的逻辑演变，提升RL模型可解释性。
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Building Reasonable Inference for Vision-Language Models in Blind Image Quality Assessment
- **Authors:** Yuan Li, Zitang Sun, Yen-ju Chen, Shin'ya Nishida
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09555](https://arxiv.org/abs/2512.09555)
- **Reason:** 针对VLM推理不稳定、预测不接地问题，提出两阶段调优方法，提升推理可靠性与人类对齐性，属于深度学习可解释性研究。
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] Investigate the Low-level Visual Perception in Vision-Language based Image Quality Assessment
- **Authors:** Yuan Li, Zitang Sun, Yen-Ju Chen, Shin'ya Nishida
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09573](https://arxiv.org/abs/2512.09573)
- **Reason:** 分析MLLM低层次视觉感知缺陷，通过增强视觉编码器对齐提升失真识别能力，属于深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性

## 深度学习理论

### [Score: 9.0/10] Understanding the Failure Modes of Transformers through the Lens of Graph Neural Networks
- **Authors:** Hunjae Lee
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09182](https://arxiv.org/abs/2512.09182)
- **Reason:** 用GNN理论分析Transformer信息传播瓶颈，统一现有解决方案并解释其有效性，属于深度学习理论中Transformer的关键理论理解。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Provably Learning from Modern Language Models via Low Logit Rank
- **Authors:** Noah Golowich, Allen Liu, Abhishek Shetty
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09892](https://arxiv.org/abs/2512.09892)
- **Reason:** 基于现代LLM的低logit秩实证观察，提出高效算法从LLM查询中学习，为现代LLM的可学习性提供首个端到端理论保证。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] GS-KAN: Parameter-Efficient Kolmogorov-Arnold Networks via Sprecher-Type Shared Basis Functions
- **Authors:** Oscar Eliasson
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09084](https://arxiv.org/abs/2512.09084)
- **Reason:** 提出GS-KAN通过共享基函数提升Kolmogorov-Arnold Networks参数效率，属于深度学习理论中网络架构的创新研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Spectral Embedding via Chebyshev Bases for Robust DeepONet Approximation
- **Authors:** Muhammad Abid, Omer San
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09165](https://arxiv.org/abs/2512.09165)
- **Reason:** 提出谱嵌入的DeepONet改进SEDONet，提升PDE求解非周期特征捕捉能力，属于深度学习理论中网络架构的重要研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation
- **Authors:** Ce Wang, Weihang Dai, Hanru Bai, Xiaomeng Li
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09267](https://arxiv.org/abs/2512.09267)
- **Reason:** 提出基于谱排序的对比学习方法，提升半监督回归表示能力，属于深度学习理论中对比学习的创新研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Self-Supervised Learning with Gaussian Processes
- **Authors:** Yunshan Duan, Sinead Williamson
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09322](https://arxiv.org/abs/2512.09322)
- **Reason:** 提出GPSSL用高斯过程改进自监督学习不确定性量化，属于深度学习理论中自监督学习的创新方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Rates and architectures for learning geometrically non-trivial operators
- **Authors:** T. Mitchell Roddenberry, Leo Tzou, Ivan Dokmanić, Maarten V. de Hoop, Richard G. Baraniuk
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09376](https://arxiv.org/abs/2512.09376)
- **Reason:** 扩展算子学习理论至几何积分算子（如广义Radon变换），证明其无维度灾难，提出类交叉注意力架构，为科学机器学习中的算子学习提供理论与架构支撑。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Drawback of Enforcing Equivariance and its Compensation via the Lens of Expressive Power
- **Authors:** Yuzhu Chen, Tian Qin, Xinmei Tian, Fengxiang He, Dacheng Tao
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09673](https://arxiv.org/abs/2512.09673)
- **Reason:** 分析等变约束对模型表达能力的限制，证明可通过增大模型规模补偿该缺陷，揭示等变网络泛化性与模型复杂度的关系，为等变网络设计提供理论指导。
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Analysis of Dirichlet Energies as Over-smoothing Measures
- **Authors:** Anna Bison, Alessandro Sperduti
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09890](https://arxiv.org/abs/2512.09890)
- **Reason:** 分析两种Dirichlet能量（非归一化/归一化拉普拉斯）作为GNN过平滑度量的差异，指出归一化拉普拉斯的缺陷，为GNN动态监控提供理论指导。
Score: 7
Field: 深度学习理论

### [Score: 6.0/10] Hands-on Evaluation of Visual Transformers for Object Recognition and Detection
- **Authors:** Dimitrios N. Vlachogiannis, Dimitrios A. Koutsomitropoulos
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09579](https://arxiv.org/abs/2512.09579)
- **Reason:** 对比ViT与CNN架构在目标任务中的性能，为深度学习理论中的网络架构设计提供实践依据。
Score: 6
Field: 深度学习理论

### [Score: 6.0/10] Latent-Autoregressive GP-VAE Language Model
- **Authors:** Yves Ruffenach
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09535](https://arxiv.org/abs/2512.09535)
- **Reason:** 将高斯过程（GP）集成到变分自编码器（VAE）中，构建 latent-autoregressive 语言模型，研究序列动态在 latent 空间的表现，为语言模型结构设计提供新视角。
Score: 6
Field: 深度学习理论

## 多模态智能体

### [Score: 9.0/10] Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning
- **Authors:** Kaichen He, Zihao Wang, Muyao Li, Anji Liu, Yitao Liang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09706](https://arxiv.org/abs/2512.09706)
- **Reason:** 提出CrossAgent框架，统一处理异质动作空间（API、GUI、机器人指令），自适应选择交互粒度，在Minecraft环境中超越固定动作基线，显著提升智能体适应性与效率。
Score: 9
Field: 多模态智能体

### [Score: 8.0/10] VisualActBench: Can VLMs See and Act like a Human?
- **Authors:** Daoan Zhang, Pai Liu, Xiaofei Zhou, Yuan Ge, Guangchen Lan, Jing Bi, Christopher Brinton, Ehsan Hoque, Jiebo Luo
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09907](https://arxiv.org/abs/2512.09907)
- **Reason:** 提出VisualActBench基准评估VLM的视觉动作推理能力，聚焦多模态智能体的主动推理与人类决策对齐问题，为提升模型真实世界适用性提供了重要基础。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Architectures for Building Agentic AI
- **Authors:** Sławomir Nowaczyk
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09458](https://arxiv.org/abs/2512.09458)
- **Reason:** 定义智能体系统架构（目标管理器、规划器、工具路由器等），分析组件化、接口设计对可靠性的影响，为多模态智能体设计提供系统性指导。
Score: 8
Field: 多模态智能体

## 高效大模型训练与推理

### [Score: 8.0/10] Towards Lossless Ultimate Vision Token Compression for VLMs
- **Authors:** Dehua Zheng, Mouxiao Huang, Borui Jiang, Hailin Hu, Xinghao Chen
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09010](https://arxiv.org/abs/2512.09010)
- **Reason:** 针对VLM视觉token冗余问题提出LUVC框架，实现2倍推理加速且训练-free，直接优化高效大模型推理中的token压缩。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Efficient Feature Compression for Machines with Global Statistics Preservation
- **Authors:** Md Eimran Hossain Eimon, Hyomin Choi, Fabien Racapé, Mateen Ulhaq, Velibor Adzic, Hari Kalva, Borko Furht
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09235](https://arxiv.org/abs/2512.09235)
- **Reason:** 用Z-score归一化改进FCM，减少比特率17.09%且不牺牲精度，属于高效大模型的特征压缩优化。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] ROI-Packing: Efficient Region-Based Compression for Machine Vision
- **Authors:** Md Eimran Hossain Eimon, Alena Krause, Ashan Perera, Juan Merlos, Hari Kalva, Velibor Adzic, Borko Furht
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09258](https://arxiv.org/abs/2512.09258)
- **Reason:** 提出ROI-based图像压缩，比VVC减少44.1%比特率且不影响任务精度，优化高效大模型的视觉数据压缩。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces
- **Authors:** Yueer Zhou, Yichen Wu, Ying Wei
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.08960](https://arxiv.org/abs/2512.08960)
- **Reason:** 针对LoRA在终身学习中的灾难性遗忘问题，提出PS-LoRA通过子空间对齐更新解决冲突，提升多领域适应稳定性，属于高效大模型训练与推理的关键改进。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] StructuredDNA: A Bio-Physical Framework for Energy-Aware Transformer Routing
- **Authors:** Mustapha Hamdi
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.08968](https://arxiv.org/abs/2512.08968)
- **Reason:** 受生物启发提出StructuredDNA框架，通过能量感知路由提升Transformer能量效率与参数效率，属于高效大模型训练与推理的创新方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Tensor-Compressed and Fully-Quantized Training of Neural PDE Solvers
- **Authors:** Jinming Lu, Jiayi Tian, Yequan Zhao, Hai Li, Zheng Zhang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09202](https://arxiv.org/abs/2512.09202)
- **Reason:** 提出全量化训练与张量分解框架，提升PINN边缘设备部署效率，属于高效大模型训练与推理的重要应用。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Hetero-SplitEE: Split Learning of Neural Networks with Early Exits for Heterogeneous IoT Devices
- **Authors:** Yuki Oda, Yuta Ono, Hiroshi Nakamura, Hideki Takase
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09313](https://arxiv.org/abs/2512.09313)
- **Reason:** 提出Hetero-SplitEE框架支持异构IoT设备拆分学习，提升协作训练效率，属于高效大模型训练与推理的重要改进。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design
- **Authors:** Amin Tavakoli, Raswanth Murugan, Ozan Gokdemir, Arvind Ramanathan, Frances Arnold, Anima Anandkumar
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09329](https://arxiv.org/abs/2512.09329)
- **Reason:** 提出自蒸馏微调方法提升蛋白语言模型设计能力，属于高效大模型训练与推理的重要应用。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Knowledge Diversion for Efficient Morphology Control and Policy Transfer
- **Authors:** Fu Feng, Ruixiao Shi, Yucheng Xie, Jianlu Shen, Jing Wang, Xin Geng
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09796](https://arxiv.org/abs/2512.09796)
- **Reason:** 提出DivMorph，通过SVD分解Transformer权重为共享learngenes和特定tailors，动态门控调制，减少单智能体部署模型大小17×，提升跨任务迁移样本效率3×。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning
- **Authors:** Khurram Khalil, Muhammad Mahad Khaliq, Khaza Anuarul Hoque
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09829](https://arxiv.org/abs/2512.09829)
- **Reason:** 提出RIFT，用强化学习生成最小高影响故障场景，加速LLM加速器故障评估，减少测试向量99%，提升成本效益12.8×，支撑高效LLM硬件设计。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Token Expand-Merge: Training-Free Token Compression for Vision-Language-Action Models
- **Authors:** Yifan Ye, Jiaqi Ma, Jun Cen, Zhihe Lu
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09927](https://arxiv.org/abs/2512.09927)
- **Reason:** 提出训练-free的Token扩展-合并方法，实现Vision-Language-Action模型的Token压缩，提升推理速度同时保持任务性能，符合高效大模型训练与推理研究方向
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Enabling Next-Generation Consumer Experience with Feature Coding for Machines
- **Authors:** Md Eimran Hossain Eimon, Juan Merlos, Ashan Perera, Hari Kalva, Velibor Adzic, Borko Furht
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09232](https://arxiv.org/abs/2512.09232)
- **Reason:** 介绍MPEG的FCM标准，通过压缩中间特征支持split-inference，减少比特率75.9%，优化高效大模型的特征传输。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs
- **Authors:** Yezi Liu, William Youngwoo Chung, Hanning Chen, Calvin Yeung, Mohsen Imani
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09369](https://arxiv.org/abs/2512.09369)
- **Reason:** 提出PathHD框架，通过超维计算替代神经路径编码，仅需单LLM调用完成知识图谱推理，有效降低推理 latency 和 GPU 内存占用，提升LLM推理效率。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Mixture of Lookup Key-Value Experts
- **Authors:** Zongcheng Wang
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09723](https://arxiv.org/abs/2512.09723)
- **Reason:** 改进MoLE的上下文无关专家选择机制，提出MoLKV通过输入查询与缓存key-value专家交互，实现上下文感知专家输出，提升小模型性能，适用于资源受限设备。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression
- **Authors:** Gustavo Coelho Haase, Paulo Henrique Dourado da Silva
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09886](https://arxiv.org/abs/2512.09886)
- **Reason:** 提出HPM-KD知识蒸馏框架，通过自适应配置、渐进蒸馏链、多教师集成等组件，实现10-15×模型压缩，无需手动调参，提升压缩效率与实用性。
Score: 7
Field: 高效大模型训练与推理

## 大模型新技术

### [Score: 8.0/10] TextGuider: Training-Free Guidance for Text Rendering via Attention Alignment
- **Authors:** Kanghyun Baek, Sangyub Lee, Jin Young Choi, Jaewoo Song, Daemin Park, Jooyoung Choi, Chaehun Shin, Bohyung Han, Sungroh Yoon
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09350](https://arxiv.org/abs/2512.09350)
- **Reason:** 针对扩散型文本到图像模型的文本渲染遗漏问题，提出无训练引导方法，通过注意力对齐提升文本完整性与准确性，属于大模型新技术中的扩散模型研究。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Learning Unmasking Policies for Diffusion Language Models
- **Authors:** Metod Jazbec, Theo X. Olausson, Louis Bétune, Pierre Ablin, Michael Kirchhof, Joao Monterio, Victor Turrisi, Jason Ramapuram, Marco Cuturi
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09106](https://arxiv.org/abs/2512.09106)
- **Reason:** 针对扩散语言模型的解掩码策略，用强化学习训练提升生成质量与效率，属于大模型新技术中扩散LLM的重要改进。
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] Color encoding in Latent Space of Stable Diffusion Models
- **Authors:** Guillem Arias, Ariadna Solà, Martí Armengod, Maria Vanrell
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09477](https://arxiv.org/abs/2512.09477)
- **Reason:** 系统分析Stable Diffusion潜在空间的颜色编码机制，揭示颜色信息的分布规律，为扩散模型的可解释性与编辑应用提供基础，属于大模型新技术方向。
Score: 7
Field: 大模型新技术

## 大模型安全与对齐

### [Score: 8.0/10] Unconsciously Forget: Mitigating Memorization; Without Knowing What is being Memorized
- **Authors:** Er Jin, Yang Zhang, Yongli Mou, Yanfei Dong, Stefan Decker, Kenji Kawaguchi, Johannes Stegmaier
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09687](https://arxiv.org/abs/2512.09687)
- **Reason:** 提出剪枝方法缓解大模型记忆问题，无需针对特定概念，有效抑制 copyrighted内容生成，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing
- **Authors:** Zixia Wang, Gaojie Jin, Jia Hu, Ronghui Mu
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.08967](https://arxiv.org/abs/2512.08967)
- **Reason:** 提出聚类引导的去噪平滑方法CluCERT，解决LLM对抗鲁棒性认证问题，提升模型安全性与可靠性，属于大模型安全与对齐的重要研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study
- **Authors:** Adrian Ryser, Florian Allwein, Tim Schlippe
- **Published:** 2025-12-11
- **Link:** [https://arxiv.org/abs/2512.09088](https://arxiv.org/abs/2512.09088)
- **Reason:** 研究LLM幻觉对用户信任的影响，发现上下文敏感的信任校准机制，识别直觉等信任因素，为LLM安全使用提供实践建议。
Score: 7
Field: 大模型安全与对齐

