# ArXiv 每日推荐 - 2025-12-16

> 更新于北京时间：2025-12-16 12:38:45
> 已自动阅读了 188 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：97721

## 大模型安全与对齐

### [Score: 9.0/10] MLLM Machine Unlearning via Visual Knowledge Distillation
- **Authors:** Yuhang Wang, Zhenxing Niu, Haoxuan Ji, Guangyu He, Haichang Gao, Gang Hua
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11325](https://arxiv.org/abs/2512.11325)
- **Reason:** 针对MLLM的机器遗忘问题，提出视觉知识蒸馏方法，选择性擦除视觉知识同时保留文本知识，属于大模型安全与对齐中的unlearning，创新且有效。
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization
- **Authors:** Yifan Niu, Han Xiao, Dongyi Liu, Nuo Chen, Jia Li
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11391](https://arxiv.org/abs/2512.11391)
- **Reason:** 提出零空间约束优化框架，减轻大模型安全对齐的性能损失，属于大模型安全与对齐
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints
- **Authors:** Kai Yao, Marc Juarez
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11771](https://arxiv.org/abs/2512.11771)
- **Reason:** 首次系统评估AI图像指纹技术的鲁棒性，形式化白盒/黑盒威胁模型（指纹移除、伪造），实验5种攻击策略与14种指纹方法，发现现有方法的鲁棒性-准确性权衡问题，为大模型安全的指纹归因技术改进提供关键实证依据。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] SpectralKrum: A Spectral-Geometric Defense Against Byzantine Attacks in Federated Learning
- **Authors:** Aditya Tripathi, Karan Sharma, Rahul Mishra, Tapas Kumar Maiti
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11760](https://arxiv.org/abs/2512.11760)
- **Reason:** 提出谱几何防御方法，抵御联邦学习中的拜占庭攻击，提升大模型安全，属于大模型安全与对齐
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] BAID: A Benchmark for Bias Assessment of AI Detectors
- **Authors:** Priyam Basu, Yunfeng Zhang, Vipul Raheja
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11505](https://arxiv.org/abs/2512.11505)
- **Reason:** 构建BAID基准评估AI文本检测器的偏见，覆盖7大类 sociolinguistic 因素，揭示对少数群体的性能差异，属于大模型安全与对齐中的公平性研究
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection
- **Authors:** Georgios Kaoukis, Ioannis Aris Koufopoulos, Psaroudaki Eleni, Danae Pla Karidi, Evaggelia Pitoura, George Papastefanatos, Panayiotis Tsaparas
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11506](https://arxiv.org/abs/2512.11506)
- **Reason:** 结合领域知识图与检索增强生成实现绿色washing自动检测，解决LLM在可持续发展领域的误导性问题，属于大模型安全与对齐中的虚假信息治理
Score: 8
Field: 大模型安全与对齐

## 高效大模型训练与推理

### [Score: 9.0/10] Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference
- **Authors:** Adilet Metinov, Gulida M. Kudakeeva, Bolotbek uulu Nursultan, Gulnara D. Kabaeva
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11221](https://arxiv.org/abs/2512.11221)
- **Reason:** 提出训练无关的KV缓存优化方法，实现LLM推理的亚线性内存增长，提升推理效率，属于高效大模型训练与推理
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes
- **Authors:** Junghwan Lim, Sungmin Lee, Dongseok Kim, Taehyun Kim, Eunhwan Park, Jeesoo Lee, Jeongdoo Lee, Junhyeok Lee, Wai Ting Cheung, Dahye Choi, Minsu Ha, Jaeheui Her, Jaeyeon Huh, Hanbin Jung, Changjin Kang, Beomgyu Kim, Minjae Kim, Taewhan Kim, Youngrok Kim, Hyukjin Kweon, Haesol Lee, Kungyu Lee, Dongpin Oh, Yeongjae Park, Bokki Ryu, Dongjoo Weon
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11463](https://arxiv.org/abs/2512.11463)
- **Reason:** 针对大模型推理训练的模型崩溃、不稳定问题，提出混合并行、两阶段SFT、鲁棒RLFT等优化方案，提升长上下文推理效率与性能，为高效训练提供实用指南
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] Lightweight 3D Gaussian Splatting Compression via Video Codec
- **Authors:** Qi Yang, Geert Van Der Auwera, Zhu Li
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11186](https://arxiv.org/abs/2512.11186)
- **Reason:** 针对3D高斯 splatting的高计算问题，提出基于视频编解码器的轻量级压缩方法，显著提升率失真性能并降低时间，属于高效大模型中的高压缩方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Rethinking Expert Trajectory Utilization in LLM Post-training
- **Authors:** Bowen Ding, Yuhan Chen, Jiayang Lv, Jiyao Yuan, Qi Zhu, Shuangshuang Tian, Dantong Zhu, Futing Wang, Heyuan Deng, Fei Mi, Lifeng Shang, Tao Lin
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11470](https://arxiv.org/abs/2512.11470)
- **Reason:** 提出Plasticity-Ceiling框架，优化LLM后训练中的专家轨迹利用，提升训练效率，属于高效大模型训练与推理
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models
- **Authors:** Xiaoyu Ma, Zhengqing Yuan, Zheyuan Zhang, Kaiwen Shi, Lichao Sun, Yanfang Ye
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11769](https://arxiv.org/abs/2512.11769)
- **Reason:** 提出轻量级推理 wrapper，通过KV缓存、混合精度等技术加速VLA模型推理，在保持性能的同时降低计算成本，解决低资源环境下的高效推理问题
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Autoregressive Video Autoencoder with Decoupled Temporal and Spatial Context
- **Authors:** Cuifeng Shen, Lumin Xu, Xingguo Zhu, Gengdai Liu
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11293](https://arxiv.org/abs/2512.11293)
- **Reason:** 提出自回归视频自动编码器，分离时空上下文，提升压缩效率和重建质量，属于高效大模型中的压缩方向。
Score: 7
Field: 高效大模型训练与推理

## 多模态智能体

### [Score: 8.0/10] VGent: Visual Grounding via Modular Design for Disentangling Reasoning and Prediction
- **Authors:** Weitai Kang, Jason Kuen, Mengwei Ren, Zijun Wei, Yan Yan, Kangning Liu
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11099](https://arxiv.org/abs/2512.11099)
- **Reason:** 提出模块化视觉 grounding框架，分离MLLM推理与边界框预测，解决自回归解码慢和幻觉问题，提升多模态智能体中grounding能力，实验性能优。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Using GUI Agent for Electronic Design Automation
- **Authors:** Chunyi Li, Longfei Li, Zicheng Zhang, Xiaohong Liu, Min Tang, Weisi Lin, Guangtao Zhai
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11611](https://arxiv.org/abs/2512.11611)
- **Reason:** 首次系统研究GUI Agent在电子设计自动化（EDA）中的应用，构建GUI-EDA数据集（含2000+高-quality截图-动作对），基准测试30+主流GUI Agent并提出EDAgent模型，超越Ph.D.学生表现，推动多模态智能体向专业工程领域延伸。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering
- **Authors:** Yifei He, Pranit Chawla, Yaser Souri, Subhojit Som, Xia Song
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.10962](https://arxiv.org/abs/2512.10962)
- **Reason:** 针对计算机使用代理（CUAs）的训练数据稀缺问题，提出step-level过滤将 noisy rollouts转化为可靠监督，构建WebSTAR数据集（13.3K轨迹、100K带推理步骤），训练的Qwen-2.5-VL-Instruct模型在WebVoyager上超越SOTA，推动多模态智能体的可扩展训练。
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents
- **Authors:** Stefan Tabakov, Asen Popov, Dimitar Dimitrov, S. Ensiye Kiyamousavi, Vladimir Hristov, Boris Kraychev
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11584](https://arxiv.org/abs/2512.11584)
- **Reason:** 提出原子动作切片方法，提升Vision-Language-Action（VLA）代理的泛化能力，属于多模态智能体
Score: 7
Field: 多模态智能体

## 原生多模态大模型

### [Score: 8.0/10] VFMF: World Modeling by Forecasting Vision Foundation Model Features
- **Authors:** Gabrijel Boduljak, Yushi Lan, Christian Rupprecht, Andrea Vedaldi
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11225](https://arxiv.org/abs/2512.11225)
- **Reason:** 提出用视觉基础模型特征的生成式预测做世界建模，结合autoregressive flow matching解决不确定性问题，属于原生多模态大模型的世界模型应用。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Exploring MLLM-Diffusion Information Transfer with MetaCanvas
- **Authors:** Han Lin (University of North Carolina at Chapel Hill), Xichen Pan (Meta), Ziqi Huang (Meta), Ji Hou (Meta), Jialiang Wang (Meta), Weifeng Chen (Meta), Zecheng He (Meta), Felix Juefei-Xu (Meta), Junzhe Sun (Meta), Zhipeng Fan (Meta), Ali Thabet (Meta), Mohit Bansal (University of North Carolina at Chapel Hill), Chu Wang (Meta)
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11464](https://arxiv.org/abs/2512.11464)
- **Reason:** 提出MetaCanvas框架连接多模态大语言模型（MLLM）与扩散模型，将MLLM作为潜在空间规划器，解决多模态理解与生成的能力 gap，实验覆盖文本到图像/视频生成、编辑等6项任务，显著提升生成的精确控制能力，为多模态大模型的跨模态信息传递提供新方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Insight Miner: A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language
- **Authors:** Yunkai Zhang, Yawen Zhang, Ming Zheng, Kezhen Chen, Chongyang Gao, Ruian Ge, Siyuan Teng, Amine Jelloul, Jinmeng Rao, Xiaoyuan Guo, Chiang-Wei Fang, Zeyu Zheng, Jie Yang
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11251](https://arxiv.org/abs/2512.11251)
- **Reason:** 构建时间序列与自然语言对齐的多模态数据集，支持原生多模态大模型的训练，属于原生多模态大模型方向
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] Infinity and Beyond: Compositional Alignment in VAR and Diffusion T2I Models
- **Authors:** Hossein Shahabadi, Niki Sepasian, Arash Marioriyad, Ali Sharifi-Zarchi, Mahdieh Soleymani Baghshah
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11542](https://arxiv.org/abs/2512.11542)
- **Reason:** 系统比较视觉自回归（VAR）与扩散文本到图像（T2I）模型的组合对齐能力（覆盖颜色、属性绑定、空间关系等维度），发现Infinity系列VAR模型在组合性上优于主流扩散模型，建立了统一基线，为多模态生成的组合性优化提供关键参考。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] EditMGT: Unleashing Potentials of Masked Generative Transformers in Image Editing
- **Authors:** Wei Chow, Linfeng Li, Lingdong Kong, Zefeng Li, Qi Xu, Hang Song, Tian Ye, Xian Wang, Jinbin Bai, Shilin Xu, Xiangtai Li, Junting Pan, Shaoteng Liu, Ran Zhou, Tianshu Yang, Songhua Liu
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11715](https://arxiv.org/abs/2512.11715)
- **Reason:** 首次提出基于掩码生成Transformer（MGT）的图像编辑框架，利用MGT局部解码特性解决扩散模型的非目标区域修改问题，构建CrispEdit-2M高分辨率数据集，在风格变化（+3.6%）、风格迁移（+17.6%）等任务上优于扩散模型，且速度快6倍。
Score: 7
Field: 原生多模态大模型

## 大模型新技术

### [Score: 8.0/10] FilmWeaver: Weaving Consistent Multi-Shot Videos with Cache-Guided Autoregressive Diffusion
- **Authors:** Xiangyang Luo, Qingyu Li, Xiaokun Liu, Wenyu Qin, Miao Yang, Meng Wang, Pengfei Wan, Di Zhang, Kun Gai, Shao-Lun Huang
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11274](https://arxiv.org/abs/2512.11274)
- **Reason:** 用缓存引导的自回归扩散生成一致的多镜头视频，解决跨镜头一致性问题，属于大模型新技术中的diffusion视频生成，实验验证性能优。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] JoyAvatar: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion
- **Authors:** Chaochao Li, Ruikui Wang, Liangbo Zhou, Jinheng Feng, Huaishao Luo, Huan Zhang, Youzheng Wu, Xiaodong He
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11423](https://arxiv.org/abs/2512.11423)
- **Reason:** 用自回归扩散实现实时无限音频驱动头像生成，解决误差累积问题，属于大模型新技术中的diffusion应用，性能优且实用。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Flowception: Temporally Expansive Flow Matching for Video Generation
- **Authors:** Tariq Berrada Ifriqi, John Nguyen, Karteek Alahari, Jakob Verbeek, Ricky T. Q. Chen
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11438](https://arxiv.org/abs/2512.11438)
- **Reason:** 提出时间扩展的流匹配用于非自回归可变长度视频生成，提升效率和质量，属于大模型新技术中的flow matching生成，方法创新。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Beyond Memorization: Gradient Projection Enables Selective Learning in Diffusion Models
- **Authors:** Divya Kothandaraman, Jaclyn Pytlarz
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11194](https://arxiv.org/abs/2512.11194)
- **Reason:** 提出梯度投影框架解决扩散模型的记忆问题，属于大模型新技术中的diffusion LLM方向
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis
- **Authors:** Junjie Ye, Rong Xue, Basile Van Hoorick, Pavel Tokmakov, Muhammad Zubair Irshad, Yue Wang, Vitor Guizilini
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11797](https://arxiv.org/abs/2512.11797)
- **Reason:** 将预训练视频扩散模型用于机器人数据合成，通过运动渲染约束避免幻觉，是diffusion LLM在机器人领域的创新应用，属于大模型新技术范畴
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] AutoRefiner: Improving Autoregressive Video Diffusion Models via Reflective Refinement Over the Stochastic Sampling Path
- **Authors:** Zhengyang Yu, Akio Hayakawa, Masato Ishii, Qingtao Yu, Takashi Shibuya, Jing Zhang, Yuki Mitsufuji
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11203](https://arxiv.org/abs/2512.11203)
- **Reason:** 针对自回归视频扩散模型的采样质量问题，提出反射式细化方法作为高效插件，提升样本 fidelity，属于大模型新技术中的diffusion改进。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits
- **Authors:** Minwoo Park, Junwoo Chang, Jongeun Choi, Roberto Horowitz
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11345](https://arxiv.org/abs/2512.11345)
- **Reason:** 研究对称感知的扩散策略引导，涉及diffusion模型的改进，属于大模型新技术
Score: 7
Field: 大模型新技术

## 深度学习理论

### [Score: 8.0/10] MoB: Mixture of Bidders
- **Authors:** Dev Vyas
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.10969](https://arxiv.org/abs/2512.10969)
- **Reason:** 提出Mixture of Bidders框架，用VCG拍卖替代MoE的gating网络，解决灾难性遗忘问题，在Split-MNIST上的平均准确率（88.77%）远高于Gated MoE（19.54%）和Monolithic EWC（27.96%），为深度学习架构中的MoE改进提供新方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] In-Context Multi-Objective Optimization
- **Authors:** Xinyu Zhang, Conor Hassan, Julien Martinelli, Daolang Huang, Samuel Kaski
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11114](https://arxiv.org/abs/2512.11114)
- **Reason:** 提出基于Transformer的上下文多目标优化框架TAMO，改进多目标优化器的通用性和效率，属于深度学习理论中的优化方向
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Sliced ReLU attention: Quasi-linear contextual expressivity via sorting
- **Authors:** Siwan Boufadène (LIGM), François-Xavier Vialard (LIGM)
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11411](https://arxiv.org/abs/2512.11411)
- **Reason:** 提出新的Sliced ReLU注意力机制，实现准线性复杂度和强上下文表达能力，属于深度学习理论中的网络架构方向
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration
- **Authors:** Alexander Tyurin
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11587](https://arxiv.org/abs/2512.11587)
- **Reason:** 分析梯度下降的动力学，揭示其作为感知器算法的隐式加速现象，属于深度学习理论中的优化方向
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective
- **Authors:** Etienne Boursier, Claire Boyer
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11784](https://arxiv.org/abs/2512.11784)
- **Reason:** 分析大prompt下Softmax注意力的线性特性，涉及Transformer注意力机制，属于深度学习理论
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Fairness-Regularized Online Optimization with Switching Costs
- **Authors:** Pengfei Li, Yuelin Han, Adam Wierman, Shaolei Ren
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11131](https://arxiv.org/abs/2512.11131)
- **Reason:** 提出公平正则化的在线优化框架，处理切换成本，属于深度学习理论中的优化方向
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] The Vekua Layer: Exact Physical Priors for Implicit Neural Representations via Generalized Analytic Functions
- **Authors:** Vladimer Khasia
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11138](https://arxiv.org/abs/2512.11138)
- **Reason:** 提出Vekua Layer，结合物理先验和广义解析函数，改进隐式神经表示的谱偏差和优化效率，属于深度学习理论
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] On the failure of ReLU activation for physics-informed machine learning
- **Authors:** Conor Rowan
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11184](https://arxiv.org/abs/2512.11184)
- **Reason:** 揭示ReLU激活函数在物理感知机器学习中的失败原因，涉及网络架构中的激活函数选择，属于深度学习理论
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] A Simple Generalisation of the Implicit Dynamics of In-Context Learning
- **Authors:** Francesco Innocenti, El Mehdi Achour
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11255](https://arxiv.org/abs/2512.11255)
- **Reason:** 推广上下文学习的隐式动力学理论，涉及Transformer结构的上下文学习机制，属于深度学习理论
Score: 7
Field: 深度学习理论

### [Score: 6.0/10] Fast EXP3 Algorithms
- **Authors:** Ryoma Sato, Shinji Ito
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11201](https://arxiv.org/abs/2512.11201)
- **Reason:** 提出快速EXP3在线学习算法，改进优化效率，属于深度学习理论中的优化方向
Score: 6
Field: 深度学习理论

## 深度学习可解释性

### [Score: 8.0/10] Features Emerge as Discrete States: The First Application of SAEs to 3D Representations
- **Authors:** Albert Miao, Chenliang Zhou, Jiawei Zhou, Cengiz Oztireli
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11263](https://arxiv.org/abs/2512.11263)
- **Reason:** 首次将稀疏自编码器（SAE）应用于3D表示，分解模型特征增强可解释性，属于深度学习可解释性
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Back to the Baseline: Examining Baseline Effects on Explainability Metrics
- **Authors:** Agustin Martin Picard (ANITI), Thibaut Boissin (ANITI), Varshini Subhash (SU), Rémí Cadène (SU), Thomas Fel (ANITI)
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11433](https://arxiv.org/abs/2512.11433)
- **Reason:** 聚焦可解释性指标（如Insertion/Deletion）的基线选择问题，揭示基线对归因方法评估的关键影响并提出改进基线，是深度学习可解释性的基础研究
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] A Fast Interpretable Fuzzy Tree Learner
- **Authors:** Javier Fumanal-Idocin, Raquel Fernandez-Peralta, Javier Andreu-Perez
- **Published:** 2025-12-15
- **Link:** [https://arxiv.org/abs/2512.11616](https://arxiv.org/abs/2512.11616)
- **Reason:** 提出快速可解释的模糊树学习器，增强模型的可解释性，属于深度学习可解释性
Score: 7
Field: 深度学习可解释性

