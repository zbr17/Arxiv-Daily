<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-19</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >大模型新技术</a>
<a href='#' >深度学习理论</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-19</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-19 12:37:19</p>
<p>已自动阅读了 230 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：113445</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Qwen-Image-Layered: Towards Inherent Editability via Layer Decomposition</h3>
<p><strong>Authors:</strong> Shengming Yin, Zekai Zhang, Zecheng Tang, Kaiyuan Gao, Xiao Xu, Kun Yan, Jiahao Li, Yilei Chen, Yuxiang Chen, Heung-Yeung Shum, Lionel M. Ni, Jingren Zhou, Junyang Lin, Chenfei Wu</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出基于层分解的扩散模型Qwen-Image-Layered，将单RGB图像分解为语义分离的RGBA层，实现可编辑的图像生成，解决了现有模型编辑一致性差的问题，实验验证其分解质量和编辑性能 superior。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15603' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TalkVerse: Democratizing Minute-Long Audio-Driven Video Generation</h3>
<p><strong>Authors:</strong> Zhenzhi Wang, Jian Wang, Ke Ma, Dahua Lin, Bing Zhou</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 构建大规模音频-视频数据集，提出高效音频驱动视频生成模型，支持零-shot配音与长视频生成，属于原生多模态大模型（音频+视频）的核心研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.14938' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GRAN-TED: Generating Robust, Aligned, and Nuanced Text Embedding for Diffusion Models</h3>
<p><strong>Authors:</strong> Bozhou Li, Sihan Yang, Yushuo Guan, Ruichuan An, Xinlong Chen, Yang Shi, Pengfei Wan, Wentao Zhang, Yuanxing zhang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出针对扩散模型的文本嵌入框架GRAN-TED，通过TED-6K基准和两阶段训练策略提升文本到图像/视频生成的语义保真度，解决了现有文本编码器的评估和适配问题。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15560' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FlowBind: Efficient Any-to-Any Generation with Bidirectional Flows</h3>
<p><strong>Authors:</strong> Yeonwoo Cha, Semin Kim, Jinhyeon Kwon, Seunghoon Hong</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出高效任意模态生成框架FlowBind，通过共享 latent 空间与双向流模型实现多模态转换，解决现有方法数据需求大、计算成本高的问题，直接对应原生多模态大模型的核心研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15420' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> HERBench: A Benchmark for Multi-Evidence Integration in Video Question Answering</h3>
<p><strong>Authors:</strong> Dan Ben-Ami, Gabriele Serussi, Kobi Cohen, Chaim Baskin</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 构建视频问答多证据整合基准，针对Video-LLMs的跨时间多模态推理能力评估，推动原生多模态大模型的视频理解研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.14870' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Vibe Spaces for Creatively Connecting and Expressing Visual Concepts</h3>
<p><strong>Authors:</strong> Huzheng Yang, Katherine Xu, Andrew Lu, Michael D. Grossberg, Yutong Bai, Jianbo Shi</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出Vibe Space框架解决视觉概念融合问题，基于CLIP潜在空间实现多模态语义一致生成，属于原生多模态大模型的图像理解与生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.14884' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PMMD: A pose-guided multi-view multi-modal diffusion for person generation</h3>
<p><strong>Authors:</strong> Ziyu Shang, Haoran Liu, Rongchao Zhang, Zhiqian Wei, Tongtong Feng</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出姿态引导的多视图多模态扩散模型，结合姿态、多视图与文本实现人物生成，属于原生多模态大模型的图像生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15069' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> 3DProxyImg: Controllable 3D-Aware Animation Synthesis from Single Image via 2D-3D Aligned Proxy Embedding</h3>
<p><strong>Authors:</strong> Yupeng Zhu, Xiongzhen Zhang, Ye Chen, Bingbing Ni</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出轻量级3D动画框架，结合2D图像生成与3D几何控制，实现单图3D动画生成，属于原生多模态大模型（图像+3D）的研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15126' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Borrowing from anything: A generalizable framework for reference-guided instance editing</h3>
<p><strong>Authors:</strong> Shengxiao Zhou, Chenghua Li, Jianhao Huang, Qinghao Hu, Yifan Zhang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出参考引导的实例编辑框架，解决语义纠缠问题，实现跨图像的特征迁移，属于原生多模态大模型的图像理解与编辑方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15138' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MMMamba: A Versatile Cross-Modal In Context Fusion Framework for Pan-Sharpening and Zero-Shot Image Enhancement</h3>
<p><strong>Authors:</strong> Yingying Wang, Xuanhua He, Chen Wu, Jialing Huang, Suiyun Zhang, Rui Liu, Xinghao Ding, Haoxuan Che</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出基于Mamba的跨模态融合框架，实现全色与多光谱图像融合及零-shot超分，属于原生多模态大模型（PAN+MS）的研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15261' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics</h3>
<p><strong>Authors:</strong> Junjie Chen, Fei Wang, Zhihao Huang, Qing Zhou, Kun Li, Dan Guo, Linfeng Zhang, Xun Yang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出因果框架用于3D对话头部动态生成，结合音频与视觉模态，属于原生多模态大模型（音频+3D）的研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.15340' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models</h3>
<p><strong>Authors:</strong> Lunbin Zeng, Jingfeng Yao, Bencheng Liao, Hongyuan Tao, Wenyu Liu, Xinggang Wang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出DiffusionVL框架将自回归模型转换为扩散视觉语言模型，通过简单微调实现范式迁移，解决了现有扩散VLM性能落后的问题，实验验证其在多基准上的性能提升和推理加速。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.15713' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Corrective Diffusion Language Models</h3>
<p><strong>Authors:</strong> Shuibai Zhang, Fred Zhangzhi Peng, Yiheng Zhang, Jin Pan, Grigorios G. Chrysos</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 针对扩散语言模型（MDLM）无法有效纠正错误的问题，提出纠正导向的训练方法，引入Code Revision Benchmark评估纠正行为，属于用户明确关注的大模型新技术（diffusion LLM）范畴。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.15596' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Softly Constrained Denoisers for Diffusion Models</h3>
<p><strong>Authors:</strong> Victor M. Yeom Song, Severi Rissanen, Arno Solin, Samuel Kaski, Mingfei Sun</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出将软约束整合到扩散模型的denoiser架构中，解决传统约束方法导致的分布偏差问题，同时保持对约束的适应性，属于大模型新技术中的扩散模型改进方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.14980' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SoFlow: Solution Flow Models for One-Step Generative Modeling</h3>
<p><strong>Authors:</strong> Tianze Luo, Haotian Yuan, Zhuang Liu</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出SoFlow框架实现单步生成，通过优化Flow Matching损失与一致性损失解决扩散模型多步效率问题，属于大模型新技术中的高效生成方法。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.15657' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision</h3>
<p><strong>Authors:</strong> Wenlong Xia, Jinhao Zhang, Ce Zhang, Yaojia Wang, Youmin Gong, Jie Mei</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出基于扩散模型的3D visuomotor政策，引入隐式场景监督提升政策性能和鲁棒性，在机器人操纵任务上取得SOTA，属于大模型新技术中的扩散模型应用。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.15020' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Entropy-Reservoir Bregman Projection: An Information-Geometric Unification of Model Collapse</h3>
<p><strong>Authors:</strong> Jingwei Chen</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出ERBP信息几何框架统一自参考学习中的模型崩溃问题，分析熵衰减机制并提出熵reservoir稳定方法，从理论上解释模型崩溃原因及修复策略有效性，属于深度学习理论中的自监督学习研究。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14879' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models</h3>
<p><strong>Authors:</strong> Ali Ghodsi</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出统一框架整合Attention与SSM序列模型，证明交互秩间隙、头数等价定理及梯度传播差异，从理论上分析序列模型的表达能力与训练性权衡，属于深度学习理论中的序列架构研究。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.15115' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Dynamic Learning Rate Scheduling based on Loss Changes Leads to Faster Convergence</h3>
<p><strong>Authors:</strong> Shreyas Subramanian, Bala Krishnamoorthy, Pranav Murthy</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出GreedyLR动态学习率调度器，基于损失变化自适应调整学习率，在NLP、CV和LLM任务上验证了收敛速度和精度提升，有理论分析支持，对深度学习理论中的优化器研究贡献显著。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14527' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hard Labels In! Rethinking the Role of Hard Labels in Mitigating Local Semantic Drift</h3>
<p><strong>Authors:</strong> Jiacheng Cui, Bingkui Tong, Xinyue Bi, Xiaohan Zhao, Jiacheng Liu, Zhiqiang shen</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 重新审视hard labels在soft-label主导训练中的作用，提出HALD范式利用hard labels缓解局部语义漂移，理论分析其成因并通过实验验证在数据集蒸馏和分类任务上的性能提升，对深度学习训练范式有重要启示。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.15647' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Quantum Decision Transformers (QDT): Synergistic Entanglement and Interference for Offline Reinforcement Learning</h3>
<p><strong>Authors:</strong> Abraham Itzhak Weinberg</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出量子启发的决策Transformer架构QDT，整合量子纠缠注意力与量子前馈网络解决传统DT的长 horizon 信用分配问题，通过实验验证组件协同效应及2000%性能提升，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14726' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> How Does Fourier Analysis Network Work? A Mechanism Analysis and a New Dual-Activation Layer Proposal</h3>
<p><strong>Authors:</strong> Sam Jeong, Hae Yong Kim</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 深入分析Fourier Analysis Network的工作机制，发现正弦激活的局部梯度特性缓解死亡ReLU问题，提出双激活层DAL并验证其在多任务上的收敛与精度提升，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14873' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Understanding NTK Variance in Implicit Neural Representations</h3>
<p><strong>Authors:</strong> Chengguang Ou, Yixin Zhuang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 分析隐式神经表示（INR）中神经 tangent 核（NTK）方差的影响因素，解释 positional encoding 等架构对光谱偏差的缓解机制，属于深度学习理论中的模型理论分析。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.15169' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction</h3>
<p><strong>Authors:</strong> Mathieu Blondel, Michael E. Sander, Germain Vivier-Ardisson, Tianlin Liu, Vincent Roulet</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 建立自回归语言模型（ARMs）与能量基模型（EBMs）的严格等价性，推导两者在监督学习中的等价关系及蒸馏误差界，为理解ARMs的前瞻能力提供深度学习理论层面的核心洞察。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.15605' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Universal Reasoning Model</h3>
<p><strong>Authors:</strong> Zitian Gao, Lynx Chen, Yihao Xiao, He Xing, Ran Tao, Haoming Luo, Joey Zhou, Bryan Dai</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 系统分析Universal Transformers性能来源，提出URM改进架构，通过短卷积和截断反向传播提升推理性能，在ARC-AGI任务上取得SOTA，对推理模型架构设计有重要参考价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14693' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Puzzle Curriculum GRPO for Vision-Centric Reasoning</h3>
<p><strong>Authors:</strong> Ahmadreza Jeddi, Hakki Can Karaimer, Hue Nguyen, Zhongling Wang, Ke Zhao, Javad Rajabi, Ran Zhang, Raghav Goyal, Babak Taati, Radek Grzeszczuk</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出Puzzle Curriculum GRPO方法，通过自监督谜题环境优化VLM的强化学习后训练，解决推理一致性与奖励稀疏问题，属于深度学习理论中的强化学习优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14944' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LLM as a Neural Architect: Controlled Generation of Image Captioning Models Under Strict API Contracts</h3>
<p><strong>Authors:</strong> Krunal Jesani, Dmitry Ignatov, Radu Timofte</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出LLM引导的神经架构搜索 pipeline，用LLM生成符合API规范的图像caption模型，实验验证其生成模型的有效性，对自动化模型设计有探索价值。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14706' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Task Matrices: Linear Maps for Cross-Model Finetuning Transfer</h3>
<p><strong>Authors:</strong> Darrin O' Brien, Dhikshith Gajulapalli, Eric Xia</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出任务矩阵概念，验证预训练与微调模型间的线性编码关系，证明线性映射可有效传递任务信息，属于深度学习理论中的模型迁移研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.14880' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> How Smoothing is N-simplicial Attention?</h3>
<p><strong>Authors:</strong> Alexandre Dussolle, Pietro Liò</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出N-simplicial Attention机制，扩展注意力从 pairwise 到更高阶交互，并推导其平滑性的Lipschitz上界，属于深度学习理论中网络架构（注意力机制）的关键研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.15600' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> DEER: Draft with Diffusion, Verify with Autoregressive Models</h3>
<p><strong>Authors:</strong> Zicong Cheng, Guo-Wei Yang, Jia Li, Zhijie Deng, Meng-Hao Guo, Shi-Min Hu</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出DEER框架用扩散大语言模型（dLLM）作为草稿模型加速自回归模型推理，实现单步生成32 token长草稿段及5.54x速度提升，属于高效大模型训练与推理中的推理加速研究。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.15176' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training</h3>
<p><strong>Authors:</strong> Can Jin, Hongwu Peng, Mingcan Xiang, Qixin Zhang, Xiangchi Yuan, Amit Hasan, Ohiremen Dibua, Yifan Gong, Yan Kang, Dimitris N. Metaxas</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出动态Top-p路由的MoE架构DTop-p，通过PI控制器实现稀疏性精准控制，解决传统Top-k路由的均匀稀疏问题，是高效大模型训练的核心技术突破。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.13996' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SocialNav-MoE: A Mixture-of-Experts Vision Language Model for Socially Compliant Navigation with Reinforcement Fine-Tuning</h3>
<p><strong>Authors:</strong> Tomohito Kawabata, Xinyu Zhang, Ling Xiao</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 针对机器人社交导航任务提出高效Mixture-of-Experts视觉语言模型，解决大模型实时部署问题，结合小VLM、强化学习微调与多模态融合，直接对应高效大模型推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.14757' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Uni-Parser Technical Report</h3>
<p><strong>Authors:</strong> Xi Fang, Haoyi Tao, Shuwen Yang, Suyang Zhong, Haocheng Lu, Han Lyu, Chaozheng Huang, Xinyu Li, Linfeng Zhang, Guolin Ke</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出工业级文档解析引擎，采用多专家架构与分布式推理实现高吞吐量，属于高效大模型训练与推理的基础设施研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.15098' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees</h3>
<p><strong>Authors:</strong> Junjie Ma, Jinlong Li</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出基于强化学习的动态草稿树方法RADAR，动态决定草稿模型调用次数以减少冗余计算，显著加速LLM推理，是高效大模型推理的重要技术创新。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.14069' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Massive Editing for Large Language Models Based on Dynamic Weight Generation</h3>
<p><strong>Authors:</strong> Wentao Wan, Qiqing Lao, Zhiwei Xie, Hefeng Wu, Runnan Lin, Liang Lin, Keze Wang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出基于动态权重生成的大模型大规模知识编辑方法，解决现有知识编辑的可靠性、通用性和局部性挑战，为高效修改大模型知识提供低代价方案，对高效大模型训练有重要价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.14395' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Null-LoRA: Low-Rank Adaptation on Null Space</h3>
<p><strong>Authors:</strong> Yi Zhang, Yulei Kang, Haoxuan Chen, Jinxuan Li, ian-Fang Hu</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出Null-LoRA方法，通过null空间优化LoRA的参数高效微调，提升模型性能与参数效率，属于高效大模型训练的核心研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.15233' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> KD360-VoxelBEV: LiDAR and 360-degree Camera Cross Modality Knowledge Distillation for Bird's-Eye-View Segmentation</h3>
<p><strong>Authors:</strong> Wenke E, Yixin Sun, Jiaxu Liu, Hubert P. H. Shum, Amir Atapour-Abarghouei, Toby P. Breckon</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出跨模态知识蒸馏框架，将LiDAR+相机模型的知识蒸馏到单相机模型，提升推理速度与性能，属于高效大模型推理的研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.15311' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bits for Privacy: Evaluating Post-Training Quantization via Membership Inference</h3>
<p><strong>Authors:</strong> Chenxiang Zhang, Tongxi Qu, Zhong Li, Tian Zhang, Jun Pang, Sjouke Mauw</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 研究后训练量化（PTQ）对模型隐私泄漏的影响，分析不同量化算法与精度下的隐私-效用权衡，为高效大模型部署中的隐私保护提供实践指导，属于高效大模型训练与推理的重要延伸研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.15335' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Improving VQA Reliability: A Dual-Assessment Approach with Self-Reflection and Cross-Model Verification</h3>
<p><strong>Authors:</strong> Xixian Wu, Yang Ou, Pengchao Tian, Zian Yang, Jielei Zhang, Peiyi Li, Longwen Gao</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 针对视觉问答模型的幻觉问题，提出双评估框架提升可靠性，通过自反思与跨模型验证优化大模型输出一致性，属于大模型安全与对齐核心方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.14770' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Expand and Prune: Maximizing Trajectory Diversity for Effective GRPO in Generative Models</h3>
<p><strong>Authors:</strong> Shiran Ge, Chenyi Huang, Yuang Ai, Qihang Fan, Huaibo Huang, Ran He</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出Pro-GRPO方法，通过扩展-剪枝策略优化生成模型的GRPO对齐，解决奖励聚类问题，属于大模型安全与对齐的核心研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.15347' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Epistemic diversity across language models mitigates knowledge collapse</h3>
<p><strong>Authors:</strong> Damian Hodel, Jevin D. West</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 研究语言模型生态的认知多样性对知识崩溃的缓解作用，发现适度多样性可减少性能衰减，为大模型安全与对齐中的知识保持问题提供新视角。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.15011' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling</h3>
<p><strong>Authors:</strong> Annu Rana, Gaurav Kumar</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出Model-First Reasoning范式，通过显式问题建模减少LLM规划任务中的约束违反和不一致解，有效缓解幻觉问题，实验覆盖多领域验证有效性，对大模型安全与对齐有重要意义。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.14474' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Where is the Watermark? Interpretable Watermark Detection at the Block Level</h3>
<p><strong>Authors:</strong> Maria Bulychev, Neil G. Marchant, Benjamin I. P. Rubinstein</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出块级可解释水印检测方法，通过局部嵌入与区域级解释解决传统水印的黑盒问题，直接对应深度学习可解释性的研究方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.14994' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Explainable Action Form Assessment by Exploiting Multimodal Chain-of-Thoughts Reasoning</h3>
<p><strong>Authors:</strong> Mengshi Qi, Yeteng Wu, Xianlin Zhang, Huadong Ma</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出可解释的动作评估框架，通过多模态Chain-of-Thought生成推理过程，构建CoT-AFA数据集，直接对应深度学习可解释性的研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.15153' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> How a Bit Becomes a Story: Semantic Steering via Differentiable Fault Injection</h3>
<p><strong>Authors:</strong> Zafaryab Haider, Md Hafizur Rahman, Shane Moeykens, Vijay Devabhaktuni, Prabuddha Chakraborty</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出BLADE框架研究bit级扰动对视觉语言模型语义的影响，揭示低电平变化对高维语义的引导作用，对理解模型语义编码和鲁棒性有重要意义。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.14715' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hybrid Attribution Priors for Explainable and Robust Model Training</h3>
<p><strong>Authors:</strong> Zhuoran Zhang, Feng Zhang, Shangyuan Li, Yang Shi, Yuanxing Zhang, Wei Chen, Tengjiao Wang, Kam-Fai Wong</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出Class-Aware Attribution Prior和混合先验框架，引导模型捕捉细粒度类区分，提升解释性和鲁棒性，实验验证其在全数据、少样本和对抗场景下的有效性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.14719' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Isolation to Entanglement: When Do Interpretability Methods Identify and Disentangle Known Concepts?</h3>
<p><strong>Authors:</strong> Aaron Mueller, Andrew Lee, Shruti Joshi, Ekdeep Singh Lubana, Dhanya Sridhar, Patrik Reizinger</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 评估可解释性方法（如稀疏自动编码器）对多概念的分解能力，发现现有方法难以实现概念独立操纵，为深度学习可解释性中的概念分解问题提供实证与理论 insights。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.15134' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Step-GUI Technical Report</h3>
<p><strong>Authors:</strong> Haolong Yan, Jia Wang, Xin Huang, Yeqing Shen, Ziyang Meng, Zhimin Fan, Kaijun Tan, Jin Gao, Lieyu Shi, Mi Yang, Shiliang Yang, Zhirui Wang, Brian Li, Kang An, Chenyang Li, Lei Lei, Mengmeng Duan, Danxun Liang, Guodong Liu, Hang Cheng, Hao Wu, Jie Dong, Junhao Huang, Mei Chen, Renjie Yu, Shunshan Li, Xu Zhou, Yiting Dai, Yineng Deng, Yingdan Liang, Zelin Chen, Wen Sun, Chengxu Yan, Chunqin Xu, Dong Li, Fengqiong Xiao, Guanghao Fan, Guopeng Li, Guozhen Peng, Hongbing Li, Hang Li, Hongming Chen, Jingjing Xie, Jianyong Li, Jingyang Zhang, Jiaju Ren, Jiayu Yuan, Jianpeng Yin, Kai Cao, Liang Zhao, Liguo Tan, Liying Shi, Mengqiang Ren, Min Xu, Manjiao Liu, Mao Luo, Mingxin Wan, Na Wang, Nan Wu, Ning Wang, Peiyao Ma, Qingzhou Zhang, Qiao Wang, Qinlin Zeng, Qiong Gao, Qiongyao Li, Shangwu Zhong, Shuli Gao, Shaofan Liu, Shisi Gao, Shuang Luo, Xingbin Liu, Xiaojia Liu, Xiaojie Hou, Xin Liu, Xuanti Feng, Xuedan Cai, Xuan Wen, Xianwei Zhu, Xin Liang, Xin Liu, Xin Zhou, Yingxiu Zhao, Yukang Shi, Yunfang Xu, Yuqing Zeng, Yixun Zhang, Zejia Weng, Zhonghao Yan, Zhiguo Huang, Zhuoyu Wang, Zheng Ge, Jing Li, Yibo Zhu, Binxing Jiao, Xiangyu Zhang, Daxin Jiang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 针对GUI自动化任务提出自进化训练 pipeline 和 GUI-MCP 协议，解决了高质量训练数据获取和异质设备部署问题，在多个GUI基准上取得SOTA性能，对多模态智能体的实际应用有重要价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.15431' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MobileWorldBench: Towards Semantic World Modeling For Mobile Agents</h3>
<p><strong>Authors:</strong> Shufan Li, Konstantinos Kallidromitis, Akash Gokul, Yusuke Kato, Kazuki Kozuka, Aditya Grover</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出MobileWorldBench基准与MobileWorld数据集，研究GUI代理的语义世界建模，将VLM世界模型集成到移动代理规划框架中，直接对应多模态智能体中的GUI Agent方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.14014' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence</h3>
<p><strong>Authors:</strong> Jiaxu Wan, Xu Wang, Mengwei Xie, Hang Zhang, Mu Xu, Yang Han, Hong Zhang, Ding Yuan, Yifan Yang</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出BEV-grounding的空间智能框架，结合视觉与空间推理，用Chain-of-Thought解决空间问题，属于多模态智能体的空间导航方向。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.15160' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SynthSeg-Agents: Multi-Agent Synthetic Data Generation for Zero-Shot Weakly Supervised Semantic Segmentation</h3>
<p><strong>Authors:</strong> Wangyu Wu, Zhenhong Chen, Xiaowei Huang, Fei Ma, Jimin Xiao</p>
<p><strong>Published:</strong> 2025-12-18</p>
<p><strong>Reason:</strong> 提出LLM驱动的多代理合成数据生成框架，用于零-shot弱监督分割，属于多模态智能体的应用研究。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.15310' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>