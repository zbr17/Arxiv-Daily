# ArXiv 每日推荐 - 2025-12-24

> 更新于北京时间：2025-12-24 12:42:59
> 已自动阅读了 351 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：181559

## 原生多模态大模型

### [Score: 9.0/10] Xiaomi MiMo-VL-Miloco Technical Report
- **Authors:** Jiaze Li, Jingyang Chen, Yuxun Qu, Shijie Xu, Zhenru Lin, Junyou Zhu, Boshen Xu, Wenhui Tan, Pei Fu, Jianzhong Ju, Zhenbo Luo, Jian Luan
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17436](https://arxiv.org/abs/2512.17436)
- **Reason:** 开源家庭场景视觉语言模型MiMo-VL-Miloco，通过两阶段训练与链式思维监督提升家庭场景理解及多模态推理能力，属于原生多模态大模型研究范畴。
Score: 9
Field: 原生多模态大模型

### [Score: 9.0/10] GroundingME: Exposing the Visual Grounding Gap in MLLMs through Multi-Dimensional Evaluation
- **Authors:** Rang Li, Lei Li, Shuhuai Ren, Hao Tian, Shuhao Gu, Shicheng Li, Zihao Yue, Yudong Wang, Wenhan Ma, Zhe Yang, Jingyuan Ma, Zhifang Sui, Fuli Luo
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17495](https://arxiv.org/abs/2512.17495)
- **Reason:** 提出GroundingME基准评估MLLM的视觉接地能力，揭示其在相似物体区分、空间关系理解及不可接地查询拒绝的不足，并提出改进策略，涉及大模型安全（幻觉问题），符合原生多模态大模型方向。
Score: 9
Field: 原生多模态大模型

### [Score: 8.0/10] InfoTok: Adaptive Discrete Video Tokenizer via Information-Theoretic Compression
- **Authors:** Haotian Ye (Stanford University), Qiyuan He (Stanford University), Jiaqi Han (Stanford University), Puheng Li (Stanford University), Jiaojiao Fan (Stanford University), Zekun Hao (Stanford University), Fitsum Reda (NVIDIA), Yogesh Balaji (NVIDIA), Huayu Chen (Adobe Research), Sheng Liu (Adobe Research), Angela Yao (National University of Singapore), James Zou (Stanford University), Stefano Ermon (Stanford University), Haoxiang Wang (Stanford University), Ming-Yu Liu (NVIDIA)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.16975](https://arxiv.org/abs/2512.16975)
- **Reason:** 提出InfoTok自适应视频tokenizer框架，结合信息论优化token压缩，解决固定速率tokenization的冗余或信息丢失问题，属于原生多模态大模型中的tokenizer研究，对视频多模态理解有重要价值。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Towards Deeper Emotional Reflection: Crafting Affective Image Filters with Generative Priors
- **Authors:** Peixuan Zhang, Shuchen Weng, Jiajun Tang, Si Li, Boxin Shi
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17376](https://arxiv.org/abs/2512.17376)
- **Reason:** 提出情感图像滤镜任务及AIF模型，结合多模态Transformer与扩散模型生成先验，提升情感图像生成的内容一致性与情感保真度，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] InsertAnywhere: Bridging 4D Scene Geometry and Diffusion Models for Realistic Video Object Insertion
- **Authors:** Hoiyeong Jin, Hyojin Jang, Jeongho Kim, Junha Hyung, Kinam Kim, Dongjin Kim, Huijin Choi, Hyeonji Kim, Jaegul Choo
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17504](https://arxiv.org/abs/2512.17504)
- **Reason:** 提出InsertAnywhere框架结合4D场景几何与扩散模型，实现视频物体插入的几何一致性与视觉真实感，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Robust-R1: Degradation-Aware Reasoning for Robust Visual Understanding
- **Authors:** Jiaqi Tang, Jianmin Chen, Wei Wei, Xiaogang Xu, Runtao Liu, Xiangyu Wu, Qipeng Xie, Jiafei Wu, Lei Zhang, Qifeng Chen
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17532](https://arxiv.org/abs/2512.17532)
- **Reason:** 提出Robust-R1框架通过结构化推理链提升MLLM在视觉降解下的鲁棒性，构建degradation-aware数据集，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] RoomEditor++: A Parameter-Sharing Diffusion Architecture for High-Fidelity Furniture Synthesis
- **Authors:** Qilong Wang, Xiaofan Ming, Zhenyi Lin, Jinwen Li, Dongwei Ren, Wangmeng Zuo, Qinghua Hu
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17573](https://arxiv.org/abs/2512.17573)
- **Reason:** 提出RoomEditor++扩散架构用于高保真家具合成，构建RoomBench++数据集，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] HeadHunt-VAD: Hunting Robust Anomaly-Sensitive Heads in MLLM for Tuning-Free Video Anomaly Detection
- **Authors:** Zhaolin Cai, Fan Li, Ziwei Zheng, Haixia Bi, Lijun He
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17601](https://arxiv.org/abs/2512.17601)
- **Reason:** 提出HeadHunt-VAD通过寻找MLLM中的异常敏感注意力头，实现无调优视频异常检测，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Generative Human-Object Interaction Detection via Differentiable Cognitive Steering of Multi-modal LLMs
- **Authors:** Zhaolin Cai, Huiyu Duan, Zitong Xu, Fan Li, Zhi Liu, Jing Liu, Wei Shen, Xiongkuo Min, Guangtao Zhai
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17640](https://arxiv.org/abs/2512.17640)
- **Reason:** 提出GRASP-HO框架通过认知steering模块将视觉证据注入MLLM，实现开放词汇HOI检测，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Region-Constraint In-Context Generation for Instructional Video Editing
- **Authors:** Zhongwei Zhang, Fuchen Long, Wei Li, Zhaofan Qiu, Wu Liu, Ting Yao, Tao Mei
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17650](https://arxiv.org/abs/2512.17650)
- **Reason:** 提出ReCo框架结合区域约束的in-context生成实现指令视频编辑，构建ReCo-Data数据集，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] AdaptPrompt: Parameter-Efficient Adaptation of VLMs for Generalizable Deepfake Detection
- **Authors:** Yichen Jiang, Mohammed Talha Alam, Sohail Ahmed Khan, Duc-Tien Dang-Nguyen, Fakhri Karray
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17730](https://arxiv.org/abs/2512.17730)
- **Reason:** 提出AdaptPrompt框架高效适配VLMs用于通用Deepfake检测，构建Diff-Gen数据集，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Chorus: Multi-Teacher Pretraining for Holistic 3D Gaussian Scene Encoding
- **Authors:** Yue Li, Qi Ma, Runyi Yang, Mengjiao Ma, Bin Ren, Nikola Popovic, Nicu Sebe, Theo Gevers, Luc Van Gool, Danda Pani Paudel, Martin R. Oswald
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17817](https://arxiv.org/abs/2512.17817)
- **Reason:** 提出Chorus多教师预训练框架学习3D Gaussian的holistic编码，结合多个2D基础模型信号，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] InfSplign: Inference-Time Spatial Alignment of Text-to-Image Diffusion Models
- **Authors:** Sarah Rastegar, Violeta Chatalbasheva, Sieger Falkena, Anuj Singh, Yanbo Wang, Tejas Gokhale, Hamid Palangi, Hadi Jamali-Rad
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17851](https://arxiv.org/abs/2512.17851)
- **Reason:** 提出InfSplign方法在推理时调整噪声，提升文本到图像的空间对齐精度，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Visually Prompted Benchmarks Are Surprisingly Fragile
- **Authors:** Haiwen Feng, Long Lian, Lisa Dunlap, Jiahao Shu, XuDong Wang, Renhao Wang, Trevor Darrell, Alane Suhr, Angjoo Kanazawa
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17875](https://arxiv.org/abs/2512.17875)
- **Reason:** 研究VLM视觉提示基准的脆弱性，发现视觉标记设计等细节显著影响模型性能和 leaderboard 排名，对原生多模态大模型的评估方法有重要改进
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Both Semantics and Reconstruction Matter: Making Representation Encoders Ready for Text-to-Image Generation and Editing
- **Authors:** Shilong Zhang, He Zhang, Zhifei Zhang, Chongjian Ge, Shuchen Xue, Shaoteng Liu, Mengwei Ren, Soo Ye Kim, Yuqian Zhou, Qing Liu, Daniil Pakhomov, Kai Zhang, Zhe Lin, Ping Luo
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17909](https://arxiv.org/abs/2512.17909)
- **Reason:** 改进文本到图像生成的表示编码器，兼顾语义保留和像素重建，解决了现有编码器导致生成结构不准确的问题，属于原生多模态大模型中的图像生成研究
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Stable and Efficient Single-Rollout RL for Multimodal Reasoning
- **Authors:** Rui Liu, Dian Yu, Lei Ke, Haolin Liu, Yujun Zhou, Zhenwen Liang, Haitao Mi, Pratap Tokekar, Dong Yu
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18215](https://arxiv.org/abs/2512.18215)
- **Reason:** 提出MSSR框架改进多模态LLM的RLVR训练稳定性和效率，解决了单rollout训练的崩溃问题，属于原生多模态大模型的推理优化
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] OmniMER: Indonesian Multimodal Emotion Recognition via Auxiliary-Enhanced LLM Adaptation
- **Authors:** Xueming Yan, Boyan Xu, Yaochu Jin, Lixian Xiao, Wenlong Ye, Runyang Cai, Zeqi Zheng, Jingfa Liu, Aimin Yang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19379](https://arxiv.org/abs/2512.19379)
- **Reason:** 构建印尼语多模态情感识别基准IndoMER，提出OmniMER框架基于LLM适配多模态任务，提升低资源场景下的情感识别性能，属于原生多模态大模型方向
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] CARE What Fails: Contrastive Anchored-REflection for Verifiable Multimodal
- **Authors:** Yongxin Wang, Zhicheng Yang, Meng Cao, Mingfei Han, Haokun Lin, Yingying Zhu, Xiaojun Chang, Xiaodan Liang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19554](https://arxiv.org/abs/2512.19554)
- **Reason:** 提出CARE框架，利用故障作为监督信号提升多模态推理的准确性和训练平滑度，对原生多模态大模型的推理优化有价值
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection
- **Authors:** Yizhi Wang, Linan Yue, Min-Ling Zhang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18956](https://arxiv.org/abs/2512.18956)
- **Reason:** 提出三阶段框架生成高质量多模态长链式思维，提升多模态大模型推理能力，属于原生多模态大模型的核心研究。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] DAVE: A VLM Vision Encoder for Document Understanding and Web Agents
- **Authors:** Brandon Huang (UC Berkeley), Hang Hua (Salesforce Research), Zhuoran Yu (UC Berkeley), Trevor Darrell (UC Berkeley), Rogerio Feris (Salesforce Research), Roei Herzig (Salesforce Research)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17221](https://arxiv.org/abs/2512.17221)
- **Reason:** 针对文档理解和Web Agents设计VLM视觉编码器，通过自监督和监督预训练提升结构与空间信息提取能力，属于原生多模态大模型中的视觉encoder研究，支持多模态智能体任务。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Deep But Reliable: Advancing Multi-turn Reasoning for Thinking with Images
- **Authors:** Wenhao Yang (Tsinghua University), Yu Xia (Tsinghua University), Jinlong Huang (Tsinghua University), Shiyin Lu (Tsinghua University), Qing-Guo Chen (Tsinghua University), Zhao Xu (Tsinghua University), Weihua Luo (Tsinghua University), Kaifu Zhang (Tsinghua University), Yuanyu Wan (Tsinghua University), Lijun Zhang (Tsinghua University)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17306](https://arxiv.org/abs/2512.17306)
- **Reason:** 提出DRIM模型，通过多-turn工具调用和RL优化提升多模态大模型的视觉推理可靠性，属于原生多模态大模型中的视觉推理研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Beyond Semantic Features: Pixel-level Mapping for Generalized AI-Generated Image Detection
- **Authors:** Chenming Zhou, Jiaan Wang, Yu Li, Lei Li, Juan Cao, Sheng Tang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17350](https://arxiv.org/abs/2512.17350)
- **Reason:** 提出像素级映射预处理步骤破坏图像语义特征，强制检测器关注生成过程的高频痕迹，提升AI生成图像检测的跨模型泛化性，涉及图像生成与理解，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] LumiCtrl : Learning Illuminant Prompts for Lighting Control in Personalized Text-to-Image Models
- **Authors:** Muhammad Atif Butt, Kai Wang, Javier Vazquez-Corral, Joost Van De Weijer
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17489](https://arxiv.org/abs/2512.17489)
- **Reason:** 提出LumiCtrl方法学习光照提示，结合物理增强与边缘引导解纠缠，提升文本到图像模型的光照控制能力，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] FLEG: Feed-Forward Language Embedded Gaussian Splatting from Any Views
- **Authors:** Qijian Tian, Xin Tan, Jiayu Ying, Xuhong Wang, Yuan Xie, Lizhuang Ma
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17541](https://arxiv.org/abs/2512.17541)
- **Reason:** 提出FLEG模型从任意视图重建语言嵌入的3D Gaussian Splatting，结合无3D标注训练与对比学习，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] StereoMV2D: A Sparse Temporal Stereo-Enhanced Framework for Robust Multi-View 3D Object Detection
- **Authors:** Di Wu, Feng Yang, Wenhui Zhao, Jinwen Yu, Pan Liao, Benlian Xu, Dingwen Zhang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17620](https://arxiv.org/abs/2512.17620)
- **Reason:** 提出StereoMV2D框架结合temporal stereo提升多视图3D目标检测的深度感知，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Dexterous World Models
- **Authors:** Byungjun Kim, Taeksoo Kim, Junyoung Lee, Hanbyul Joo
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17907](https://arxiv.org/abs/2512.17907)
- **Reason:** 提出场景-动作条件的视频扩散框架，生成人类与场景交互的时序一致视频，属于原生多模态大模型中的图像生成研究
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] QuantiPhy: A Quantitative Benchmark Evaluating Physical Reasoning Abilities of Vision-Language Models
- **Authors:** Li Puyin, Tiange Xiang, Ella Mao, Shirley Wei, Xinye Chen, Adnan Masood, Li Fei-fei, Ehsan Adeli
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19526](https://arxiv.org/abs/2512.19526)
- **Reason:** 提出多模态大模型物理推理的定量基准，评估VLMs的物理理解能力，属于原生多模态大模型的基础研究。
Score: 7
Field: 原生多模态大模型

## 深度学习可解释性

### [Score: 9.0/10] Keypoint Counting Classifiers: Turning Vision Transformers into Self-Explainable Models Without Training
- **Authors:** Kristoffer Wickstrøm, Teresa Dorszewski, Siyan Chen, Michael Kampffmeyer, Elisabeth Wetzer, Robert Jenssen
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17891](https://arxiv.org/abs/2512.17891)
- **Reason:** 提出无需训练将ViT转化为自解释模型的方法，利用关键点计数实现可解释性，解决了现有自解释模型依赖复杂训练的问题，属于深度学习可解释性的创新工作
Score: 9
Field: 深度学习可解释性

### [Score: 9.0/10] From Points to Coalitions: Hierarchical Contrastive Shapley Values for Prioritizing Data Samples
- **Authors:** Canran Xiao, Jiabao Dou, Zhiming Lin, Zong Ke, Liwei Hou
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19363](https://arxiv.org/abs/2512.19363)
- **Reason:** 提出分层对比Shapley值框架HCDV，解决大规模数据样本估值的复杂度问题，提升效率和准确性，符合深度学习可解释性方向
Score: 9
Field: 深度学习可解释性

### [Score: 8.0/10] From Black-Box Tuning to Guided Optimization via Hyperparameters Interaction Analysis
- **Authors:** Moncef Garouani, Ayah Barhrhouj
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19246](https://arxiv.org/abs/2512.19246)
- **Reason:** 提出MetaSHAP框架，基于Shapley值分析超参数交互，提供可解释的调优 insights，解决超参数调优的黑盒问题，符合深度学习可解释性方向
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Brain-Grounded Axes for Reading and Steering LLM States
- **Authors:** Sandro Andric
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19399](https://arxiv.org/abs/2512.19399)
- **Reason:** 用人类大脑活动作为LLM状态的坐标系统，实现对LLM状态的读取和引导，提升大模型的可解释性和可控性，符合深度学习可解释性方向
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies
- **Authors:** Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19673](https://arxiv.org/abs/2512.19673)
- **Reason:** 分解LLM的内部层和模块政策，提出Bottom-up Policy Optimization，提升复杂推理性能，有助于理解LLM的内部机制，符合深度学习可解释性方向
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Understanding Chain-of-Thought in Large Language Models via Topological Data Analysis
- **Authors:** Chenghao Li, Chaoning Zhang, Yi Lu, Shuxu Chen, Xudong Wang, Jiaquan Zhang, Zhicheng Wang, Zhengxun Jin, Kuien Liu, Sung-Ho Bae, Guoqing Wang, Yang Yang, Hen Tao Shen
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19135](https://arxiv.org/abs/2512.19135)
- **Reason:** 用拓扑数据分析LLM链式思维的结构机制，揭示推理链的语义连贯性与逻辑冗余，属于深度学习可解释性研究。
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN
- **Authors:** Balram Singh, Ram Prakash Sharma, Somnath Dey
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17864](https://arxiv.org/abs/2512.17864)
- **Reason:** 提出CBAM-VGG16模型结合注意力模块，提升植物病害检测的可解释性，使用多种解释方法（Grad-CAM等），符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] Trustworthy and Explainable Deep Reinforcement Learning for Safe and Energy-Efficient Process Control: A Use Case in Industrial Compressed Air Systems
- **Authors:** Vincent Bezold, Patrick Wagner, Jakob Hofmann, Marco Huber, Alexander Sauer
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18317](https://arxiv.org/abs/2512.18317)
- **Reason:** 结合SHAP等方法实现RL的可解释性，揭示政策决策的关键因素，属于深度学习可解释性在工业场景的应用
Score: 7
Field: 深度学习可解释性

## 高效大模型训练与推理

### [Score: 9.0/10] CodeGEMM: A Codebook-Centric Approach to Efficient GEMM in Quantized LLMs
- **Authors:** Gunho Park, Jeongin Bae, Byeongwook Kim, Baeseong park, Jiwon Ryu, Hoseung Kim, Se Jung Kwon, Dongsoo Lee
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17970](https://arxiv.org/abs/2512.17970)
- **Reason:** 提出CodeGEMM优化量化LLM的GEMM计算，通过预计算质心与激活的内积避免重复查找，显著提升推理效率，属于高效大模型训练与推理的核心技术创新
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] MixKVQ: Query-Aware Mixed-Precision KV Cache Quantization for Long-Context Reasoning
- **Authors:** Tao Zhang, Ziqian Zeng, Hao Peng, Huiping Zhuang, Cen Chen
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19206](https://arxiv.org/abs/2512.19206)
- **Reason:** 针对长上下文推理的KV缓存量化问题，提出查询感知的混合精度策略，有效平衡性能与内存消耗，对大模型高效推理具有重要应用价值
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] MAGIC: Achieving Superior Model Merging via Magnitude Calibration
- **Authors:** Yayuan Li, Jian Zhang, Jintao Guo, Zihan Cheng, Lei Qi, Yinghuan Shi, Yang Gao
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19320](https://arxiv.org/abs/2512.19320)
- **Reason:** 针对模型合并中的特征幅度偏差问题，提出MAGIC框架，在不额外训练的情况下提升CV和NLP任务的合并性能，对高效模型融合有重要贡献
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] Efficient Mixture-of-Agents Serving via Tree-Structured Routing, Adaptive Pruning, and Dependency-Aware Prefill-Decode Overlap
- **Authors:** Zijun Wang, Yijiahao Qi, Hanqiu Chen, Zishen Wan, Gongjin Sun, Dongyang Li, Shuyi Pei, Cong Hao
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18126](https://arxiv.org/abs/2512.18126)
- **Reason:** 针对混合智能体的服务延迟问题，提出树结构路由、自适应剪枝等方法，大幅降低延迟同时保持精度，对高效大模型推理有重要贡献
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] ProCache: Constraint-Aware Feature Caching with Selective Computation for Diffusion Transformer Acceleration
- **Authors:** Fanpu Cao (Tsinghua University), Yaofo Chen (Tsinghua University), Zeng You (Tsinghua University), Wei Luo (Tsinghua University), Cen Chen (Tsinghua University)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17298](https://arxiv.org/abs/2512.17298)
- **Reason:** 提出约束感知特征缓存和选择性计算框架，加速扩散Transformer推理，解决DiT高计算成本问题，属于高效大模型训练与推理中的推理加速研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] MoE Pathfinder: Trajectory-driven Expert Pruning
- **Authors:** Xican Yang, Yuanhe Tian, Yan Song
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18425](https://arxiv.org/abs/2512.18425)
- **Reason:** 提出轨迹驱动的MoE专家剪枝方法，通过全局轨迹信息选择专家，提升MoE模型效率，属于高效大模型训练与推理的MoE优化技术
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] When Less is More: 8-bit Quantization Improves Continual Learning in Large Language Models
- **Authors:** Michael S. Zhang, Rishi A. Ruia, Arnav Kewalram, Saathvik Dharmapuram, Utkarsh Sharma, Kevin Zhu
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18934](https://arxiv.org/abs/2512.18934)
- **Reason:** 系统研究LLM量化精度与持续学习的关系，发现8位量化通过隐式正则化提升持续学习性能（如代码生成任务性能翻倍），属于高效大模型训练与推理（量化压缩）的重要实践，有强实际应用价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Parameter-Efficient Fine-Tuning for HAR: Integrating LoRA and QLoRA into Transformer Models
- **Authors:** Irina Seregina, Philippe Lalanda, German Vega
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17983](https://arxiv.org/abs/2512.17983)
- **Reason:** 研究LoRA和QLoRA在HAR中的参数高效微调，在保持性能的同时减少可训练参数和内存使用，属于高效大模型训练的典型应用
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Conscious Data Contribution via Community-Driven Chain-of-Thought Distillation
- **Authors:** Lena Libon, Meghana Bhange, Rushabh Solanki, Elliot Creager, Ulrich Aïvodji
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18174](https://arxiv.org/abs/2512.18174)
- **Reason:** 提出社区驱动的CoT蒸馏方法，用于用户自主数据贡献，提升小模型性能，属于高效大模型训练中的蒸馏技术创新
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] NOVA: Discovering Well-Conditioned Winograd Transforms through Numerical Optimization of Vandermonde Arithmetic
- **Authors:** Jayant Lohia
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18453](https://arxiv.org/abs/2512.18453)
- **Reason:** 优化Winograd变换的点选择，解决低精度计算的数值不稳定性问题，提升卷积效率，属于高效大模型推理的底层优化技术
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Can abstract concepts from LLM improve SLM performance?
- **Authors:** Siddharth Tandon
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19069](https://arxiv.org/abs/2512.19069)
- **Reason:** 研究LLM抽象概念向小模型的迁移，提升小语言模型性能，属于高效大模型训练与推理中的小模型优化方向。
Score: 7
Field: 高效大模型训练与推理

## 深度学习理论

### [Score: 9.0/10] On the Convergence Rate of LoRA Gradient Descent
- **Authors:** Siqiao Mu, Diego Klabjan
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18248](https://arxiv.org/abs/2512.18248)
- **Reason:** 首次分析LoRA梯度下降的非渐近收敛率，证明其收敛到 stationary point 的速率为O(1/log T)，属于深度学习理论中优化器的关键理论结果
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] On the Universality of Transformer Architectures; How Much Attention Is Enough?
- **Authors:** Amirreza Abbasi, Mohsen Hooshmand
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18445](https://arxiv.org/abs/2512.18445)
- **Reason:** 研究Transformer的普适性，分析注意力机制的最小需求，揭示了Transformer架构的表达能力边界，属于深度学习理论中的网络架构基础研究
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] When Does Learning Renormalize? Sufficient Conditions for Power Law Spectral Dynamics
- **Authors:** Yizhou Zhang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18209](https://arxiv.org/abs/2512.18209)
- **Reason:** 研究深度学习中的幂律谱动力学，提出学习重归一化的充分条件，揭示了深度模型训练的粗粒度动力学机制，属于深度学习理论的基础研究
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Towards Guided Descent: Optimization Algorithms for Training Neural Networks At Scale
- **Authors:** Ansh Nagwekar
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18373](https://arxiv.org/abs/2512.18373)
- **Reason:** 系统研究神经网络优化算法，从SGD到高阶方法，分析各方法的局限性和改进方向，为大规模模型训练提供了原则性指导，属于深度学习理论的优化器研究
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Secret mixtures of experts inside your LLM
- **Authors:** Enric Boix-Adsera
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18452](https://arxiv.org/abs/2512.18452)
- **Reason:** 发现LLM中隐式的MoE结构，揭示MLP层的稀疏计算特性，为Transformer架构的理解提供了新视角，属于深度学习理论中的网络架构研究
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] The Geometry of Abstraction: Continual Learning via Recursive Quotienting
- **Authors:** Xin Li
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18471](https://arxiv.org/abs/2512.18471)
- **Reason:** 从几何角度研究持续学习，提出递归商映射方法解决 catastrophic forgetting，揭示了抽象的拓扑变形机制，属于深度学习理论中的网络架构研究
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] The Interaction Bottleneck of Deep Neural Networks: Discovery, Proof, and Modulation
- **Authors:** Huiqi Deng, Qihan Ren, Zhuofan Chen, Zhenyuan Cui, Wen Shen, Peng Zhang, Hongbin Pei, Quanshi Zhang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18607](https://arxiv.org/abs/2512.18607)
- **Reason:** 研究深度神经网络的交互瓶颈，发现通用的“中阶交互缺失”偏置并通过理论证明其内在原因，同时提出调制方法连接微观交互结构与宏观表示能力，对理解网络架构的表示偏置有重要理论贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] From Shortcut to Induction Head: How Data Diversity Shapes Algorithm Selection in Transformers
- **Authors:** Ryotaro Kawata, Yujin Song, Alberto Bietti, Naoki Nishikawa, Taiji Suzuki, Samuel Vaiter, Denny Wu
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18634](https://arxiv.org/abs/2512.18634)
- **Reason:** 理论分析Transformer中数据多样性对算法选择的影响（归纳头vs位置捷径），推导了数据分布与模型行为的定量关系，揭示了Transformer机制的核心驱动因素，对深度学习理论（Transformer架构）有重要价值。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] On the Koopman-Based Generalization Bounds for Multi-Task Deep Learning
- **Authors:** Mahdi Mohammadigohari, Giuseppe Di Fatta, Giuseppe Nicosia, Panos M. Pardalos
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19199](https://arxiv.org/abs/2512.19199)
- **Reason:** 利用Koopman算子理论建立多任务深度学习的泛化界，提出比传统范数方法更紧的界，有助于深入理解多任务学习的理论基础
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] A Logical View of GNN-Style Computation and the Role of Activation Functions
- **Authors:** Pablo Barceló, Floris Geerts, Matthias Lanzinger, Klara Pakhomenko, Jan Van den Bussche
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19332](https://arxiv.org/abs/2512.19332)
- **Reason:** 从逻辑角度分析GNN的计算机制，证明ReLU激活函数比有界激活更具表达性，深化了对GNN架构和激活函数的理论理解
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture
- **Authors:** Christian H\"agg, Kathl\'en Kohn, Giovanni Luca Marchetti, Boris Shapiro
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19367](https://arxiv.org/abs/2512.19367)
- **Reason:** 基于Kolmogorov-Arnold理论提出Sprecher Networks，实现参数高效和内存友好的网络架构，深化了对深度学习架构的理论研究
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Merging of Kolmogorov-Arnold networks trained on disjoint datasets
- **Authors:** Andrew Polar, Michael Poluektov
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18921](https://arxiv.org/abs/2512.18921)
- **Reason:** 研究Kolmogorov-Arnold网络（KAN）在disjoint数据集上的合并策略，发现牛顿-卡茨马茨方法与分段线性基函数的组合可提升训练效率，属于深度学习理论中新型网络架构的应用创新。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Large Language Models as Discounted Bayesian Filters
- **Authors:** Jensen Zhang, Jing Yang, Keze Wang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18489](https://arxiv.org/abs/2512.18489)
- **Reason:** 提出贝叶斯滤波框架评估LLM在动态环境中的在线推理，揭示其信念更新的系统性折扣机制，属于深度学习理论中推理机制的研究。
Score: 7
Field: 深度学习理论

## 多模态智能体

### [Score: 8.0/10] CodeDance: A Dynamic Tool-integrated MLLM for Executable Visual Reasoning
- **Authors:** Qi Song (Zhejiang University), Honglin Li (Zhejiang University), Yingchen Yu (Zhejiang University), Haoyi Zhou (Zhejiang University), Lin Yang (Zhejiang University), Song Bai (Zhejiang University), Qi She (Zhejiang University), Zilong Huang (Zhejiang University), Yunqing Zhao (Zhejiang University)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17312](https://arxiv.org/abs/2512.17312)
- **Reason:** 设计动态工具整合的MLLM，通过代码 orchestrate 工具执行可解释视觉推理，属于多模态智能体中的工具集成智能体研究，提升多模态推理能力。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] A Benchmark and Agentic Framework for Omni-Modal Reasoning and Tool Use in Long Videos
- **Authors:** Mohammed Irfan Kurpath (MBZUAI), Jaseel Muhammad Kaithakkodan (MBZUAI), Jinxing Zhou (MBZUAI), Sahal Shaji Mullappilly (MBZUAI), Mohammad Almansoori (MBZUAI), Noor Ahsan (MBZUAI), Beknur Kalmakhanbet (MBZUAI), Sambal Shikhar (MBZUAI), Rishabh Lalla (MBZUAI), Jean Lahoud (MBZUAI), Mariette Awad (MBZUAI), Fahad Shahbaz Khan (MBZUAI), Salman Khan (MBZUAI), Rao Muhammad Anwer (MBZUAI), Hisham Cholakkal (MBZUAI)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.16978](https://arxiv.org/abs/2512.16978)
- **Reason:** 提出LongShOTBench基准和LongShOTAgent框架，支持长视频的全模态推理和工具使用，属于多模态智能体中的工具使用和原生多模态大模型中的长视频理解研究。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] LangDriveCTRL: Natural Language Controllable Driving Scene Editing with Multi-modal Agents
- **Authors:** Yun He, Francesco Pittaluga, Ziyu Jiang, Matthias Zwicker, Manmohan Chandraker, Zaid Tasneem
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17445](https://arxiv.org/abs/2512.17445)
- **Reason:** 提出自然语言控制的驾驶场景编辑框架，通过多模态Agent协调工具实现细粒度编辑，提升指令对齐与场景真实感，符合多模态智能体方向。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Animate Any Character in Any World
- **Authors:** Yitong Wang, Fangyun Wei, Hongyang Zhang, Bo Dai, Yan Lu
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17796](https://arxiv.org/abs/2512.17796)
- **Reason:** 提出AniX框架通过自然语言控制3D场景中的角色动画，结合多模态Agent实现开放动作，符合多模态智能体方向。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement
- **Authors:** Saman Forouzandeh, Wei Peng, Parham Moradi, Xinghuo Yu, Mahdi Jalili
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18950](https://arxiv.org/abs/2512.18950)
- **Reason:** 提出MACLA框架为LLM Agents构建层级程序记忆，通过贝叶斯选择与对比精修提升样本效率（训练速度快2800倍）与可解释性，解决了LLM Agents的知识复用难题，属于多模态智能体的关键技术创新。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] EchoTrail-GUI: Building Actionable Memory for GUI Agents via Critic-Guided Self-Exploration
- **Authors:** Runze Li, Yuwen Zhai, Bo Xu, LiWu Xu, Nian Shi, Wei Zhang, Ran Lin, Liang Wang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19396](https://arxiv.org/abs/2512.19396)
- **Reason:** 为GUI Agents构建动态可行动记忆，提升任务成功率与效率，属于多模态智能体中的GUI Agent核心研究。
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] FC-MIR: A Mobile Screen Awareness Framework for Intent-Aware Recommendation based on Frame-Compressed Multimodal Trajectory Reasoning
- **Authors:** Zhe Yang, Xiaoshuang Sheng, Zhengnan Zhang, Jidong Wu, Zexing Wang, Xin He, Shenghua Xu, Guanjing Xiong
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19107](https://arxiv.org/abs/2512.19107)
- **Reason:** 基于移动UI轨迹的多模态推理框架，实现意图感知推荐，涉及GUI Agent的核心能力，属于多模态智能体研究。
Score: 7
Field: 多模态智能体

## 大模型安全与对齐

### [Score: 8.0/10] EMMA: Concept Erasure Benchmark with Comprehensive Semantic Metrics and Diverse Categories
- **Authors:** Lu Wei (Waseda University), Yuta Nakashima (Waseda University), Noa Garcia (Waseda University)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17320](https://arxiv.org/abs/2512.17320)
- **Reason:** 提出概念擦除基准EMMA，评估模型隐私、偏见等问题，属于大模型安全与对齐中的概念擦除和模型安全研究，为该领域提供全面评估工具。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Adversarial Robustness of Vision in Open Foundation Models
- **Authors:** Jonathon Fox, William J Buchanan, Pavlos Papadopoulos
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17902](https://arxiv.org/abs/2512.17902)
- **Reason:** 评估LLaVA和Llama 3.2 Vision的对抗鲁棒性，发现视觉模态是攻击向量，且对抗鲁棒性与标准基准性能无直接关联，对大模型安全与对齐中的对抗鲁棒性研究有重要意义
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Towards Benchmarking Privacy Vulnerabilities in Selective Forgetting with Large Language Models
- **Authors:** Wei Qian, Chenxu Zhao, Yangyi Li, Mengdi Huai
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18035](https://arxiv.org/abs/2512.18035)
- **Reason:** 构建选择性遗忘的隐私漏洞基准，系统评估LLM的隐私风险，为大模型安全与对齐中的隐私保护提供了标准化工具
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Optimizer Dynamics at the Edge of Stability with Differential Privacy
- **Authors:** Ayana Hussain, Ricky Fang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.19019](https://arxiv.org/abs/2512.19019)
- **Reason:** 分析差分隐私下优化器（GD、Adam）的稳定性动态，揭示隐私噪声对优化“边缘稳定性”的影响，结合了大模型安全（差分隐私）与深度学习理论（优化器机制），为隐私-preserving训练提供理论指导。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Monitoring Monitorability
- **Authors:** Melody Y. Guan, Miles Wang, Micah Carroll, Zehao Dou, Annie Y. Wei, Marcus Williams, Benjamin Arnav, Joost Huizinga, Ian Kivlichan, Mia Glaese, Jakub Pachocki, Bowen Baker
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18311](https://arxiv.org/abs/2512.18311)
- **Reason:** 研究AI系统的可观察性，聚焦链式思维（CoT）监控以检测不当行为，涉及安全部署与模型行为管理，对大模型安全对齐有重要价值。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] MEEA: Mere Exposure Effect-Driven Confrontational Optimization for LLM Jailbreaking
- **Authors:** Jianyi Zhang, Shizhao Liu, Ziyin Zhou, Zhen Li
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18755](https://arxiv.org/abs/2512.18755)
- **Reason:** 基于心理学单纯曝光效应提出LLM越狱攻击框架，评估多轮安全鲁棒性，对大模型安全对齐的防御研究有参考价值。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] Embedded Safety-Aligned Intelligence via Differentiable Internal Alignment Embeddings
- **Authors:** Harsh Rathva, Ojas Srivastava, Pruthwik Mishra
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18309](https://arxiv.org/abs/2512.18309)
- **Reason:** 提出ESAI框架将对齐约束嵌入多Agent的内部表示，通过可微分对齐嵌入实现安全约束，属于大模型安全与对齐的理论框架创新
Score: 7
Field: 大模型安全与对齐

## 大模型新技术

### [Score: 8.0/10] G3Splat: Geometrically Consistent Generalizable Gaussian Splatting
- **Authors:** Mehdi Hosseinzadeh, Shin-Fang Chng, Yi Xu, Simon Lucey, Ian Reid, Ravi Garg
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17547](https://arxiv.org/abs/2512.17547)
- **Reason:** 提出G3Splat模型通过几何先验提升3D Gaussian Splatting的几何一致性与泛化性，属于大模型新技术方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] FlexAvatar: Flexible Large Reconstruction Model for Animatable Gaussian Head Avatars with Detailed Deformation
- **Authors:** Cheng Peng, Zhuo Su, Liao Wang, Chen Guo, Zhaohu Li, Chengjiang Long, Zheng Lv, Jingxiang Sun, Chenyangguang Zhang, Yebin Liu
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17717](https://arxiv.org/abs/2512.17717)
- **Reason:** 提出FlexAvatar模型从单张或稀疏图像重建可动画的3D头像，结合Transformer与UNet解码器，属于大模型新技术方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] InSPECT: Invariant Spectral Features Preservation of Diffusion Models
- **Authors:** Baohua Yan, Qingyuan Liu, Jennifer Kava, Xuan Di
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17873](https://arxiv.org/abs/2512.17873)
- **Reason:** 提出InSPECT扩散模型，通过保留不变谱特征改进生成质量、收敛速度和计算效率，是大模型新技术中扩散模型的基础设计创新
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Is Your Conditional Diffusion Model Actually Denoising?
- **Authors:** Daniel Pfrommer, Zehao Dou, Christopher Scarvelis, Max Simchowitz, Ali Jadbabaie
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18736](https://arxiv.org/abs/2512.18736)
- **Reason:** 质疑条件扩散模型的“实际去噪能力”，提出Schedule Deviation度量并理论证明偏差的内在原因（条件空间的平滑性偏置），对大模型新技术（扩散模型）的核心机制有突破性见解。
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] EMAG: Self-Rectifying Diffusion Sampling with Exponential Moving Average Guidance
- **Authors:** Ankit Yadav (Monash University), Ta Duc Huy (Monash University), Lingqiao Liu (Monash University)
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17303](https://arxiv.org/abs/2512.17303)
- **Reason:** 提出指数移动平均引导的扩散采样策略，改进扩散模型生成质量，属于大模型新技术中的diffusion LLM研究。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] 3D-RE-GEN: 3D Reconstruction of Indoor Scenes with a Generative Framework
- **Authors:** Tobias Sautter, Jan-Niklas Dihlmann, Hendrik P. A. Lensch
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17459](https://arxiv.org/abs/2512.17459)
- **Reason:** 提出生成式框架3D-RE-GEN，整合多领域模型实现室内场景3D重建，提升模型可修改性与真实感，属于大模型新技术方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] 3One2: One-step Regression Plus One-step Diffusion for One-hot Modulation in Dual-path Video Snapshot Compressive Imaging
- **Authors:** Ge Wang, Xing Liu, Xin Yuan
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17578](https://arxiv.org/abs/2512.17578)
- **Reason:** 提出3One2框架结合回归与扩散模型解决视频压缩成像的解耦问题，属于大模型新技术方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Pix2NPHM: Learning to Regress NPHM Reconstructions From a Single Image
- **Authors:** Simon Giebenhain, Tobias Kirschstein, Liam Schoneveld, Davide Davoli, Zhe Chen, Matthias Nie{\ss}ner
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17773](https://arxiv.org/abs/2512.17773)
- **Reason:** 提出Pix2NPHM模型从单张图像回归NPHM参数实现高保真3D头像重建，属于大模型新技术方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Re-Depth Anything: Test-Time Depth Refinement via Self-Supervised Re-lighting
- **Authors:** Ananta R. Bhattarai, Helge Rhodin
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.17908](https://arxiv.org/abs/2512.17908)
- **Reason:** 利用扩散模型的SDS和自监督重光照改进深度估计的测试时精炼，解决了Depth Anything V2在真实场景的域适应问题，属于大模型新技术中的扩散模型应用
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Reflective Confidence: Correcting Reasoning Flaws via Online Self-Correction
- **Authors:** Qinglin Zeng, Jing Yang, Keze Wang
- **Published:** 2025-12-23
- **Link:** [https://arxiv.org/abs/2512.18605](https://arxiv.org/abs/2512.18605)
- **Reason:** 提出反射置信度框架，通过在线自我纠正改善LLM推理错误并减少计算开销，属于大模型推理优化的新技术。
Score: 7
Field: 大模型新技术

