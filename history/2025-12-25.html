<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-25</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>高效大模型训练与推理</a>
<a href='#' >多模态智能体</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >深度学习理论</a>
<a href='#' >大模型新技术</a>
<a href='#' >原生多模态大模型</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-25</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-25 12:41:22</p>
<p>已自动阅读了 192 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：109072</p>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.5/10]</span> Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs</h3>
<p><strong>Authors:</strong> Rui Pan, Zhuofu Chen, Ravi Netravali</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出FailFast框架，用扩散LLM改进speculative decoding的 drafting策略，动态调整推测长度，实现AR LLM的无损加速，对高效大模型训练与推理中的推理效率提升有重大价值
Score: 9.5
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20573' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> HEART-VIT: Hessian-Guided Efficient Dynamic Attention and Token Pruning in Vision Transformer</h3>
<p><strong>Authors:</strong> Mohammad Helal Uddin, Liam Seymour, Sabur Baidya</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 基于Hessian引导的动态注意力与token剪枝优化Vision Transformer，涉及高效模型训练与压缩，贴合高效大模型训练与推理的研究方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20120' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Progressive Learned Image Compression for Machine Perception</h3>
<p><strong>Authors:</strong> Jungwoo Kim, Jun-Hyuk Kim, Jong-Seok Lee</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出渐进式学习图像压缩方法用于机器感知任务，涉及高效压缩技术，贴合高效大模型训练与推理的研究方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20070' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AMoE: Agglomerative Mixture-of-Experts Vision Foundation Model</h3>
<p><strong>Authors:</strong> Sofian Chaybouti, Sanath Narayan, Yasser Dahou, Phúc H. Lê Khac, Ankit Singh, Ngoc Dung Huynh, Wamiq Reyaz Para, Hilde Kuehne, Hakim Hacid</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 基于多教师蒸馏的混合专家视觉基础模型，涉及高效模型训练与MoE架构，贴合高效大模型训练与推理的研究方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20157' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Generative Latent Coding for Ultra-Low Bitrate Image Compression</h3>
<p><strong>Authors:</strong> Zhaoyang Jia, Jiahao Li, Bin Li, Houqiang Li, Yan Lu</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出生成式潜在编码方法用于超低码率图像压缩，涉及高效压缩技术，贴合高效大模型训练与推理的研究方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20194' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FlashVLM: Text-Guided Visual Token Selection for Large Multimodal Models</h3>
<p><strong>Authors:</strong> Kaitong Cai, Jusheng Zhang, Jing Yang, Yijia Fan, Pengtao Xie, Jian Wang, Keze Wang</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出文本引导的视觉token选择框架，减少多模态模型的计算成本，提升推理效率，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20561' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fine-Tuned In-Context Learners for Efficient Adaptation</h3>
<p><strong>Authors:</strong> Jorg Bornschein, Clare Lyle, Yazhe Li, Amal Rannen-Triki, Xu Owen He, Razvan Pascanu</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 结合in-context学习与微调，提升模型在小样本和大样本下的适应效率与性能，对高效大模型训练与推理中的模型适应问题有研究价值
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.19879' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</h3>
<p><strong>Authors:</strong> Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 针对边缘设备VLA模型高推理延迟问题，提出Cross-Request Pipelining策略与Unified KV Ring Buffer优化，实现OpenVLA-7B模型2.55倍FPS提升且无需重训练，对高效大模型推理的边缘部署具重要实践价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20276' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation</h3>
<p><strong>Authors:</strong> Teqiang Zou, Hongliang Zeng, Yuxuan Nong, Yifan Li, Kehui Liu, Haotian Yang, Xinyang Ling, Xin Li, Lianyang Ma</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出异步Fast-Slow VLA框架（DuoCore-FS），通过latent buffer与action tokenizer实现VLM推理与动作生成异步执行，将3B参数VLM推理速度提升至30 Hz，显著提升全身体机器人操纵实时性，对高效大模型推理具重要贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20188' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Thermodynamic Focusing for Inference-Time Search: Practical Methods for Target-Conditioned Sampling and Prompted Inference</h3>
<p><strong>Authors:</strong> Zhan Zhang</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出推理时的目标条件采样优化方法，提升大模型的推理效率与准确性，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.19717' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Per-Axis Weight Deltas for Frequent Model Updates</h3>
<p><strong>Authors:</strong> Stefan Kuyumdzhiev, Radostin Cholakov</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出轴权重delta方法优化模型更新，减少存储与计算成本，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.19720' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EdgeFlex-Transformer: Transformer Inference for Edge Devices</h3>
<p><strong>Authors:</strong> Shoaib Mohammad, Guanqun Song, Ting Zhu</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出边缘设备的Transformer推理优化方法，提升大模型的边缘部署效率，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.19741' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Widget2Code: From Visual Widgets to UI Code via Multimodal LLMs</h3>
<p><strong>Authors:</strong> Houston H. Zhang, Tao Zhang, Baoze Lin, Yuanqi Xue, Yincheng Zhu, Huan Liu, Li Gu, Linfeng Ye, Ziqiang Wang, Xinxin Zuo, Yang Wang, Yuanhao Yu, Zhixiang Chi</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 针对GUI组件提出多模态大模型驱动的UI代码生成方法，涉及GUI Agent与GUI Grounding，贴合多模态智能体的研究方向。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.19918' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LongVideoAgent: Multi-Agent Reasoning with Long Videos</h3>
<p><strong>Authors:</strong> Runtao Liu, Ziyi Liu, Jiaqi Tang, Yue Ma, Renjie Pi, Jipeng Zhang, Qifeng Chen</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出多agent框架处理长视频推理，通过master agent协调grounding与vision agent解决长视频temporal grounding和fine-grained线索缺失问题，在LongTVQA数据集上显著优于非agent基线，为多模态智能体的长视频理解提供有效方案。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.20618' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LoLA: Long Horizon Latent Action Learning for General Robot Manipulation</h3>
<p><strong>Authors:</strong> Xiaofan Wang, Xingyu Gao, Jianlong Fu, Zuolei Li, Dean Fortier, Galen Mullins, Andrey Kolobov, Baining Guo</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出LoLA框架整合多视图观测与机器人proprioception，解决VLA模型长horizon操纵问题，在SIMPLER和LIBERO基准上显著优于现有方法，为多模态智能体的复杂任务推理提供有效解决方案。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.20166' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Active Intelligence in Video Avatars via Closed-loop World Modeling</h3>
<p><strong>Authors:</strong> Xuanhua He, Tianyu Yang, Ke Cao, Ruiqi Wu, Cheng Meng, Yong Zhang, Zhuoliang Kang, Xiaoming Wei, Qifeng Chen</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出闭环世界模型实现视频 avatar的主动智能，提升多模态智能体的自主规划能力，符合多模态智能体方向。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.20615' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting</h3>
<p><strong>Authors:</strong> Sangoh Lee, Sangwoo Mo, Wook-Shin Han</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 针对VLA模型个性化物体操纵问题，提出Visual Attentive Prompting（VAP）方法，通过视觉记忆与指令重写实现instance-level控制，在模拟与真实场景中显著提升正确物体操纵率，为多模态智能体的个性化交互提供新思路。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.20014' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> UbiQVision: Quantifying Uncertainty in XAI for Image Recognition</h3>
<p><strong>Authors:</strong> Akshat Dubey, Aleksandar Anžel, Bahar İlgen, Georges Hattab</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 研究可解释人工智能中的不确定性量化，涉及深度学习可解释性的核心问题，贴合深度学习可解释性的研究方向。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.20288' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Explainable time-series forecasting with sampling-free SHAP for Transformers</h3>
<p><strong>Authors:</strong> Matthias Hertel, Sebastian P\"utz, Ralf Mikut, Veit Hagenmeyer, Benjamin Sch\"afer</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出SHAPformer，通过注意力操纵实现采样-free的SHAP解释，提升Transformer时间序列预测的解释效率与准确性，对深度学习可解释性中的Shapley值应用有重要改进
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.20514' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Deleuzian Representation Hypothesis</h3>
<p><strong>Authors:</strong> Clément Cornet, Romaric Besançon, Hervé Le Borgne</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出基于聚类的可解释概念提取方法，提升模型的可解释性，符合深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.19734' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Concept Generalization in Humans and Large Language Models: Insights from the Number Game</h3>
<p><strong>Authors:</strong> Arghavan Bazigaran, Hansem Sohn</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 通过数字游戏任务对比人类与LLM的概念泛化能力，用贝叶斯模型分析归纳偏置与推理策略差异，揭示LLM依赖数学规则而人类更灵活的泛化机制，为理解LLM概念学习过程提供可解释性 insights。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.20162' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Mitigating LLM Hallucination via Behaviorally Calibrated Reinforcement Learning</h3>
<p><strong>Authors:</strong> Jiayun Wu, Jiashuo Liu, Zhiyuan Zeng, Tianyang Zhan, Wenhao Huang</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出行为校准的强化学习方法，通过优化严格适当评分规则提升LLM的不确定性量化与诚实性，有效减少幻觉，对大模型安全与对齐中的模型诚实性问题有重要价值
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.19920' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LADLE-MM: Limited Annotation based Detector with Learned Ensembles for Multimodal Misinformation</h3>
<p><strong>Authors:</strong> Daniele Cardullo, Simone Teglia, Irene Amerini</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出有限标注的多模态错误信息检测器，涉及大模型安全与错误信息识别，符合大模型安全与对齐的研究方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20257' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hard Negative Sample-Augmented DPO Post-Training for Small Language Models</h3>
<p><strong>Authors:</strong> Haocheng Lu, Minjun Zhu, Henry Yu</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 利用DPO结合难负样本增强小模型的后训练，提升大模型的对齐效果，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.19728' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ArcGen: Generalizing Neural Backdoor Detection Across Diverse Architectures</h3>
<p><strong>Authors:</strong> Zhonghao Yang, Cheng Luo, Daojing He, Yiming Li, Yu Li</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出架构无关的神经后门检测方法，提升大模型的安全性，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.19730' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> How I Met Your Bias: Investigating Bias Amplification in Diffusion Models</h3>
<p><strong>Authors:</strong> Nathan Roos, Ekaterina Iakovleva, Ani Gjergji, Vito Paolo Pastore, Enzo Tartaglione</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 实证分析采样算法与超参数对扩散模型偏见放大的影响，揭示固定模型下偏见的可控性，对大模型安全与对齐中的偏见问题有研究价值
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20233' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Scaling Reinforcement Learning for Content Moderation with Large Language Models</h3>
<p><strong>Authors:</strong> Hamed Firooz, Rui Liu, Yuchen Lu, Zhenyu Hou, Fangzhou Xiong, Xiaoyang Zhang, Changshu Jian, Zhicheng Zhu, Jiayuan Ma, Jacob Tao, Chaitali Gupta, Xiaochang Peng, Shike Mei, Hang Cui, Yang Qin, Shuo Tang, Jason Gaedtke, Arpit Mittal</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 针对大规模内容审核的政策对齐问题，系统研究RL在LLM微调中的应用，提出可验证奖励和LLM-as-judge策略，实现比监督微调高100倍的数据效率，显著提升复杂政策推理性能，对工业级大模型安全与对齐具重要实践意义。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20061' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Offline Safe Policy Optimization From Heterogeneous Feedback</h3>
<p><strong>Authors:</strong> Ze Gong, Pradeep Varakantham, Akshat Kumar</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 针对离线RL的安全对齐问题，提出PreSa框架直接从偏好反馈与安全标签学习安全政策，避免显式奖励/成本模型的误差积累，在连续控制任务中显著优于现有基线，为大模型安全与对齐提供新的离线学习范式。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20173' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Mixture-of-Experts with Gradient Conflict-Driven Subspace Topology Pruning for Emergent Modularity</h3>
<p><strong>Authors:</strong> Yuxing Gan, Ziyu Lei</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出CDSP-MoE框架，用梯度冲突驱动共享子空间的拓扑修剪，解决MoE的结构隔离与过拟合问题，实现 emergent modularity，对深度学习理论中的MoE结构设计有重大创新
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20291' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Saddle-to-Saddle Dynamics Explains A Simplicity Bias Across Neural Network Architectures</h3>
<p><strong>Authors:</strong> Yedi Zhang, Andrew Saxe (Google Brain), Peter E. Latham</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出统一的saddle-to-saddle动力学框架，解释全连接、卷积、注意力等多架构的simplicity bias，揭示梯度下降中模型复杂度递增的底层机制，作者团队在深度学习理论领域具高影响力，结果对理解网络学习动态与架构设计有重要理论价值。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20607' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> Demystifying LLM-as-a-Judge: Analytically Tractable Model for Inference-Time Scaling</h3>
<p><strong>Authors:</strong> Indranil Halder, Cengiz Pehlevan</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出分析LLM-as-a-judge推理时缩放的解析模型，研究泛化误差与推理样本数、奖励设定的关系，对深度学习理论中的推理时计算分析有贡献
Score: 8.5
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.19905' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> Learning to Reason in LLMs by Expectation Maximization</h3>
<p><strong>Authors:</strong> Junghyun Lee, Branislav Kveton, Sunav Choudhary, Subhojyoti Mukherjee, Anup Rao, Ryan A. Rossi, Alexa Siu</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 将LLM推理形式化为 latent变量模型，用期望最大化算法学习推理过程，分析不同采样方案对推理准确性的影响，对深度学习理论中的推理机制学习有贡献
Score: 8.5
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20169' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> Relu and softplus neural nets as zero-sum turn-based games</h3>
<p><strong>Authors:</strong> Stephane Gaubert, Yiannis Vlassopoulos</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 将ReLU与Softplus神经网络解释为零和回合制游戏，推导路径积分公式与Shapley-Bellman递归的联系，对深度学习理论中的网络解释与鲁棒性分析有新视角
Score: 8.5
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20582' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Block-Recurrent Dynamics in Vision Transformers</h3>
<p><strong>Authors:</strong> Mozes Jacobs, Thomas Fel, Richard Hakim, Alessandra Brondetta, Demba Ba, T. Andy Keller</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出Vision Transformers的块循环假设，研究其深度动力学结构与网络架构特性，符合深度学习理论的研究方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.19941' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Exploring Deep-to-Shallow Transformable Neural Networks for Intelligent Embedded Systems</h3>
<p><strong>Authors:</strong> Xiangzhong Luo, Weichen Liu</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出深度可转换为浅层的神经架构搜索方法，属于深度学习理论中的网络架构方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.19731' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> How Many Experts Are Enough? Towards Optimal Semantic Specialization for Mixture-of-Experts</h3>
<p><strong>Authors:</strong> Sumin Park, Noseong Park</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出MoE的语义 specialization优化方法，属于深度学习理论中的网络架构方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.19765' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.5/10]</span> Orthogonal Activation with Implicit Group-Aware Bias Learning for Class Imbalance</h3>
<p><strong>Authors:</strong> Sukumar Kishanthan, Asela Hevapathige</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出正交激活函数结合隐式组感知偏置学习，在嵌入层解决类不平衡问题，提升特征区分性，对深度学习理论中的激活函数与模型结构设计有创新
Score: 7.5
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20006' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Effect of Activation Function and Model Optimizer on the Performance of Human Activity Recognition System Using Various Deep Learning Models</h3>
<p><strong>Authors:</strong> Subrata Kumer Paula, Dewan Nafiul Islam Noora, Rakhi Rani Paula, Md. Ekramul Hamidb, Fahmid Al Faridc, Hezerul Abdul Karimd, Md. Maruf Al Hossain Princee, Abu Saleh Musa Miahb</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 系统研究激活函数与优化器对人体活动识别模型性能的影响，涉及深度学习理论中的优化器与模型设计，符合深度学习理论的研究方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20104' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> High-Performance Self-Supervised Learning by Joint Training of Flow Matching</h3>
<p><strong>Authors:</strong> Kosuke Ukita, Tsuyoshi Okita</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出flow matching联合训练的自监督学习方法，属于深度学习理论方向的创新。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.19729' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.5/10]</span> Control Variate Score Matching for Diffusion Models</h3>
<p><strong>Authors:</strong> Khaled Kahouli, Romuald Elie, Klaus-Robert M\"uller, Quentin Berthet, Oliver T. Unke, Arnaud Doucet</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出控制变量分数匹配框架，统一DSI与TSI估计器，最小化全噪声谱的方差，提升扩散模型的分数估计效率与样本质量，对大模型新技术中的扩散模型改进有贡献
Score: 8.5
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20003' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CoDi -- an exemplar-conditioned diffusion model for low-shot counting</h3>
<p><strong>Authors:</strong> Grega Šuštar, Jer Pelhan, Alan Lukežič, Matej Kristan</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出示例条件扩散模型用于少样本计数任务，涉及扩散模型这一大模型新技术，符合大模型新技术的研究方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20153' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PairFlow: Closed-Form Source-Target Coupling for Few-Step Generation in Discrete Flow Models</h3>
<p><strong>Authors:</strong> Mingue Park, Jisung Hwang, Seungwoo Yoo, Kyeongmin Yeo, Minhyuk Sung</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出PairFlow轻量级预处理步骤，通过闭合形式反转构建源-目标耦合样本，提升离散流模型的少步生成效率，对大模型新技术中的流模型改进有价值
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20063' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Repurposing Video Diffusion Transformers for Robust Point Tracking</h3>
<p><strong>Authors:</strong> Soowon Son, Honggyu An, Chaehyun Kim, Hyunah Ko, Jisu Nam, Dahyun Chung, Siyoon Jin, Jung Yi, Jaewon Min, Junhwa Hur, Seungryong Kim</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 将视频扩散Transformer用于点跟踪任务，拓展扩散模型的应用场景，属于大模型新技术方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20606' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Generating the Past, Present and Future from a Motion-Blurred Image</h3>
<p><strong>Authors:</strong> SaiKiran Tedla, Kelly Zhu, Trevor Canham, Felix Taubner, Michael S. Brown, Kiriakos N. Kutulakos, David B. Lindell</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出利用预训练视频扩散模型从运动模糊图像生成包含过去、现在和未来的视频序列，涉及图像生成与视频理解，贴合原生多模态大模型的研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.19817' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> How Much 3D Do Video Foundation Models Encode?</h3>
<p><strong>Authors:</strong> Zixuan Huang, Xiang Li, Zhaoyang Lv, James M. Rehg</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 系统研究视频基础模型的3D编码能力，涉及多模态大模型与图像理解，符合原生多模态大模型的研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.19949' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Few-Shot-Based Modular Image-to-Video Adapter for Diffusion Models</h3>
<p><strong>Authors:</strong> Zhenhao Li, Shaohan Yi, Zheng Liu, Leonartinus Gao, Minh Ngoc Le, Ambrose Ling, Zhuoran Wang, Md Amirul Islam, Zhixiang Chi, Yuanhao Yu</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出轻量级模块化适配器实现少样本图像到视频生成，涉及扩散模型与多模态转换，贴合原生多模态大模型的研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20000' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LiDARDraft: Generating LiDAR Point Cloud from Versatile Inputs</h3>
<p><strong>Authors:</strong> Haiyun Wei, Fan Lu, Yunwei Zhu, Zehan Zheng, Weiyi Xue, Lin Shao, Xudong Zhang, Ya Wu, Rong Fu, Guang Chen</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 实现从文本、图像等多模态输入生成LiDAR点云，涉及多模态转换与3D生成，贴合原生多模态大模型的研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20105' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DDAVS: Disentangled Audio Semantics and Delayed Bidirectional Alignment for Audio-Visual Segmentation</h3>
<p><strong>Authors:</strong> Jingqi Tian, Yiheng Du, Haoji Zhang, Yuji Wang, Isaac Ning Lee, Xulong Bai, Tianrui Zhu, Jingxuan Niu, Yansong Tang</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出解纠缠音频语义与延迟双向对齐方法实现音视频分割，涉及多模态融合与原生多模态处理，贴合原生多模态大模型的研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20117' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation</h3>
<p><strong>Authors:</strong> Ji-Hoon Kim, Junseok Ahn, Doyeop Kwak, Joon Son Chung, Shinji Watanabe</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 实现文本驱动的音视频交互式对话生成，涉及原生多模态融合与生成，贴合原生多模态大模型的研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20296' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CRAFT: Continuous Reasoning and Agentic Feedback Tuning for Multimodal Text-to-Image Generation</h3>
<p><strong>Authors:</strong> V. Kovalev, A. Kuvshinov, A. Buzovkin, D. Pokidov, D. Timonin</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出连续推理与Agent反馈调优方法优化多模态文本到图像生成，涉及多模态生成与Agent交互，贴合原生多模态大模型的研究方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20362' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UTDesign: A Unified Framework for Stylized Text Editing and Generation in Graphic Design Images</h3>
<p><strong>Authors:</strong> Yiming Zhao, Yuanpeng Gao, Yuxuan Luo, Jiwei Duan, Shisong Lin, Longfei Xiong, Zhouhui Lian</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出统一框架解决图文设计中的文本编辑与生成问题，结合文本与图像的原生多模态生成技术，提升设计效率与质量，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20479' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Learning to Reason in 4D: Dynamic Spatial Understanding for Vision Language Models</h3>
<p><strong>Authors:</strong> Shengchao Zhou, Yuxin Chen, Yuying Ge, Wei Huang, Jiehong Lin, Ying Shan, Xiaojuan Qi</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 针对视觉语言模型的动态空间推理能力提升，构建4D-aware训练资源与模型，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20557' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SpatialTree: How Spatial Abilities Branch Out in MLLMs</h3>
<p><strong>Authors:</strong> Yuxi Xiao, Longfei Li, Shen Yan, Xinhang Liu, Sida Peng, Yunchao Wei, Xiaowei Zhou, Bingyi Kang</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 构建MLLMs的空间能力层次框架，提升多模态大模型的空间理解能力，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20617' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SemanticGen: Video Generation in Semantic Space</h3>
<p><strong>Authors:</strong> Jianhong Bai, Xiaoshi Wu, Xintao Wang, Fu Xiao, Yuanxing Zhang, Qinghe Wang, Xiaoyu Shi, Menghan Xia, Zuozhu Liu, Haoji Hu, Pengfei Wan, Kun Gai</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出语义空间的视频生成方法，提升视频生成的效率与质量，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20619' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</h3>
<p><strong>Authors:</strong> YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出Vision-Language Simulation Model（VLSM），统一视觉布局草图与自然语言指令理解以合成工业仿真代码，构建首个大规模多模态数据集，为原生多模态大模型在工业场景落地提供新思路与基准。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20387' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning to Refocus with Video Diffusion Models</h3>
<p><strong>Authors:</strong> SaiKiran Tedla, Zhoutong Zhang, Xuaner Zhang, Shumian Xin</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 基于视频扩散模型实现单张散焦图像的焦堆栈视频生成，涉及图像生成与多模态融合，符合原生多模态大模型的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.19823' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SE360: Semantic Edit in 360$^\circ$ Panoramas via Hierarchical Data Construction</h3>
<p><strong>Authors:</strong> Haoyi Zhong, Fang-Lue Zhang, Andrew Chalmers, Taehyun Rhee</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 基于分层数据构建与Transformer扩散模型实现360全景图语义编辑，涉及图像生成与理解，贴合原生多模态大模型的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.19943' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieval</h3>
<p><strong>Authors:</strong> Nguyen Lam Phu Quy, Pham Phu Hoa, Tran Chi Nguyen, Dao Sy Duy Minh, Nguyen Hoang Minh Ngoc, Huynh Trung Kiet</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 结合多模态检索增强图像描述的上下文丰富性，涉及图像理解与多模态融合，符合原生多模态大模型的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20042' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UMAMI: Unifying Masked Autoregressive Models and Deterministic Rendering for View Synthesis</h3>
<p><strong>Authors:</strong> Thanh-Tung Le, Tuan Pham, Tung Nguyen, Deying Kong, Xiaohui Xie, Stephan Mandt</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 结合掩码自回归模型与确定性渲染实现视图合成，涉及图像生成与多模态融合，符合原生多模态大模型的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20107' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark</h3>
<p><strong>Authors:</strong> Hao Guo, Xugong Qin, Jun Jie Ou Yang, Peng Zhang, Gangyan Zeng, Yubo Li, Hailun Lin</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 构建自然语言引导的文档图像检索数据集与基准，涉及文本-图像检索与多模态处理，符合原生多模态大模型的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20174' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The devil is in the details: Enhancing Video Virtual Try-On via Keyframe-Driven Details Injection</h3>
<p><strong>Authors:</strong> Qingdong He, Xueqin Chen, Yanjie Pan, Peng Tang, Pengcheng Xu, Zhenye Gan, Chengjie Wang, Xiaobin Hu, Jiangning Zhang, Yabiao Wang</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 基于关键帧细节注入增强视频虚拟试穿效果，涉及视频生成与多模态融合，符合原生多模态大模型的研究方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20340' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Multi-Grained Text-Guided Image Fusion for Multi-Exposure and Multi-Focus Scenarios</h3>
<p><strong>Authors:</strong> Mingwei Tang, Jiahao Nie, Guang Yang, Ziqing Cui, Jie Li</p>
<p><strong>Published:</strong> 2025-12-24</p>
<p><strong>Reason:</strong> 提出多粒度文本引导的图像融合方法，利用视觉语言模型的跨模态对齐提升融合质量，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20556' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>