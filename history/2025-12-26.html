<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-26</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>大模型安全与对齐</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >大模型新技术</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-26</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-26 12:38:47</p>
<p>已自动阅读了 177 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：99527</p>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Beyond Artifacts: Real-Centric Envelope Modeling for Reliable AI-Generated Image Detection</h3>
<p><strong>Authors:</strong> Ruiqi Liu, Yi Han, Zhengbo Zhang, Liwei Yao, Zhiyuan Yan, Jialiang Shen, ZhiJin Chen, Boyi Sun, Lubin Weng, Jing Dong, Yan Wang, Shu Wu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出真实图像中心的检测范式，通过建模真实图像分布边界解决现有方法依赖生成器 artifacts的问题，显著提升真实场景下AI生成图像检测的鲁棒性。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20937' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Efficient and Robust Video Defense Framework against 3D-field Personalized Talking Face</h3>
<p><strong>Authors:</strong> Rui-qing Sun, Xingshan Yao, Tian Lan, Hui-Yang Zhao, Jia-Ling Shi, Chen-Hao Cui, Zhijing Wu, Chen Yang, Xian-Ling Mao</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出高效视频防御框架，通过扰动3D信息采集过程保护肖像视频免受3D生成攻击，平衡防御效果与视频质量，提升大模型隐私安全。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21019' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Turn Toward Better Alignment: Few-Shot Generative Adaptation with Equivariant Feature Rotation</h3>
<p><strong>Authors:</strong> Chenghao Xu, Qi Liu, Jiexi Yan, Muli Yang, Cheng Deng</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出等变特征旋转策略，通过Lie群旋转将源与目标特征对齐到 proxy 空间，解决少样本生成的域 gap 问题，提升生成模型的对齐性能。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21174' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Robustness Certificates for Neural Networks against Adversarial Attacks</h3>
<p><strong>Authors:</strong> Sara Taheri, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Majid Zamani</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出统一框架，通过障碍证书验证神经网络在训练与测试阶段的对抗攻击鲁棒性，提供形式化保证并扩展至PAC边界，是大模型安全与对齐领域的突破性工作
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20865' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Revisiting the Learning Objectives of Vision-Language Reward Models</h3>
<p><strong>Authors:</strong> Simon Roy, Samuel Barbeau, Giovanni Beltrame, Christian Desrosiers, Nicolas Thome</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 在统一框架下重新评估视觉语言奖励模型的学习目标，发现简单三元组损失优于现有复杂方法，为大模型安全与对齐中的奖励模型设计提供重要实证依据
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20675' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Real Time Detection and Quantitative Analysis of Spurious Forgetting in Continual Learning</h3>
<p><strong>Authors:</strong> Weiwei Wang</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出浅/深对齐框架，定量分析持续学习中的虚假遗忘，设计实时检测与自适应缓解策略，有效提高LLM的鲁棒性，属于大模型安全与对齐中的对齐方向核心研究
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20634' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models</h3>
<p><strong>Authors:</strong> Li-Zhong Szu-Tu, Ting-Lin Wu, Chia-Jui Chang, He Syu, Yu-Lun Liu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 揭示视觉语言模型的流行度偏差（著名建筑识别准确率比普通建筑高34%），提出YearGuessr多模态基准并量化偏差，属于大模型安全与对齐中的偏差研究方向
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21337' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bridging Efficiency and Safety: Formal Verification of Neural Networks with Early Exits</h3>
<p><strong>Authors:</strong> Yizhak Yisrael Elboher, Avraham Raviv, Amihay Elboher, Zhouxing Shi, Omri Azencot, Hillel Kugler, Guy Katz</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 针对带提前退出的神经网络提出形式化鲁棒性验证框架，结合效率与安全，通过早期停止与启发式优化将验证速度提升数倍，属于大模型安全与对齐方向
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20755' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Generalization of RLVR Using Causal Reasoning as a Testbed</h3>
<p><strong>Authors:</strong> Brian Lu, Hongyu Zhao, Shuo Sun, Hao Peng, Rui Ding, Hongyuan Mei</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 以因果推理为测试床研究RLVR的泛化能力，发现其在模型具备初始推理能力时优于SFT，为大模型安全与对齐中的RLVR设计提供关键实证支持
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20760' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Defending against adversarial attacks using mixture of experts</h3>
<p><strong>Authors:</strong> Mohammad Meymani, Roozbeh Razavi-Far</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出基于混合专家的对抗防御系统，通过端到端训练专家与门控机制，将模型的对抗鲁棒性提升20%以上，属于大模型安全与对齐方向
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20821' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Time-Efficient Evaluation and Enhancement of Adversarial Robustness in Deep Neural Networks</h3>
<p><strong>Authors:</strong> Runqi Lin</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出时间高效的对抗鲁棒性评估与增强方法，将评估时间缩短50%以上，同时保持鲁棒性提升效果，属于大模型安全与对齐中的鲁棒性研究方向
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.20893' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Latent Implicit Visual Reasoning</h3>
<p><strong>Authors:</strong> Kelvin Li, Chuyi Shang, Leonid Karlinsky, Rogerio Feris, Trevor Darrell, Roei Herzig</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出无监督视觉推理token机制，通过任务自适应视觉重编码解决LMMs依赖语言推理的问题，突破多模态大模型的视觉推理范式。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21218' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VL4Gaze: Unleashing Vision-Language Models for Gaze Following</h3>
<p><strong>Authors:</strong> Shijing Wang, Chaoqun Cui, Yaping Huang, Hyung Jin Chang, Yihua Cheng</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 构建了首个针对视觉语言模型（VLMs）的 gaze 理解基准VL4Gaze，通过多任务监督解锁VLMs的 gaze 语义推理与空间定位能力，推动多模态大模型在视觉注意力任务的落地。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20735' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Benchmarking and Enhancing VLM for Compressed Image Understanding</h3>
<p><strong>Authors:</strong> Zifu Zhang, Tongda Xu, Siqi Li, Shengxi Li, Yue Zhang, Mai Xu, Yan Wang</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 构建首个评估VLMs压缩图像理解能力的基准，分析性能差距并提出通用适配方法，增强多模态大模型对压缩图像的鲁棒性。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20901' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PanoGrounder: Bridging 2D and 3D with Panoramic Scene Representations for VLM-based 3D Visual Grounding</h3>
<p><strong>Authors:</strong> Seongmin Jung, Seongho Choi, Gunwoo Jeon, Minsu Cho, Jongwoo Lim</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出基于全景表示的VLM框架，解决3D视觉接地任务的泛化问题，推动多模态大模型在3D场景理解中的应用。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20907' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> T2AV-Compass: Towards Unified Evaluation for Text-to-Audio-Video Generation</h3>
<p><strong>Authors:</strong> Zhe Cao, Tao Wang, Jiaming Wang, Yanghai Wang, Yuanxing Zhang, Jialu Chen, Miao Deng, Jiahao Wang, Yubin Guo, Chenxi Liao, Yize Zhang, Zhaoxiang Zhang, Jiaheng Liu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 构建首个文本到音视频生成的统一基准，通过双层次评估（客观+主观）揭示现有模型的跨模态对齐与真实感缺陷，为多模态大模型的评估体系奠定基础。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21094' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UniRec-0.1B: Unified Text and Formula Recognition with 0.1B Parameters</h3>
<p><strong>Authors:</strong> Yongkun Du, Zhineng Chen, Yazhen Xie, Weikang Baiand Hao Feng, Wei Shi, Yuchen Su, Can Huang, Yu-Gang Jiang</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出轻量级统一识别模型，通过分层监督与语义解耦tokenizer解决文本与公式的结构变异问题，提升多模态大模型的效率与准确性。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21095' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FreeInpaint: Tuning-free Prompt Alignment and Visual Rationality Enhancement in Image Inpainting</h3>
<p><strong>Authors:</strong> Chao Gong, Dong Li, Yingwei Pan, Jingjing Chen, Ting Yao, Tao Mei</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出无微调的prompt对齐方法，通过先验引导噪声优化与复合引导目标提升文本引导图像修复的合理性，增强多模态大模型的文本生成能力。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21104' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VisRes Bench: On Evaluating the Visual Reasoning Capabilities of VLMs</h3>
<p><strong>Authors:</strong> Brigitta Malagurski Törtei, Yasser Dahou, Ngoc Dung Huynh, Wamiq Reyaz Para, Phúc H. Lê Khac, Ankit Singh, Sofian Chaybouti, Sanath Narayan</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 构建评估VLMs视觉推理能力的基准，通过三个层次任务揭示现有模型的感知与关系推理缺陷，为多模态大模型的推理能力提升提供方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21194' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond Weight Adaptation: Feature-Space Domain Injection for Cross-Modal Ship Re-Identification</h3>
<p><strong>Authors:</strong> Tingfeng Xian, Wenlve Zhou, Zhiheng Zhou, Zhelin Li</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出特征空间域注入策略，解决现有参数高效微调（PEFT）方法在跨模态船舶重识别中的局限性，提升多模态大模型的跨模态适应能力。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.20892' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DreaMontage: Arbitrary Frame-Guided One-Shot Video Generation</h3>
<p><strong>Authors:</strong> Jiawei Liu, Junqiao Li, Jiangfan Deng, Gen Li, Siyu Zhou, Zetao Fang, Shanshan Lao, Zengde Deng, Jianing Zhu, Tingting Ma, Jiayi Li, Yunqiu Wang, Qian He, Xinglong Wu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出任意帧引导的一键式视频生成框架，整合中间条件机制、视觉表达SFT与分段自回归推理，实现高保真长视频生成，匹配原生多模态大模型中的image generation方向
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21252' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision</h3>
<p><strong>Authors:</strong> Weiqi Li, Zehao Zhang, Liang Lin, Guangrun Wang</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 通过注意力监督实现视频扩散模型的直接条件控制，结合3D-aware布局条件与自动标注 pipeline，显著提升条件对齐度与视觉保真度，属于原生多模态大模型中的image generation方向
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21268' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Streaming Video Instruction Tuning</h3>
<p><strong>Authors:</strong> Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出Streamo实时流视频LLM，构建46.5万条指令的Streamo-Instruct数据集，支持多任务流视频理解，匹配原生多模态大模型中的image understanding方向
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21334' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Forward Only Learning for Orthogonal Neural Networks of any Depth</h3>
<p><strong>Authors:</strong> Paul Caillon, Alex Colagrande, Erwan Fagnou, Blaise Delattre, Alexandre Allauzen</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出FOTON框架，实现任意深度正交神经网络的前向-only训练，理论证明其与反向传播的等价性，解决反向传播的计算负担，属于深度学习理论中优化器与网络架构的关键突破
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20668' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Understanding Scaling Laws in Deep Neural Networks via Feature Learning Dynamics</h3>
<p><strong>Authors:</strong> Zihan Yao, Ruoyu Wu, Tianxiang Gao</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 研究深度学习中缩放定律的特征学习动力学机制，解决深度扩展时的性能退化问题，提出深度感知学习率修正方法，对深度学习理论的缩放规律研究有重要意义
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21075' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Analytic and Variational Stability of Deep Learning Systems</h3>
<p><strong>Authors:</strong> Ronald Katende</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出统一的分析和变分框架研究深度学习系统的稳定性，涵盖不同架构与优化方法，推导稳定性定理并解释架构与算法对鲁棒性的影响，对深度学习理论的稳定性分析有重要贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21208' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TrashDet: Iterative Neural Architecture Search for Efficient Waste Detection</h3>
<p><strong>Authors:</strong> Tony Tran, Bin Hu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出迭代式硬件感知神经架构搜索框架，针对TinyML设备优化垃圾检测模型，为神经架构搜索在边缘设备的高效应用提供实践参考。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20746' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PUFM++: Point Cloud Upsampling via Enhanced Flow Matching</h3>
<p><strong>Authors:</strong> Zhi-Song Liu, Chenhang He, Roland Maier, Andreas Rupp</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出增强型流匹配框架，通过两阶段流匹配与自适应时间调度器提升点云上采样的几何 fidelity与鲁棒性，为优化器在3D任务的应用提供新思路。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20988' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations</h3>
<p><strong>Authors:</strong> Jinghan Li, Yang Jin, Hao Jiang, Yadong Mu, Yang Song, Kun Xu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出NExT-Vid框架，利用掩码下一帧预测学习视频自回归表示，提升视觉表示学习性能，为自回归模型在视频任务的应用提供参考。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21004' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Granular-ball Guided Masking: Structure-aware Data Augmentation</h3>
<p><strong>Authors:</strong> Shuyin Xia, Fan Chen, Dawei Dai, Meng Yang, Junwei Han, Xinbo Gao, Guoyin Wang</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出基于颗粒球计算的结构感知数据增强策略，通过粗到细分层掩码保留语义关键区域，提升模型鲁棒性，为数据增强的结构感知理论提供新视角。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21011' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Matrix Completion Via Reweighted Logarithmic Norm Minimization</h3>
<p><strong>Authors:</strong> Zhijie Wang, Liangtian He, Qinghua Zhang, Jifei Miao, Liang-Jian Deng, Jun Liu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出重加权对数范数作为非凸正则项，解决核范数的过收缩问题，提升矩阵补全性能，为优化理论中的正则化方法提供新选择。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21050' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Parameter-Efficient Neural CDEs via Implicit Function Jacobians</h3>
<p><strong>Authors:</strong> Ilya Kuleshov, Alexey Zaytsev</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出参数高效的神经CDE框架，通过隐函数Jacobians减少参数数量（仅需原模型1/10参数），同时保持其连续RNN特性，属于深度学习理论中的网络架构方向
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20625' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Stabilizing Multimodal Autoencoders: A Theoretical and Empirical Analysis of Fusion Strategies</h3>
<p><strong>Authors:</strong> Diyar Altinses, Andreas Schwung</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 理论分析多模态自动编码器的Lipschitz稳定性，提出正则化注意力融合策略，显著提升训练稳定性与性能，属于深度学习理论中的网络架构方向
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20749' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Improving Matrix Exponential for Generative AI Flows: A Taylor-Based Approach Beyond Paterson--Stockmeyer</h3>
<p><strong>Authors:</strong> Jorge Sastre, Daniel Faronbi, Jos\'e Miguel Alonso, Peter Traver, Javier Ib\'a\~nez, Nuria Lloret</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出基于Taylor展开的矩阵指数计算方法，优于经典Paterson--Stockmeyer算法，显著提升生成AI流的效率与稳定性，属于深度学习理论中的优化器方向
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.20777' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Mechanistic Analysis of Transformers for Dynamical Systems</h3>
<p><strong>Authors:</strong> Gregory Duthé, Nikolaos Evangelou, Wei Liu, Ioannis G. Kevrekidis, Eleni Chatzi</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 从动力系统视角分析Transformer的表示能力与局限性，连接empirical观察与经典理论，解释Transformer在不同动力场景下的成败原因，对深度学习理论中Transformer的机制理解有帮助
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21113' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Input-Adaptive Visual Preprocessing for Efficient Fast Vision-Language Model Inference</h3>
<p><strong>Authors:</strong> Putu Indah Githa Cahyani, Komang David Dananjaya Suartana, Novanto Yudistira</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出内容自适应视觉预处理方法，通过动态调整输入分辨率与裁剪减少FastVLM推理冗余，显著提升多模态大模型的部署效率。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20839' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks</h3>
<p><strong>Authors:</strong> Ningyuan Liu, Jing Yang, Kaitong Cai, Keze Wang</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 设计可逆Transformer块，通过重建输入激活消除中间缓存需求，将MoE LLM全参数微调的内存开销显著降低，支持单GPU训练，有效解决高效大模型训练的内存瓶颈
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20920' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GriDiT: Factorized Grid-Based Diffusion for Efficient Long Image Sequence Generation</h3>
<p><strong>Authors:</strong> Snehal Singh Tomar, Alexandros Graikos, Arjun Krishna, Dimitris Samaras, Klaus Mueller</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出分解式网格扩散模型，通过低分辨率粗生成与高分辨率精修实现高效长图像序列生成，在质量与效率上显著优于现有方法，符合高效大模型训练与推理方向
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21276' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming</h3>
<p><strong>Authors:</strong> Haonan Qiu, Shikun Liu, Zijian Zhou, Zhaochong An, Weiming Ren, Zhiheng Liu, Jonas Schult, Sen He, Shoufa Chen, Yuren Cong, Tao Xiang, Ziwei Liu, Juan-Manuel Perez-Rua</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 通过空间、时间与时间步冗余消除，实现高效高分辨率视频生成，在1080p基准上比基线快76.2倍，是高效大模型训练与推理方向的重要突破
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21338' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PHOTON: Hierarchical Autoregressive Modeling for Lightspeed and Memory-Efficient Language Generation</h3>
<p><strong>Authors:</strong> Yuma Ichikawa, Naoya Takagi, Takumi Nakagawa, Yuzi Kanazawa, Akira Sakai</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出分层自回归模型，通过多分辨率上下文访问减少KV缓存流量，实现内存高效语言生成，比Transformer快1000倍，是高效大模型训练与推理方向的颠覆性工作
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20687' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Memory-Efficient Acceleration of Block Low-Rank Foundation Models on Resource Constrained GPUs</h3>
<p><strong>Authors:</strong> Pierre Abillama, Changwoo Lee, Juechu Dong, David Blaauw, Dennis Sylvester, Hun-Seok Kim</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 针对块低秩基础模型设计自定义Triton内核，在资源受限GPU（如Jetson Orin Nano）上实现3.76倍加速与3倍模型压缩，符合高效大模型训练与推理方向
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20861' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Data-Free Pruning of Self-Attention Layers in LLMs</h3>
<p><strong>Authors:</strong> Dhananjay Saikumar, Blesson Varghese</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出Gate-Norm标准，无需数据、微调或正向传递即可剪枝LLM自注意力层，在保持98%精度的同时实现1.3倍推理加速，符合高效大模型推理的核心需求
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20636' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Fast SAM2 with Text-Driven Token Pruning</h3>
<p><strong>Authors:</strong> Avilasha Mandal, Chaoning Zhang, Fachrina Dewi Puspitasari, Xudong Wang, Jiaquan Zhang, Caiyan Qin, Guoqing Wang, Yang Yang, Heng Tao Shen</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出文本引导的token剪枝框架，通过轻量级路由机制筛选关键token，将SAM2的推理速度提升42.5%、内存占用降低37.4%，同时保持分割精度，符合高效大模型推理方向
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FedMPDD: Communication-Efficient Federated Learning with Privacy Preservation Attributes via Projected Directional Derivative</h3>
<p><strong>Authors:</strong> Mohammadreza Rostami, Solmaz S. Kia</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 通过投影方向导数将联邦学习的通信成本从O(d)降至O(m)（m≪d），同时保持收敛率与隐私性，属于高效大模型训练与推理中的联邦学习方向
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20814' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Model Merging via Multi-Teacher Knowledge Distillation</h3>
<p><strong>Authors:</strong> Seyed Arshan Dalili, Mehrdad Mahdavi</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 针对模型合并的泛化问题提出PAC-Bayes边界，将模型合并转化为多教师知识蒸馏并结合Sharpness-Aware Minimization，提升合并模型性能，对高效大模型训练有实践价值
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21288' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</h3>
<p><strong>Authors:</strong> Yuntao Dai, Hang Gu, Teng Wang, Qianyu Cheng, Yifei Zheng, Zhiyong Qiu, Lei Gong, Wenqi Lou, Xuehai Zhou</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出Cross-Request Pipelining策略优化边缘设备上视觉语言模型的推理延迟，实现2.55倍FPS提升，解决实时交互的 latency 问题，对大模型高效推理有实际意义
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.20276' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Self-supervised Multiplex Consensus Mamba for General Image Fusion</h3>
<p><strong>Authors:</strong> Yingying Wang, Rongjin Zhuang, Hui Zheng, Xuanhua He, Ke Cao, Xiaotong Tu, Xinghao Ding</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出基于Mamba的自监督图像融合框架，通过多专家共识与跨模态扫描提升融合性能，推动Mamba在多模态任务的创新应用。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20921' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FluencyVE: Marrying Temporal-Aware Mamba with Bypass Attention for Video Editing</h3>
<p><strong>Authors:</strong> Mingshu Cai, Yixuan Li, Osamu Yoshie, Yuya Ieiri</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 将Mamba整合到视频编辑模型中替换时序注意力层，提升视频编辑的时间一致性与推理效率，推动Mamba在视频任务的创新应用。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21015' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UltraShape 1.0: High-Fidelity 3D Shape Generation via Scalable Geometric Refinement</h3>
<p><strong>Authors:</strong> Tanghui Jia, Dongyu Yan, Dehao Hao, Yang Li, Kaiyi Zhang, Xianyi He, Lanjiong Li, Jinnan Chen, Lutao Jiang, Qishen Yin, Long Quan, Ying-Cong Chen, Li Yuan</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 提出两阶段3D扩散框架，通过数据预处理提升训练数据质量，结合voxel-based细化解决3D形状生成的细节问题，推动大模型新技术在3D任务的应用。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21185' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Generalization of Diffusion Models Arises with a Balanced Representation Space</h3>
<p><strong>Authors:</strong> Zekai Zhang, Xiao Li, Xiang Li, Lianghe Shi, Meng Wu, Molei Tao, Qing Qu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 分析扩散模型泛化与记忆的表示空间机制，提出表示引导的记忆检测和编辑方法，对扩散模型的理论理解与实际应用有重要贡献
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20963' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Dominating vs. Dominated: Generative Collapse in Diffusion Models</h3>
<p><strong>Authors:</strong> Hayeon Jeong, Jong-Seok Lee</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 首次系统分析扩散模型的生成崩溃现象（DvD不平衡），提出DominanceBench基准并揭示其数据与架构成因，为diffusion模型的可控生成研究提供关键洞见，属于大模型新技术方向
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20666' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> DiEC: Diffusion Embedded Clustering</h3>
<p><strong>Authors:</strong> Haidong Hu</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 利用预训练扩散U-Net的内部激活进行无监督聚类，通过层与时间步搜索优化表示，实现比传统方法高10%的聚类准确率，属于大模型新技术中的diffusion应用方向
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.20905' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AndroidLens: Long-latency Evaluation with Nested Sub-targets for Android GUI Agents</h3>
<p><strong>Authors:</strong> Yue Cao, Yingyao Wang, Pi Bu, Jingxuan Xing, Wei Jiang, Zekun Zhu, Junpeng Ma, Sashuai Zhou, Tong Lu, Jun Song, Yu Cheng, Yuning Jiang, Bo Zheng</p>
<p><strong>Published:</strong> 2025-12-25</p>
<p><strong>Reason:</strong> 针对Android GUI智能体的长延迟任务评估框架，构建含571个跨38领域任务的基准，解决现有基准在应用覆盖、任务复杂度和评估粒度上的局限性，高度匹配多模态智能体研究方向
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.21302' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>