# ArXiv 每日推荐 - 2025-12-27

> 更新于北京时间：2025-12-27 12:29:34
> 已自动阅读了 31 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：21679

## 深度学习理论

### [Score: 9.0/10] Mixture of Attention Schemes (MoAS): Learning to Route Between MHA, GQA, and MQA
- **Authors:** Esmail Gumaan
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20650](https://arxiv.org/abs/2512.20650)
- **Reason:** 提出动态选择注意力机制（MHA/GQA/MQA）的混合架构，通过学习路由器优化建模质量与推理效率的权衡，实验验证动态路由优于静态混合，属于深度学习理论中的网络架构改进方向。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] From Fake Focus to Real Precision: Confusion-Driven Adversarial Attention Learning in Transformers
- **Authors:** Yawei Liu
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20661](https://arxiv.org/abs/2512.20661)
- **Reason:** 提出对抗性注意力反馈机制，通过动态 masking 策略与判别器博弈，引导模型重新分配注意力权重至任务相关词，解决Transformer过度关注常见词的问题，属于深度学习理论中的注意力机制改进方向。
Score: 8
Field: 深度学习理论

## 大模型安全与对齐

### [Score: 9.0/10] Safety Alignment of LMs via Non-cooperative Games
- **Authors:** Anselm Paulus, Ilia Kulikov, Brandon Amos, R\'emi Munos, Ivan Evtimov, Kamalika Chaudhuri, Arman Zharmagambetov
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20806](https://arxiv.org/abs/2512.20806)
- **Reason:** 将语言模型的安全对齐建模为攻击者-防御者的非合作游戏，通过在线强化学习联合训练，提升防御模型的有用性与抗攻击能力，属于大模型安全与对齐中的对齐方法方向。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] MicroProbe: Efficient Reliability Assessment for Foundation Models with Minimal Data
- **Authors:** Aayam Bansal, Ishaan Gangwani
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20630](https://arxiv.org/abs/2512.20630)
- **Reason:** 提出仅用100个策略选择的探针样本实现基础模型可靠性评估的方法，结合提示多样性、不确定性量化和自适应加权，解决传统评估数据量大、成本高的问题，属于大模型安全与对齐中的可靠性评估方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] A Benchmark for Evaluating Outcome-Driven Constraint Violations in Autonomous AI Agents
- **Authors:** Miles Q. Li, Benjamin C. M. Fung, Martin Weiss, Pulei Xiong, Khalil Al-Hussaeni, Claude Fachkha
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20798](https://arxiv.org/abs/2512.20798)
- **Reason:** 提出评估自主AI智能体结果驱动约束违反的基准，包含40个多步骤场景，分析12个SOTA LLM的违反率，揭示推理能力与安全性的非正相关关系，属于大模型安全与对齐中的对齐评估方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Beyond Context: Large Language Models Failure to Grasp Users Intent
- **Authors:** Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.21110](https://arxiv.org/abs/2512.21110)
- **Reason:** 实证分析ChatGPT、Claude等SOTA LLM无法理解用户意图的安全漏洞，揭示情感框架、渐进式披露等攻击方法的有效性，指出当前安全机制忽视意图理解的局限性，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] Reasoning Relay: Evaluating Stability and Interchangeability of Large Language Models in Mathematical Reasoning
- **Authors:** Leo Lu, Jonathan Zhang, Sean Chua, Spencer Kim, Kevin Zhu, Sean O'Brien, Vasu Sharma
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20647](https://arxiv.org/abs/2512.20647)
- **Reason:** 研究不同LLM之间推理链的互换性，通过截断基线模型推理链并让其他模型继续，评估推理的稳定性与连贯性，涉及LLM推理的trustworthiness，属于大模型安全与对齐方向。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] AIAuditTrack: A Framework for AI Security system
- **Authors:** Zixun Luo, Yuhang Fan, Yufei Li, Youzhi Zhang, Hengyu Lin, Ziqi Wang
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20649](https://arxiv.org/abs/2512.20649)
- **Reason:** 提出基于区块链的AI安全框架，利用DID和VC建立可信AI实体，通过链上记录交互轨迹实现跨系统监督与审计，并设计风险扩散算法溯源危险行为，属于大模型安全与对齐中的安全治理方向。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Bridging the AI Trustworthiness Gap between Functions and Norms
- **Authors:** Daan Di Scala, Sophie Lathouwers, Michael van Bekkum
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20671](https://arxiv.org/abs/2512.20671)
- **Reason:** 分析功能型AI（FTAI）与规范型AI（NTAI）之间的可信度差距，提出语义语言作为桥梁，帮助开发者将规范转化为具体实现，属于大模型安全与对齐中的可信度评估方向。
Score: 7
Field: 大模型安全与对齐

## 深度学习可解释性

### [Score: 9.0/10] Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation
- **Authors:** Tomoaki Yamaguchi, Yutong Zhou, Masahiro Ryo, Keisuke Katsura
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.21066](https://arxiv.org/abs/2512.21066)
- **Reason:** 提出结合SHAP可解释性与多模态LLM迭代优化的Agentic XAI框架，通过11轮细化提升解释的特异性、清晰性等指标，验证其在农业推荐系统中的有效性，属于深度学习可解释性方向。
Score: 9
Field: 深度学习可解释性

## 高效大模型训练与推理

### [Score: 8.0/10] BitRL-Light: 1-bit LLM Agents with Deep Reinforcement Learning for Energy-Efficient Smart Home Lighting Optimization
- **Authors:** Ravi Gupta, Shabista Haider
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20623](https://arxiv.org/abs/2512.20623)
- **Reason:** 提出1-bit量化大语言模型与深度Q网络结合的框架，用于边缘设备智能家庭照明控制，实现71.4倍能耗降低和32%节能，同时保持92%任务准确率，属于高效大模型训练与推理中的模型压缩方向。
Score: 8
Field: 高效大模型训练与推理

## 原生多模态大模型

### [Score: 8.0/10] MegaRAG: Multimodal Knowledge Graph-Based Retrieval Augmented Generation
- **Authors:** Chi-Hsiang Hsiao, Yi-Cheng Wang, Tzung-Sheng Lin, Yi-Ren Yeh, Chu-Song Chen
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.20626](https://arxiv.org/abs/2512.20626)
- **Reason:** 提出结合多模态知识图谱的检索增强生成框架，将视觉线索整合到知识图谱构建、检索和生成过程，解决传统RAG仅处理文本的局限，提升多模态内容理解与推理能力，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

## 多模态智能体

### [Score: 8.0/10] RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic
- **Authors:** Le Wang, Zonghao Ying, Xiao Yang, Quanchen Zou, Zhenfei Yin, Tianlin Li, Jian Yang, Yaodong Yang, Aishan Liu, Xianglong Liu
- **Published:** 2025-12-26
- **Link:** [https://arxiv.org/abs/2512.21220](https://arxiv.org/abs/2512.21220)
- **Reason:** 提出基于混合推理（反向反射推理+正向预测推理）的安全框架，保护视觉语言模型驱动的具身智能体，减少危险行为，实验验证其在物理机器人上的实用性，属于多模态智能体方向。
Score: 8
Field: 多模态智能体

