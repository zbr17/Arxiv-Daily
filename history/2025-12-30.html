<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-12-30</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>深度学习理论</a>
<a href='#' >多模态智能体</a>
<a href='#' >大模型新技术</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >深度学习可解释性</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-12-30</h1>
<div class='meta-info'><p>更新于北京时间：2025-12-30 12:42:11</p>
<p>已自动阅读了 175 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：96418</p>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Vision Transformers are Circulant Attention Learners</h3>
<p><strong>Authors:</strong> Dongchen Han, Tianyu Li, Ziyi Wang, Gao Huang (Tsinghua University)</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 发现ViT自注意力矩阵的循环特性，提出循环注意力机制将复杂度降至O(NlogN)，作者Gao Huang具有高影响力，属于深度学习理论中的网络架构创新。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21542' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Unifying Learning Dynamics and Generalization in Transformers Scaling Law</h3>
<p><strong>Authors:</strong> Chiwun Yang ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 将Transformer学习动态形式化为ODE系统，分析SGD训练的泛化误差，统一缩放律的理论基础，深化对大模型学习机制的理解。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.22088' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Analyzing the Mechanism of Attention Collapse in VGGT from a Dynamics Perspective</h3>
<p><strong>Authors:</strong> Huan Li, Longjun Luo, Yuling Shi, Xiaodong Gu</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 从动力学角度分析VGGT中注意力崩溃机制，属于深度学习理论中的注意力机制研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21691' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> An Equivariance Toolbox for Learning Dynamics</h3>
<p><strong>Authors:</strong> Yongyi Yang, Liu Ziyin</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 开发通用的equivariance工具箱，研究学习动态的一阶和二阶约束，连接变换结构与优化几何，对深度学习理论研究有贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21447' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Scalable Deep Subspace Clustering Network</h3>
<p><strong>Authors:</strong> Nairouz Mrabah, Mohamed Bouguessa, Sihem Sami</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出SDSNet解决传统子空间聚类的高复杂度问题，通过地标近似、联合优化自编码器与自表达目标提升效率，属于深度学习理论中的网络架构设计。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21434' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CausalFSFG: Rethinking Few-Shot Fine-Grained Visual Categorization from Causal Perspective</h3>
<p><strong>Authors:</strong> Zhiwen Yang, Jinglin Xu, Yuxin Pen</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 从因果视角改进少样本细粒度分类，消除虚假相关性，属于深度学习理论中的泛化机制研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21617' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Spatiotemporal-Untrammelled Mixture of Experts for Multi-Person Motion Prediction</h3>
<p><strong>Authors:</strong> Zheng Yin, Chengjian Li, Xiangbo Shu, Meiqi Cao, Rui Yan, Jinhui Tang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出ST-MoE通过混合专家模型捕捉时空依赖，属于深度学习理论中的网络架构（MoE）创新。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21707' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization</h3>
<p><strong>Authors:</strong> Evgeny Alves Limarenko, Anastasiia Studenikina</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 改进3D掩码自编码器的拓扑稀疏性，属于深度学习理论中的网络架构（3D MAE）创新。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21769' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Approximation Capabilities of Feedforward Neural Networks with GELU Activations</h3>
<p><strong>Authors:</strong> Konstantin Yakovlev (), Nikita Puchkin ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 推导GELU激活的前馈神经网络对函数及其高阶导数的逼近误差界，深化了深度学习理论中激活函数逼近能力的理解。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.21749' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Why Smooth Stability Assumptions Fail for ReLU Learning</h3>
<p><strong>Authors:</strong> Ronald Katende ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 指出ReLU网络的光滑稳定性假设不成立，通过具体反例分析并提出广义导数条件，推进深度学习理论中稳定性分析的研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2512.22055' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MAI-UI Technical Report: Real-World Centric Foundation GUI Agents</h3>
<p><strong>Authors:</strong> Hanzhang Zhou, Xu Zhang, Panrong Tong, Jianan Zhang, Liangyu Chen, Quyu Kong, Chenglin Cai, Chen Liu, Yue Wang, Jingren Zhou, Steven Hoi</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出MAI-UI系列基础GUI代理，解决真实部署的四大挑战，实验验证在GUI grounding和导航任务上的SOTA性能，对多模态智能体实际应用有重要价值。
Score: 9
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.22047' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TrackTeller: Temporal Multimodal 3D Grounding for Behavior-Dependent Object References</h3>
<p><strong>Authors:</strong> Jiahong Yu, Ziqi Wang, Hailiang Zhao, Wei Zhai, Xueqiang Yan, Shuiguang Deng</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出TrackTeller框架解决动态3D场景中的目标grounding问题，属于多模态智能体中的GUI grounding方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.21641' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AstraNav-World: World Model for Foresight Control and Consistency</h3>
<p><strong>Authors:</strong> Junjun Hu, Jintao Chen, Haochen Bai, Minghua Luo, Shichao Xie, Ziyi Chen, Fei Liu, Zedong Chu, Xinda Xue, Botao Ren, Xiaolong Wu, Mu Xu, Shanghang Zhang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出统一远见控制与一致性的世界模型，用于具身导航，属于多模态智能体中的GUI navigation方向。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.21714' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> iSHIFT: Lightweight Slow-Fast GUI Agent with Adaptive Perception</h3>
<p><strong>Authors:</strong> Sarthak Mehrotra, Sairam V C Rebbapragada, Mani Hemanth Reddy Bonthu, Vineeth N Balasubramanian</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对GUI代理的效率与精度平衡问题，提出轻量级慢-快框架iSHIFT，提升任务处理效率和精度，对多模态智能体研究有价值。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2512.22009' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> dUltra: Ultra-Fast Diffusion Language Models via Reinforcement Learning</h3>
<p><strong>Authors:</strong> Shirui Chen, Jiantao Jiao, Lillian J. Ratliff, Banghua Zhu</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对扩散语言模型的推理速度问题，提出RL-based框架dUltra优化unmasking策略，对diffusion LLM这一大模型新技术的高效推理有重要贡献。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21446' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DiverseGRPO: Mitigating Mode Collapse in Image Generation via Diversity-Aware GRPO</h3>
<p><strong>Authors:</strong> Henglin Liu, Huijuan Huang, Jing Wang, Chang Liu, Xiu Li, Xiangyang Ji</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对扩散模型模式崩溃问题，引入分布级创造力奖励和结构感知正则化，提升生成多样性，属于大模型新技术中的扩散模型改进方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21514' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Knot Forcing: Taming Autoregressive Video Diffusion Models for Real-time Infinite Interactive Portrait Animation</h3>
<p><strong>Authors:</strong> Steven Xiao, Xindi Zhang, Dechao Meng, Qi Wang, Peng Zhang, Bang Zhang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 改进自回归视频扩散模型实现实时肖像动画，属于大模型新技术中的diffusion LLM方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21734' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation</h3>
<p><strong>Authors:</strong> Jinqi Xiao, Qing Yan, Liming Jiang, Zichuan Liu, Hao Kang, Shen Sang, Tiancheng Zhi, Jing Liu, Cheng Yang, Xin Lu, Bo Yuan</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出指令引导的混合低秩专家模型实现多条件图像生成，属于大模型新技术中的指令引导生成方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21788' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Flexible Multitask Learning with Factorized Diffusion Policy</h3>
<p><strong>Authors:</strong> Chaoqi Liu, Haonan Chen, Sigmund H. H{\o}eg, Shaoxiong Yao, Yunzhu Li, Kris Hauser, Yilun Du</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出分解扩散策略的多任务学习框架，属于扩散模型新应用，符合大模型新技术方向。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21898' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Training-Free Disentangled Text-Guided Image Editing via Sparse Latent Constraints</h3>
<p><strong>Authors:</strong> Mutiara Shabrina, Nova Kurnia Putri, Jefri Satria Ferdiansyah, Sabita Khansa Dewi, Novanto Yudistira</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出稀疏潜在约束的无训练文本引导图像编辑方法，改进语义泄漏问题，属于大模型新技术中的图像编辑方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21637' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ShinyNeRF: Digitizing Anisotropic Appearance in Neural Radiance Fields</h3>
<p><strong>Authors:</strong> Albert Barreiro, Roger Mar\'i, Rafael Redondo, Gloria Haro, Carles Bosch</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 改进NeRF的各向异性反射建模，属于大模型新技术中的3D生成方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21692' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Inference-based GAN Video Generation</h3>
<p><strong>Authors:</strong> Jingbo Yang, Adrian G. Bors</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出推理式GAN视频生成模型，属于大模型新技术中的GAN生成方向。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2512.21776' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> A Comedy of Estimators: On KL Regularization in RL Training of LLMs</h3>
<p><strong>Authors:</strong> Vedant Shah (), Johan Obando-Ceron (), Vineet Jain (), Brian Bartoldson (), Bhavya Kailkhura (), Sarthak Mittal (), Glen Berseth (), Pablo Samuel Castro (), Yoshua Bengio (), Nikolay Malkin (), Moksh Jain (), Siddarth Venkatraman (), Aaron Courville ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 系统分析RL训练LLM中KL正则化估计器的梯度偏差问题，揭示其对下游性能的影响，为大模型安全对齐的RL训练提供改进方向。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21852' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Shallow Humor to Metaphor: Towards Label-Free Harmful Meme Detection via LMM Agent Self-Improvement</h3>
<p><strong>Authors:</strong> Jian Lang, Rongpei Hong, Ting Zhong, Leiting Chen, Qiang Gao, Fan Zhou</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出无标签有害meme检测框架ALARM，通过LMM智能体自改进提升适应性，属于大模型安全与对齐中的有害内容检测领域。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21598' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models</h3>
<p><strong>Authors:</strong> Mengqi He, Xinyu Tian, Xin Shen, Jinhong Ni, Shu Zou, Zhaoyuan Yang, Jing Zhang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 研究视觉语言模型（VLMs）的对抗攻击，发现高熵token（约20%）主导生成轨迹，提出的EGA攻击暴露了VLM安全机制的弱点，对大模型安全研究有重要价值。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21815' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Look Closer! An Adversarial Parametric Editing Framework for Hallucination Mitigation in VLMs</h3>
<p><strong>Authors:</strong> Jiayu Hu, Beibei Li, Jiangwei Xia, Yanjun Qin, Bing Ji, Zhongshi He</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对VLMs的幻觉问题，提出ALEAHallu框架通过对抗性参数编辑减少幻觉，实验验证在生成和判别任务上的有效性，对大模型安全对齐研究有贡献。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21999' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models</h3>
<p><strong>Authors:</strong> Zongmin Zhang, Zhen Sun, Yifan Liao, Wenhan Dong, Xinlei He, Xingshuo Han, Shengmin Xu, Xinyi Huang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 研究prompt-driven视频分割基础模型的后门攻击，提出BadVSFM两阶段策略提升后门效果，对大模型安全研究有价值。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.22046' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets</h3>
<p><strong>Authors:</strong> Matyas Bohacek, Ignacio Vilanova Echavarri</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出生成AI数据集的合规性评级框架，解决数据集的伦理、法律与透明度问题，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21775' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Exploration of Reproducible Generated Image Detection</h3>
<p><strong>Authors:</strong> Yihang Duan</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 研究AI生成图像检测的可重复性问题，分析现有方法局限性，属于大模型安全与对齐中的Deepfake检测领域。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21562' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FUSE: Unifying Spectral and Semantic Cues for Robust AI-Generated Image Detection</h3>
<p><strong>Authors:</strong> Md. Zahid Hossain, Most. Sharmin Sultana Samu, Md. Kamrozzaman Bhuiyan, Farhad Uz Zaman, Md. Rakibul Islam</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 融合光谱与语义特征提升AI生成图像检测鲁棒性，属于大模型安全与对齐中的Deepfake检测领域。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2512.21695' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SVBench: Evaluation of Video Generation Models on Social Reasoning</h3>
<p><strong>Authors:</strong> Wenshuo Peng, Gongxuan Wang, Tianmeng Yang, Chuanhao Li, Xiaojie Xu, Hui He, Kaipeng Zhang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 构建首个视频生成社会推理基准，评估模型社会认知能力，涉及视频生成与多模态推理，属于原生多模态大模型中的图像生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21507' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EraseLoRA: MLLM-Driven Foreground Exclusion and Background Subtype Aggregation for Dataset-Free Object Removal</h3>
<p><strong>Authors:</strong> Sanghyun Jo, Donghwan Lee, Eunji Jung, Seong Je Oh, Kyungsu Kim</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出MLLM驱动的无数据集目标移除框架，提升目标移除准确性与背景一致性，属于原生多模态大模型中的图像编辑与生成方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21545' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TAMEing Long Contexts in Personalization: Towards Training-Free and State-Aware MLLM Personalized Assistant</h3>
<p><strong>Authors:</strong> Rongpei Hong, Jian Lang, Ting Zhong, Yong Wang, Fan Zhou</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出长上下文MLLM个性化基准LCMP和TAME框架，属于原生多模态大模型中的个性化与长上下文处理方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21616' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Omni-Weather: Unified Multimodal Foundation Model for Weather Generation and Understanding</h3>
<p><strong>Authors:</strong> Zhiwang Zhou, Yuandong Pu, Xuming He, Yidi Liu, Yixin Chen, Junchao Gong, Xiang Zhuang, Wanghan Xu, Qinglong Cao, Shixiang Tang, Yihao Liu, Wenlong Zhang, Lei Bai</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出统一天气生成与理解的多模态基础模型，属于原生多模态大模型中的多模态基础模型方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21643' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UniPercept: Towards Unified Perceptual-Level Image Understanding across Aesthetics, Quality, Structure, and Texture</h3>
<p><strong>Authors:</strong> Shuo Cao, Jiayang Li, Xiaohui Li, Yuandong Pu, Kaiwen Zhu, Yuanting Gao, Siqi Luo, Yi Xin, Qi Qin, Yu Zhou, Xiangyu Chen, Wenlong Zhang, Bin Fu, Yu Qiao, Yihao Liu</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出统一感知级图像理解框架，构建基准和基线模型，属于原生多模态大模型中的图像理解方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21675' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Scene-VLM: Multimodal Video Scene Segmentation via Vision-Language Models</h3>
<p><strong>Authors:</strong> Nimrod Berman, Adam Botach, Emanuel Ben-Baruch, Shunit Haviv Hakimi, Asaf Gendler, Ilan Naiman, Erez Yosef, Igor Kviatkovsky</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 用视觉语言模型进行视频场景分割，属于原生多模态大模型中的视频理解方向。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21778' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> See Less, See Right: Bi-directional Perceptual Shaping For Multimodal Reasoning</h3>
<p><strong>Authors:</strong> Shuoshuo Zhang, Yizhen Zhang, Jingjing Fu, Lei Song, Jiang Bian, Yujiu Yang, Rui Wang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对VLMs的视觉依赖不足和跨域泛化差的问题，提出BiPS双向感知塑造方法提升多模态推理性能，对原生多模态大模型研究有贡献。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.22120' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GQ-VAE: A gated quantized VAE for learning variable length tokens</h3>
<p><strong>Authors:</strong> Theo Datta (), Kayla Huang (), Sham Kakade (), David Brandfonbrener ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出GQ-VAE作为可预训练的tokenizer，学习可变长度离散token，提升压缩率和语言建模性能，对原生多模态大模型的tokenization技术有贡献。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21913' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Hierarchy-Aware Fine-Tuning of Vision-Language Models</h3>
<p><strong>Authors:</strong> Jiayu Li, Rajesh Gangireddy, Samet Akcay, Wei Cheng, Juhua Hu</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出层级感知微调框架解决VLMs层级分类不一致问题，属于原生多模态大模型中的模型适应与优化方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21529' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SyncAnyone: Implicit Disentanglement via Progressive Self-Correction for Lip-Syncing in the wild</h3>
<p><strong>Authors:</strong> Xindi Zhang, Dechao Meng, Steven Xiao, Qi Wang, Peng Zhang, Bang Zhang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出两阶段学习实现野生环境下唇同步，属于原生多模态大模型中的音频-视觉同步与生成方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21736' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EVE: A Generator-Verifier System for Generative Policies</h3>
<p><strong>Authors:</strong> Yusuf Ali, Gryphon Patlin, Karthik Kothuri, Muhammad Zubair Irshad, Wuwei Liang, Zsolt Kira</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出生成式策略的generator-verifier框架，用零样本VLM作为验证器提升性能，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21430' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> StereoVLA: Enhancing Vision-Language-Action Models with Stereo Vision</h3>
<p><strong>Authors:</strong> Shengliang Deng, Mi Yan, Yixin Zheng, Jiayi Su, Wenhao Zhang, Xiaoguang Zhao, Heming Cui, Zhizheng Zhang, He Wang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 用立体视觉增强VLA模型，结合几何与语义特征，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2512.21970' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards Long-window Anchoring in Vision-Language Model Distillation</h3>
<p><strong>Authors:</strong> Haoyi Zhou, Shuo Li, Tianyu Chen, Qi Song, Chonghan Gao, Jianxin Li</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出LAid框架将大模型长上下文能力蒸馏到小模型，属于高效大模型训练与推理中的知识蒸馏方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21576' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RAPTOR: Real-Time High-Resolution UAV Video Prediction with Efficient Video Attention</h3>
<p><strong>Authors:</strong> Zhan Chen, Zile Guo, Enze Zhu, Peirong Zhang, Xiaoxuan Liu, Lei Wang, Yidan Zhang</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出高效视频注意力实现实时高分辨率无人机视频预测，属于高效大模型训练与推理中的高效推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21710' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees</h3>
<p><strong>Authors:</strong> Haodong Lei, Hongsong Wang, Xin Geng, Liang Wang, Pan Zhou</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对视觉自回归模型的sequential inference慢的问题，提出ADT-Tree动态调整draft树的深度和宽度，显著提升推理速度，对高效大模型推理研究有贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21857' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DPAR: Dynamic Patchification for Efficient Autoregressive Visual Generation</h3>
<p><strong>Authors:</strong> Divyansh Srivastava, Akshay Mehra, Pranav Maneriker, Debopam Sanyal, Vishnu Raj, Vijay Kamarshi, Fan Du, Joshua Kimball</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对自回归图像生成中token计数随分辨率二次增长的问题，提出DPAR动态聚合token成patch，减少计算量，提升训练效率，对高效大模型训练有价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21867' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Output Alignment For 1-bit Post-Training Quantization of Large Language Models</h3>
<p><strong>Authors:</strong> Dung Anh Hoang (), Cuong Pham (), Cuong Nguyen (), Trung le (), Jianfei Cai (), Thanh-Toan Do ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 针对1-bit大模型量化中输出匹配失败的问题，提出数据感知的PTQ方法，有效提升量化模型性能且开销小，对高效大模型推理有重要研究价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21651' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> An Information Theoretic Perspective on Agentic System Design</h3>
<p><strong>Authors:</strong> Shizhe He (), Avanika Narayan (), Ishan S. Khare (), Scott W. Linderman (), Christopher Ré (), Dan Biderman ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 用信息论框架分析多LM代理系统的压缩器-预测器设计，提出互信息估计量化压缩质量，为高效大模型部署中的系统设计提供理论指导。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21720' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model</h3>
<p><strong>Authors:</strong> Yanhao Li (), Lu Ma (), Jiaran Zhang (), Lexiang Tang (), Wentao Zhang (), Guibo Luo ()</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出自适应长度惩罚的RL框架，在减少大模型推理长度的同时保持任务性能，对高效大模型推理的可控性有实用价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.21540' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks</h3>
<p><strong>Authors:</strong> Zubair Shah, Noaman Khan</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 将剪枝视为模型组件的博弈均衡结果，提出理论驱动的剪枝算法，属于模型压缩，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2512.22106' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Deepfake Detective: Interpreting Neural Forensics Through Sparse Features and Manifolds</h3>
<p><strong>Authors:</strong> Subramanyam Sahoo, Jared Junkin</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出机制可解释性框架解释Deepfake检测模型决策过程，属于深度学习可解释性中的白盒解释方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.21670' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Towards Responsible and Explainable AI Agents with Consensus-Driven Reasoning</h3>
<p><strong>Authors:</strong> Eranga Bandara, Tharaka Hewa, Ross Gore, Sachin Shetty, Ravi Mukkamala, Peter Foytik, Abdul Rahman, Safdar H. Bouk, Xueping Liang, Amin Hass, Sachini Rajapakse, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan</p>
<p><strong>Published:</strong> 2025-12-29</p>
<p><strong>Reason:</strong> 提出基于多模型共识和推理层治理的负责任可解释AI代理架构，解决现有代理的可解释性与责任性问题，符合深度学习可解释性方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2512.21699' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>