# ArXiv 每日推荐 - 2025-12-31

> 更新于北京时间：2025-12-31 12:51:54
> 已自动阅读了 394 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：215898

## 大模型安全与对齐

### [Score: 9.0/10] Unbiased Visual Reasoning with Controlled Visual Inputs
- **Authors:** Zhaonan Li, Shijie Lu, Fei Wang, Jacob Dineen, Xiao Ye, Zhikun Xu, Siyi Liu, Young Min Cho, Bangzheng Li, Daniel Chang, Kenny Nguyen, Qizheng Yang, Muhao Chen, Ben Zhou
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22183](https://arxiv.org/abs/2512.22183)
- **Reason:** 提出VISTA框架分离VLMs的感知与推理，通过强化学习减少模型对虚假相关的依赖，提升无偏推理能力，有效解决大模型的鲁棒性与安全性问题。
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] M-ErasureBench: A Comprehensive Multimodal Evaluation Benchmark for Concept Erasure in Diffusion Models
- **Authors:** Ju-Hsuan Weng, Jia-Wei Liao, Cheng-Fu Chou, Jun-Cheng Chen
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22877](https://arxiv.org/abs/2512.22877)
- **Reason:** 提出首个多模态概念擦除基准M-ErasureBench，覆盖文本、嵌入、潜变量模态，提出IRECE提升鲁棒性，属于大模型安全与对齐的概念擦除研究。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] Direct Diffusion Score Preference Optimization via Stepwise Contrastive Policy-Pair Supervision
- **Authors:** Dohyun Kim, Seungwoo Lyu, Seung Wook Kim, Paul Hongsuck Seo
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23426](https://arxiv.org/abs/2512.23426)
- **Reason:** 提出基于对比政策对监督的扩散分数偏好优化，解决扩散模型与用户意图对齐的问题，提升文本-图像对齐和视觉质量。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] PurifyGen: A Risk-Discrimination and Semantic-Purification Model for Safe Text-to-Image Generation
- **Authors:** Zongsheng Cao, Yangfan He, Anran Liu, Jun Xie, Feng Chen, Zepeng Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23546](https://arxiv.org/abs/2512.23546)
- **Reason:** 提出训练-free的prompt净化框架，通过双阶段语义距离评估和双空间变换，减少文本到图像生成中的不安全内容，性能优于现有方法。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] ProGuard: Towards Proactive Multimodal Safeguard
- **Authors:** Shaohan Yu, Lijun Li, Chenyang Si, Lu Sheng, Jing Shao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23573](https://arxiv.org/abs/2512.23573)
- **Reason:** 提出主动多模态安全防护框架，构建多模态安全数据集，通过强化学习训练模型识别OOD安全风险，主动 moderation能力显著提升。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Theory and Algorithms for Learning with Multi-Class Abstention and Multi-Expert Deferral
- **Authors:** Anqi Mao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22886](https://arxiv.org/abs/2512.22886)
- **Reason:** 针对LLM幻觉和高推理成本问题，提出多专家延迟和弃权的理论与算法，提升大模型可靠性和推理效率，属于大模型安全与对齐的核心问题
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] APO: Alpha-Divergence Preference Optimization
- **Authors:** Wang Zixian
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22953](https://arxiv.org/abs/2512.22953)
- **Reason:** 提出基于alpha-散度的偏好优化框架，连续插值forward和reverse KL行为，提升大模型对齐训练的稳定性和性能
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance
- **Authors:** Zhuo Li, Pengyu Cheng, Zhechao Yu, Feifei Tong, Anningzhe Gao, Tsung-Hui Chang, Xiang Wan, Erchao Zhao, Xiaoxi Jiang, Guanjun Jiang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23461](https://arxiv.org/abs/2512.23461)
- **Reason:** 提出DIR方法利用信息论指导消除奖励模型中的归纳偏差（如长度、谄媚、格式偏差），提升RLHF的对齐效果，解决了大模型对齐中的关键问题。
Score: 8
Field: 大模型安全与对齐

## 多模态智能体

### [Score: 9.0/10] VideoZoomer: Reinforcement-Learned Temporal Focusing for Long Video Reasoning
- **Authors:** Yang Ding, Yizhen Zhang, Xin Lai, Ruihang Chu, Yujiu Yang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22315](https://arxiv.org/abs/2512.22315)
- **Reason:** 提出agentic框架VideoZoomer，通过强化学习让MLLMs动态控制视觉焦点，实现长视频的渐进式推理，显著提升长视频理解性能，属于多模态智能体的典型应用。
Score: 9
Field: 多模态智能体

### [Score: 9.0/10] Video-BrowseComp: Benchmarking Agentic Video Research on Open Web
- **Authors:** Zhengyang Liang, Yan Shu, Xiangrui Liu, Minghao Qin, Kaixin Liang, Paolo Rota, Nicu Sebe, Zheng Liu, Lizi Liao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23044](https://arxiv.org/abs/2512.23044)
- **Reason:** 提出首个开放网络视频推理基准，评估多模态智能体的主动视频推理能力，解决现有基准仅关注被动感知的问题，推动视频智能体研究。
Score: 9
Field: 多模态智能体

### [Score: 8.0/10] DreamOmni3: Scribble-based Editing and Generation
- **Authors:** Bin Xia, Bohao Peng, Jiyang Liu, Sitong Wu, Jingyao Li, Junjia Huang, Xu Zhao, Yitong Wang, Ruihang Chu, Bei Yu, Jiaya Jia
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22525](https://arxiv.org/abs/2512.22525)
- **Reason:** 提出结合文本、图像和自由手绘涂鸦的多模态编辑与生成框架，通过GUI实现用户交互，针对复杂编辑场景优化区域定位与处理，符合多模态智能体的GUI交互研究方向。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] OpenGround: Active Cognition-based Reasoning for Open-World 3D Visual Grounding
- **Authors:** Wenyuan Huang, Zhao Wang, Zhou Wei, Ting Huang, Fang Zhao, Jian Yang, Zhenyu Zhang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23020](https://arxiv.org/abs/2512.23020)
- **Reason:** 针对开放世界3D视觉接地问题，提出主动认知推理框架，使用VLMs动态更新OLT，解决预定义OLT的局限性，属于多模态智能体中的接地任务。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] OmniAgent: Audio-Guided Active Perception Agent for Omnimodal Audio-Video Understanding
- **Authors:** Keda Tao, Wenjie Du, Bohan Yu, Weiqiang Wang, Jian Liu, Huan Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23646](https://arxiv.org/abs/2512.23646)
- **Reason:** 提出音频引导的主动感知代理，通过动态规划和粗到细音频感知，提升多模态音频-视频理解的细粒度推理能力，在3个基准上优于现有模型。
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] Envision: Embodied Visual Planning via Goal-Imagery Video Diffusion
- **Authors:** Yuming Gu, Yizhi Wang, Yining Hong, Yipeng Gao, Hao Jiang, Angtian Wang, Bo Liu, Nathaniel S. Dennler, Zhengfei Kuang, Hao Li, Gordon Wetzstein, Chongyang Ma
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22626](https://arxiv.org/abs/2512.22626)
- **Reason:** 提出基于扩散模型的具身视觉规划框架，通过目标图像约束生成物理一致的轨迹，支持机器人规划与控制，属于多模态智能体的具身agent研究。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] VPTracker: Global Vision-Language Tracking via Visual Prompt and MLLM
- **Authors:** Jingchao Wang, Kaiwen Zhou, Zhijian Wu, Kunhua Ji, Dingjiang Huang, Yefeng Zheng
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22799](https://arxiv.org/abs/2512.22799)
- **Reason:** 提出基于MLLM的全局视觉语言跟踪框架，通过位置感知视觉提示提升鲁棒性，属于多模态智能体的视觉跟踪研究。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] EgoReAct: Egocentric Video-Driven 3D Human Reaction Generation
- **Authors:** Libo Zhang, Zekun Li, Tianyu Li, Zeyu Cao, Rui Xu, Xiaoxiao Long, Wenjia Wang, Jingbo Wang, Yuan Liu, Wenping Wang, Daquan Zhou, Taku Komura, Zhiyang Dou
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22808](https://arxiv.org/abs/2512.22808)
- **Reason:** 提出基于第一视角视频的3D人体反应生成框架，保持空间一致性与因果性，属于多模态智能体的具身动作生成研究。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] MUSON: A Reasoning-oriented Multimodal Dataset for Socially Compliant Navigation in Urban Environments
- **Authors:** Zhuonan Liu, Xinyu Zhang, Zishuo Wang, Tomohito Kawabata, Xuesu Xiao, Ling Xiao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22867](https://arxiv.org/abs/2512.22867)
- **Reason:** 构建社会合规导航的多模态数据集，包含Chain-of-Thought标注支持LLM推理，属于多模态智能体的社会导航研究。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] ColaVLA: Leveraging Cognitive Latent Reasoning for Hierarchical Parallel Trajectory Planning in Autonomous Driving
- **Authors:** Qihang Peng, Xuesong Chen, Chenye Yang, Shaoshuai Shi, Hongsheng Li
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22939](https://arxiv.org/abs/2512.22939)
- **Reason:** 提出结合VLM推理的自动驾驶轨迹规划框架，提升实时性与安全性，属于多模态智能体的自动驾驶研究。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] SpatialMosaic: A Multiview VLM Dataset for Partial Visibility
- **Authors:** Kanghee Lee, Injae Lee, Minseok Kwak, Kwonyoung Ryu, Jungi Hong, Jaesik Park
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23365](https://arxiv.org/abs/2512.23365)
- **Reason:** 提出多视图VLM数据集SpatialMosaic，用于评估部分可见性下的空间推理，填补部分可见性空间推理的数据集空白。
Score: 7
Field: 多模态智能体

## 高效大模型训练与推理

### [Score: 9.0/10] Self-Evaluation Unlocks Any-Step Text-to-Image Generation
- **Authors:** Xin Yu, Xiaojuan Qi, Zhengqi Li, Kai Zhang, Richard Zhang, Zhe Lin, Eli Shechtman, Tianyu Wang, Yotam Nitzan
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22374](https://arxiv.org/abs/2512.22374)
- **Reason:** 提出自评估模型Self-E，支持任意步文本到图像生成，兼顾少步推理的效率与多步生成的质量，是文本生成模型效率与性能平衡的重要突破。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] Breaking the Memory Wall: Exact Analytical Differentiation via Tiled Operator-Space Evolution
- **Authors:** Shuhuan Wang, Yuzhen Xie, Jiayi Li, Yinliang Diao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23068](https://arxiv.org/abs/2512.23068)
- **Reason:** 提出Phase Gradient Flow框架，实现选择性状态空间模型的O(1)内存精确导数计算，解决长序列建模的内存瓶颈，极大提升大模型训练效率
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] KernelEvolve: Scaling Agentic Kernel Coding for Heterogeneous AI Accelerators at Meta
- **Authors:** Gang Liao (Meta), Hongsen Qin (Meta), Ying Wang (Meta), Alicia Golden (Meta), Michael Kuchnik (Meta), Yavuz Yetim (Meta), Jia Jiunn Ang (Meta), Chunli Fu (Meta), Yihan He (Meta), Samuel Hsia (Meta), Zewei Jiang (Meta), Dianshi Li (Meta), Uladzimir Pashkevich (Meta), Varna Puvvada (Meta), Feng Shi (Meta), Matt Steiner (Meta), Ruichao Xiao (Meta), Nathan Yan (Meta), Xiayu Yu (Meta), Zhou Fang (Meta), Abdul Zainul-Abedin (Meta), Ketan Singh (Meta), Hongtao Yu (Meta), Wenyuan Chi (Meta), Barney Huang (Meta), Sean Zhang (Meta), Noah Weller (Meta), Zach Marine (Meta), Wyatt Cook (Meta), Carole-Jean Wu (Meta), Gaoxiang Liu (Meta)
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23236](https://arxiv.org/abs/2512.23236)
- **Reason:** 针对异构AI加速器提出Agentic内核编码框架KernelEvolve，自动化DLRM模型的内核生成与优化，大幅提升训练/推理效率，由Meta团队开发并在生产环境验证，具有强工业落地价值。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] SpotEdit: Selective Region Editing in Diffusion Transformers
- **Authors:** Zhibin Qin, Zhenxiong Tan, Zeqing Wang, Songhua Liu, Xinchao Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22323](https://arxiv.org/abs/2512.22323)
- **Reason:** 提出训练-free的选择性区域编辑框架，仅更新修改区域的特征，减少冗余计算，提升扩散Transformer的编辑效率与准确性，属于高效大模型推理的重要进展。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] DeFloMat: Detection with Flow Matching for Stable and Efficient Generative Object Localization
- **Authors:** Hansang Lee, Chaelin Lee, Nieun Seo, Joon Seok Lim, Helen Hong
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22406](https://arxiv.org/abs/2512.22406)
- **Reason:** 用条件流匹配（CFM）替代扩散模型的随机去噪过程，提升生成式目标检测的效率与稳定性，解决扩散模型的 latency 瓶颈，属于高效大模型推理的关键改进。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Unleashing Foundation Vision Models: Adaptive Transfer for Diverse Data-Limited Scientific Domains
- **Authors:** Qiankun Li, Feng He, Huabao Chen, Xin Ning, Kun Wang, Zengfu Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22664](https://arxiv.org/abs/2512.22664)
- **Reason:** 提出Cluster Attention Adapter（CLAdapter）实现基础视觉模型的自适应迁移，在小数据科学领域提升性能，属于高效大模型训练与推理的参数高效微调研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] TrimTokenator-LC: Towards Adaptive Visual Token Pruning for Large Multimodal Models with Long Contexts
- **Authors:** Hao Zhang, Mengsi Lyu, Bo Huang, Yulong Ao, Yonghua Lin
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22748](https://arxiv.org/abs/2512.22748)
- **Reason:** 针对长上下文多模态大模型提出自适应视觉token剪枝方法，通过intra/inter-image冗余分解提升推理效率，属于高效大模型训练与推理的token剪枝研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Plug-and-Play Fidelity Optimization for Diffusion Transformer Acceleration via Cumulative Error Minimization
- **Authors:** Tong Shao, Yusen Fu, Guoying Sun, Jingde Kong, Zhuotao Tian, Jingyong Su
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23258](https://arxiv.org/abs/2512.23258)
- **Reason:** 提出基于累积误差最小化的即插即用保真度优化方法，加速扩散Transformer推理，提升推理效率和保真度。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] SoulX-LiveTalk Technical Report
- **Authors:** Le Shen, Qiao Qian, Tan Yu, Ke Zhou, Tianhang Yu, Yu Zhan, Zhenjie Wang, Ming Tao, Shunshun Yin, Siyuan Liu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23379](https://arxiv.org/abs/2512.23379)
- **Reason:** 提出14B参数的实时流扩散框架，解决大规模扩散模型的实时部署问题，实现高保真实时流。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Stream-DiffVSR: Low-Latency Streamable Video Super-Resolution via Auto-Regressive Diffusion
- **Authors:** Hau-Shiang Shiu, Chin-Yang Lin, Zhixiang Wang, Chi-Wei Hsiao, Po-Fan Yu, Yu-Chih Chen, Yu-Lun Liu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23709](https://arxiv.org/abs/2512.23709)
- **Reason:** 提出因果条件扩散框架，通过四步蒸馏去噪和时序引导，实现低延迟在线视频超分辨率，latency较现有扩散方法降低130x，性能提升显著。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] DiRL: An Efficient Post-Training Framework for Diffusion Language Models
- **Authors:** Ying Zhu, Jiaxin Wan, Xiaoran Liu, Siyanag He, Qiqi Wang, Xu Guo, Tianyi Liang, Zengfeng Huang, Ziwei He, Xipeng Qiu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22234](https://arxiv.org/abs/2512.22234)
- **Reason:** 提出高效扩散语言模型后训练框架，结合FlexAttention加速和LMDeploy优化，通过DiPO提升复杂推理性能，数学任务上优于Qwen2.5系列。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] LLMBoost: Make Large Language Models Stronger with Boosting
- **Authors:** Zehao Chen, Tianxiang Ai, Yifei Li, Gongxun Li, Yuyang Wei, Wang Zhou, Guanghui Li, Bin Yu, Zhijun Chen, Hailong Sun, Fuzhen Zhuang, Jianxin Li, Deqing Wang, Yikun Ban
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22309](https://arxiv.org/abs/2512.22309)
- **Reason:** 提出LLMBoost集成学习框架，通过跨模型注意力机制和链训练范式利用LLM中间表示，实现高效的性能提升和近并行推理，属于高效大模型训练与推理的重要进展。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] AFA-LoRA: Enabling Non-Linear Adaptations in LoRA with Activation Function Annealing
- **Authors:** Jiacheng Li, Jianchao Tan, Zhidong Yang, Feiye Huo, Yerui Sun, Yuchen Xie, Xunliang Cai
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22455](https://arxiv.org/abs/2512.22455)
- **Reason:** 针对LoRA线性适应的局限性，提出激活函数退火策略引入非线性表达，在不增加复杂度的情况下缩小与全参数训练的性能差距，属于高效大模型训练中的参数高效微调重要改进。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] The Quest for Winning Tickets in Low-Rank Adapters
- **Authors:** Hamed Damirchi, Cristian Rodriguez-Opazo, Ehsan Abbasnejad, Zhen Zhang, Javen Shi
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22495](https://arxiv.org/abs/2512.22495)
- **Reason:** 验证彩票假说在LoRA中的有效性，发现稀疏子网络可匹配dense adapters性能，提出Partial-LoRA方法减少训练参数，属于高效大模型训练中参数高效微调与模型压缩的重要研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Merge before Forget: A Single LoRA Continual Learning via Continual Merging
- **Authors:** Fuli Qiao, Mehrdad Mahdavi
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23017](https://arxiv.org/abs/2512.23017)
- **Reason:** 提出持续合并LoRA的连续学习方法，解决LoRA内存增长和任务干扰问题，显著提升大模型持续学习的效率和性能
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Energy and Memory-Efficient Federated Learning With Ordered Layer Freezing
- **Authors:** Ziru Niu, Hai Dong, A. K. Qin, Tao Gu, Pengcheng Zhang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23200](https://arxiv.org/abs/2512.23200)
- **Reason:** 提出FedOLF通过有序层冻结和Tensor Operation Approximation技术，在保证模型 accuracy 的前提下，显著降低联邦学习中边缘设备的计算与内存开销，属于高效大模型训练的关键优化方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL
- **Authors:** Abolfazl Younesi, Abbas Shabrang Maryan, Elyas Oustad, Zahra Najafabadi Samani, Mohsen Ansari, Thomas Fahringer
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23310](https://arxiv.org/abs/2512.23310)
- **Reason:** 提出Lyapunov辅助的DRL框架Splitwise，实现LLM的边缘-云协同推理，在保证 accuracy 的同时优化延迟、能耗与内存占用，解决了LLM在边缘设备部署的核心瓶颈。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2
- **Authors:** Yilun Luo, HuaQing Zheng, Haoqian Meng, Wenyuan Liu, Peng Zhang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23367](https://arxiv.org/abs/2512.23367)
- **Reason:** 针对OpenPangu模型设计低比特量化方案（INT8/W4A8），在Atlas A2上实现高效部署，显著提升推理速度并降低内存开销，为大模型在专用硬件上的优化提供了实践参考。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] End-to-End Test-Time Training for Long Context
- **Authors:** Arnuv Tandon, Karan Dalal, Xinhao Li, Daniel Koceja, Marcel Röd, Sam Buchanan, Xiaolong Wang, Jure Leskovec, Sanmi Koyejo, Tatsunori Hashimoto, Carlos Guestrin, Jed McCaleb, Yejin Choi, Yu Sun
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23675](https://arxiv.org/abs/2512.23675)
- **Reason:** 提出TTT-E2E通过测试时训练处理LLM长上下文推理，在保持与全注意力Transformer相当性能的同时，实现恒定推理延迟，为长上下文LLM的高效推理提供了新范式。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks
- **Authors:** Zubair Shah, Noaman Khan
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22106](https://arxiv.org/abs/2512.22106)
- **Reason:** 将神经网络剪枝建模为组件间的非合作博弈均衡问题，提出无需显式重要性评分的剪枝算法，为模型压缩提供理论接地的新视角，属于高效大模型训练与推理中的模型压缩方向，实验验证了稀疏性-精度权衡的竞争力。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] KV-Tracker: Real-Time Pose Tracking with Transformers
- **Authors:** Marwan Taher, Ignacio Alzugaray, Kirill Mazur, Xin Kong, Andrew J. Davison
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22581](https://arxiv.org/abs/2512.22581)
- **Reason:** 提出缓存Transformer全局自注意力的KV对以加速实时姿势跟踪推理，模型无关且提升15倍速度，符合高效大模型训练与推理的推理加速研究。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Hash Grid Feature Pruning
- **Authors:** Yangzhi Ma, Bojun Liu, Jie Li, Li Li, Dong Liu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22882](https://arxiv.org/abs/2512.22882)
- **Reason:** 提出Hash Grid特征剪枝方法，去除无效特征提升存储效率，属于高效大模型训练与推理的特征剪枝研究。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Masking Teacher and Reinforcing Student for Distilling Vision-Language Models
- **Authors:** Byung-Kwan Lee, Yu-Chiang Frank Wang, Ryo Hachiuma
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22238](https://arxiv.org/abs/2512.22238)
- **Reason:** 提出mask-progressive强化学习蒸馏框架，通过逐步恢复教师模型能力和离线RL引导，提升视觉语言模型的蒸馏效率和性能。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Dynamic Subspace Composition: Efficient Adaptation via Contractive Basis Expansion
- **Authors:** Vladimer Khasia
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23448](https://arxiv.org/abs/2512.23448)
- **Reason:** 提出DSC框架通过收缩基扩展实现模型高效适应，解决Mixture of Experts的表示崩溃与梯度不稳定问题，是参数高效微调的重要方法。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] FRoD: Full-Rank Efficient Fine-Tuning with Rotational Degrees for Fast Convergence
- **Authors:** Guoan Wan, Tianyu Chen, Fangzheng Feng, Haoyi Zhou, Runhua Xu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23485](https://arxiv.org/abs/2512.23485)
- **Reason:** 提出FRoD通过分层联合分解与旋转自由度实现全秩高效微调，在仅更新1.72%参数的情况下匹配全量微调精度，同时提升收敛速度。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Leash: Adaptive Length Penalty and Reward Shaping for Efficient Large Reasoning Model
- **Authors:** Yanhao Li, Lu Ma, Jiaran Zhang, Lexiang Tang, Wentao Zhang, Guibo Luo
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.21540](https://arxiv.org/abs/2512.21540)
- **Reason:** 提出Leash通过自适应长度惩罚与强化学习奖励塑造，在减少LLM推理长度的同时保持性能，显著提升推理效率，是高效大模型推理的实用方法。
Score: 7
Field: 高效大模型训练与推理

## 大模型新技术

### [Score: 9.0/10] Dream-VL & Dream-VLA: Open Vision-Language and Vision-Language-Action Models with Diffusion Language Model Backbone
- **Authors:** Jiacheng Ye, Shansan Gong, Jiahui Gao, Junming Fan, Shuang Wu, Wei Bi, Haoli Bai, Lifeng Shang, Lingpeng Kong
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22615](https://arxiv.org/abs/2512.22615)
- **Reason:** 首次基于扩散语言模型（dLLM）构建视觉语言（Dream-VL）和视觉语言动作（Dream-VLA）模型，在机器人任务上超越现有模型，符合大模型新技术的diffusion LLM研究方向。
Score: 9
Field: 大模型新技术

### [Score: 8.0/10] Characterizing Motion Encoding in Video Diffusion Timesteps
- **Authors:** Vatsal Baherwani, Yixuan Ren, Abhinav Shrivastava
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22175](https://arxiv.org/abs/2512.22175)
- **Reason:** 系统研究视频扩散模型中运动编码的时间步特性，验证早期时间步主导运动、后期主导外观的启发式结论，提出时间步约束的运动定制方法，对扩散模型的运动理解与编辑有重要价值。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Human-Aligned Generative Perception: Bridging Psychophysics and Generative Models
- **Authors:** Antara Titikhsha, Om Kulkarni, Dharun Muthaiah
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22272](https://arxiv.org/abs/2512.22272)
- **Reason:** 利用人类感知嵌入（HPE）引导扩散模型的几何控制，解决生成模型忽略几何约束的问题，提升生成结果与人类感知的对齐度，是扩散模型的重要改进方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Parallel Diffusion Solver via Residual Dirichlet Policy Optimization
- **Authors:** Ruoyu Wang, Ziyu Li, Beier Zhu, Liangyu Yuan, Hanwang Zhang, Xun Yang, Xiaojun Chang, Chi Zhang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22796](https://arxiv.org/abs/2512.22796)
- **Reason:** 提出基于残差Dirichlet策略优化的并行扩散求解器，提升扩散模型采样效率与质量，属于大模型新技术的扩散模型优化研究。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Guided Path Sampling: Steering Diffusion Models Back on Track with Principled Path Guidance
- **Authors:** Haosen Li, Wenshuo Chen, Shaofeng Liang, Lei Wang, Haozhe Jia, Yutao Yue
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22881](https://arxiv.org/abs/2512.22881)
- **Reason:** 提出Guided Path Sampling解决扩散模型的CFG路径偏移问题，通过流形约束插值提升稳定性，属于大模型新技术的扩散模型优化研究。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Decomposing Task Vectors for Refined Model Editing
- **Authors:** Hamed Damirchi, Ehsan Abbasnejad, Zhen Zhang, Javen Shi
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22511](https://arxiv.org/abs/2512.22511)
- **Reason:** 提出任务向量分解方法，将其分为共享知识与独特任务组件，实现更精准的模型编辑（如多任务合并、扩散模型风格混合、毒性reduction），属于大模型新技术中的模型编辑关键进展。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Trust Region Masking for Long-Horizon LLM Reinforcement Learning
- **Authors:** Yingru Li, Jiacai Liu, Jiawei Xu, Yuxuan Tong, Ziniu Li, Baoxiang Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23075](https://arxiv.org/abs/2512.23075)
- **Reason:** 推导长序列LLM强化学习的信任区域边界，提出Trust Region Masking方法，解决长horizon任务的训练不稳定问题，属于大模型新技术的重要突破
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Taming the Tail: Stable LLM Reinforcement Learning via Dynamic Vocabulary Pruning
- **Authors:** Yingru Li, Jiawei Xu, Jiacai Liu, Yuxuan Tong, Ziniu Li, Tianle Cai, Ge Zhang, Qian Liu, Baoxiang Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23087](https://arxiv.org/abs/2512.23087)
- **Reason:** 分析LLM强化学习的训练-推理 mismatch，提出动态词汇剪枝方法，提升长序列RL训练的稳定性，属于大模型新技术的关键进展
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] GeCo: A Differentiable Geometric Consistency Metric for Video Generation
- **Authors:** Leslie Gu, Junhwa Hur, Charles Herrmann, Fangneng Zhan, Todd Zickler, Deqing Sun, Hanspeter Pfister
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22274](https://arxiv.org/abs/2512.22274)
- **Reason:** 提出可微分的几何一致性度量GeCo，用于检测视频生成中的几何变形与遮挡不一致问题，可作为训练指导提升生成质量，对视频生成的评估与优化有重要意义。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] DeMoGen: Towards Decompositional Human Motion Generation with Energy-Based Diffusion Models
- **Authors:** Jianrong Zhang, Hehe Fan, Yi Yang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22324](https://arxiv.org/abs/2512.22324)
- **Reason:** 利用能量基扩散模型实现人体运动的分解生成，发现可重用的运动基元，为运动生成的可控性与泛化性提供新方法，属于大模型新技术。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Reverse Personalization
- **Authors:** Han-Wei Kung, Tuomas Varanka, Nicu Sebe
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22984](https://arxiv.org/abs/2512.22984)
- **Reason:** 提出基于扩散反转的面部匿名化框架，解决现有方法依赖预训练模型中主体或需微调的问题，支持属性可控匿名化，属于扩散技术应用。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Task-oriented Learnable Diffusion Timesteps for Universal Few-shot Learning of Dense Tasks
- **Authors:** Changgyoon Oh, Jongoh Jeong, Jegyeong Cho, Kuk-Jin Yoon
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23210](https://arxiv.org/abs/2512.23210)
- **Reason:** 提出面向任务的可学习扩散时间步长，解决扩散模型时间步长选择依赖经验的问题，提升密集任务的少样本学习性能。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] SURE Guided Posterior Sampling: Trajectory Correction for Diffusion-Based Inverse Problems
- **Authors:** Minwoo Kim, Hongki Lim
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23232](https://arxiv.org/abs/2512.23232)
- **Reason:** 提出基于SURE梯度更新和PCA噪声估计的扩散采样轨迹校正方法，解决扩散逆问题中的误差累积，提升采样准确性。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] ASemConsist: Adaptive Semantic Feature Control for Training-Free Identity-Consistent Generation
- **Authors:** Shin seong Kim, Minjung Shin, Hyunin Cho, Youngjung Uh
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23245](https://arxiv.org/abs/2512.23245)
- **Reason:** 提出自适应语义特征控制框架，用于无训练的身份一致生成，解决扩散模型中身份一致性与提示对齐的权衡问题。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation
- **Authors:** Shaocong Xu, Songlin Wei, Qizhe Wei, Zheng Geng, Hong Li, Licheng Shen, Qianpu Sun, Shu Han, Bin Ma, Bohan Li, Chongjie Ye, Yuhang Zheng, Nan Wang, Saining Zhang, Hao Zhao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23705](https://arxiv.org/abs/2512.23705)
- **Reason:** 利用视频扩散模型的光学知识，提出TransPhy3D数据集和DKT模型，提升透明物体的深度和法线估计性能，零样本优于现有方法。
Score: 7
Field: 大模型新技术

## 原生多模态大模型

### [Score: 9.0/10] JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation
- **Authors:** Kai Liu, Jungang Li, Yuchong Sun, Shengqiong Wu, Jianzhang Gao, Daoan Zhang, Wei Zhang, Sheng Jin, Sicheng Yu, Geng Zhan, Jiayi Ji, Fan Zhou, Liang Zheng, Shuicheng Yan, Hao Fei, Tat-Seng Chua
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22905](https://arxiv.org/abs/2512.22905)
- **Reason:** 提出首个统一的音视频多模态LLM（JavisGPT），支持理解与生成，在JAV任务上超越现有模型，符合原生多模态大模型的研究方向。
Score: 9
Field: 原生多模态大模型

### [Score: 8.0/10] VideoScaffold: Elastic-Scale Visual Hierarchies for Streaming Video Understanding in MLLMs
- **Authors:** Naishan Zheng, Jie Huang, Qingpei Guo, Feng Zhao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22226](https://arxiv.org/abs/2512.22226)
- **Reason:** 针对多模态大模型的流式视频理解，提出动态弹性尺度视觉层次框架，实现从细粒度帧理解到抽象事件推理的平滑过渡，提升视频理解性能。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] MoFu: Scale-Aware Modulation and Fourier Fusion for Multi-Subject Video Generation
- **Authors:** Run Ling, Ke Cao, Jian Lu, Ao Ma, Haowei Liu, Runze He, Changwei Wang, Rongtao Xu, Yihua Shao, Zhanjie Zhang, Peng Wu, Guibing Guo, Wei Feng, Zheng Zhang, Jingjing Lv, Junjie Shen, Ching Law, Xingwei Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22310](https://arxiv.org/abs/2512.22310)
- **Reason:** 解决多主体视频生成的尺度不一致与排列敏感问题，提出尺度感知调制与傅里叶融合策略，提升生成结果的视觉质量与一致性，属于原生多模态大模型的关键改进。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Self-Rewarded Multimodal Coherent Reasoning Across Diverse Visual Domains
- **Authors:** Jesen Zhang, Ningyuan Liu, Kaitong Cai, Sidi Liu, Jing Yang, Ziliang Chen, Xiaofei Sun, Keze Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22545](https://arxiv.org/abs/2512.22545)
- **Reason:** 针对多模态LLM的推理连贯性与视觉 grounding问题，提出SR-MCR框架，用自参考奖励信号增强过程级引导，基于Qwen2.5-VL提升推理性能，属于原生多模态大模型的推理优化。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] REVEALER: Reinforcement-Guided Visual Reasoning for Element-Level Text-Image Alignment Evaluation
- **Authors:** Fulin Shi, Wenyi Xiao, Bin Chen, Liang Din, Leilei Gan
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23169](https://arxiv.org/abs/2512.23169)
- **Reason:** 提出强化学习引导的元素级文本-图像对齐评估框架，使用MLLMs进行显式语义定位和可解释判断，提升评估的细粒度和可解释性。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] GaussianDWM: 3D Gaussian Driving World Model for Unified Scene Understanding and Multi-Modal Generation
- **Authors:** Tianchen Deng, Xuefeng Chen, Yi Chen, Qu Chen, Yuyao Xu, Lijin Yang, Le Xu, Yu Zhang, Bo Zhang, Wuxiong Huang, Hesheng Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23180](https://arxiv.org/abs/2512.23180)
- **Reason:** 提出基于3D高斯场景表示的统一驾驶世界模型，支持多模态场景理解和生成，解决现有驾驶世界模型缺乏3D理解的问题。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] MM-UAVBench: How Well Do Multimodal Large Language Models See, Think, and Plan in Low-Altitude UAV Scenarios?
- **Authors:** Shiqi Dai, Zizhi Ma, Zhicong Luo, Xuesong Yang, Yibin Huang, Wanyue Zhang, Chi Chen, Zonghao Guo, Wang Xu, Yufei Sun, Maosong Sun
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23219](https://arxiv.org/abs/2512.23219)
- **Reason:** 提出针对低空UAV场景的MLLM基准，评估感知、认知、规划能力，填补UAV场景MLLM评估空白。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Bridging Your Imagination with Audio-Video Generation via a Unified Director
- **Authors:** Jiaxu Zhang, Tianshu Hu, Yuan Zhang, Zenan Li, Linjie Luo, Guosheng Lin, Xin Chen
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23222](https://arxiv.org/abs/2512.23222)
- **Reason:** 提出统一导演模型UniMAGE，桥接用户提示与结构化脚本，支持音频-视频生成，解决现有系统脚本与关键帧设计分离的问题。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] CountGD++: Generalized Prompting for Open-World Counting
- **Authors:** Niki Amini-Naieni, Andrew Zisserman
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23351](https://arxiv.org/abs/2512.23351)
- **Reason:** 提出通用提示的开放世界计数模型，支持文本和视觉示例（包括排除项），提升计数的灵活性和准确性。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] DriveLaW:Unifying Planning and Video Generation in a Latent Driving World
- **Authors:** Tianze Xia, Yongkang Li, Lijun Zhou, Jingfeng Yao, Kaixin Xiong, Haiyang Sun, Bing Wang, Kun Ma, Hangjun Ye, Wenyu Liu, Xinggang Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23421](https://arxiv.org/abs/2512.23421)
- **Reason:** 提出统一规划和视频生成的潜在驾驶世界模型，解决现有方法规划与生成分离的问题，提升驾驶场景理解和生成性能。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] CoFi-Dec: Hallucination-Resistant Decoding via Coarse-to-Fine Generative Feedback in Large Vision-Language Models
- **Authors:** Zongsheng Cao, Yangfan He, Anran Liu, Jun Xie, Feng Chen, Zepeng Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23453](https://arxiv.org/abs/2512.23453)
- **Reason:** 提出训练-free的粗到细生成反馈解码框架，缓解大视觉语言模型的幻觉问题，在6个幻觉基准上显著降低实体和语义级幻觉，性能优于现有方法。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation
- **Authors:** Yuxin Wen, Qing Shuai, Di Kang, Jing Li, Cheng Wen, Yue Qian, Ningxin Jiao, Changhai Chen, Weijie Chen, Yiran Wang, Jinkun Guo, Dongyue An, Han Liu, Yanyu Tong, Chao Zhang, Qing Guo, Juan Chen, Qiao Zhang, Youyi Zhang, Zihao Yao, Cheng Zhang, Hong Duan, Xiaoping Wu, Qi Chen, Fei Cheng, Liang Dong, Peng He, Hao Zhang, Jiaxin Lin, Chao Zhang, Zhongyi Fan, Yifan Li, Zhichao Hu, Yuhong Liu, Linus, Jie Jiang, Xiaolong Li, Linchao Bao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23464](https://arxiv.org/abs/2512.23464)
- **Reason:** 首次将基于流匹配的Diffusion Transformer扩展到十亿参数规模，通过全阶段训练范式提升文本到3D人体运动生成的指令跟随能力，性能优于开源基准。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] ThinkGen: Generalized Thinking for Visual Generation
- **Authors:** Siyu Jiao, Yiheng Lin, Yujie Zhong, Qi She, Wei Zhou, Xiaohan Lan, Zilong Huang, Fei Yu, Yingchen Yu, Yunqing Zhao, Yao Zhao, Yunchao Wei
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23568](https://arxiv.org/abs/2512.23568)
- **Reason:** 提出首个思维驱动的视觉生成框架，结合MLLM的CoT推理和Diffusion Transformer，通过分离式GRPO训练提升多场景生成性能，结果优于基线。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Rethinking Fine-Tuning: Unlocking Hidden Capabilities in Vision-Language Models
- **Authors:** Mingyuan Zhang, Yue Bai, Yifan Wang, Yiyang Huang, Yun Fu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23073](https://arxiv.org/abs/2512.23073)
- **Reason:** 提出Mask Fine-Tuning方法，通过重参数化视觉语言模型的内部子网，在不更新backbone的情况下提升多模态模型性能，属于原生多模态大模型的关键优化
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] CoAgent: Collaborative Planning and Consistency Agent for Coherent Video Generation
- **Authors:** Qinglin Zeng, Kaitong Cai, Ruiqi Chen, Qinhan Lv, Keze Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22536](https://arxiv.org/abs/2512.22536)
- **Reason:** 针对视频生成中的叙事连贯性与视觉一致性问题，提出plan-synthesize-verify pipeline，通过Storyboard Planner和Global Context Manager维护实体记忆，属于原生多模态大模型的视频生成研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] CritiFusion: Semantic Critique and Spectral Alignment for Faithful Text-to-Image Generation
- **Authors:** ZhenQi Chen, TsaiChing Ni, YuanFu Yang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22681](https://arxiv.org/abs/2512.22681)
- **Reason:** 提出结合语义批判与光谱对齐的文本到图像生成框架，提升语义一致性与视觉质量，属于原生多模态大模型的图像生成研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] ByteLoom: Weaving Geometry-Consistent Human-Object Interactions through Progressive Curriculum Learning
- **Authors:** Bangya Liu, Xinyu Gong, Zelin Zhao, Ziyang Song, Yulei Lu, Suhui Wu, Jun Zhang, Suman Banerjee, Hao Zhang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22854](https://arxiv.org/abs/2512.22854)
- **Reason:** 提出基于DiT的HOI视频生成框架，通过RCM-cache机制保持几何一致性，属于原生多模态大模型的人体-物体交互生成研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] CLIP-Joint-Detect: End-to-End Joint Training of Object Detectors with Contrastive Vision-Language Supervision
- **Authors:** Behnam Raoufi, Hossein Sharify, Mohamad Mahdee Ramezanee, Khosrow Hajsadeghi, Saeed Bagheri Shouraki
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22969](https://arxiv.org/abs/2512.22969)
- **Reason:** 提出目标检测器的视觉语言对比联合训练框架，提升closed-set检测性能，属于原生多模态大模型的视觉语言对齐研究。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Contour Information Aware 2D Gaussian Splatting for Image Representation
- **Authors:** Masaya Takabe, Hiroshi Watanabe, Sujun Hong, Tomohiro Ikai, Zheming Fan, Ryo Ishimoto, Kakeru Sugimoto, Ruri Imichi
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23255](https://arxiv.org/abs/2512.23255)
- **Reason:** 提出轮廓信息感知的2D高斯splatting图像表示框架，解决少高斯数下边界模糊的问题，提升图像表示的边界保留能力。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Bridging Cognitive Gap: Hierarchical Description Learning for Artistic Image Aesthetics Assessment
- **Authors:** Henglin Liu, Nisha Huang, Chang Liu, Jiangpeng Yan, Huijuan Huang, Jixuan Ying, Tong-Yee Lee, Pengfei Wan, Xiangyang Ji
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23413](https://arxiv.org/abs/2512.23413)
- **Reason:** 提出基于多模态描述的艺术图像美学评估框架，使用LLM解码器处理长文本语义，提升美学评估性能和效率。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Deterministic Image-to-Image Translation via Denoising Brownian Bridge Models with Dual Approximators
- **Authors:** Bohan Xiao, Peiyong Wang, Qisheng He, Ming Dong
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23463](https://arxiv.org/abs/2512.23463)
- **Reason:** 提出双逼近器的去噪布朗桥模型，解决确定性图像到图像翻译的保真度和质量问题，在图像生成和超分辨率任务上优于随机及确定性基线。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] TV-RAG: A Temporal-aware and Semantic Entropy-Weighted Framework for Long Video Retrieval and Understanding
- **Authors:** Zongsheng Cao, Yangfan He, Anran Liu, Feng Chen, Zepeng Wang, Jun Xie
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23483](https://arxiv.org/abs/2512.23483)
- **Reason:** 提出训练-free架构，结合时间衰减检索和熵加权关键帧采样，提升长视频推理的时间对齐和语义连贯性，在多个长视频基准上优于现有方法。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] IdentityStory: Taming Your Identity-Preserving Generator for Human-Centric Story Generation
- **Authors:** Donghao Zhou, Jingyu Lin, Guibao Shen, Quande Liu, Jialin Gao, Lihao Liu, Lan Du, Cunjian Chen, Chi-Wing Fu, Xiaowei Hu, Pheng-Ann Heng
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23519](https://arxiv.org/abs/2512.23519)
- **Reason:** 提出框架通过迭代身份发现和重新去噪身份注入，确保多帧图像中人类角色的身份一致性，提升人类中心故事生成的性能。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] AnyMS: Bottom-up Attention Decoupling for Layout-guided and Training-free Multi-subject Customization
- **Authors:** Binhe Yu, Zhen Wang, Kexin Li, Yuqian Yuan, Wenqiao Zhang, Long Chen, Juncheng Li, Jun Xiao, Yueting Zhuang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23537](https://arxiv.org/abs/2512.23537)
- **Reason:** 提出训练-free框架，通过自底向上的双级注意力解耦，解决多主体定制中的文本对齐、身份保持和布局控制问题，支持复杂构图和多主体扩展。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Same or Not? Enhancing Visual Perception in Vision-Language Models
- **Authors:** Damiano Marsili, Aditya Mehta, Ryan Y. Lin, Georgia Gkioxari
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23592](https://arxiv.org/abs/2512.23592)
- **Reason:** 构建大规模图像对数据集TWIN，通过细粒度视觉感知任务提升视觉语言模型的细粒度识别能力，在FGVQA基准上较基线提升19.3%。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Memorization in 3D Shape Generation: An Empirical Study
- **Authors:** Shu Pu, Boya Zeng, Kaichen Zhou, Mengyu Wang, Zhuang Liu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23628](https://arxiv.org/abs/2512.23628)
- **Reason:** 设计评估框架研究3D形状生成模型的记忆性，分析数据模态、多样性及模型设计对记忆的影响，为防止数据泄漏和提升多样性提供 insights。
Score: 7
Field: 原生多模态大模型

## 深度学习理论

### [Score: 9.0/10] Visual Language Hypothesis
- **Authors:** Xiu Li
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23335](https://arxiv.org/abs/2512.23335)
- **Reason:** 从结构和拓扑角度研究视觉表示学习，提出视觉语言假设，推导语义不变性和表示机制的理论结果，具有深度理论价值。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Fundamental Novel Consistency Theory: $H$-Consistency Bounds
- **Authors:** Yutao Zhong
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22880](https://arxiv.org/abs/2512.22880)
- **Reason:** 提出H-一致性边界理论，统一分析分类任务中 surrogate损失与目标损失的误差，为深度学习损失函数设计和泛化分析提供关键理论支撑
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] A Simple, Optimal and Efficient Algorithm for Online Exp-Concave Optimization
- **Authors:** Yi-Han Wang, Peng Zhao, Zhi-Hua Zhou
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23190](https://arxiv.org/abs/2512.23190)
- **Reason:** 提出LightONS算法，解决Online Newton Step的计算瓶颈，回答COLT'13开放问题，显著提升在线exp-凹优化的效率，属于深度学习理论的重要突破
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Theoretical Foundations of Scaling Law in Familial Models
- **Authors:** Huan Song, Qingfei Zhao, Ting Long, Shuyu Tian, Hongjun An, Jiawei Shao, Chi Zhang, Xuelong Li
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23407](https://arxiv.org/abs/2512.23407)
- **Reason:** 扩展经典缩放定律至“一次训练、多模型部署”的Familial模型，引入Granularity作为新缩放变量，建立统一缩放函数L(N,D,G)，为动态架构的模型设计提供了理论基础。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] YOLO-Master: MOE-Accelerated with Specialized Transformers for Enhanced Real-time Detection
- **Authors:** Xu Lin, Jinlong Peng, Zhenye Gan, Jiawen Zhu, Jun Liu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23273](https://arxiv.org/abs/2512.23273)
- **Reason:** 提出基于MoE的YOLO框架，动态分配计算资源，解决静态密集计算的资源错配问题，提升实时目标检测性能和效率。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Towards Unsupervised Causal Representation Learning via Latent Additive Noise Model Causal Autoencoders
- **Authors:** Hans Jarett J. Ong, Brian Godwin S. Lim, Dominic Dayta, Renzo Roel P. Tan, Kazushi Ikeda
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22150](https://arxiv.org/abs/2512.22150)
- **Reason:** 提出LANCA框架，利用加性噪声模型作为归纳偏置，通过确定性WAE和ANM层提升无监督因果表示学习的鲁棒性，结果优于基线。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Frequency Regularization: Unveiling the Spectral Inductive Bias of Deep Neural Networks
- **Authors:** Jiahao Lu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22192](https://arxiv.org/abs/2512.22192)
- **Reason:** 研究正则化的谱偏置，提出视觉诊断框架和SSR指标，揭示L2正则化的低通滤波效应及精度-鲁棒性权衡，为泛化提供信号处理视角。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Transformer Reconstructed with Dynamic Value Attention
- **Authors:** Xiaowei Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22212](https://arxiv.org/abs/2512.22212)
- **Reason:** 提出动态值注意力机制，简化Transformer结构为单头注意力并移除前馈网络，训练效率提升37.6%且保持性能，改进Transformer固有局限性。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] M\"untz-Sz\'asz Networks: Neural Architectures with Learnable Power-Law Bases
- **Authors:** Gnankan Landry Regis N'guessan
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22222](https://arxiv.org/abs/2512.22222)
- **Reason:** 提出基于可学习幂律基的网络架构，继承Müntz-Szász定理的universal approximation，提升奇异函数近似性能，在PINN任务上优于MLP。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] The Affine Divergence: Aligning Activation Updates Beyond Normalisation
- **Authors:** George Bird
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22247](https://arxiv.org/abs/2512.22247)
- **Reason:** 研究梯度下降中激活更新与理想状态的系统不匹配，从理论角度重新诠释归一化的作用，提出新的归一化方法PatchNorm和替代affine map的解决方案，对深度学习理论中的优化器和网络架构设计有重要参考价值。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Completed Hyperparameter Transfer across Modules, Width, Depth, Batch and Duration
- **Authors:** Bruno Mlodozeniec, Pierre Ablin, Louis Béthune, Dan Busbridge, Michal Klein, Jason Ramapuram, Marco Cuturi
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22382](https://arxiv.org/abs/2512.22382)
- **Reason:** 提出Complete(d)参数化方法，统一模型宽度、深度、batch size和训练时长的缩放，支持模块级超参数优化与传递，显著提升LLM训练速度，属于深度学习理论中超参数与模型缩放的关键研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] The Bayesian Geometry of Transformer Attention
- **Authors:** Naman Aggarwal, Siddhartha R. Dalal, Vishal Misra
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22471](https://arxiv.org/abs/2512.22471)
- **Reason:** 通过构建贝叶斯风洞实验，揭示Transformer通过残差流、前馈网络和注意力实现贝叶斯推理的几何机制，对深度学习理论中的Transformer架构与推理原理有重要贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] On Admissible Rank-based Input Normalization Operators
- **Authors:** Taeyun Kim
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22587](https://arxiv.org/abs/2512.22587)
- **Reason:** 提出基于秩的输入归一化算子的三条公理（不变性、稳定性），证明满足公理的算子需分解为特征秩表示和单调Lipschitz scalarization，对深度学习理论中的归一化方法设计有重要指导意义。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Learning with the $p$-adics
- **Authors:** Andr\'e F. T. Martins
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22692](https://arxiv.org/abs/2512.22692)
- **Reason:** 探索用p-adic数替代实数作为机器学习的基础框架，为深度学习理论提供新的几何和代数视角，作者在自然语言处理和机器学习理论领域有影响力
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Understanding the Mechanisms of Fast Hyperparameter Transfer
- **Authors:** Nikhil Ghosh, Denny Wu, Alberto Bietti
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22768](https://arxiv.org/abs/2512.22768)
- **Reason:** 建立超参数跨尺度迁移的理论框架，解释μP快速迁移的机制，对大模型高效训练的超参数选择有重要指导意义
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Principled Algorithms for Optimizing Generalized Metrics in Binary Classification
- **Authors:** Anqi Mao, Mehryar Mohri, Yutao Zhong
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23133](https://arxiv.org/abs/2512.23133)
- **Reason:** 提出优化广义 metrics的 principled算法，基于H-一致性理论解决类不平衡和非对称成本问题，为深度学习分类任务提供理论指导
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Enhancing Noise Resilience in Face Clustering via Sparse Differential Transformer
- **Authors:** Dafeng Zhang, Yongqi Song, Shizhuo Liu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22612](https://arxiv.org/abs/2512.22612)
- **Reason:** 提出Sparse Differential Transformer解决Vanilla Transformer的噪声问题，通过稀疏化和差分机制提升人脸聚类的抗噪性，属于深度学习理论的网络架构优化。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Neighbor-Aware Token Reduction via Hilbert Curve for Vision Transformers
- **Authors:** Yunge Li, Lanyu Xu
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22760](https://arxiv.org/abs/2512.22760)
- **Reason:** 提出基于Hilbert曲线的邻居感知token减少方法，保留空间连续性提升ViT效率，属于深度学习理论的网络架构优化。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Let Samples Speak: Mitigating Spurious Correlation by Exploiting the Clusterness of Samples
- **Authors:** Weiwei Li, Junzhuo Liu, Yuanyuan Ren, Yuchen Zheng, Yahao Liu, Wen Li
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22874](https://arxiv.org/abs/2512.22874)
- **Reason:** 提出数据驱动的虚假相关消除方法，通过样本聚类性识别并中和虚假特征，提升模型泛化，属于深度学习理论的模型泛化研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Pruning Graphs by Adversarial Robustness Evaluation to Strengthen GNN Defenses
- **Authors:** Yongyu Wang
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22128](https://arxiv.org/abs/2512.22128)
- **Reason:** 提出基于对抗鲁棒性评估的剪枝框架，识别并移除图中脆弱边，增强图神经网络的防御能力，在高扰动场景下性能显著提升。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] On the Existence and Behaviour of Secondary Attention Sinks
- **Authors:** Jeffrey T. H. Wong, Cheng Zhang, Louis Mahon, Wayne Luk, Anton Isopoussu, Yiren Zhao
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22213](https://arxiv.org/abs/2512.22213)
- **Reason:** 发现并分析次级注意力sink的存在和特性，揭示其在中间层的形成机制及对注意力的影响，为Transformer优化提供新视角。
Score: 7
Field: 深度学习理论

### [Score: 6.0/10] Visual Autoregressive Modelling for Monocular Depth Estimation
- **Authors:** Amir El-Ghoussani, Andr\'e Kaup, Nassir Navab, Gustavo Carneiro, Vasileios Belagiannis
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22653](https://arxiv.org/abs/2512.22653)
- **Reason:** 提出基于视觉自回归先验的单目深度估计方法，用scale-wise条件上采样和classifier-free guidance提升性能，属于深度学习理论的模型结构创新。
Score: 6
Field: 深度学习理论

## 深度学习可解释性

### [Score: 8.0/10] Pose-Guided Residual Refinement for Interpretable Text-to-Motion Generation and Editing
- **Authors:** Sukhyun Jeong, Yong-Hoon Choi
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22464](https://arxiv.org/abs/2512.22464)
- **Reason:** 提出混合表示框架，用pose码编码全局结构、残差码捕捉细粒度动态，提升文本到运动生成的可解释性与编辑性，属于深度学习可解释性的重要应用。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] KANO: Kolmogorov-Arnold Neural Operator for Image Super-Resolution
- **Authors:** Chenyu Li, Danfeng Hong, Bing Zhang, Zhaojie Pan, Jocelyn Chanussot
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22822](https://arxiv.org/abs/2512.22822)
- **Reason:** 首次将Kolmogorov-Arnold定理引入超分辨率，提出可解释的KANO算子，通过B-spline函数捕捉光谱特征，属于深度学习可解释性研究。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] EvoXplain: When Machine Learning Models Agree on Predictions but Disagree on Why -- Measuring Mechanistic Multiplicity Across Training Runs
- **Authors:** Chama Bensmail
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22240](https://arxiv.org/abs/2512.22240)
- **Reason:** 提出诊断框架，测量模型解释在重复训练中的稳定性，揭示高accuracy模型的解释多模态性，reframe可解释性为模型类的属性。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Mechanistic Analysis of Circuit Preservation in Federated Learning
- **Authors:** Muhammad Haseeb, Salaar Masood, Muhammad Abdullah Sohail
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23043](https://arxiv.org/abs/2512.23043)
- **Reason:** 用机制可解释性方法分析联邦学习Non-IID数据下的电路崩溃问题，首次揭示性能下降的内部机制，属于深度学习可解释性的重要应用
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Plug In, Grade Right: Psychology-Inspired AGIQA
- **Authors:** Zhicheng Liao, Baoliang Chen, Hanwei Zhu, Lingyu Zhu, Shiqi Wang, Weisi Lin
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.22780](https://arxiv.org/abs/2512.22780)
- **Reason:** 受心理测量学启发提出AGIQA模型，通过Arithmetic GRM模块提升质量评估的可解释性，属于深度学习可解释性研究。
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants
- **Authors:** Sheng-Kai Chen, Yi-Ling Tsai, Chun-Chih Chang, Yan-Chen Chen, Po-Chiang Lin
- **Published:** 2025-12-30
- **Link:** [https://arxiv.org/abs/2512.23312](https://arxiv.org/abs/2512.23312)
- **Reason:** 采用Shapley值归因（SHAP）解释神经逆运动学模型（IKNet）的决策机制，结合物理障碍评估揭示模型内部耦合关系，符合深度学习可解释性中Shapley value的应用方向，为可解释性在机器人安全部署中的应用提供了实证基础。
Score: 7
Field: 深度学习可解释性

