# ArXiv 每日推荐 - 2026-01-06

> 更新于北京时间：2026-01-06 12:42:32
> 已自动阅读了 172 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：96256

## 大模型安全与对齐

### [Score: 9.0/10] The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition
- **Authors:** Xiaoze Liu, Weichen Yu, Matt Fredrikson, Xiaoqian Wang, Jing Gao
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00065](https://arxiv.org/abs/2601.00065)
- **Reason:** 发现LLM组合中的tokenizer transplant漏洞，提出breaker token攻击，实现对基模型的隐蔽破坏，实验验证攻击的有效性和隐蔽性，符合大模型安全与对齐方向。
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability
- **Authors:** Zongwei Wang, Bincheng Gu, Hongyu Yu, Junliang Yu, Tao He, Jiayin Feng, Min Gao
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00240](https://arxiv.org/abs/2601.00240)
- **Reason:** 研究LLM Agent对人类的群体偏见，提出信念中毒攻击（BPA）揭示安全漏洞，并讨论缓解策略，关联大模型安全与对齐中的alignment与LLM safety研究。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching
- **Authors:** Yi Sun, Xinhao Zhong, Hongyan Li, Yimin Zhou, Junhao Li, Bin Chen, Xuan Wang
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00267](https://arxiv.org/abs/2601.00267)
- **Reason:** 提出训练-free的精准概念擦除方法ActErase，属于大模型安全与对齐方向，有效解决扩散模型中的敏感概念生成问题，提升模型安全性。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation
- **Authors:** Yiling Wang, Zeyu Zhang, Yiran Wang, Hao Tang
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00590](https://arxiv.org/abs/2601.00590)
- **Reason:** 针对文本到动作生成的安全问题，提出Minimal Motion Unlearning策略，解决现有离散码本替换方法导致的良性性能下降和动作不流畅问题，实验验证在HumanML3D和Motion-X上的Forget-set FID显著优于SOTA，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models
- **Authors:** Neeraj Anand, Samyak Jha, Udbhav Bamba, Rahul Rahaman
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00659](https://arxiv.org/abs/2601.00659)
- **Reason:** 针对视觉语言模型的幻觉问题，提出训练-free的CRoPS框架，利用多个幻觉模型的对比解码缓解幻觉，实验验证在6个基准数据集上的CHAIN得分提升20%，符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents
- **Authors:** Laksh Advani
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00513](https://arxiv.org/abs/2601.00513)
- **Reason:** 针对小模型Agent“正确但推理错误”的现象，提出Reasoning Integrity Score量化推理过程完整性，验证RAG对推理可靠性的提升，为可信智能体的过程验证提供方法，关联大模型安全与对齐中的trustworthy agent研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI
- **Authors:** Laksh Advani
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00516](https://arxiv.org/abs/2601.00516)
- **Reason:** 提出Siamese Recurrent Autoencoder结合对比学习与重构损失的Trajectory Guard模型，解决Agentic AI的轨迹异常检测问题，实现实时安全验证，性能优于基线且延迟低，关联大模型安全与对齐中的异常检测方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Adversarial Samples Are Not Created Equal
- **Authors:** Jennifer Crawford, Amol Khanna, Fred Lu, Amy R. Wagoner, Stella Biderman, Andre T. Nguyen, Edward Raff
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00577](https://arxiv.org/abs/2601.00577)
- **Reason:** 区分利用非鲁棒特征与未利用非鲁棒特征的两种对抗样本，提出集成度量量化对抗扰动对非鲁棒特征的操纵，重新审视对抗鲁棒性现象，关联大模型安全与对齐中的对抗样本研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations
- **Authors:** Longtian Qiu, Shan Ning, Chuyu Zhang, Jiaxuan Sun, Xuming He
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00623](https://arxiv.org/abs/2601.00623)
- **Reason:** 针对MLLM幻觉问题，提出难度感知的DPO框架，通过难度估计和难度感知训练平衡偏好数据的难度不平衡，在不增加额外数据或训练的情况下提升幻觉抑制效果和泛化能力，属于大模型安全与对齐的重要方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] A Comprehensive Dataset for Human vs. AI Generated Image Detection
- **Authors:** Rajarshi Roy, Nasrin Imanpour, Ashhar Aziz, Shashwat Bajpai, Gurpreet Singh, Shwetangshu Biswas, Kapil Wanaskar, Parth Patwa, Subhankar Ghosh, Shreyas Dixit, Nilesh Ranjan Pal, Vipula Rawte, Ritvik Garimella, Gaytri Jena, Vasu Sharma, Vinija Jain, Aman Chadha, Aishwarya Naresh Reganti, Amitava Das
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00553](https://arxiv.org/abs/2601.00553)
- **Reason:** 构建MS COCOAI数据集用于AI生成图像检测，属于大模型安全与对齐方向，为解决生成内容的安全问题（如虚假信息）提供基础资源。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Explicit Abstention Knobs for Predictable Reliability in Video Question Answering
- **Authors:** Jorge Ortiz
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00138](https://arxiv.org/abs/2601.00138)
- **Reason:** 提出显式弃权机制提高视频QA的可靠性，通过阈值调整平衡准确性与弃权率，关联大模型安全与对齐中的predictable reliability研究。
Score: 7
Field: 大模型安全与对齐

## 深度学习理论

### [Score: 9.0/10] Deep Networks Learn Deep Hierarchical Models
- **Authors:** Amit Daniely
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00455](https://arxiv.org/abs/2601.00455)
- **Reason:** 证明层wise SGD可以高效学习深度分层模型，该模型类超越之前的可学习模型，理论分析人类教师标签对分层结构学习的促进作用，符合深度学习理论方向。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering
- **Authors:** Hongxi Li, Chunlin Huang
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00276](https://arxiv.org/abs/2601.00276)
- **Reason:** 推导宽L2正则化网络的task-driven kernel ODE，证明监督学习的低秩特性和SGD噪声的低秩性，统一确定性和随机视角的对齐，符合深度学习理论方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Deep Delta Learning
- **Authors:** Yifan Zhang, Yifeng Liu, Mengdi Wang, Quanquan Gu
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00417](https://arxiv.org/abs/2601.00417)
- **Reason:** 提出Delta Operator替代残差连接，实现数据依赖的几何变换，动态控制特征更新，理论分析其谱特性，实验验证优于传统残差网络，符合深度学习理论方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making
- **Authors:** Tiansi Dong, Henry He, Pietro Liò, Mateja Jamnik
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00142](https://arxiv.org/abs/2601.00142)
- **Reason:** 提出Sphere Neural Networks，将概念嵌入为球面上的圆，实现可靠的逻辑推理并解决灾难性遗忘，属于深度学习理论中的network architecture研究。
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception
- **Authors:** Xianhui Liu, Siqi Jiang, Yi Xie, Yuqing Lin, Siao Liu
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00598](https://arxiv.org/abs/2601.00598)
- **Reason:** 研究多模态感知中的优化偏差问题，提出Modality Dominance Index量化模态主导性，设计MDACL框架缓解优化偏差，实验验证在RGB-IR基准数据集上的SOTA性能，符合深度学习理论方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations
- **Authors:** Hyunjun Kim
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00457](https://arxiv.org/abs/2601.00457)
- **Reason:** 分析MoE中几何正则化的效果，发现权重与激活空间的正交性无显著相关，正则化无法有效减少重叠，为MoE正则化设计提供新见解，符合深度学习理论方向。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Learning to be Reproducible: Custom Loss Design for Robust Neural Networks
- **Authors:** Waqas Ahmed, Sheeba Samuel, Kevin Coakley, Birgitta Koenig-Ries, Odd Erik Gundersen
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00578](https://arxiv.org/abs/2601.00578)
- **Reason:** 提出Custom Loss Function（CLF）减少模型对随机因素的敏感性，平衡准确性与训练稳定性，提高模型可重复性与鲁棒性，属于深度学习理论中的损失函数设计研究。
Score: 7
Field: 深度学习理论

## 深度学习可解释性

### [Score: 9.0/10] Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning
- **Authors:** Valentin Noël
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00791](https://arxiv.org/abs/2601.00791)
- **Reason:** Spectral Signatures of Valid Mathematical Reasoning
Authors: Valentin Noël
Published: 2026-01-05
Link: https://arxiv.org/abs/2601.00791
Reason: 提出训练-free的光谱分析方法，通过attention矩阵的图谱特征检测LLM数学推理的有效性，准确率高且无需微调，属于深度学习可解释性中的white-box explanation研究。
Score: 9
Field: 深度学习可解释性

### [Score: 8.0/10] A Comparative Analysis of Interpretable Machine Learning Methods
- **Authors:** Mattia Billa, Giovanni Orlandi, Veronica Guidetti, Federica Mandreoli
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00428](https://arxiv.org/abs/2601.00428)
- **Reason:** 系统比较16种可解释ML方法在216个真实表格数据集上的性能，分析数据集结构特征对性能的影响，提供可解释方法选择的实践指导，符合深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Controllable Concept Bottleneck Models
- **Authors:** Hongbin Lin, Chenyang Ren, Juangui Xu, Zhengyu Hu, Cheng-Long Wang, Yao Shu, Hui Xiong, Jingfeng Zhang, Di Wang, Lijie Hu
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00451](https://arxiv.org/abs/2601.00451)
- **Reason:** 提出可控的概念瓶颈模型CCBM，支持多粒度编辑，利用影响函数实现闭式近似，避免重新训练，实验验证其效率和适应性，符合深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability
- **Authors:** Kasra Fouladi, Hamta Rahmani
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00655](https://arxiv.org/abs/2601.00655)
- **Reason:** 提出IGBO框架，结合可解释性（如Temporal Integrated Gradients）与准确性的双目标优化，通过DAG约束特征重要性，实验验证有效，属于深度学习可解释性中的引导优化研究。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs
- **Authors:** Akash Kumar Panda, Olaoluwa Adigun, Bart Kosko
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00097](https://arxiv.org/abs/2601.00097)
- **Reason:** 提出Agentic框架用LLM从文本中提取因果反馈FCM，通过FCM的动力系统平衡LLM的自主性与可控性，属于深度学习可解释性中的因果推理研究。
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering
- **Authors:** Chaodong Tong, Qi Zhang, Chen Li, Lei Jiang, Yanbing Liu
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00269](https://arxiv.org/abs/2601.00269)
- **Reason:** 提出FaithSCAN框架检测VQA幻觉，通过分析模型内部信号理解幻觉成因，属于深度学习可解释性方向，提升多模态模型的可靠性。
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] The Illusion of Insight in Reasoning Models
- **Authors:** Liv G. d'Aliberti, Manoel Horta Ribeiro
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00514](https://arxiv.org/abs/2601.00514)
- **Reason:** 研究推理模型的“insight”幻觉问题，通过分析1M+推理轨迹、多模型架构等，发现mid-reasoning shifts是不稳定推理行为的症状而非真正的自我纠正机制，对理解模型推理行为的可解释性有重要价值。
Score: 7
Field: 深度学习可解释性

## 原生多模态大模型

### [Score: 8.0/10] TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model
- **Authors:** Yabo Chen, Yuanzhi Liang, Jiepeng Wang, Tingxi Chen, Junfei Cheng, Zixiao Gu, Yuyang Huang, Zicheng Jiang, Wei Li, Tian Li, Weichen Li, Zuoxin Li, Guangce Liu, Jialun Liu, Junqi Liu, Haoyuan Wang, Qizhen Weng, Xuan'er Wu, Xunzhi Xiang, Xiaoyan Yang, Xin Zhang, Shiwen Zhang, Junyu Zhou, Chengcheng Zhou, Haibin Huang, Chi Zhang, Xuelong Li
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00051](https://arxiv.org/abs/2601.00051)
- **Reason:** 提出4D世界模型框架TeleWorld，整合多模态动态合成、场景重建与长期记忆，聚焦原生多模态大模型的核心方向（多模态整合、图像生成、世界模型），对多模态大模型的实用化有重要推进。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians
- **Authors:** Melonie de Almeida, Daniela Ivanova, Tong Shi, John H. Williamson, Paul Henderson
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00678](https://arxiv.org/abs/2601.00678)
- **Reason:** 提出单向前向的3D高斯场景表示框架，实现camera-guided的图像到视频生成，实验验证在KITTI、Waymo等数据集上的SOTA性能和推理效率，符合原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation
- **Authors:** Taekyung Ki, Sangwon Jang, Jaehyeong Jo, Jaehong Yoon, Sung Ju Hwang
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00664](https://arxiv.org/abs/2601.00664)
- **Reason:** 提出Avatar Forcing框架，基于扩散模型实现实时多模态输入（音频、动作）的互动头像生成，低延迟且表情丰富，属于原生多模态大模型中的image generation与native multi-modal研究。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark
- **Authors:** Pan Wang, Yang Liu, Guile Wu, Eduardo R. Corral-Soto, Chengjie Huang, Binbin Xu, Dongfeng Bai, Xu Yan, Yuan Ren, Xingxin Chen, Yizhe Wu, Tao Huang, Wenjun Wan, Xin Wu, Pei Zhou, Xuyang Dai, Kangbo Lv, Hongbo Zhang, Yosef Fried, Aixue Ye, Bailan Feng, Zhenyu Chen, Zhen Li, Yingcong Chen, Yiyi Liao, Bingbing Liu
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00092](https://arxiv.org/abs/2601.00092)
- **Reason:** 构建覆盖多认知任务的4D空间推理基准，系统评估多模态大模型的空间理解能力，为原生多模态大模型的能力迭代提供关键评测依据。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding
- **Authors:** He Wang, Longteng Guo, Pengkang Huo, Xuanxu Lin, Yichen Yuan, Jie Jiang, Jing Liu
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00264](https://arxiv.org/abs/2601.00264)
- **Reason:** 构建跨学科的科学图表-文本多模态数据集，为原生多模态大模型提供基础训练资源，助力提升模型的跨领域理解能力。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos
- **Authors:** Yuxue Yang, Lue Fan, Ziqi Shi, Junran Peng, Feng Wang, Zhaoxiang Zhang
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00393](https://arxiv.org/abs/2601.00393)
- **Reason:** 提出NeoVerse框架利用野外单目视频增强4D世界模型，属于原生多模态大模型方向，提升模型对现实场景的理解能力。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] CPPO: Contrastive Perception for Vision Language Policy Optimization
- **Authors:** Ahmad Rezaei, Mohsen Gholami, Saeed Ranjbar Alvar, Kevin Cannons, Mohammad Asiful Hossain, Zhou Weimin, Shunbo Zhou, Yong Zhang, Mohammad Akbari
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00501](https://arxiv.org/abs/2601.00501)
- **Reason:** 提出对比感知的视觉语言政策优化方法CPPO，属于原生多模态大模型方向，提升多模态模型的感知与推理协同能力。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models
- **Authors:** Jintao Lin, Bowen Dong, Weikang Shi, Chenyang Lei, Suiyun Zhang, Rui Liu, Xihui Liu
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00561](https://arxiv.org/abs/2601.00561)
- **Reason:** 提出AEGIS基准评估统一多模态模型的世界知识能力，属于原生多模态大模型方向，为理解多模态模型的知识应用能力提供关键评测依据。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval
- **Authors:** Mingyu Jeon, Sunjae Yoon, Jonghee Kim, Junyeoung Kim
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00584](https://arxiv.org/abs/2601.00584)
- **Reason:** 提出GranAlign框架解决零样本视频时刻检索的语义粒度不匹配问题，属于原生多模态大模型方向，提升视频-文本对齐的准确性。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Grading Handwritten Engineering Exams with Multimodal Large Language Models
- **Authors:** Janez Perš, Jon Muhovič, Andrej Košir, Boštjan Murovec
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00730](https://arxiv.org/abs/2601.00730)
- **Reason:** 提出端到端的多模态LLM workflow，处理手写工程试卷的文本和图，实现自动批改，实验验证在真实课程中的性能，符合原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

### [Score: 6.0/10] OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning
- **Authors:** Liuxiang Qiu, Hui Da, Yuzhen Niu, Tiesong Zhao, Yang Cao, Zheng-Jun Zha
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00352](https://arxiv.org/abs/2601.00352)
- **Reason:** 提出单域泛化框架OmniVaT，解决多模态视觉-触觉学习的跨域适应问题，属于原生多模态大模型方向，提升模型的现实场景适应能力。
Score: 6
Field: 原生多模态大模型

## 大模型新技术

### [Score: 8.0/10] FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection
- **Authors:** Ruiqiang Zhang, Hengyi Wang, Chang Liu, Guanjie Wang, Zehua Ma, Weiming Zhang
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00535](https://arxiv.org/abs/2601.00535)
- **Reason:** 提出训练-free的扩散Transformer文本渲染方法FreeText，属于大模型新技术（diffusion LLM）方向，有效提升文本-图像生成的准确性与灵活性。
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models
- **Authors:** Anne Harrington, A. Sophia Koepke, Shyamgopal Karthik, Trevor Darrell, Alexei A. Efros
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00090](https://arxiv.org/abs/2601.00090)
- **Reason:** 针对扩散模型的模式崩溃问题提出噪声优化方法，属于大模型新技术（diffusion模型改进），有效提升扩散模型的生成多样性与稳定性。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models
- **Authors:** Shengjun Zhang, Zhang Zhang, Chensheng Dai, Yueqi Duan
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00423](https://arxiv.org/abs/2601.00423)
- **Reason:** 提出熵感知的Group Relative Policy Optimization，合并低熵步骤为高熵步骤，提升SDE采样的效率，实验验证在不同奖励设置下的有效性，符合大模型新技术方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Categorical Reparameterization with Denoising Diffusion models
- **Authors:** Samson Gourevitch, Alain Durmus, Eric Moulines, Jimmy Olsson, Yazid Janati
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00781](https://arxiv.org/abs/2601.00781)
- **Reason:** 提出扩散模型的分类重参数化方法，利用训练-free的扩散采样器改善梯度优化性能，属于大模型新技术中的diffusion LLM研究。
Score: 7
Field: 大模型新技术

### [Score: 6.0/10] Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting
- **Authors:** Aarya Sumuk
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00368](https://arxiv.org/abs/2601.00368)
- **Reason:** 提出掩码条件体素扩散方法，用于3D几何与颜色联合修复，属于大模型新技术（diffusion）方向，拓展扩散模型的3D应用场景。
Score: 6
Field: 大模型新技术

## 高效大模型训练与推理

### [Score: 8.0/10] GRIT -- Geometry-Aware PEFT with K-FAC Preconditioning, Fisher-Guided Reprojection, and Dynamic Rank Adaptation
- **Authors:** Pritish Saha, Chandrav Rajbangshi, Rudra Goyal, Mohit Goyal, Anurag Deo, Biswajit Roy, Ningthoujam Dhanachandra Singh, Raxit Goswami, Amitava Das
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00231](https://arxiv.org/abs/2601.00231)
- **Reason:** 提出几何感知的PEFT方法GRIT，结合K-FAC预处理、Fisher-guided重投影和动态秩自适应，减少训练参数同时保持性能，实验验证在多个基准上优于LoRA和QLoRA，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts
- **Authors:** Zihan Fang, Zheng Lin, Senkang Hu, Yanan Ma, Yihang Tao, Yiqin Deng, Xianhao Chen, Yuguang Fang
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00583](https://arxiv.org/abs/2601.00583)
- **Reason:** 提出HFedMoE框架，结合联邦学习与MoE解决资源异构客户端的LLM微调问题，通过专家选择与稀疏聚合提高训练效率，关联高效大模型训练与推理中的MoE与联邦学习方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Memory Bank Compression for Continual Adaptation of Large Language Models
- **Authors:** Thomas Katraouras, Dimitrios Rafailidis
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00756](https://arxiv.org/abs/2601.00756)
- **Reason:** 提出MBC模型，通过codebook优化压缩LLM持续适应中的记忆库，减少内存使用同时保持精度，关联高效大模型训练与推理中的high compression方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems
- **Authors:** Shanli Xing, Yiyan Zhai, Alexander Jiang, Yixin Dong, Yong Wu, Zihao Ye, Charlie Ruan, Yingyi Huang, Yineng Zhang, Liangsheng Yin, Aksara Bayyapu, Luis Ceze, Tianqi Chen
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00227](https://arxiv.org/abs/2601.00227)
- **Reason:** 提出FlashInfer-Bench框架，连接LLM Agent的kernel生成、基准测试与部署，建立标准化闭环流程，关联高效大模型训练与推理中的LLM infra方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks
- **Authors:** Cory Fan, Wenchao Zhang
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00703](https://arxiv.org/abs/2601.00703)
- **Reason:** 提出空间下采样的各向同性网络，提升demosaicing的效率和性能，适用于移动平台，实验验证JD3Net在多个任务上的强性能，符合高效大模型训练与推理方向。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Federated Customization of Large Models: Approaches, Experiments, and Insights
- **Authors:** Yuchuan Ye, Ming Ding, Youjia Chen, Peng Cheng, Dusit Niyato
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00526](https://arxiv.org/abs/2601.00526)
- **Reason:** 探索联邦学习框架下的大模型定制方法（如prefix-tuning），验证其在联邦场景的可行性与性能，为高效大模型训练中的联邦定制提供实践 insights。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Do Chatbot LLMs Talk Too Much? The YapBench Benchmark
- **Authors:** Vadim Borisov, Michael Gröger, Mina Mikhael, Richard H. Schreiber
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00624](https://arxiv.org/abs/2601.00624)
- **Reason:** 提出YapBench基准测试LLM的冗余输出问题，量化verbosity并分析模型性能，为减少LLM推理的token成本提供评估工具，关联高效大模型训练与推理中的推理效率方向。
Score: 7
Field: 高效大模型训练与推理

### [Score: 6.0/10] LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization
- **Authors:** Jie Li, Kwan-Yee K. Wong, Kai Han
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00222](https://arxiv.org/abs/2601.00222)
- **Reason:** 提出低维码本的组合向量量化方法LooC，聚焦高效大模型训练与推理中的高压缩方向，显著提升向量量化的效率与性能。
Score: 6
Field: 高效大模型训练与推理

### [Score: 6.0/10] Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers
- **Authors:** Söhnke Benedikt Fischedick, Daniel Seichter, Benedict Stephan, Robin Schmidt, Horst-Michael Gross
- **Published:** 2601-01-05
- **Link:** [https://arxiv.org/abs/2601.00359](https://arxiv.org/abs/2601.00359)
- **Reason:** 提出DVEFormer通过知识蒸馏与RGB-D Transformer实现高效密集视觉嵌入预测，属于高效大模型训练与推理方向，满足实时应用需求。
Score: 6
Field: 高效大模型训练与推理

## 多模态智能体

### [Score: 7.0/10] RoboReward: General-Purpose Vision-Language Reward Models for Robotics
- **Authors:** Tony Lee, Andrew Wagenmaker, Karl Pertsch, Percy Liang (Stanford University), Sergey Levine (University of California, Berkeley), Chelsea Finn (Stanford University)
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00675](https://arxiv.org/abs/2601.00675)
- **Reason:** 构建了机器人领域的视觉-语言奖励数据集RoboReward，提出负例数据增强 pipeline生成校准的负例和近 misses，训练的通用VL奖励模型在真实机器人强化学习中提升效果，连接了视觉-语言模型与多模态智能体的 reward设计，对多模态智能体的发展有实践价值。
Score: 7
Field: 多模态智能体

### [Score: 6.0/10] LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration
- **Authors:** Abu Hanif Muhammad Syarubany, Farhan Zaki Rahmani, Trio Widianto
- **Published:** 2026-01-05
- **Link:** [https://arxiv.org/abs/2601.00555](https://arxiv.org/abs/2601.00555)
- **Reason:** 提出端到端的LLM-based多模态智能体系统，处理室内购物任务，结合LLM的自然语言理解、视觉语义地图构建、机器人运动控制，实现从用户指令到导航和物体检索的端到端执行，属于多模态智能体的实践应用。
Score: 6
Field: 多模态智能体

