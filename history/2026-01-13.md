# ArXiv 每日推荐 - 2026-01-13

> 更新于北京时间：2026-01-13 12:41:35
> 已自动阅读了 147 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：81632

## 高效大模型训练与推理

### [Score: 9.0/10] MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs
- **Authors:** Jiyuan Zhang, Yining Liu, Siqi Yan, Lisen Deng, Jennifer Cao, Shuqi Yang, Min Ni, Bi Xue, Shen Li
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05296](https://arxiv.org/abs/2601.05296)
- **Reason:** 针对MoE训练的内存瓶颈，提出端到端优化的数据结构与核设计，实现4倍加速与50%内存节省，是高效大模型训练与推理中MoE架构优化的重要突破。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning
- **Authors:** Jingcheng Hu, Yinmin Zhang, Shijie Shang, Xiaobo Yang, Yue Peng, Zhewei Huang, Hebin Zhou, Xin Wu, Jie Cheng, Fanqi Wan, Xiangwen Kong, Chengyuan Yao, Kaiwen Yan, Ailin Huang, Hongyu Zhou, Qi Han, Zheng Ge, Daxin Jiang, Xiangyu Zhang, Heung-Yeung Shum
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05593](https://arxiv.org/abs/2601.05593)
- **Reason:** 提出并行协调推理框架，突破传统 sequential推理的计算限制，将测试时计算扩展至百万token级，显著提升数学推理性能，是高效大模型训练与推理的重要创新。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding
- **Authors:** Yuxuan Zhou, Fei Huang, Heng Li, Fengyi Wu, Tianyu Wang, Jianwei Zhang, Junyang Lin, Zhi-Qi Cheng
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05724](https://arxiv.org/abs/2601.05724)
- **Reason:** 提出Hierarchical Speculative Decoding（HSD），通过分层验证解决投机解码的联合不可处理问题，提升接受率与推理效率，实验表明集成到EAGLE-3后性能提升12%且保持分布保真度，是高效LLM推理的关键技术突破。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] Sketch&Patch++: Efficient Structure-Aware 3D Gaussian Representation
- **Authors:** Yuang Shi, Simone Gasparini, Géraldine Morin, Wei Tsang Ooi
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05394](https://arxiv.org/abs/2601.05394)
- **Reason:** 提出结构感知的3D高斯表示，提升存储和推理效率，属于高效大模型训练与推理中的高压缩
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching
- **Authors:** Hongyaoxing Gul, Lijuan Hu, Shuzi Niu, Fangfang Liu
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05684](https://arxiv.org/abs/2601.05684)
- **Reason:** 提出灵活低秩矩阵草图方法，快速选择最优秩以提升量化效率与质量，属于高效大模型训练与推理中模型压缩方向的进展。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Distilling Lightweight Domain Experts from Large ML Models by Identifying Relevant Subspaces
- **Authors:** Pattarawat Chormai, Ali Hashemi, Klaus-Robert M\"uller, Gr\'egoire Montavon
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05913](https://arxiv.org/abs/2601.05913)
- **Reason:** 提出SubDistill蒸馏算法，聚焦特定子任务蒸馏大模型的相关组件，提升小模型性能及与教师模型的决策结构一致性，解决现有蒸馏未针对性处理子任务的问题，实验验证在CIFAR-100和ImageNet上的优势，作者团队包含知名学者Klaus-Robert M\"uller。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] STResNet & STYOLO : A New Family of Compact Classification and Object Detection Models for MCUs
- **Authors:** Sudhakar Sah, Ravish Kumar
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05364](https://arxiv.org/abs/2601.05364)
- **Reason:** 针对MCU设计轻量模型，属于高效大模型训练与推理中的模型压缩和边缘设备高效推理
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] EdgeLDR: Quaternion Low-Displacement Rank Neural Networks for Edge-Efficient Deep Learning
- **Authors:** Vladimir Frants, Sos Agaian, Karen Panetta
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05379](https://arxiv.org/abs/2601.05379)
- **Reason:** 利用四元数低位移秩网络提升边缘设备效率，属于高效大模型训练与推理中的模型压缩和边缘高效推理
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] One Language-Free Foundation Model Is Enough for Universal Vision Anomaly Detection
- **Authors:** Bin-Bin Gao, Chengjie Wang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05552](https://arxiv.org/abs/2601.05552)
- **Reason:** 参数高效的通用异常检测模型，属于高效大模型训练与推理中的参数高效训练
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] GS-DMSR: Dynamic Sensitive Multi-scale Manifold Enhancement for Accelerated High-Quality 3D Gaussian Splatting
- **Authors:** Nengbo Lu, Minghua Pan, Shaohua Sun, Yizhou Liang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05584](https://arxiv.org/abs/2601.05584)
- **Reason:** 加速3D高斯 splatting的训练，属于高效大模型训练与推理中的高效训练
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] LatentVLA: Efficient Vision-Language Models for Autonomous Driving via Latent Action Prediction
- **Authors:** Chengen Xie, Bin Sun, Tianyu Li, Junjie Wu, Zhihui Hao, XianPeng Lang, Hongyang Li
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05611](https://arxiv.org/abs/2601.05611)
- **Reason:** 高效的Vision-Language模型用于自动驾驶，属于高效大模型训练与推理中的高效推理
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Compressing image encoders via latent distillation
- **Authors:** Caroline Mazini Rodrigues (IRISA, CNRS), Nicolas Keriven (CNRS, IRISA, COMPACT), Thomas Maugey (COMPACT)
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05639](https://arxiv.org/abs/2601.05639)
- **Reason:** 通过潜在蒸馏压缩图像编码器，属于高效大模型训练与推理中的高压缩
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time
- **Authors:** Christopher Thirgood, Oscar Mendez, Erin Ling, Jon Storey, Simon Hadfield
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05738](https://arxiv.org/abs/2601.05738)
- **Reason:** 实时3D高斯 SLAM，属于高效大模型训练与推理中的实时推理
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers
- **Authors:** Guray Ozgur, Eduarda Caldeira, Tahar Chettaoui, Jan Niklas Kolf, Marco Huber, Naser Damer, Fadi Boutros
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05741](https://arxiv.org/abs/2601.05741)
- **Reason:** 训练-free的面部质量评估，属于高效大模型训练与推理中的高效训练
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Over-Searching in Search-Augmented Large Language Models
- **Authors:** Roy Xie, Deepak Gopinath, David Qiu, Dong Lin, Haitian Sun, Saloni Potdar, Bhuwan Dhingra
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05503](https://arxiv.org/abs/2601.05503)
- **Reason:** 系统分析搜索增强LLM的过搜索问题，提出TPC指标量化性能-成本权衡，探索缓解策略，对高效大模型推理中的搜索策略优化有实践价值。
Score: 7
Field: 高效大模型训练与推理

## 深度学习可解释性

### [Score: 9.0/10] Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer
- **Authors:** Yifan Zhang, Wei Bi, Kechi Zhang, Dongming Jin, Jie Fu, Zhi Jin
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05770](https://arxiv.org/abs/2601.05770)
- **Reason:** 提出Discrete Transformer架构，通过功能解耦与温度退火采样从Transformer中提取可解释算法，解决superposition问题，是深度学习可解释性中白盒解释的重要突破。
Score: 9
Field: 深度学习可解释性

### [Score: 8.0/10] Do Sparse Autoencoders Identify Reasoning Features in Language Models?
- **Authors:** George Ma, Zhongyuan Liang, Irene Y. Chen, Somayeh Sojoudi
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05679](https://arxiv.org/abs/2601.05679)
- **Reason:** 通过因果实验与LLM引导伪造，揭示SAE主要捕捉语言相关特征而非推理计算，对深度学习可解释性中的白盒解释方法评估有关键启示。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] ART: Adaptive Reasoning Trees for Explainable Claim Verification
- **Authors:** Sahil Wadhwa, Himanshu Kumar, Guanqun Yang, Abbaas Alif Mohamed Nishar, Pranab Mohanty, Swapnil Shinde, Yue Wu
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05455](https://arxiv.org/abs/2601.05455)
- **Reason:** 提出Adaptive Reasoning Trees框架，通过分层推理（根主张分支为支持/攻击论据）及pairwise裁判评估，提升主张验证的可解释性与可靠性，解决LLM输出不可解释的问题，实验表明优于Chain-of-Thought等基线，建立可解释验证新基准。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Explainable AI: Learning from the Learners
- **Authors:** Ricardo Vinuesa, Steven L. Brunton, Gianmarco Mengaldo
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05525](https://arxiv.org/abs/2601.05525)
- **Reason:** 提出可解释AI（XAI）结合因果推理的框架，用于科学工程中的发现、优化与认证，强调通过XAI提取模型内部机制实现人类-AI协作，为可解释性研究提供新视角。
Score: 8
Field: 深度学习可解释性

## 大模型安全与对齐

### [Score: 9.0/10] Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making
- **Authors:** Jua Han, Jaeyoon Seo, Jungbin Min, Jean Oh, Jihie Kim
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05529](https://arxiv.org/abs/2601.05529)
- **Reason:** 系统评估LLM在安全关键机器人决策（如火灾疏散）中的风险，设计完全信息、不完全信息、安全空间推理三类任务，发现当前LLM存在严重漏洞（如ASCII导航0%成功、引导机器人走向危险），强调LLM不适合直接部署，对大模型安全对齐研究有重要警示意义。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] VIB-Probe: Detecting and Mitigating Hallucinations in Vision-Language Models via Variational Information Bottleneck
- **Authors:** Feiran Zhang, Yixin Wu, Zhenghua Wang, Xiaohua Wang, Changze Lv, Xuanjing Huang, Xiaoqing Zheng
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05547](https://arxiv.org/abs/2601.05547)
- **Reason:** 检测和缓解Vision-Language Models的幻觉，属于大模型安全与对齐中的安全问题解决
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] SceneAlign: Aligning Multimodal Reasoning to Scene Graphs in Complex Visual Scenes
- **Authors:** Chuhan Wang, Xintong Li, Jennifer Yuntong Zhang, Junda Wu, Chengkai Huang, Lina Yao, Julian McAuley, Jingbo Shang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05600](https://arxiv.org/abs/2601.05600)
- **Reason:** 多模态推理对齐场景图，属于大模型安全与对齐中的对齐问题解决
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models
- **Authors:** Cooper Lin, Maohao Ran, Yanting Zhang, Zhenglin Wan, Hongwei Fan, Yibo Xu, Yike Guo, Wei Xue, Jun Song
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05570](https://arxiv.org/abs/2601.05570)
- **Reason:** 提出多代理POMDP基准Crisis-Bench，评估LLM在企业危机中的声誉管理能力，发现通用安全对齐与专业效用的矛盾，为 context-aware 专业对齐研究提供量化框架。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility
- **Authors:** G M Shahariar, Zabir Al Nazi, Md Olid Hasan Bhuiyan, Zhouxing Shi
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05739](https://arxiv.org/abs/2601.05739)
- **Reason:** 提出PII-VisBench基准，分层评估VLM在不同主体可见度下的PII泄露风险，发现模型对高可见度主体的PII披露率更高，为VLM隐私安全对齐提供量化评估工具。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] What's Left Unsaid? Detecting and Correcting Misleading Omissions in Multimodal News Previews
- **Authors:** Fanxiao Li, Jiaying Wu, Tingchao Fu, Dayang Li, Herun Wan, Wei Zhou, Min-Yen Kan
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05563](https://arxiv.org/abs/2601.05563)
- **Reason:** 检测多模态新闻预览的误导性，属于大模型安全与对齐中的安全问题解决
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Generalizable and Adaptive Continual Learning Framework for AI-generated Image Detection
- **Authors:** Hanyi Wang, Jun Lan, Yaoyu Kang, Huijia Zhu, Weiqiang Wang, Zhuosheng Zhang, Shilin Wang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05580](https://arxiv.org/abs/2601.05580)
- **Reason:** AI生成图像检测的持续学习框架，属于大模型安全与对齐中的安全问题解决
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints
- **Authors:** Adrian Serrano, Erwan Umlil, Ronan Thomas
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05986](https://arxiv.org/abs/2601.05986)
- **Reason:** 系统评估Deepfake检测模型在真实场景下的对抗鲁棒性，分析攻击-防御 mismatch 场景的性能，对大模型安全与对齐中的对抗攻击防御研究有参考价值。
Score: 7
Field: 大模型安全与对齐

## 深度学习理论

### [Score: 8.0/10] Bi-Orthogonal Factor Decomposition for Vision Transformers
- **Authors:** Fenil R. Doshi, Thomas Fel, Talia Konkle, George Alvarez
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05328](https://arxiv.org/abs/2601.05328)
- **Reason:** 研究Vision Transformers的注意力机制，通过双正交因子分解解析位置和内容因素，属于深度学习理论中的网络架构分析
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection
- **Authors:** Feihu Jin, Ying Tan
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05501](https://arxiv.org/abs/2601.05501)
- **Reason:** 提出分层混合优化框架，结合一阶优化的精度与零阶优化的探索能力，解决LLM微调的局部最优问题，属于深度学习理论中优化器方向的创新。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Transformer Is Inherently a Causal Learner
- **Authors:** Xinyue Wang, Stephen Wang, Biwei Huang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05647](https://arxiv.org/abs/2601.05647)
- **Reason:** 证明自回归Transformer自然编码时间延迟因果结构，通过梯度敏感性恢复因果图，对深度学习理论中Transformer架构的因果特性研究有重要贡献。
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] ROAP: A Reading-Order and Attention-Prior Pipeline for Optimizing Layout Transformers in Key Information Extraction
- **Authors:** Tingwei Xie, Jinxin He, Yonghong Song
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05470](https://arxiv.org/abs/2601.05470)
- **Reason:** 优化Layout Transformers的注意力机制，属于深度学习理论中的网络架构改进
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Quantifying and Inducing Shape Bias in CNNs via Max-Pool Dilation
- **Authors:** Takito Sawada, Akinori Iwata, Masahiro Okuda
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05599](https://arxiv.org/abs/2601.05599)
- **Reason:** 量化和诱导CNN的形状偏差，属于深度学习理论中的网络架构分析
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Learning Geometric Invariance for Gait Recognition
- **Authors:** Zengbin Wang, Junjie Li, Saihui Hou, Xu Liu, Chunshui Cao, Yongzhen Huang, Muyi Sun, Siye Wang, Man Zhang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05604](https://arxiv.org/abs/2601.05604)
- **Reason:** 学习步态识别的几何不变性，属于深度学习理论中的网络架构改进
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Adaptive Disentangled Representation Learning for Incomplete Multi-View Multi-Label Classification
- **Authors:** Quanjiang Li, Zhiming Liu, Tianxiang Xu, Tingjin Luo, Chenping Hou
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05785](https://arxiv.org/abs/2601.05785)
- **Reason:** 自适应解纠缠表示学习，属于深度学习理论中的表示学习创新
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Poisson Hyperplane Processes with Rectified Linear Units
- **Authors:** Shufei Ge, Shijia Wang, Lloyd Elliott
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05586](https://arxiv.org/abs/2601.05586)
- **Reason:** 建立Poisson超平面过程与两层ReLU神经网络的概率联系，提出贝叶斯推理算法，对深度学习理论中ReLU架构的概率表示有深入研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations
- **Authors:** Yongyi Yang, Jianyang Gao
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05732](https://arxiv.org/abs/2601.05732)
- **Reason:** 改进Hyper-Connections架构，通过显式构造双随机矩阵避免迭代不稳定性，提升训练稳定性与吞吐量，属于深度学习理论中网络架构优化的进展。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers
- **Authors:** Mohamed Amine Hallam, Kuo-Kun Tseng
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05807](https://arxiv.org/abs/2601.05807)
- **Reason:** 系统分析位置编码融合机制对长序列Transformer性能的影响，发现融合策略是长序列任务的关键设计选择，属于深度学习理论中网络架构优化的研究。
Score: 7
Field: 深度学习理论

## 原生多模态大模型

### [Score: 8.0/10] MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding
- **Authors:** Zizhong Li, Haopeng Zhang, Jiawei Zhang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05495](https://arxiv.org/abs/2601.05495)
- **Reason:** 多模态多粒度表示用于长视频理解，属于原生多模态大模型的视频理解
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] MoGen: A Unified Collaborative Framework for Controllable Multi-Object Image Generation
- **Authors:** Yanfeng Li, Yue Sun, Keren Fu, Sio-Kei Im, Xiaoming Liu, Guangtao Zhai, Xiaohong Liu, Tao Tan
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05546](https://arxiv.org/abs/2601.05546)
- **Reason:** 可控多目标图像生成的统一框架，属于原生多模态大模型的图像生成
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] SceneFoundry: Generating Interactive Infinite 3D Worlds
- **Authors:** ChunTeng Chen, YiChen Hsu, YiWen Liu, WeiFang Sun, TsaiChing Ni, ChunYi Lee, Min Sun, YuanFu Yang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05810](https://arxiv.org/abs/2601.05810)
- **Reason:** 生成交互式3D世界，属于原生多模态大模型的图像生成
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] Phase4DFD: Multi-Domain Phase-Aware Attention for Deep
- **Authors:** Mehrdad Fazli, Bowen Wei, Ziwei Zhu
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05939](https://arxiv.org/abs/2601.05939)
- **Reason:** 针对视觉语言模型的幻觉问题，提出训练-free的Context Embedding Injection方法，通过层-wise生成动态分析提升视觉忠实性，对原生多模态大模型的可靠性研究有重要价值。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction
- **Authors:** Longbin Ji, Xiaoxiong Liu, Junyuan Shang, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05966](https://arxiv.org/abs/2601.05966)
- **Reason:** 提出 autoregressive视频生成框架VideoAR，结合多尺度下一帧预测解决扩散模型的计算密集问题，提升时间一致性与效率，属于原生多模态大模型中的视频生成方向关键进展。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces
- **Authors:** Yeonsang Shin, Insoo Kim, Bongkeun Kim, Keonwoo Bae, Bohyung Han
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05680](https://arxiv.org/abs/2601.05680)
- **Reason:** 提出联合离散-连续空间的变长序列生成框架，解决传统离散化方法的精度问题，应用于半导体布局等高精度领域，属于原生多模态大模型中的生成方向创新。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] Coding the Visual World: From Image to Simulation Using Vision Language Models
- **Authors:** Sagi Eppel
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05344](https://arxiv.org/abs/2601.05344)
- **Reason:** 利用Vision Language Models生成代码模拟图像，涉及多模态大模型的图像理解和生成应用
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting
- **Authors:** Xuan Cheng, Jiahao Rao, Chengyang Li, Wenhao Wang, Weilin Chen, Lvqing Yang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05511](https://arxiv.org/abs/2601.05511)
- **Reason:** 用3D高斯 splatting实现可动画的面部交换，属于原生多模态大模型的图像生成
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] DIFF-MF: A Difference-Driven Channel-Spatial State Space Model for Multi-Modal Image Fusion
- **Authors:** Yiming Sun, Zifan Ye, Qinghua Hu, Pengfei Zhu
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05538](https://arxiv.org/abs/2601.05538)
- **Reason:** 多模态图像融合的状态空间模型，属于原生多模态大模型的图像理解
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Towards Generalized Multi-Image Editing for Unified Multimodal Models
- **Authors:** Pengcheng Xu, Peng Tang, Donghao Luo, Xiaobin Hu, Weichu Cui, Qingdong He, Zhennan Chen, Jiangning Zhang, Charles Ling, Boyu Wang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05572](https://arxiv.org/abs/2601.05572)
- **Reason:** 统一多模态模型的多图像编辑，属于原生多模态大模型的图像生成
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Orient Anything V2: Unifying Orientation and Rotation Understanding
- **Authors:** Zehan Wang, Ziang Zhang, Jiayang Xu, Jialei Wang, Tianyu Pang, Chao Du, HengShuang Zhao, Zhou Zhao
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05573](https://arxiv.org/abs/2601.05573)
- **Reason:** 统一目标方向和旋转理解，属于原生多模态大模型的图像理解
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals
- **Authors:** Nate Gillman, Yinghua Zhou, Zitian Tang, Evan Luo, Arjan Chakravarthy, Daksh Aggarwal, Michael Freeman, Charles Herrmann, Chen Sun
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05848](https://arxiv.org/abs/2601.05848)
- **Reason:** 教视频模型完成物理条件目标，属于原生多模态大模型的视频生成
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting
- **Authors:** Yinghan Xu, John Dingliana
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05853](https://arxiv.org/abs/2601.05853)
- **Reason:** 分解和修复3D人体 avatar，属于原生多模态大模型的图像生成
Score: 7
Field: 原生多模态大模型

## 大模型新技术

### [Score: 8.0/10] Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation
- **Authors:** Jin Wang, Jianxiang Lu, Comi Chen, Guangzheng Xu, Haoyu Yang, Peng Chen, Na Zhang, Yifan Xu, Longhuang Wu, Shuai Shao, Qinglin Lu, Ping Luo
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05722](https://arxiv.org/abs/2601.05722)
- **Reason:** 视频扩散模型生成3D角色，属于大模型新技术中的diffusion模型创新
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Boosting Latent Diffusion Models via Disentangled Representation Alignment
- **Authors:** John Page, Xuesong Niu, Kai Wu, Kun Gai
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05823](https://arxiv.org/abs/2601.05823)
- **Reason:** 改进潜在扩散模型的解纠缠表示，属于大模型新技术中的diffusion模型创新
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR
- **Authors:** Zijun Min, Bingshuai Liu, Ante Wang, Long Zhang, Anxiang Zeng, Haibo Zhang, Jinsong Su
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05607](https://arxiv.org/abs/2601.05607)
- **Reason:** 融合token级与序列级政策优化，解决RLVR中的方差与信用分配问题，提升数学推理任务性能，属于大模型新技术中RLVR方向的优化进展。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck
- **Authors:** Huilin Deng, Hongchen Luo, Yue Zhu, Long Li, Zhuoyue Chen, Xinghao Zhao, Ming Li, Jihai Zhang, Mengchang Wang, Yang Cao, Yu Kang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05870](https://arxiv.org/abs/2601.05870)
- **Reason:** 提出迭代信息瓶颈引导的潜政策优化，解决RLVR中的探索崩溃问题，提升数学推理的准确性与多样性，属于大模型新技术中RLVR方向的创新。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] GenCtrl -- A Formal Controllability Toolkit for Generative Models
- **Authors:** Emily Cheng, Carmen Amo Alonso, Federico Danieli, Arno Blaas, Luca Zappella, Pau Rodriguez, Xavier Suau
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05637](https://arxiv.org/abs/2601.05637)
- **Reason:** 提出形式化可控性框架，通过估计生成模型的可控集解决“模型是否真正可控”的基础问题，提供分布-free的PAC边界保证，实验验证在对话与文本-图像生成任务中的有效性，是大模型可控性研究的重要理论进展。
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment
- **Authors:** Jin Wang, Jianxiang Lu, Guangzheng Xu, Comi Chen, Haoyu Yang, Linqing Wang, Peng Chen, Mingtao Chen, Zhichao Hu, Longhuang Wu, Shuai Shao, Qinglin Lu, Ping Luo
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05729](https://arxiv.org/abs/2601.05729)
- **Reason:** 改进GRPO用于图像到视频生成，属于大模型新技术中的生成模型优化
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks
- **Authors:** ShaoZhen Liu, Xinting Huang, Houwen Peng, Xin Chen, Xinyang Song, Qi Li, Zhenan Sun
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05616](https://arxiv.org/abs/2601.05616)
- **Reason:** 提出两阶段训练框架，通过自生成CoT数据增强LLM自我纠正能力，提升数学推理性能，属于大模型新技术中推理框架的创新。
Score: 7
Field: 大模型新技术

## 多模态智能体

### [Score: 8.0/10] PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering
- **Authors:** Yu Liu, Wenxiao Zhang, Cong Cao, Wenxuan Lu, Fangfang Yuan, Diandian Guo, Kun Peng, Qiang Sun, Kaiyan Zhang, Yanbing Liu, Jin B. Hong, Bowen Zhou, Zhiyuan Ma
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05465](https://arxiv.org/abs/2601.05465)
- **Reason:** 提出Plan-Retrieve-Inspect-Solve-Memoize多代理架构，结合Two-Stage Group Relative Policy Optimization解决检索崩溃与学习不稳定问题，提升开放域多跳问答性能，实验验证在十项基准上达SOTA。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation
- **Authors:** Zezhou Wang, Ziyun Zhang, Xiaoyi Zhang, Zhuzhong Qian, Yan Lu
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05787](https://arxiv.org/abs/2601.05787)
- **Reason:** 针对GUI代理训练的“数据少、专家轨迹分布偏移”瓶颈，提出BEPA双级同化框架，将静态专家轨迹转化为政策对齐的指导，在OSWorld-Verified上提升UITARS1.5-7B成功率从22.87%至32.13%，是GUI Agent研究的重要进展。
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management
- **Authors:** Ruizhe Zhang, Xinke Jiang, Zhibang Yang, Zhixin Zhang, Jiaran Gao, Yuzhen Xiao, Hongbin Lai, Xu Chu, Junfeng Zhao, Yasha Wang
- **Published:** 2026-01-12
- **Link:** [https://arxiv.org/abs/2601.05890](https://arxiv.org/abs/2601.05890)
- **Reason:** 提出分层多代理框架StackPlanner，通过任务级记忆控制与经验记忆检索解决中心代理的“记忆膨胀、协作不稳定”问题，提升长程多代理协作可靠性，实验验证在深度搜索与代理系统基准上的优势。
Score: 7
Field: 多模态智能体

