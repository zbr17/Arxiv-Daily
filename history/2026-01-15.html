<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2026-01-15</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>深度学习可解释性</a>
<a href='#' >深度学习理论</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >原生多模态大模型</a>
<a href='#' >大模型新技术</a>
<a href='#' >多模态智能体</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2026-01-15</h1>
<div class='meta-info'><p>更新于北京时间：2026-01-15 12:45:54</p>
<p>已自动阅读了 251 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：135308</p>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Where Does Vision Meet Language? Understanding and Refining Visual Fusion in MLLMs via Contrastive Attention</h3>
<p><strong>Authors:</strong> Shezheng Song, Shasha Li, Jie Yu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 通过层-wise masking分析揭示MLLMs中视觉-文本融合的演化规律（如特定层融合、 late-stage“review”现象），并提出对比注意力框架优化融合，提升多模态推理性能，对多模态模型的内部机制理解和可解释性有重要贡献。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08151' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EviNAM: Intelligibility and Uncertainty via Evidential Neural Additive Models</h3>
<p><strong>Authors:</strong> S\"oren Schleibaum, Anton Frederik Thielmann, Julian Teusch, Benjamin S\"afken, J\"org P. M\"uller</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 结合神经additive模型（NAM）与证据学习，实现可解释性与不确定性估计，属于深度学习可解释性的创新方法，实验验证性能。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08556' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs</h3>
<p><strong>Authors:</strong> Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 结合Owen-Shapley归因解决强化学习中序列级奖励的信用分配问题，与深度学习可解释性方向高度相关
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08403' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set</h3>
<p><strong>Authors:</strong> Kaivalya Rawal, Eoin Delaney, Zihao Fu, Sandra Wachter, Chris Russell</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出解释评估方法AXE，检测Rashomon集中模型的行为差异，评估特征重要性解释的质量，属于深度学习可解释性方向
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08703' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TabPFN Through The Looking Glass: An interpretability study of TabPFN and its internal representations</h3>
<p><strong>Authors:</strong> Aviral Gupta, Armaan Sethi, Dhruv Kumar</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 分析表格基础模型TabPFN的内部表示，揭示其决策过程中的结构化信息，对深度学习可解释性研究有一定贡献，但聚焦于表格模型。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08181' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Novel Approach to Explainable AI with Quantized Active Ingredients in Decision Making</h3>
<p><strong>Authors:</strong> A. M. A. S. D. Alagiyawanna, Asoka Karunananda, Thushari Silva, A. Mahasinghe</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 结合量子玻尔兹曼机（QBM）与经典玻尔兹曼机（CBM），使用SHAP等方法实现可解释性，属于深度学习可解释性的跨领域方法，实验验证有效性。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08733' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English</h3>
<p><strong>Authors:</strong> Sargam Yadav (Dundalk Institute of Technology), Abhishek Kaushik (Dundalk Institute of Technology), Kevin Mc Daid (Dundalk Institute of Technology)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 结合多模态模型和SHAP、LIME可解释性技术检测印地语-英语混合文本中的性别歧视，属于深度学习可解释性方向
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08457' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> WaveFormer: Frequency-Time Decoupled Vision Modeling with Wave Equation</h3>
<p><strong>Authors:</strong> Zishan Shu (Unknown), Juntong Wu (Unknown), Wei Yan (Unknown), Xudong Liu (Unknown), Hongyu Zhang (Unknown), Chang Liu (Unknown), Youdong Mao (Unknown), Jie Chen (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出基于波动方程的WaveFormer模型，通过Wave Propagation Operator实现O(N log N)复杂度的全局交互，替代ViT/CNN，在多个任务上实现竞争精度和更高吞吐量，属于深度学习理论中的网络架构创新。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08602' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> NOVAK: Unified adaptive optimizer for deep neural networks</h3>
<p><strong>Authors:</strong> Sergii Kavun</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出统一自适应优化器NOVAK，整合自适应动量估计、修正学习率调度等组件，通过理论分析和多数据集/架构实证验证优化器性能，对深度学习理论中的优化器研究具有核心贡献。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.07876' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Demystifying the Slash Pattern in Attention: The Role of RoPE</h3>
<p><strong>Authors:</strong> Yuan Cheng, Fengzhuo Zhang, Yunlong Hou, Cunxiao Du, Chao Du, Tianyu Pang, Aixin Sun, Zhuoran Yang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 揭示旋转位置编码（RoPE）导致的注意力斜线模式，通过理论证明和实证验证解释成因，由知名学者Zhuoran Yang团队完成，对大模型注意力机制研究具有核心价值。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08297' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Controlled LLM Training on Spectral Sphere</h3>
<p><strong>Authors:</strong> Tian Xie, Haoming Luo, Haoyu Tang, Yiwen Hu, Jason Klein Liu, Qingnan Ren, Yang Wang, Wayne Xin Zhao, Rui Yan, Bing Su, Chong Luo, Baining Guo (Microsoft, Renmin University)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出光谱球优化器（SSO）实现大模型训练的严格光谱约束，由Microsoft和人民大学团队开发，在多架构大模型预训练中表现优异，对大模型训练稳定性与效率有核心贡献。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08393' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Closed-Loop LLM Discovery of Non-Standard Channel Priors in Vision Models</h3>
<p><strong>Authors:</strong> Tolgay Atinc Uzun (Unknown), Dmitry Ignatov (Unknown), Radu Timofte (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出LLM驱动的神经架构搜索框架，解决通道配置的组合优化问题，通过AST突变生成训练数据，实验验证在CIFAR-100上提升accuracy，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08517' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RewriteNets: End-to-End Trainable String-Rewriting for Generative Sequence Modeling</h3>
<p><strong>Authors:</strong> Harshil Vejendla (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出基于字符串重写的RewriteNets架构，替代Transformer，显式结构归纳偏置，在系统泛化任务上表现优异，计算效率更高，属于深度学习理论中的网络架构创新。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.07868' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Riemannian Zeroth-Order Gradient Estimation with Structure-Preserving Metrics for Geodesically Incomplete Manifolds</h3>
<p><strong>Authors:</strong> Shaocong Ma, Heng Huang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出黎曼流形上的零阶梯度估计方法，针对测地不完全流形设计结构保持度量，由机器学习理论知名学者Heng Huang团队完成，具有重要理论价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08039' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Deep Exploration of Epoch-wise Double Descent in Noisy Data: Signal Separation, Large Activation, and Benign Overfitting</h3>
<p><strong>Authors:</strong> Tomoki Kubo, Ryuken Uda, Yusuke Iida</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 深入探索带噪声数据中的epoch-wise双下降现象，关联良性过拟合与大激活问题，对深度学习理论中的泛化机制研究具有实证价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08316' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces</h3>
<p><strong>Authors:</strong> Angshul Majumdar</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 研究稀疏智能体控制（SAC），证明稀疏性对大动作空间LLM稳定性的必要性，属于深度学习理论中的稀疏优化与控制，具有重要理论贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08271' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Greedy Is Enough: Sparse Action Discovery in Agentic LLMs</h3>
<p><strong>Authors:</strong> Angshul Majumdar</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出贪心算法解决智能体LLM的稀疏动作发现，证明其精确恢复性，属于深度学习理论中的稀疏学习，具有理论与应用价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08280' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models</h3>
<p><strong>Authors:</strong> Bo Wang, Junzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 分析MoE与dense模型的预训练知识归因，揭示稀疏架构的知识存储模式，属于深度学习理论中的网络架构与预训练，具有重要的可解释性与架构洞察。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08383' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Divide and Conquer: Static-Dynamic Collaboration for Few-Shot Class-Incremental Learning</h3>
<p><strong>Authors:</strong> Kexin Bao (Unknown), Daichi Zhang (Unknown), Yong Li (Unknown), Dan Zeng (Unknown), Shiming Ge (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出静态-动态协作框架解决少样本类增量学习的稳定性-可塑性 dilemma，分为静态保留和动态学习阶段，属于深度学习理论中的增量学习研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08448' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CD^2: Constrained Dataset Distillation for Few-Shot Class-Incremental Learning</h3>
<p><strong>Authors:</strong> Kexin Bao (Unknown), Daichi Zhang (Unknown), Hansong Zhang (Unknown), Yong Li (Unknown), Yutao Yue (Unknown), Shiming Ge (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出约束数据集蒸馏框架，通过数据集蒸馏模块和蒸馏约束模块解决少样本类增量学习的灾难性遗忘问题，属于深度学习理论中的数据集蒸馏研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08519' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Max-Min Neural Network Operators For Approximation of Multivariate Functions</h3>
<p><strong>Authors:</strong> Abhishek Yadav, Uaday Singh, Feng Dai</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出最大-最小神经网络算子用于多元函数逼近，建立收敛定理并推导逼近阶，对深度学习理论中的网络架构与函数逼近研究有理论贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.07886' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Generalization Analysis and Method for Domain Generalization for a Family of Recurrent Neural Networks</h3>
<p><strong>Authors:</strong> Atefeh Termehchi, Ekram Hossain, Isaac Woungang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 针对循环神经网络的域泛化问题进行泛化分析并提出方法，对深度学习理论中的泛化能力研究有贡献，但RNN关注度相对较低。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08122' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LDLT L-Lipschitz Network Weight Parameterization Initialization</h3>
<p><strong>Authors:</strong> Marius F. R. Juston, Ramavarapu S. Sreenivas, Dustin Nottage, Ahmet Soylemezoglu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 分析LDLT-based L-Lipschitz层的初始化动态，推导输出方差闭式解，对深度学习理论中的初始化研究有理论贡献，但应用范围较窄。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08253' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Your Group-Relative Advantage Is Biased</h3>
<p><strong>Authors:</strong> Fengkai Yang, Zherui Chen, Xiaohan Wang, Xiaodong Lu, Jiajun Chai, Guojun Yin, Wei Lin, Shuai Ma, Fuzhen Zhuang, Deqing Wang, Yaodong Yang, Jianxin Li, Yikun Ban</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 揭示基于组的强化学习中组相对优势估计的固有偏差，提出HA-DW方法解决，属于深度学习理论中的强化学习优化问题，实验验证有效。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08521' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Model-Agnostic Solutions for Deep Reinforcement Learning in Non-Ergodic Contexts</h3>
<p><strong>Authors:</strong> Bert Verbruggen, Arne Vanhoyweghen, Vincent Ginis</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 研究非遍历环境下的深度强化学习，提出引入时间依赖的解决方法，属于深度学习理论中的强化学习扩展，具有理论意义。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08726' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning from Demonstrations via Capability-Aware Goal Sampling</h3>
<p><strong>Authors:</strong> Yuanlin Duan, Yuning Wang, Wenjie Qiu, He Zhu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出能力感知的目标采样方法，优化模仿学习的长 horizon 任务性能，属于深度学习理论方向
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08731' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Hierarchical Sparse Plus Low Rank Compression of LLM</h3>
<p><strong>Authors:</strong> Pawan Kumar (Unknown), Aditi Gupta (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出两阶段LLM压缩方案，结合稀疏矩阵和分层稀疏低秩分解，硬件友好且保持性能，在LLaMA-7B上验证有效，属于高效大模型训练与推理中的高压缩研究。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.07839' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> KVzap: Fast, Adaptive, and Faithful KV Cache Pruning</h3>
<p><strong>Authors:</strong> Simon Jegou (NVIDIA), Maximilian Jeblick</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> NVIDIA团队提出KV缓存剪枝方法KVzap，实现2-4倍缓存压缩且精度损失可忽略，解决长上下文大模型推理的缓存瓶颈，具有极高实际价值。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.07891' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HIPPO: Accelerating Video Large Language Models Inference via Holistic-aware Parallel Speculative Decoding</h3>
<p><strong>Authors:</strong> Qitan Lv, Tianyu Liu, Wen Wu, Xuenan Xu, Bowen Zhou, Feng Wu, Chao Zhang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 针对视频LLM推理慢的问题，提出HIPPO框架，通过语义感知token保留（避免语义损失）和并行推测解码（重叠生成与验证），实现最高3.51x的推理加速，推动视频大模型的高效推理研究。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08273' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Sliced-Wasserstein Distribution Alignment Loss Improves the Ultra-Low-Bit Quantization of Large Language Models</h3>
<p><strong>Authors:</strong> Deyu Cao, Yixin Yin, Samin Aref</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 针对大模型超低比特量化的分布扭曲问题，提出切片瓦瑟斯坦损失实现分布对齐，显著恢复量化模型性能，对高效大模型推理具有重要价值。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.07878' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Sherry: Hardware-Efficient 1.25-Bit Ternary Quantization via Fine-grained Sparsification</h3>
<p><strong>Authors:</strong> Hong Huang, Decheng Wu, Qiangqiang Hu, Guanghua Yu, Jinhai Yang, Jianchen Zhu, Xue Liu, Dapeng Wu (Tencent)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出1.25比特三元量化框架Sherry，通过细粒度稀疏化解决硬件对齐问题，在LLaMA-3.2上实现精度保持与推理加速，对大模型边缘部署高效性有重要贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.07892' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ORBIT: On-policy Exploration-Exploitation for Controllable Multi-Budget Reasoning</h3>
<p><strong>Authors:</strong> Kun Liang, Clive Bai, Xin Xu, Chenming Tang, Sanwoo Lee, Weijie Liu, Saiyong Yang, Yunfang Wu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出ORBIT框架实现大模型可控多预算推理，通过强化学习发现帕累托最优推理行为，对大模型推理效率与可控性有重要贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08310' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms</h3>
<p><strong>Authors:</strong> Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出零样本LLM引导的核心与频率分配方法，优化嵌入式平台的能耗与性能，属于高效大模型训练与推理中的资源管理创新，实验验证显著提升。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08166' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Improving LLM Reasoning with Homophily-aware Structural and Semantic Text-Attributed Graph Compression</h3>
<p><strong>Authors:</strong> Zijun Di, Bin Lu, Huquan Kang, Luoyi Fu, Jiaxin Ding, Xiaoying Gan, Lei Zhou, Xinbing Wang, Chenghu Zhou</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出HS2C框架，利用图同质性压缩文本属性图，提升LLM推理性能，属于高效大模型训练与推理中的图压缩创新，实验验证有效性。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08187' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> EfficientFSL: Enhancing Few-Shot Classification via Query-Only Tuning in Vision Transformers</h3>
<p><strong>Authors:</strong> Wenwen Liao (Unknown), Hang Ruan (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出查询仅微调框架，减少Vision Transformer的微调计算开销，在少样本分类任务上表现优异，属于高效大模型训练与推理中的轻量级微调研究。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08499' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Embedded AI Companion System on Edge Devices</h3>
<p><strong>Authors:</strong> Rahul Gupta, Stephen D. H. Hsu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出边缘设备上的AI companion系统，通过active/inactive记忆 phases优化性能，属于高效大模型训练与推理中的边缘设备优化，实验验证有效性。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08128' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> When Models Know When They Do Not Know: Calibration, Cascading, and Cleaning</h3>
<p><strong>Authors:</strong> Chenjie Hao, Weyl Lu, Yuko Ishiwaka, Zengyi Li, Weier Wan, Yubei Chen</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出模型校准、级联与数据清洗的方法，利用模型的不确定性感知提升效率与可靠性，属于高效大模型训练与推理中的模型优化，实验验证有效性。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.07965' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation</h3>
<p><strong>Authors:</strong> Yizhan Feng, Hichem Snoussi, Yuhang Wang, Jing Teng, Abel Cherouat, Tian Wang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 结合知识蒸馏、Chain-of-Thought引导和QLoRA量化，将大模型能力迁移到轻量模型用于无人机控制，属于高效大模型训练与推理方向
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08412' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Parallel Context-of-Experts Decoding for Retrieval Augmented Generation</h3>
<p><strong>Authors:</strong> Giulio Corallo, Paolo Papotti</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出并行上下文专家解码框架，优化Retrieval Augmented Generation的多文档推理效率，属于高效大模型训练与推理方向
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08670' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Asymptotic Universal Alignment: A New Alignment Framework via Test-Time Scaling</h3>
<p><strong>Authors:</strong> Yang Cai, Weiqiang Zheng</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出渐近通用对齐（U-alignment）框架，分析测试时缩放的最优收敛率，揭示现有对齐方法的局限性，属于大模型安全与对齐的重要理论贡献。
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08777' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SafeRedir: Prompt Embedding Redirection for Robust Unlearning in Image Generation Models</h3>
<p><strong>Authors:</strong> Renyang Liu (Unknown), Kangjie Chen (Unknown), Han Qiu (Unknown), Jie Zhang (Unknown), Kwok-Yan Lam (Unknown), Tianwei Zhang (Unknown), See-Kiong Ng (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出轻量级推理时框架，通过prompt嵌入重定向解决图像生成模型的有害概念记忆问题，有效卸载不安全内容，鲁棒对抗攻击，属于大模型安全与对齐研究。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08623' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Q-realign: Piggybacking Realignment on Quantization for Safe and Efficient LLM Deployment</h3>
<p><strong>Authors:</strong> Qitao Tan, Xiaoying Song, Ningxi Cheng, Ninghao Liu, Xiaoming Zhai, Lingzi Hong, Yanzhi Wang, Zhen Xiang, Geng Yuan</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 将安全对齐与量化结合，在量化过程中恢复大模型安全属性，解决微调导致的对齐退化问题，对大模型安全高效部署具有实际价值。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08089' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Coverage Improvement and Fast Convergence of On-policy Preference Learning</h3>
<p><strong>Authors:</strong> Juno Kim, Jihun Yun, Jason D. Lee (University of Southern California), Kwang-Sung Jun</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 研究on-policy偏好学习的覆盖性提升与快速收敛，涉及大模型对齐中的偏好学习理论，作者包含知名学者Jason D. Lee，具有理论价值。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08421' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety</h3>
<p><strong>Authors:</strong> Can Jin, Rui Wu, Tong Che, Qixin Zhang, Hongwu Peng, Jiahui Zhao, Zhenting Wang, Wenqi Wei, Ligong Han, Zhao Zhang, Yuan Cao, Ruixiang Tang, Dimitris N. Metaxas</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出结合判例与法规的案例增强审议对齐方法，提升LLM安全性，实验验证有效性，属于大模型安全与对齐的应用创新。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08000' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Semantic Gravity Wells: Why Negative Constraints Backfire</h3>
<p><strong>Authors:</strong> Shailesh Rana</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 揭示负约束失效的机制（语义重力井），分析两种失败模式，属于大模型安全与对齐中的指令遵循问题，具有重要的机制洞察。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08070' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant</h3>
<p><strong>Authors:</strong> Oleg Romanchuk, Roman Bondar</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 揭示AI智能体架构中的语义洗钱问题，分析其认识论缺陷，属于大模型安全与对齐中的认识论安全，具有重要的理论洞察。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation</h3>
<p><strong>Authors:</strong> Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis, Guokan Shang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出基于稀疏自编码器的可学习稀疏激活引导向量方法，优化LLM的领域适应和对齐能力，解决多语义神经元问题，属于大模型安全与对齐方向
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08441' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock</h3>
<p><strong>Authors:</strong> Didier Sornette, Sandro Claudio Lera, Ke Wu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 从人类交互结构的角度分析AI对齐失败的结构性原因，提出AGI的风险在于放大人类矛盾，属于大模型安全与对齐方向
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Semantic Misalignment in Vision-Language Models under Perceptual Degradation</h3>
<p><strong>Authors:</strong> Guo Cheng (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 系统研究视觉语言模型在感知退化下的语义错位问题，提出语言级错位指标，揭示像素级鲁棒性与多模态语义可靠性的脱节，属于大模型安全与对齐中的鲁棒性研究。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08355' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Cross-modal Proxy Evolving for OOD Detection with Vision-Language Models</h3>
<p><strong>Authors:</strong> Hao Tang (Unknown), Yu Liu (Unknown), Shuanglin Yan (Unknown), Fei Shen (Unknown), Shengfeng He (Unknown), Jing Qin (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出CoEvo框架，通过双向代理进化解决视觉语言模型的零样本OOD检测问题，提升鲁棒性，属于大模型安全与对齐中的OOD检测研究。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08476' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Provably Safe Reinforcement Learning using Entropy Regularizer</h3>
<p><strong>Authors:</strong> Abhijit Mazumdar, Rafal Wisniewski, Manuela L. Bujorianu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出基于熵正则化的可证明安全强化学习算法，分析其有限样本regret bounds，属于大模型安全与对齐中的安全RL，具有理论保证。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08646' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> WebTrap Park: An Automated Platform for Systematic Security Evaluation of Web Agents</h3>
<p><strong>Authors:</strong> Xinyi Wu, Jiagui Chen, Geng Hong, Jiayi Dong, Xudong Pan, Jiarun Dai, Min Yang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出针对Web Agents的自动化安全评估平台，系统检测Agent安全风险，属于大模型安全与对齐方向
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08406' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PersonaDual: Balancing Personalization and Objectivity via Adaptive Reasoning</h3>
<p><strong>Authors:</strong> Xiaoyou Liu, Xinyi Mou, Shengbin Yue, Liang Wang, Yuqing Wang, Qiexiang Wang, Tianrui Qin, Wangchunshu Zhou, Zhongyu Wei</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出自适应推理框架平衡LLM的个性化与客观性，优化意图理解和响应质量，属于大模型安全与对齐方向
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08679' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Uncovering Political Bias in Large Language Models using Parliamentary Voting Records</h3>
<p><strong>Authors:</strong> Jieying Chen, Karen de Jong, Andreas Poole, Jan Burakowski, Elena Elderson Nosti, Joep Windt, Chendi Wang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 利用议会投票记录评估LLM的政治偏见，提出跨国家的偏见基准，属于大模型安全与对齐方向
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08785' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CASHEW: Stabilizing Multimodal Reasoning via Iterative Trajectory Aggregation</h3>
<p><strong>Authors:</strong> Chaoyu Li, Deeparghya Dutta Barua, Fei Tao, Pooyan Fazli</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 针对多模态大模型多步推理不稳定问题，提出迭代轨迹聚合框架CASHEW及强化学习变体CASHEW-RL，通过视觉验证过滤幻觉并接地推理，在13个多模态基准上取得显著性能提升（如ScienceQA+23.6%），对多模态推理稳定性研究有重要价值。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08010' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Representations of Text and Images Align From Layer One</h3>
<p><strong>Authors:</strong> Evžen Wybitul, Javier Rando, Florian Tramèr, Stanislav Fort</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 通过合成图像的方法证明多模态模型（如Gemma 3）中text和image的表示从第一层就存在对齐，挑战了“对齐仅存在于深层”的传统观点，为多模态表示学习的层内对齐研究提供了新证据和方法。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08017' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> KidVis: Do Multimodal Large Language Models Possess the Visual Perceptual Capabilities of a 6-Year-Old?</h3>
<p><strong>Authors:</strong> Xianfeng Wang, Kaiwei Zhang, Qi Jia, Zijian Chen, Guangtao Zhai, Xiongkuo Min</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 构建KidVis基准评估MLLMs的基础视觉能力（如注意力、追踪、辨别等），发现当前MLLMs缺乏人类的基础视觉原语，且存在“Scaling Law Paradox”（参数增加无法线性提升基础能力），对多模态模型的视觉能力发展有重要启示。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08292' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Motion Attribution for Video Generation</h3>
<p><strong>Authors:</strong> Xindi Wu (Unknown), Despoina Paschalidou (Unknown), Jun Gao (Unknown), Antonio Torralba (Unknown), Laura Leal-Taixé (Unknown), Olga Russakovsky (Unknown), Sanja Fidler (Unknown), Jonathan Lorraine (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出Motive框架，用于视频生成模型的运动归因，指导数据筛选提升运动一致性和物理 plausibility，属于原生多模态大模型中的视频生成研究。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08828' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ViDoRe V3: A Comprehensive Evaluation of Retrieval Augmented Generation in Complex Real-World Scenarios</h3>
<p><strong>Authors:</strong> António Loison, Quentin Macé, Antoine Edy, Victor Xing, Tom Balough, Gabriel Moreira, Bo Liu, Manuel Faysse, Céline Hudelot, Gautier Viaud</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出覆盖多模态（文本、表格、图像）的Retrieval Augmented Generation基准，评估复杂场景下的RAG性能，属于原生多模态大模型方向
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08620' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> UM-Text: A Unified Multimodal Model for Image Understanding</h3>
<p><strong>Authors:</strong> Lichen Ma, Xiaolong Fu, Gaojing Zhou, Zipeng Guo, Ting Zhu, Yichun Liu, Yu Shi, Jason Li, Junshi Huang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出统一多模态模型UM-Text，结合VLM处理自然语言指令和参考图像，生成风格一致的视觉文本，解决了之前方法忽略风格一致性的问题，对多模态图像理解和文本编辑有实际价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08321' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Edge-Optimized Multimodal Learning for UAV Video Understanding via BLIP-2</h3>
<p><strong>Authors:</strong> Yizhan Feng (Unknown), Hichem Snoussi (Unknown), Jing Teng (Unknown), Jian Liu (Unknown), Yuyang Wang (Unknown), Abel Cherouat (Unknown), Tian Wang (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 基于BLIP-2构建轻量级多模态任务平台，集成YOLO模型扩展多任务能力，提出关键帧采样和提示优化，属于原生多模态大模型中的轻量级应用研究。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08408' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> What If TSF: A Benchmark for Reframing Forecasting as Scenario-Guided Multimodal Forecasting</h3>
<p><strong>Authors:</strong> Jinkwan Jang, Hyunbin Jin, Hyungjin Park, Kyubyung Chae, Taesup Kim</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出场景引导的多模态时间序列预测基准，结合文本场景描述与时间序列数据，属于原生多模态大模型方向
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.08509' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SnapGen++: Unleashing Diffusion Transformers for Efficient High-Fidelity Image Generation on Edge Devices</h3>
<p><strong>Authors:</strong> Dongting Hu, Aarush Gupta, Magzhan Gabidolla, Arpit Sahni, Huseyin Coskun, Yanyu Li, Yerlan Idelbayev, Ahsan Mahmood, Aleksei Lebedev, Dishani Lahiri, Anujraaj Goyal, Ju Hu, Mingming Gong, Sergey Tulyakov, Anil Kag</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出高效扩散Transformer框架SnapGen++，通过紧凑DiT架构、弹性训练（联合优化不同容量子模型）和知识引导蒸馏，实现边缘设备上的高保真图像生成（4-step推理），推动扩散模型的高效部署。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.08303' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Revealing the Attention Floating Mechanism in Masked Diffusion Models</h3>
<p><strong>Authors:</strong> Xin Dai, Pengcheng Huang, Zhenghao Liu, Shuo Wang, Yukun Yan, Chaojun Xiao, Yu Gu, Ge Yu, Maosong Sun (NEUIR)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 揭示掩码扩散模型的注意力浮动机制，解释其优于自回归模型的上下文学习能力，由知名NLP学者Maosong Sun团队完成，对扩散大模型研究具有重要意义。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.07894' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TP-Blend: Textual-Prompt Attention Pairing for Precise Object-Style Blending in Diffusion Models</h3>
<p><strong>Authors:</strong> Xin Jin, Yichuan Zhong, Yapeng Tian</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出轻量级训练-free框架TP-Blend，通过交叉注意力物体融合和自注意力风格融合，解决扩散模型中物体-风格同时注入的问题，在SD-XL上实现高精度的内容-外观控制，推动扩散模型的编辑能力提升。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.08011' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Training Free Zero-Shot Visual Anomaly Localization via Diffusion Inversion</h3>
<p><strong>Authors:</strong> Samet Hicsonmez, Abd El Rahman Shabayek, Djamila Aouada</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出训练-free的零-shot视觉异常定位框架，利用扩散模型的反转生成正常重建图像，通过输入与重建的差异定位异常，在VISA数据集上取得SOTA性能，避免了对细粒度prompt的依赖，推动扩散模型在异常检测中的应用。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.08022' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Training-Free Distribution Adaptation for Diffusion Models via Maximum Mean Discrepancy Guidance</h3>
<p><strong>Authors:</strong> Matina Mahdizadeh Sani, Nima Jamali, Mohammad Jalali, Farzan Farnia</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出基于MMD的训练无关扩散模型分布适配方法，实现生成分布与目标分布对齐，对扩散大模型的自适应生成具有意义。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.08379' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Creativity in AI as Emergence from Domain-Limited Generative Models</h3>
<p><strong>Authors:</strong> Corina Chutaux (SU FdL)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出AI创造力作为领域限制生成模型的涌现现象，属于大模型新技术中的创造力研究，为AI创造力提供新的理论框架。
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.08388' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Sketch-Based Facade Renovation With Generative AI: A Streamlined Framework for Bypassing As-Built Modelling in Industrial Adaptive Reuse</h3>
<p><strong>Authors:</strong> Warissara Booranamaitree, Xusheng Du, Yushu Cai, Zhengyang Wang, Ye Zhang, Haoran Xie</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 结合视觉语言模型、Stable Diffusion和ControlNet实现基于草图的建筑立面翻新，属于大模型新技术方向
Score: 7
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.08531' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UR-Bench: A Benchmark for Multi-Hop Reasoning over Ultra-High-Resolution Images</h3>
<p><strong>Authors:</strong> Siqi Li (Unknown), Xinyu Cai (Unknown), Jianbiao Mei (Unknown), Nianchen Deng (Unknown), Pinlong Cai (Unknown), Licheng Wen (Unknown), Yufan Shen (Unknown), Xuemeng Yang (Unknown), Botian Shi (Unknown), Yong Liu (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出超高清图像多跳推理基准UR-Bench，设计agent-based框架调用外部视觉工具，提升超高清图像推理效率，属于多模态智能体中的工具调用研究。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08748' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Reasoning Matters for 3D Visual Grounding</h3>
<p><strong>Authors:</strong> Hsiang-Wei Huang (Unknown), Kuang-Ming Chen (Unknown), Wenhao Chai (Unknown), Cheng-Yen Yang (Unknown), Jen-Hao Cheng (Unknown), Jenq-Neng Hwang (Unknown)</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出3D视觉接地的数据合成 pipeline，生成带推理过程的数据，微调LLM得到Reason3DVG-8B，提升3D视觉接地性能，属于多模态智能体中的3D视觉推理研究。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08811' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MemoBrain: Executive Memory as an Agentic Brain for Reasoning</h3>
<p><strong>Authors:</strong> Hongjin Qian, Zhao Cao, Zheng Liu</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出MemoBrain框架，为工具增强智能体构建依赖感知的执行记忆，提升长horizon推理能力，属于多模态智能体的记忆机制创新。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08079' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MPCI-Bench: A Benchmark for Multimodal Pairwise Contextual Integrity Evaluation of Language Model Agents</h3>
<p><strong>Authors:</strong> Shouju Wang, Haopeng Zhang</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出MPCI-Bench基准，评估语言模型智能体的多模态成对上下文完整性，属于多模态智能体的评估创新，有助于推动智能体研究。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08235' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation</h3>
<p><strong>Authors:</strong> Yupeng Huo, Yaxi Lu, Zhong Zhang, Haotian Chen, Yankai Lin</p>
<p><strong>Published:</strong> 2026-01-14</p>
<p><strong>Reason:</strong> 提出AtomMem框架，将记忆管理分解为原子CRUD操作，通过学习优化记忆决策，属于多模态智能体的记忆机制创新，实验验证性能提升。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08323' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>