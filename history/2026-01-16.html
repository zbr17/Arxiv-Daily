<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2026-01-16</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>深度学习理论</a>
<a href='#' >大模型安全与对齐</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >大模型新技术</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >多模态智能体</a>
<a href='#' >原生多模态大模型</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2026-01-16</h1>
<div class='meta-info'><p>更新于北京时间：2026-01-16 12:40:01</p>
<p>已自动阅读了 217 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：104231</p>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing Active Network of Concepts with Energy E3</h3>
<p><strong>Authors:</strong> Daesuk Kwon, Won-gi Paeng</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出通用智能的公理框架SANC(E3)，将表示单元的自组织作为核心，统一感知、想象、规划等认知过程，对深度学习理论的基础研究有重要启发
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08224' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond the final layer: Attentive multilayer fusion for vision transformers</h3>
<p><strong>Authors:</strong> Laure Ciernik, Marco Morik, Lukas Thede, Luca Eyring, Shinichi Nakajima, Zeynep Akata, Lukas Muttenthaler</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 研究视觉Transformer的中间层表示融合，通过注意力机制动态整合多层特征提升线性探测性能，揭示中间层信息对跨域任务的关键价值，属于深度学习理论中的表示学习研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.09322' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Universal Dynamics of Warmup Stable Decay: understanding WSD beyond Transformers</h3>
<p><strong>Authors:</strong> Annalisa Belloni, Lorenzo Noci, Antonio Orvieto</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 研究WSD学习率调度器在Transformer与CNN上的训练动态，揭示损失景观的几何特性与优化路径一致性，为深度学习理论中的优化器调度器设计提供跨架构 insights
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.09000' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces</h3>
<p><strong>Authors:</strong> Angshul Majumdar</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 研究agentic LLMs在大动作空间的稀疏控制问题，证明了稀疏性对多项式时间稳定性的必要性，对深度学习理论中的稀疏决策制定有重要贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08271' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Greedy Is Enough: Sparse Action Discovery in Agentic LLMs</h3>
<p><strong>Authors:</strong> Angshul Majumdar</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 证明贪心算法在agentic LLMs稀疏动作发现中的有效性，提供了理论保证和下界分析，对深度学习理论中的大动作空间决策有重要价值
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08280' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models</h3>
<p><strong>Authors:</strong> Bo Wang, Junzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 通过Gated-LPI指标分析MoE和dense模型的知识获取动态，揭示了MoE的低熵骨干和早期consolidation特性，对深度学习理论中的模型架构与预训练关系有重要理解
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.08383' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Depth-Wise Representation Development Under Blockwise Self-Supervised Learning for Video Vision Transformers</h3>
<p><strong>Authors:</strong> Jonas R\"omer, Timo Dickscheid</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 探索块级自监督学习在视频Transformer中的应用，分析深度方向的表示发展差异，比较端到端与块级训练的学习动态，属于深度学习理论中的训练策略研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.09040' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Integrating Diverse Assignment Strategies into DETRs</h3>
<p><strong>Authors:</strong> Yiwei Zhang, Jin Gao, Hanshi Wang, Fudong Ge, Guan Luo, Weiming Hu, Zhipeng Zhang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 针对DETR的标签分配问题，通过LoRA分支整合多种one-to-many策略，实现多策略的轻量级融合，属于深度学习理论中的目标检测网络架构优化。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.09247' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant</h3>
<p><strong>Authors:</strong> Oleg Romanchuk, Roman Bondar</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 形式化了AI代理架构中的语义洗钱问题，证明了循环认知辩护的不可消除性，对大模型安全的架构层面风险有深刻分析
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock</h3>
<p><strong>Authors:</strong> Didier Sornette, Sandro Claudio Lera, Ke Wu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 从人类社会互动结构的角度分析AI对齐失败的结构性根源，将AGI风险重新定义为人类矛盾的放大器，对大模型安全与对齐的理论框架有重要贡献
Score: 9
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BalDRO: A Distributionally Robust Optimization based Framework for Large Language Model Unlearning</h3>
<p><strong>Authors:</strong> Pengyang Shao, Naixin Zhai, Lei Chen, Yonghui Yang, Fengbin Zhu, Xun Yang, Meng Wang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 针对LLM unlearning中的样本不平衡问题，提出BalDRO框架通过min-sup过程平衡难/易样本的遗忘，显著提升遗忘质量和模型效用，属于大模型安全与对齐的关键方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.09172' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric</h3>
<p><strong>Authors:</strong> Jiali Cheng, Ziheng Chen, Chirag Agarwal, Hadi Amiri</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 从模型电路角度分析LLM unlearning的难度，提出CUD指标预测unlearning难度，为优化unlearning方法提供机制 insights，属于大模型安全与对齐的基础研究方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.09624' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety</h3>
<p><strong>Authors:</strong> Can Jin, Rui Wu, Tong Che, Qixin Zhang, Hongwu Peng, Jiahui Zhao, Zhenting Wang, Wenqi Wei, Ligong Han, Zhao Zhang, Yuan Cao, Ruixiang Tang, Dimitris N. Metaxas</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出CADA框架用案例增强deliberative alignment，解决LLM安全中的规则僵化问题，提升无害性和有用性，属于大模型安全与对齐的关键优化方向。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08000' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Semantic Gravity Wells: Why Negative Constraints Backfire</h3>
<p><strong>Authors:</strong> Shailesh Rana</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 深入研究大语言模型负约束指令遵循失败的机制，通过层分析和激活修补等方法揭示了priming failure和override failure两种模式，对大模型对齐的底层机制理解有重要价值
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08070' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Bias Detection and Rotation-Robustness Mitigation in Vision-Language Models and Generative Image Models</h3>
<p><strong>Authors:</strong> Tarannum Mithila</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 研究视觉语言模型与生成图像模型的偏差传播及旋转鲁棒性问题，提出融合数据增强、表示对齐与正则化的缓解策略，属于大模型安全与对齐的核心研究方向。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08860' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Uncovering Political Bias in Large Language Models using Parliamentary Voting Records</h3>
<p><strong>Authors:</strong> Jieying Chen, Karen de Jong, Andreas Poole, Jan Burakowski, Elena Elderson Nosti, Joep Windt, Chendi Wang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出基于议会投票记录的政治偏见基准构建方法，评估LLM的意识形态倾向与政治实体偏见，为大模型安全与对齐中的政治偏见审计提供了系统框架。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08785' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Fairness risk and its privacy-enabled solution in AI-driven robotic applications</h3>
<p><strong>Authors:</strong> Le Liu, Bangguo Yu, Nynke Vellinga, Ming Cao</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 研究AI驱动机器人应用中的公平性风险，构建效用感知公平性指标并结合隐私预算解决公平性问题，为大模型安全与对齐在机器人场景下的伦理应用提供了实践方案。
Score: 6
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.08953' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts</h3>
<p><strong>Authors:</strong> Yu Xu, Hongbin Yan, Juan Cao, Yiji Cheng, Tiankai Hang, Runze He, Zijin Yin, Shiyi Zhang, Yuxin Zhang, Jintao Li, Chunyu Wang, Qinglin Lu, Tong-Yee Lee, Fan Tang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 针对统一生成模型的任务干扰问题，提出任务感知的MoE门控机制，通过分层任务语义标注与预测对齐正则化实现专家模型的语义 specialization，属于高效大模型训练的关键技术。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08881' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation</h3>
<p><strong>Authors:</strong> Xingyao Li, Fengzhuo Zhang, Cunxiao Du, Hui Ji</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出退火松弛的投机解码策略，通过优化重采样分布与扰动分析提升自回归图像生成的推理速度，属于高效大模型推理的核心技术创新。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09212' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Spectral Complex Autoencoder Pruning: A Fidelity-Guided Criterion for Extreme Structured Channel Compression</h3>
<p><strong>Authors:</strong> Wei Liu, Xing Deng, Haijian Shao, Yingtao Jiang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出基于光谱重建保真度的通道剪枝方法，通过复杂交互场的频率域分析衡量通道冗余，在VGG16上实现高压缩率与低精度损失，针对高效大模型训练与推理中的模型压缩问题提供新方案
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09352' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Layer-Parallel Training for Transformers</h3>
<p><strong>Authors:</strong> Shuai Jiang, Marc Salvado, Eric C. Cyr, Alena Kopaničáková, Rolf Krause, Jacob B. Schroder</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出基于神经ODE的层并行训练方法，通过多水平并行算法加速Transformer的前向与反向传播，提升深层模型的训练并行性，针对高效大模型训练与推理中的并行训练问题
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09026' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache</h3>
<p><strong>Authors:</strong> Chi-Chih Chang, Siqi Zhu, Zhichen Zeng, Haibin Lin, Jiaxuan You, Mohamed S. Abdelfattah, Ziheng Jiang, Xuehai Qian</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出SRT方法，通过树结构缓存与推测解码加速强化学习的rollout过程，在PPO等 pipeline 中实现显著加速，针对高效大模型训练与推理中的RL训练 latency 问题
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09083' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling</h3>
<p><strong>Authors:</strong> Zhixiang Liang, Beichen Huang, Zheng Wang, Minjia Zhang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出STEP框架，通过隐藏状态评估推理步骤并动态剪枝无前景trace，有效降低LLM推理延迟（45%-70%）同时提升推理准确性，针对高效大模型推理的核心问题有显著改进。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09093' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> $D^2Prune$: Sparsifying Large Language Models via Dual Taylor Expansion and Attention Distribution Awareness</h3>
<p><strong>Authors:</strong> Lang Xiong, Ning Liu, Ao Ren, Yuheng Bai, Haining Fang, BinYan Zhang, Zhe Jiang, Yujuan Tan, Duo Liu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出D²Prune剪枝方法，通过双泰勒展开精确估计误差、注意力感知策略保留长tail模式，解决现有剪枝的激活分布偏移问题，有效压缩LLM同时保持性能，属于高效大模型训练的核心方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09176' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation</h3>
<p><strong>Authors:</strong> Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis, Guokan Shang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出学习稀疏激活引导向量的方法，实现LLM的细粒度领域适应，同时保持通用知识，对高效大模型的域适配有重要贡献
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08441' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning</h3>
<p><strong>Authors:</strong> Zhoubin Kou, Zihan Chen, Jing Yang, Cong Shen</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出HERON-SFL框架，结合零阶与一阶优化降低联邦学习客户端的内存与计算消耗，理论证明收敛率与模型维度无关，针对高效大模型训练与推理中的联邦学习资源限制问题
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09076' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting</h3>
<p><strong>Authors:</strong> Kangda Wei, Ruihong Huang</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出MMR-GRPO，通过多样性感知的奖励重加权减少GRPO训练的步骤与时间，在数学推理基准上实现高效训练，针对高效大模型训练与推理中的GRPO训练效率问题
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09085' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR</h3>
<p><strong>Authors:</strong> Jiaying Zhang, Lei Shi, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 针对RLVR的优化不稳定问题，提出GeoRA利用几何约束的低秩适配器，保留预训练模型的几何结构，提升RLVR性能，属于高效大模型训练的参数高效适应方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09361' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs</h3>
<p><strong>Authors:</strong> Jonathan Knoop, Hendrik Holtmann</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 系统评估消费级GPU的LLM推理性能，提供低成本本地部署指南，解决SME的隐私和成本问题，属于高效大模型推理的实际部署方向。
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.09527' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms</h3>
<p><strong>Authors:</strong> Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出零样本LLM引导的核心和频率分配框架，结合MARL和语义特征提取，显著提升嵌入式平台的能效和性能，对高效大模型推理的系统优化有重要价值
Score: 7
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.08166' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PhyRPR: Training-Free Physics-Constrained Video Generation</h3>
<p><strong>Authors:</strong> Yibo Zhao, Hengjia Li, Xiaofei He, Boxi Wu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出分阶段的扩散模型视频生成框架，通过物理推理、运动规划与潜空间融合实现物理约束的显式控制，属于大模型新技术中的扩散模型应用。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.09255' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Interpretable Probability Estimation with LLMs via Shapley Reconstruction</h3>
<p><strong>Authors:</strong> Yang Nan, Qihao Wen, Jiahao Wang, Pengfei He, Ravi Tandon, Yong Ge, Han Xu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出PRISM框架，利用Shapley值分解LLM预测的输入因子贡献，提升概率估计的可解释性和准确性，直接对应用户关注的Shapley value与可解释性方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.09151' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs</h3>
<p><strong>Authors:</strong> Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出基于Owen-Shapley归因的RL算法，解决生成搜索LLMs的信用分配问题，利用Shapley值进行片段级信用分配，对深度学习可解释性中的RL信用归因有重要价值
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08403' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set</h3>
<p><strong>Authors:</strong> Kaivalya Rawal, Eoin Delaney, Zihao Fu, Sandra Wachter, Chris Russell</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 聚焦可解释AI中解释对Rashomon集合内相似性能模型的区分能力，提出AXE方法评估特征重要性解释质量，可100%检测对抗性公平清洗，对深度学习可解释性的解释评估体系有重要贡献。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08703' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Attention Consistency Regularization for Interpretable Early-Exit Neural Networks</h3>
<p><strong>Authors:</strong> Yanhua Zhao</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 提出EGT框架优化早退神经网络的注意力一致性，通过正则化对齐早退与最终层的注意力图，在保持精度的同时提升模型可解释性，针对深度学习可解释性中的早退网络解释问题
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08891' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English</h3>
<p><strong>Authors:</strong> Sargam Yadav (Dundalk Institute of Technology), Abhishek Kaushik (Dundalk Institute of Technology), Kevin Mc Daid (Dundalk Institute of Technology)</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 针对混合语多模态性别歧视检测任务，结合SHAP和LIME技术提供特征重要性解释，推动了深度学习可解释性在多模态社会任务中的应用
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2601.08457' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MemoBrain: Executive Memory as an Agentic Brain for Reasoning</h3>
<p><strong>Authors:</strong> Hongjin Qian, Zhao Cao, Zheng Liu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 针对工具增强代理的长horizon推理上下文问题，提出依赖感知的executive memory模型，有效管理推理轨迹，在多个基准测试中优于基线，对多模态智能体的记忆机制研究有重要贡献
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08079' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination</h3>
<p><strong>Authors:</strong> Haoran Su, Yandong Sun, Congjia Yu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 论证了LLM从手工奖励工程向语言基目标指定的转变，提出多智能体协调的语义表示基础，对多模态智能体的协调机制研究有重要价值
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08237' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation</h3>
<p><strong>Authors:</strong> Yupeng Huo, Yaxi Lu, Zhong Zhang, Haotian Chen, Yankai Lin</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 将代理记忆管理分解为原子CRUD操作，通过监督微调与强化学习学习任务对齐的记忆策略，提升长上下文基准性能，对多模态智能体的记忆机制有重要贡献
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.08323' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models</h3>
<p><strong>Authors:</strong> Haoyan Gong, Hongbin Liu</p>
<p><strong>Published:</strong> 2026-01-15</p>
<p><strong>Reason:</strong> 基于Qwen3-VL大模态模型构建端到端退化车牌识别框架，通过字符感知多模态推理模块整合视觉特征与结构先验，属于原生多模态大模型的图像理解应用。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.09116' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>