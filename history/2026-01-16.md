# ArXiv 每日推荐 - 2026-01-16

> 更新于北京时间：2026-01-16 12:40:01
> 已自动阅读了 217 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：104231

## 深度学习理论

### [Score: 9.0/10] An Axiomatic Approach to General Intelligence: SANC(E3) -- Self-organizing Active Network of Concepts with Energy E3
- **Authors:** Daesuk Kwon, Won-gi Paeng
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08224](https://arxiv.org/abs/2601.08224)
- **Reason:** 提出通用智能的公理框架SANC(E3)，将表示单元的自组织作为核心，统一感知、想象、规划等认知过程，对深度学习理论的基础研究有重要启发
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] Beyond the final layer: Attentive multilayer fusion for vision transformers
- **Authors:** Laure Ciernik, Marco Morik, Lukas Thede, Luca Eyring, Shinichi Nakajima, Zeynep Akata, Lukas Muttenthaler
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09322](https://arxiv.org/abs/2601.09322)
- **Reason:** 研究视觉Transformer的中间层表示融合，通过注意力机制动态整合多层特征提升线性探测性能，揭示中间层信息对跨域任务的关键价值，属于深度学习理论中的表示学习研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Universal Dynamics of Warmup Stable Decay: understanding WSD beyond Transformers
- **Authors:** Annalisa Belloni, Lorenzo Noci, Antonio Orvieto
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09000](https://arxiv.org/abs/2601.09000)
- **Reason:** 研究WSD学习率调度器在Transformer与CNN上的训练动态，揭示损失景观的几何特性与优化路径一致性，为深度学习理论中的优化器调度器设计提供跨架构 insights
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Sparsity Is Necessary: Polynomial-Time Stability for Agentic LLMs in Large Action Spaces
- **Authors:** Angshul Majumdar
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08271](https://arxiv.org/abs/2601.08271)
- **Reason:** 研究agentic LLMs在大动作空间的稀疏控制问题，证明了稀疏性对多项式时间稳定性的必要性，对深度学习理论中的稀疏决策制定有重要贡献
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Greedy Is Enough: Sparse Action Discovery in Agentic LLMs
- **Authors:** Angshul Majumdar
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08280](https://arxiv.org/abs/2601.08280)
- **Reason:** 证明贪心算法在agentic LLMs稀疏动作发现中的有效性，提供了理论保证和下界分析，对深度学习理论中的大动作空间决策有重要价值
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Deconstructing Pre-training: Knowledge Attribution Analysis in MoE and Dense Models
- **Authors:** Bo Wang, Junzhuo Li, Hong Chen, Yuanlin Chu, Yuxuan Fan, Xuming Hu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08383](https://arxiv.org/abs/2601.08383)
- **Reason:** 通过Gated-LPI指标分析MoE和dense模型的知识获取动态，揭示了MoE的低熵骨干和早期consolidation特性，对深度学习理论中的模型架构与预训练关系有重要理解
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Depth-Wise Representation Development Under Blockwise Self-Supervised Learning for Video Vision Transformers
- **Authors:** Jonas R\"omer, Timo Dickscheid
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09040](https://arxiv.org/abs/2601.09040)
- **Reason:** 探索块级自监督学习在视频Transformer中的应用，分析深度方向的表示发展差异，比较端到端与块级训练的学习动态，属于深度学习理论中的训练策略研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Integrating Diverse Assignment Strategies into DETRs
- **Authors:** Yiwei Zhang, Jin Gao, Hanshi Wang, Fudong Ge, Guan Luo, Weiming Hu, Zhipeng Zhang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09247](https://arxiv.org/abs/2601.09247)
- **Reason:** 针对DETR的标签分配问题，通过LoRA分支整合多种one-to-many策略，实现多策略的轻量级融合，属于深度学习理论中的目标检测网络架构优化。
Score: 7
Field: 深度学习理论

## 大模型安全与对齐

### [Score: 9.0/10] Semantic Laundering in AI Agent Architectures: Why Tool Boundaries Do Not Confer Epistemic Warrant
- **Authors:** Oleg Romanchuk, Roman Bondar
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08333](https://arxiv.org/abs/2601.08333)
- **Reason:** 形式化了AI代理架构中的语义洗钱问题，证明了循环认知辩护的不可消除性，对大模型安全的架构层面风险有深刻分析
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] Why AI Alignment Failure Is Structural: Learned Human Interaction Structures and AGI as an Endogenous Evolutionary Shock
- **Authors:** Didier Sornette, Sandro Claudio Lera, Ke Wu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08673](https://arxiv.org/abs/2601.08673)
- **Reason:** 从人类社会互动结构的角度分析AI对齐失败的结构性根源，将AGI风险重新定义为人类矛盾的放大器，对大模型安全与对齐的理论框架有重要贡献
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] BalDRO: A Distributionally Robust Optimization based Framework for Large Language Model Unlearning
- **Authors:** Pengyang Shao, Naixin Zhai, Lei Chen, Yonghui Yang, Fengbin Zhu, Xun Yang, Meng Wang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09172](https://arxiv.org/abs/2601.09172)
- **Reason:** 针对LLM unlearning中的样本不平衡问题，提出BalDRO框架通过min-sup过程平衡难/易样本的遗忘，显著提升遗忘质量和模型效用，属于大模型安全与对齐的关键方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric
- **Authors:** Jiali Cheng, Ziheng Chen, Chirag Agarwal, Hadi Amiri
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09624](https://arxiv.org/abs/2601.09624)
- **Reason:** 从模型电路角度分析LLM unlearning的难度，提出CUD指标预测unlearning难度，为优化unlearning方法提供机制 insights，属于大模型安全与对齐的基础研究方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Reasoning over Precedents Alongside Statutes: Case-Augmented Deliberative Alignment for LLM Safety
- **Authors:** Can Jin, Rui Wu, Tong Che, Qixin Zhang, Hongwu Peng, Jiahui Zhao, Zhenting Wang, Wenqi Wei, Ligong Han, Zhao Zhang, Yuan Cao, Ruixiang Tang, Dimitris N. Metaxas
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08000](https://arxiv.org/abs/2601.08000)
- **Reason:** 提出CADA框架用案例增强deliberative alignment，解决LLM安全中的规则僵化问题，提升无害性和有用性，属于大模型安全与对齐的关键优化方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Semantic Gravity Wells: Why Negative Constraints Backfire
- **Authors:** Shailesh Rana
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08070](https://arxiv.org/abs/2601.08070)
- **Reason:** 深入研究大语言模型负约束指令遵循失败的机制，通过层分析和激活修补等方法揭示了priming failure和override failure两种模式，对大模型对齐的底层机制理解有重要价值
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] Bias Detection and Rotation-Robustness Mitigation in Vision-Language Models and Generative Image Models
- **Authors:** Tarannum Mithila
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08860](https://arxiv.org/abs/2601.08860)
- **Reason:** 研究视觉语言模型与生成图像模型的偏差传播及旋转鲁棒性问题，提出融合数据增强、表示对齐与正则化的缓解策略，属于大模型安全与对齐的核心研究方向。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Uncovering Political Bias in Large Language Models using Parliamentary Voting Records
- **Authors:** Jieying Chen, Karen de Jong, Andreas Poole, Jan Burakowski, Elena Elderson Nosti, Joep Windt, Chendi Wang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08785](https://arxiv.org/abs/2601.08785)
- **Reason:** 提出基于议会投票记录的政治偏见基准构建方法，评估LLM的意识形态倾向与政治实体偏见，为大模型安全与对齐中的政治偏见审计提供了系统框架。
Score: 7
Field: 大模型安全与对齐

### [Score: 6.0/10] Fairness risk and its privacy-enabled solution in AI-driven robotic applications
- **Authors:** Le Liu, Bangguo Yu, Nynke Vellinga, Ming Cao
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08953](https://arxiv.org/abs/2601.08953)
- **Reason:** 研究AI驱动机器人应用中的公平性风险，构建效用感知公平性指标并结合隐私预算解决公平性问题，为大模型安全与对齐在机器人场景下的伦理应用提供了实践方案。
Score: 6
Field: 大模型安全与对齐

## 高效大模型训练与推理

### [Score: 8.0/10] TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts
- **Authors:** Yu Xu, Hongbin Yan, Juan Cao, Yiji Cheng, Tiankai Hang, Runze He, Zijin Yin, Shiyi Zhang, Yuxin Zhang, Jintao Li, Chunyu Wang, Qinglin Lu, Tong-Yee Lee, Fan Tang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08881](https://arxiv.org/abs/2601.08881)
- **Reason:** 针对统一生成模型的任务干扰问题，提出任务感知的MoE门控机制，通过分层任务语义标注与预测对齐正则化实现专家模型的语义 specialization，属于高效大模型训练的关键技术。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation
- **Authors:** Xingyao Li, Fengzhuo Zhang, Cunxiao Du, Hui Ji
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09212](https://arxiv.org/abs/2601.09212)
- **Reason:** 提出退火松弛的投机解码策略，通过优化重采样分布与扰动分析提升自回归图像生成的推理速度，属于高效大模型推理的核心技术创新。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Spectral Complex Autoencoder Pruning: A Fidelity-Guided Criterion for Extreme Structured Channel Compression
- **Authors:** Wei Liu, Xing Deng, Haijian Shao, Yingtao Jiang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09352](https://arxiv.org/abs/2601.09352)
- **Reason:** 提出基于光谱重建保真度的通道剪枝方法，通过复杂交互场的频率域分析衡量通道冗余，在VGG16上实现高压缩率与低精度损失，针对高效大模型训练与推理中的模型压缩问题提供新方案
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Layer-Parallel Training for Transformers
- **Authors:** Shuai Jiang, Marc Salvado, Eric C. Cyr, Alena Kopaničáková, Rolf Krause, Jacob B. Schroder
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09026](https://arxiv.org/abs/2601.09026)
- **Reason:** 提出基于神经ODE的层并行训练方法，通过多水平并行算法加速Transformer的前向与反向传播，提升深层模型的训练并行性，针对高效大模型训练与推理中的并行训练问题
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache
- **Authors:** Chi-Chih Chang, Siqi Zhu, Zhichen Zeng, Haibin Lin, Jiaxuan You, Mohamed S. Abdelfattah, Ziheng Jiang, Xuehai Qian
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09083](https://arxiv.org/abs/2601.09083)
- **Reason:** 提出SRT方法，通过树结构缓存与推测解码加速强化学习的rollout过程，在PPO等 pipeline 中实现显著加速，针对高效大模型训练与推理中的RL训练 latency 问题
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling
- **Authors:** Zhixiang Liang, Beichen Huang, Zheng Wang, Minjia Zhang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09093](https://arxiv.org/abs/2601.09093)
- **Reason:** 提出STEP框架，通过隐藏状态评估推理步骤并动态剪枝无前景trace，有效降低LLM推理延迟（45%-70%）同时提升推理准确性，针对高效大模型推理的核心问题有显著改进。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] $D^2Prune$: Sparsifying Large Language Models via Dual Taylor Expansion and Attention Distribution Awareness
- **Authors:** Lang Xiong, Ning Liu, Ao Ren, Yuheng Bai, Haining Fang, BinYan Zhang, Zhe Jiang, Yujuan Tan, Duo Liu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09176](https://arxiv.org/abs/2601.09176)
- **Reason:** 提出D²Prune剪枝方法，通过双泰勒展开精确估计误差、注意力感知策略保留长tail模式，解决现有剪枝的激活分布偏移问题，有效压缩LLM同时保持性能，属于高效大模型训练的核心方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] YaPO: Learnable Sparse Activation Steering Vectors for Domain Adaptation
- **Authors:** Abdelaziz Bounhar, Rania Hossam Elmohamady Elbadry, Hadi Abdine, Preslav Nakov, Michalis Vazirgiannis, Guokan Shang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08441](https://arxiv.org/abs/2601.08441)
- **Reason:** 提出学习稀疏激活引导向量的方法，实现LLM的细粒度领域适应，同时保持通用知识，对高效大模型的域适配有重要贡献
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning
- **Authors:** Zhoubin Kou, Zihan Chen, Jing Yang, Cong Shen
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09076](https://arxiv.org/abs/2601.09076)
- **Reason:** 提出HERON-SFL框架，结合零阶与一阶优化降低联邦学习客户端的内存与计算消耗，理论证明收敛率与模型维度无关，针对高效大模型训练与推理中的联邦学习资源限制问题
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting
- **Authors:** Kangda Wei, Ruihong Huang
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09085](https://arxiv.org/abs/2601.09085)
- **Reason:** 提出MMR-GRPO，通过多样性感知的奖励重加权减少GRPO训练的步骤与时间，在数学推理基准上实现高效训练，针对高效大模型训练与推理中的GRPO训练效率问题
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR
- **Authors:** Jiaying Zhang, Lei Shi, Jiguo Li, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09361](https://arxiv.org/abs/2601.09361)
- **Reason:** 针对RLVR的优化不稳定问题，提出GeoRA利用几何约束的低秩适配器，保留预训练模型的几何结构，提升RLVR性能，属于高效大模型训练的参数高效适应方向。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs
- **Authors:** Jonathan Knoop, Hendrik Holtmann
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09527](https://arxiv.org/abs/2601.09527)
- **Reason:** 系统评估消费级GPU的LLM推理性能，提供低成本本地部署指南，解决SME的隐私和成本问题，属于高效大模型推理的实际部署方向。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms
- **Authors:** Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08166](https://arxiv.org/abs/2601.08166)
- **Reason:** 提出零样本LLM引导的核心和频率分配框架，结合MARL和语义特征提取，显著提升嵌入式平台的能效和性能，对高效大模型推理的系统优化有重要价值
Score: 7
Field: 高效大模型训练与推理

## 大模型新技术

### [Score: 8.0/10] PhyRPR: Training-Free Physics-Constrained Video Generation
- **Authors:** Yibo Zhao, Hengjia Li, Xiaofei He, Boxi Wu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09255](https://arxiv.org/abs/2601.09255)
- **Reason:** 提出分阶段的扩散模型视频生成框架，通过物理推理、运动规划与潜空间融合实现物理约束的显式控制，属于大模型新技术中的扩散模型应用。
Score: 8
Field: 大模型新技术

## 深度学习可解释性

### [Score: 8.0/10] Interpretable Probability Estimation with LLMs via Shapley Reconstruction
- **Authors:** Yang Nan, Qihao Wen, Jiahao Wang, Pengfei He, Ravi Tandon, Yong Ge, Han Xu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09151](https://arxiv.org/abs/2601.09151)
- **Reason:** 提出PRISM框架，利用Shapley值分解LLM预测的输入因子贡献，提升概率估计的可解释性和准确性，直接对应用户关注的Shapley value与可解释性方向。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Owen-Shapley Policy Optimization (OSPO): A Principled RL Algorithm for Generative Search LLMs
- **Authors:** Abhijnan Nath, Alireza Bagheri Garakani, Tianchen Zhou, Fan Yang, Nikhil Krishnaswamy
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08403](https://arxiv.org/abs/2601.08403)
- **Reason:** 提出基于Owen-Shapley归因的RL算法，解决生成搜索LLMs的信用分配问题，利用Shapley值进行片段级信用分配，对深度学习可解释性中的RL信用归因有重要价值
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Evaluating the Ability of Explanations to Disambiguate Models in a Rashomon Set
- **Authors:** Kaivalya Rawal, Eoin Delaney, Zihao Fu, Sandra Wachter, Chris Russell
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08703](https://arxiv.org/abs/2601.08703)
- **Reason:** 聚焦可解释AI中解释对Rashomon集合内相似性能模型的区分能力，提出AXE方法评估特征重要性解释质量，可100%检测对抗性公平清洗，对深度学习可解释性的解释评估体系有重要贡献。
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Attention Consistency Regularization for Interpretable Early-Exit Neural Networks
- **Authors:** Yanhua Zhao
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08891](https://arxiv.org/abs/2601.08891)
- **Reason:** 提出EGT框架优化早退神经网络的注意力一致性，通过正则化对齐早退与最终层的注意力图，在保持精度的同时提升模型可解释性，针对深度学习可解释性中的早退网络解释问题
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] An Under-Explored Application for Explainable Multimodal Misogyny Detection in code-mixed Hindi-English
- **Authors:** Sargam Yadav (Dundalk Institute of Technology), Abhishek Kaushik (Dundalk Institute of Technology), Kevin Mc Daid (Dundalk Institute of Technology)
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08457](https://arxiv.org/abs/2601.08457)
- **Reason:** 针对混合语多模态性别歧视检测任务，结合SHAP和LIME技术提供特征重要性解释，推动了深度学习可解释性在多模态社会任务中的应用
Score: 7
Field: 深度学习可解释性

## 多模态智能体

### [Score: 8.0/10] MemoBrain: Executive Memory as an Agentic Brain for Reasoning
- **Authors:** Hongjin Qian, Zhao Cao, Zheng Liu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08079](https://arxiv.org/abs/2601.08079)
- **Reason:** 针对工具增强代理的长horizon推理上下文问题，提出依赖感知的executive memory模型，有效管理推理轨迹，在多个基准测试中优于基线，对多模态智能体的记忆机制研究有重要贡献
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] The End of Reward Engineering: How LLMs Are Redefining Multi-Agent Coordination
- **Authors:** Haoran Su, Yandong Sun, Congjia Yu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08237](https://arxiv.org/abs/2601.08237)
- **Reason:** 论证了LLM从手工奖励工程向语言基目标指定的转变，提出多智能体协调的语义表示基础，对多模态智能体的协调机制研究有重要价值
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] AtomMem : Learnable Dynamic Agentic Memory with Atomic Memory Operation
- **Authors:** Yupeng Huo, Yaxi Lu, Zhong Zhang, Haotian Chen, Yankai Lin
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.08323](https://arxiv.org/abs/2601.08323)
- **Reason:** 将代理记忆管理分解为原子CRUD操作，通过监督微调与强化学习学习任务对齐的记忆策略，提升长上下文基准性能，对多模态智能体的记忆机制有重要贡献
Score: 8
Field: 多模态智能体

## 原生多模态大模型

### [Score: 7.0/10] LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models
- **Authors:** Haoyan Gong, Hongbin Liu
- **Published:** 2026-01-15
- **Link:** [https://arxiv.org/abs/2601.09116](https://arxiv.org/abs/2601.09116)
- **Reason:** 基于Qwen3-VL大模态模型构建端到端退化车牌识别框架，通过字符感知多模态推理模块整合视觉特征与结构先验，属于原生多模态大模型的图像理解应用。
Score: 7
Field: 原生多模态大模型

