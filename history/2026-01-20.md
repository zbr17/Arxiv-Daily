# ArXiv 每日推荐 - 2026-01-20

> 更新于北京时间：2026-01-20 12:43:00
> 已自动阅读了 159 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：77558

## 高效大模型训练与推理

### [Score: 9.0/10] Mugi: Value Level Parallelism For Efficient LLMs
- **Authors:** Daniel Price, Prabhu Vellaisamy, John Shen, Di Wu
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.10823](https://arxiv.org/abs/2601.10823)
- **Reason:** 提出Mugi架构，通过值级并行（VLP）优化LLM的非线性近似、小批量GEMM及全 workload 支持，实验显示softmax吞吐量提升45×、能效提升668×，属于高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] FAQ: Mitigating Quantization Error via Regenerating Calibration Data with Family-Aware Quantization
- **Authors:** Haiyang Xiao, Weiqing Li, Jinyue Guo, Guochao Jiang, Guohua Liu, Yuewei Zhang
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11200](https://arxiv.org/abs/2601.11200)
- **Reason:** 提出FAQ框架，利用同家族大模型生成携带CoT推理的高保真校准数据，优化后训练量化（PTQ）的误差，实验显示Qwen3-8B精度损失减少28.5%，属于高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] MHA2MLA-VLM: Enabling DeepSeek's Economical Multi-Head Latent Attention across Vision-Language Models
- **Authors:** Xiaoran Fan, Zhichao Sun, Tao Ji, Lixing Shen, Tao Gui
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11464](https://arxiv.org/abs/2601.11464)
- **Reason:** 针对视觉语言模型推理时KV缓存的内存与计算瓶颈，提出参数高效的MHA到MLA转换框架，通过模态自适应策略与低秩近似实现高效推理，实验验证可恢复模型性能并减少缓存占用，对高效大模型推理有重要实用价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] HOSL: Hybrid-Order Split Learning for Memory-Constrained Edge Training
- **Authors:** Aakriti, Zhe Li, Dandan Liang, Chao Huang, Rui Li, Haibo Yang
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.10940](https://arxiv.org/abs/2601.10940)
- **Reason:** 提出HOSL框架，结合零阶（ZO）与一阶（FO）优化解决边缘设备split learning的内存问题，理论证明收敛率依赖客户端模型维度，实验显示OPT模型内存减少3.7×，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Differentially Private Subspace Fine-Tuning for Large Language Models
- **Authors:** Lele Zheng, Xiang Wang, Tao Zhang, Yang Cao, Ke Cheng, Yulong Shen
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11113](https://arxiv.org/abs/2601.11113)
- **Reason:** 提出DP-SFT框架，通过主梯度方向识别任务子空间，仅在子空间注入DP噪声，减少噪声对无关参数的影响，实验显示多数据集上准确性与稳定性优于DP微调基线，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] SDFLoRA: Selective Dual-Module LoRA for Federated Fine-tuning with Heterogeneous Clients
- **Authors:** Zhikang Shen, Jianrong Lu, Haiyuan Wan, Jianhai Chen
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11219](https://arxiv.org/abs/2601.11219)
- **Reason:** 提出SDFLoRA，将LoRA分解为捕捉通用知识的全局模块与保留客户特异性的局部模块，解决联邦学习中的秩异质性问题，实验显示GLUE基准上优于联邦LoRA基线，属于高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Low-Rank Key Value Attention
- **Authors:** James O'Neill, Robert Clancy, Mariia Matskevichus, Fergal Reid
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11471](https://arxiv.org/abs/2601.11471)
- **Reason:** 提出低秩键值注意力机制LRKV，通过共享全秩KV投影加低秩残差的方式减少Transformer的KV缓存内存占用，同时保留头多样性，实验验证在2.5B规模模型上用约一半KV缓存实现更优性能，属于高效大模型训练与推理的核心优化方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Beyond Model Scaling: Test-Time Intervention for Efficient Deep Reasoning
- **Authors:** Qianyue Wang, Jinwu Hu, Yufeng Wang, Huanxiang Lin, Bolin Chen, Zhiquan Wen, Yaofo Chen, Mingkui Tan
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11252](https://arxiv.org/abs/2601.11252)
- **Reason:** 提出Test-Time交互推理范式Think-with-Me，通过过渡连词处的外部反馈干预减少LLM推理中的过度思考与冗余，在保持准确性的同时缩短推理长度，属于高效大模型训练与推理中的推理效率优化方向，实验验证在AIME24上有显著提升。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] VLAgents: A Policy Server for Efficient VLA Inference
- **Authors:** Tobias J\"ulg, Khaled Gamal, Nisarga Nilavadi, Pierre Krack, Seongjin Bien, Michael Krawez, Florian Walter, Wolfram Burgard (RobotControlStack)
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11250](https://arxiv.org/abs/2601.11250)
- **Reason:** 提出VLAgents模块化策略服务器，针对视觉-语言-动作（VLA）模型推理部署的碎片化接口与通信延迟问题，通过统一协议及自适应通信层（零拷贝共享内存+压缩流）优化效率，比OpenVLA等默认服务器性能更优，属于高效大模型推理的重要实践，项目开源且作者团队有影响力。
Score: 7
Field: 高效大模型训练与推理

## 深度学习理论

### [Score: 9.0/10] Transient learning dynamics drive escape from sharp valleys in Stochastic Gradient Descent
- **Authors:** Ning Yang, Yikuan Zhang, Qi Ouyang, Chao Tang, Yuhai Tu
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.10962](https://arxiv.org/abs/2601.10962)
- **Reason:** 分析SGD学习动力学，揭示其逃离sharp valleys的非平衡机制（ transient exploratory phase + 冻结效应），建立损失 landscape 几何与泛化的统一物理框架，属于深度学习理论中的优化与损失 landscape 方向。
Score: 9
Field: 深度学习理论

### [Score: 8.5/10] Analytic Bijections for Smooth and Interpretable Normalizing Flows
- **Authors:** Mathis Gerdes, Miranda C. N. Cheng
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.10774](https://arxiv.org/abs/2601.10774)
- **Reason:** 提出三类分析双射函数，解决归一化流中双射函数的expressivity、smoothness与invertibility trade-off，实现全局光滑、闭形式可逆且高表达力，对深度学习理论中的归一化流架构设计有突破性贡献。
Score: 8.5
Field: 深度学习理论

### [Score: 8.0/10] Unified Optimization of Source Weights and Transfer Quantities in Multi-Source Transfer Learning: An Asymptotic Framework
- **Authors:** Qingyue Zhang, Chang Chu, Haohao Fu, Tianren Peng, Yanru Wu, Guanbo Huang, Yang Li, Shao-Lun Huang
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.10779](https://arxiv.org/abs/2601.10779)
- **Reason:** 提出UOWQ框架，基于KL散度泛化误差的渐近分析联合优化多源迁移学习的源权重与迁移量，理论证明全源样本最优性并给出闭解，实验验证优于DomainNet等基准的强基线，属于深度学习理论中的优化方向。
Score: 8
Field: 深度学习理论

### [Score: 7.5/10] SoLA-Vision: Fine-grained Layer-wise Linear Softmax Hybrid Attention
- **Authors:** Ruibang Li, Guan Luo, Yiwei Zhang, Jin Gao, Bing Li, Weiming Hu
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11164](https://arxiv.org/abs/2601.11164)
- **Reason:** 针对softmax注意力二次复杂度与线性注意力容量缺陷的问题，提出层-wise线性-softmax混合注意力架构，通过细粒度混合策略平衡计算效率与模型性能，对深度学习理论中的注意力机制设计有创新性贡献。
Score: 7.5
Field: 深度学习理论

### [Score: 7.0/10] Unit-Consistent (UC) Adjoint for GSD and Backprop in Deep Learning Applications
- **Authors:** Jeffrey Uhlmann
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.10873](https://arxiv.org/abs/2601.10873)
- **Reason:** 针对正齐次网络的 gauge symmetry 问题，提出单位一致（UC）伴随方法，推导UC gauge-consistent梯度下降与反向传播，解决标准梯度下降的参数化依赖问题，属于深度学习理论中的优化方向。
Score: 7
Field: 深度学习理论

## 大模型新技术

### [Score: 9.0/10] Unlocking the Potentials of Retrieval-Augmented Generation for Diffusion Language Models
- **Authors:** Chuanyue Yu, Jiahui Wang, Yuhan Li, Heng Chang, Ge Lan, Qingyun Sun, Jia Li, Jianxin Li, Ziwei Zhang
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11342](https://arxiv.org/abs/2601.11342)
- **Reason:** 系统研究RAG在扩散语言模型（DLM）中的应用，提出SPREAD框架通过查询相关性引导去噪解决语义漂移问题，实验验证生成精度提升，属于大模型新技术中的diffusion LLM方向。
Score: 9
Field: 大模型新技术

### [Score: 7.0/10] When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models
- **Authors:** Rapha\"el Razafindralambo, R\'emy Sun, Fr\'ed\'eric Precioso, Damien Garreau, Pierre-Alexandre Mattei
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11444](https://arxiv.org/abs/2601.11444)
- **Reason:** 系统研究扩散模型的集成策略（如Deep Ensembles、Monte Carlo Dropout）对生成质量的影响，分析分数集成与图像质量的关联，属于大模型新技术中的diffusion模型优化方向，为扩散模型的性能提升提供理论与实验 insights。
Score: 7
Field: 大模型新技术

## 深度学习可解释性

### [Score: 8.0/10] Action Shapley: A Training Data Selection Metric for World Model in Reinforcement Learning
- **Authors:** Rajat Ghosh, Debojyoti Dutta
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.10905](https://arxiv.org/abs/2601.10905)
- **Reason:** 提出Action Shapley指标，基于Shapley值解决强化学习世界模型的训练数据选择问题，设计随机动态算法将计算复杂度从指数级降低80%，实验验证优于随机选择，属于深度学习可解释性方向。
Score: 8
Field: 深度学习可解释性

## 大模型安全与对齐

### [Score: 8.0/10] Spurious Rewards Paradox: Mechanistically Understanding How RLVR Activates Memorization Shortcuts in LLMs
- **Authors:** Lecheng Yan, Ruizhe Li, Guanhua Chen, Qing Li, Jiahui Geng, Wenxi Li, Vincent Wang, Chris Lee
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11061](https://arxiv.org/abs/2601.11061)
- **Reason:** 研究RLVR中虚假奖励导致LLM记忆捷径的机制，揭示Anchor-Adapter电路（中间层Functional Anchor触发记忆检索，后续层Structural Adapters适配信号），提供因果调控方法，属于大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Building Production-Ready Probes For Gemini
- **Authors:** J\'anos Kram\'ar, Joshua Engels, Zheng Wang, Bilal Chughtai, Rohin Shah, Neel Nanda, Arthur Conmy
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11516](https://arxiv.org/abs/2601.11516)
- **Reason:** 针对LLM滥用检测问题，设计能处理长上下文等生产环境分布偏移的探针架构，已部署到Gemini的用户端实例，解决大模型安全与对齐中的滥用 mitigation 问题，具有实际应用价值。
Score: 8
Field: 大模型安全与对齐

## 多模态智能体

### [Score: 8.0/10] ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models
- **Authors:** Linqing Zhong, Yi Liu, Yifei Wei, Ziyu Xiong, Maoqing Yao, Si Liu, Guanghui Ren
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11404](https://arxiv.org/abs/2601.11404)
- **Reason:** 针对视觉-语言-动作（VLA）模型直接生成动作的局限性，提出Action Chain-of-Thought（ACoT）范式，通过粗动作意图序列推理指导精确动作执行，融合显式/隐式动作推理组件，在LIBERO等数据集上取得98.5%的顶尖成绩，显著提升多模态智能体的操纵任务性能。
Score: 8
Field: 多模态智能体

## 原生多模态大模型

### [Score: 7.0/10] Think-Clip-Sample: Slow-Fast Frame Selection for Video Understanding
- **Authors:** Wenhui Tan, Ruihua Song, Jiaze Li, Jianzhong Ju, Zhenbo Luo
- **Published:** 2026-01-19
- **Link:** [https://arxiv.org/abs/2601.11359](https://arxiv.org/abs/2601.11359)
- **Reason:** 针对多模态大模型长视频理解的计算约束与帧选择问题，提出训练-free框架，通过多查询推理与clip-level慢快采样平衡局部细节与全局上下文，提升长视频理解性能与效率，属于原生多模态大模型的关键优化。
Score: 7
Field: 原生多模态大模型

