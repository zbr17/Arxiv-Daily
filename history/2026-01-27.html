<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2026-01-27</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>原生多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >大模型新技术</a>
<a href='#' >高效大模型训练与推理</a>
<a href='#' >多模态智能体</a>
<a href='#' >大模型安全与对齐</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2026-01-27</h1>
<div class='meta-info'><p>更新于北京时间：2026-01-27 12:48:06</p>
<p>已自动阅读了 135 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：77740</p>
</div>
<div id='' class='field-section'>
<h2>原生多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Emotion-LLaMAv2 and MMEVerse: A New Framework and Benchmark for Multimodal Emotion Understanding</h3>
<p><strong>Authors:</strong> Xiaojiang Peng, Jingyi Chen, Zebang Cheng, Bao Peng, Fengyi Wu, Yifei Dong, Shuyuan Tu, Qiyu Hu, Huiting Huang, Yuxiang Lin, Jun-Yan He, Kai Wang, Zheng Lian, Zhi-Qi Cheng</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出Emotion-LLaMAv2多模态情感模型及MMEVerse基准，解决原有模型依赖人脸检测器的问题，实现端到端情感推理，推动多模态情感分析领域发展。
Score: 9
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16449' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Cognitively-Inspired Tokens Overcome Egocentric Bias in Multimodal Models</h3>
<p><strong>Authors:</strong> Bridget Leonard, Scott O. Murray</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 引入认知启发的视角token解决多模态模型的自我中心偏差，提升空间推理能力，对多模态token设计与空间理解有创新贡献。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16378' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Order from Chaos: Physical World Understanding from Glitchy Gameplay Videos</h3>
<p><strong>Authors:</strong> Meng Cao, Haoran Tang, Haoze Zhao, Mingfei Han, Ruyang Liu, Qiang Sun, Xiaojun Chang, Ian Reid, Xiaodan Liang</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 利用游戏视频中的物理异常作为监督源，构建PhysGame数据集和GameBench基准，提升多模态模型的物理世界理解能力，方法新颖且有实际贡献。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16471' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Reward-Forcing: Autoregressive Video Generation with Reward Feedback</h3>
<p><strong>Authors:</strong> Jingran Zhang, Ning Li, Yuanhao Ban, Andrew Bai, Justin Cui</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出Reward-Forcing方法，用奖励信号引导自回归视频生成，简化训练流程并保持高视觉 fidelity，性能优于同类模型。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16933' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SyncLight: Controllable and Consistent Multi-View Relighting</h3>
<p><strong>Authors:</strong> David Serrano-Lozano, Anand Bhattad, Luis Herranz, Jean-François Lalonde, Javier Vazquez-Corral</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 首个解决多视图一致重光照的方法，利用多视图扩散Transformer实现精确光照控制，解决了多模态生成的一致性难题，对原生多模态大模型的图像生成研究有重要推动作用。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16981' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AnyView: Synthesizing Any Novel View in Dynamic Scenes</h3>
<p><strong>Authors:</strong> Basile Van Hoorick, Dian Chen, Shun Iwase, Pavel Tokmakov, Muhammad Zubair Irshad, Igor Vasiljevic, Swati Gupta, Fangzhou Cheng, Sergey Zakharov, Vitor Campagnolo Guizilini</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出动态场景任意新视图合成框架AnyView，基于扩散模型解决动态场景的多视图一致性问题，无需几何假设，在极端动态场景下表现优异，是原生多模态图像生成的重要进展。
Score: 8
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16982' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Where is the multimodal goal post? On the Ability of Foundation Models to Recognize Contextually Important Moments</h3>
<p><strong>Authors:</strong> Aditya K Surikuchi, Raquel Fern\'andez, Sandro Pezzelle</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 构建基于足球比赛的数据集，评估多模态基础模型识别重要时刻的能力，揭示模型依赖单一模态的问题，为多模态模型的评估与改进提供指导。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TangramPuzzle: Evaluating Multimodal Large Language Models with Compositional Spatial Reasoning</h3>
<p><strong>Authors:</strong> Daixian Liu, Jiayi Kuang, Yinghui Li, Yangning Li, Di Yin, Haoyu Cao, Xing Sun, Ying Shen, Hai-Tao Zheng, Liang Lin, Philip S. Yu</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 构建TangramPuzzle基准，基于七巧板游戏评估多模态大模型的组合空间推理能力，揭示模型重轮廓轻几何约束的问题，为空间推理评估提供新方法。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16520' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> OnlineSI: Taming Large Language Model for Online 3D Understanding and Grounding</h3>
<p><strong>Authors:</strong> Zixian Liu, Zhaoxi Chen, Liang Pan, Ziwei Liu</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出OnlineSI框架，通过有限空间记忆维持LLM对在线3D场景的理解与接地，推动多模态模型在3D场景中的实时应用。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16538' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> X-Aligner: Composed Visual Retrieval without the Bells and Whistles</h3>
<p><strong>Authors:</strong> Yuqian Zheng, Mariana-Iuliana Georgescu</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出X-Aligner跨注意力模块，改进多模态视觉检索的特征融合与对齐，在Webvid-CoVR和零样本CIR任务上取得SOTA性能。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16582' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> AutoRegressive Generation with B-rep Holistic Token Sequence Representation</h3>
<p><strong>Authors:</strong> Jiahao Li, Yunpeng Bai, Yongkang Dai, Hao Guo, Hongping Gan, Yilei Shi</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 将B-rep编码为整体token序列，用自回归模型生成，解决传统图表示的结构与拓扑分离问题，对B-rep生成的token化方法有创新。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16771' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Incorporating Eye-Tracking Signals Into Multimodal Deep Visual Models For Predicting User Aesthetic Experience In Residential Interiors</h3>
<p><strong>Authors:</strong> Chen-Ying Chien, Po-Chih Kuo</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出双分支框架融合视觉特征与眼动信号，提升住宅室内审美体验的预测准确性，对多模态融合在用户体验领域的应用有参考价值。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16811' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ColorConceptBench: A Benchmark for Probabilistic Color-Concept Understanding in Text-to-Image Models</h3>
<p><strong>Authors:</strong> Chenxi Ruan, Yu Xiao, Yihan Hou, Guosheng Hu, Wei Zeng</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 构建ColorConceptBench基准，评估文本到图像模型对颜色概念的概率理解能力，揭示模型缺乏抽象语义敏感性的问题，为颜色-概念关联的评估提供工具。
Score: 7
Field: 原生多模态大模型</p>
<p><a href='https://arxiv.org/abs/2601.16836' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> No Validation, No Problem: Predicting Model Performance from a Single Gradient</h3>
<p><strong>Authors:</strong> Fangzheng Wu, Brian Summa</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出通过分类头的单梯度预测模型性能，无需验证集即可选择最优checkpoint，实验证明在多个任务上有效，对模型训练与优化有重大创新。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16874' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> A Step to Decouple Optimization in 3DGS</h3>
<p><strong>Authors:</strong> Renjie Ding, Yaonan Wang, Min Liu, Jialin Zhu, Jiazheng Wang, Jiahao Zhao, Wenting Shen, Feixiang He, Xiang Che</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 分析3D高斯splatting中的优化耦合问题，提出Sparse Adam等改进方法，提升优化效率与表示效果，对3DGS的优化理论有深入贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16736' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CASP: Few-Shot Class-Incremental Learning with CLS Token Attention Steering Prompts</h3>
<p><strong>Authors:</strong> Shuai Huang, Xuhan Lin, Yuwu Lu</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出CASP方法，通过CLS token的注意力引导prompt解决少样本增量学习问题，实验证明在多个数据集上超过SOTA，对prompt设计与增量学习有贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16773' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Finite-Time Analysis of Gradient Descent for Shallow Transformers</h3>
<p><strong>Authors:</strong> Enes Arda, Semih Cayci, Atilla Eryilmaz</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 对浅层Transformer在核 regime下的投影梯度下降进行有限时间分析，发现宽度仅需对数级增长、优化误差与序列长度无关，为Transformer的优化理论提供了关键新见解。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16514' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Provably Learning Attention with Queries</h3>
<p><strong>Authors:</strong> Satwik Bhattamishra, Kulin Shah, Michael Hahn, Varun Kanade</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 研究单头/多头注意力的可学习性，给出单头注意力的精确学习算法与样本复杂度，证明多头注意力的不可识别性，为注意力机制的理论研究提供了里程碑式结果。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16873' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Cosine Network for Image Super-Resolution</h3>
<p><strong>Authors:</strong> Chunwei Tian, Chengyuan Zhang, Bob Zhang, Zhiwu Li, C. L. Philip Chen, David Zhang</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出余弦网络，通过奇偶异构块提取互补特征并优化训练，改进图像超分辨率性能，对网络架构设计有参考价值。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16413' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Analyzing Neural Network Information Flow Using Differential Geometry</h3>
<p><strong>Authors:</strong> Shuhang Tan, Jayson Sia, Paul Bogdan, Radoslav Ivanov</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 利用微分几何中的Ollivier-Ricci曲率分析神经网络信息流动，提出神经曲率指标识别关键连接，通过剪枝实验验证有效性，为深度学习理论提供了几何视角的新分析工具。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16366' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> On the Expressive Power of Floating-Point Transformers</h3>
<p><strong>Authors:</strong> Sejun Park, Yeachan Park, Geonho Hwang</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 研究浮点运算下Transformer的表达能力，发现其可表示非置换等变函数，且序列长度影响表达能力，填补了Transformer在实际硬件实现中的理论空白，对网络架构理论有贡献。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16450' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Process-Tensor Tomography of SGD: Measuring Non-Markovian Memory via Back-Flow of Distinguishability</h3>
<p><strong>Authors:</strong> Vasileios Sevetlidis, George Pavlidis</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 将神经训练建模为过程张量，提出可区分性回流的非马尔可夫性见证者，实证验证SGD的非马尔可夫性，为优化器记忆性分析提供了principled诊断工具，推动深度学习优化理论发展。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16563' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Multigrade Neural Network Approximation</h3>
<p><strong>Authors:</strong> Shijun Zhang, Zuowei Shen, Yuesheng Xu</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出多等级深度学习框架MGDL，通过逐层冻结与残差训练实现结构化误差细化，证明一致收敛性，为深度网络的近似理论提供了principled新框架，推动深度学习理论发展。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2601.16884' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型新技术</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> LoL: Longer than Longer, Scaling Video Generation to Hour</h3>
<p><strong>Authors:</strong> Justin Cui, Jie Wu, Ming Li, Tao Yang, Xiaojie Li, Rui Wang, Andrew Bai, Yuanhao Ban, Cho-Jui Hsieh</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出LoL方法，解决长视频生成中的sink-collapse问题，实现小时级实时视频生成，对扩散模型在长视频领域的应用有突破性贡献。
Score: 9
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.16914' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Memory-V2V: Augmenting Video-to-Video Diffusion Models with Memory</h3>
<p><strong>Authors:</strong> Dohun Lee, Chun-Hao Paul Huang, Xuelin Chen, Jong Chul Ye, Duygu Ceylan, Hyeonho Jeong</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出Memory-V2V框架，通过添加记忆模块解决多轮视频编辑中的跨一致性问题，改进视频到视频扩散模型的实用性能，对扩散模型在视频编辑场景的落地有重要价值。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.16296' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Edge-Aware Image Manipulation via Diffusion Models with a Novel Structure-Preservation Loss</h3>
<p><strong>Authors:</strong> Minsu Gong, Nuri Ryu, Jungseul Ok, Sunghyun Cho</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出结构保持损失，通过局部线性模型量化结构差异，改进扩散模型的图像编辑效果，有效保持边缘结构。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.16645' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Auto-Regressive Masked Diffusion Models</h3>
<p><strong>Authors:</strong> Mahdi Karami (Unknown), Ali Ghodsi (Unknown)</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出ARMD模型，融合自回归模型的训练效率与扩散模型的并行生成能力，针对语言建模场景解决diffusion与autoregressive的性能 gap，属于大模型新技术中的diffusion LLM方向，具有架构创新价值。
Score: 8
Field: 大模型新技术</p>
<p><a href='https://arxiv.org/abs/2601.16971' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>高效大模型训练与推理</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> A Scalable Measure of Loss Landscape Curvature for Analyzing the Training Dynamics of LLMs</h3>
<p><strong>Authors:</strong> Dayal Singh Kalra (Unknown), Jean-Christophe Gagnon-Audet (Unknown), Andrey Gromov (Unknown), Ishita Mediratta (Unknown), Kelvin Niu (Unknown), Alexander H Miller (Unknown), Michael Shvartsman (Unknown)</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出critical sharpness这一可扩展的损失 landscape曲率度量方法，解决LLM Hessian计算成本过高的问题，首次在7B参数模型上验证了训练动态的曲率现象，为高效LLM训练提供了实用诊断工具，属于高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.16979' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> LongCat-Flash-Thinking-2601 Technical Report</h3>
<p><strong>Authors:</strong> Meituan LongCat Team (Meituan), Anchun Gui (Meituan), Bei Li (Meituan), Bingyang Tao (Meituan), Bole Zhou (Meituan), Borun Chen (Meituan), Chao Zhang (Meituan), Chao Zhang (Meituan), Chen Gao (Meituan), Chen Zhang (Meituan), Chengcheng Han (Meituan), Chenhui Yang (Meituan), Chuyu Zhang (Meituan), Cong Chen (Meituan), Cunguang Wang (Meituan), Daoru Pan (Meituan), Defei Bu (Meituan), Dengchang Zhao (Meituan), Di Xiu (Meituan), Dishan Liu (Meituan), Dongyu Ru (Meituan), Dunwei Tu (Meituan), Fan Wu (Meituan), Fengcheng Yuan (Meituan), Fengcun Li (Meituan), Gang Xu (Meituan), Guanyu Wu (Meituan), Guoyuan Lin (Meituan), Haibin Wang (Meituan), Hansi Yang (Meituan), Hao Yang (Meituan), Haonan Yan (Meituan), Haoxiang Ma (Meituan), Haoxing Wen (Meituan), Hongyan Hao (Meituan), Hongyin Tang (Meituan), Hongyu Zang (Meituan), Hongzhi Ni (Meituan), Hui Su (Meituan), Jiacheng Zhang (Meituan), Jiahong Zhou (Meituan), Jiahuan Li (Meituan), Jiaming Wang (Meituan), Jian Yang (Meituan), Jianfei Zhang (Meituan), Jianhao Xu (Meituan), Jianing Wang (Meituan), Jiapeng Zhu (Meituan), Jiaqi Sun (Meituan), Jiarong Shi (Meituan), Jiarui Zhao (Meituan), Jingang Wang (Meituan), Jinluan Yang (Meituan), Jinrui Ding (Meituan), Jinwei Xiao (Meituan), Jiyuan He (Meituan), Juncan Xu (Meituan), Kefeng Zhang (Meituan), Keheng Wang (Meituan), Li Wei (Meituan), Lianhui Ma (Meituan), Lin Qiu (Meituan), Lingbing Kong (Meituan), Lingchuan Liu (Meituan), Linsen Guo (Meituan), Mengshen Zhu (Meituan), Mengxia Shen (Meituan), Mingyang Zhu (Meituan), Peiguang Li (Meituan), Peng Pei (Meituan), Pengcheng Jia (Meituan), Pengtao Zhang (Meituan), Peng Zhao (Meituan), Qi Gu (Meituan), Qiong Huang (Meituan), Qiyuan Duan (Meituan), Quanchi Weng (Meituan), Rongxiang Weng (Meituan), Rongzhi Zhang (Meituan), Rumei Li (Meituan), Shanglin Lei (Meituan), Shengnan An (Meituan), Shijun Dai (Meituan), Shuaikang Liu (Meituan), Shuang Zhou (Meituan), Shuo Wang (Meituan), Songyuan Zhao (Meituan), Tao Liang (Meituan), Tianhao Hu (Meituan), Tianze Chen (Meituan), Wei Liu (Meituan), Wei Shi (Meituan), Wei Wang (Meituan), Weifeng Tang (Meituan), Wenjie Shi (Meituan), Wenlong Zhu (Meituan), Wentao Chen (Meituan), Wentao Shi (Meituan), Xi Su (Meituan), Xiangcheng Liu (Meituan), Xiandi Ma (Meituan), Xiangyu Xi (Meituan), Xiangyuan Liu (Meituan), Xiangzhou Huang (Meituan), Xiao Liu (Meituan), Xiaodong Cai (Meituan), Xiaolong Chen (Meituan), Xiaowei Shi (Meituan), Xiaoyu Li (Meituan), Xin Chen (Meituan), Xingchen Liu (Meituan), Xuan Huang (Meituan), Xuezhi Cao (Meituan), Xunliang Cai (Meituan), Yan Chen (Meituan), Yang Bai (Meituan), Yang Liu (Meituan), Yang Yang (Meituan), Yang Zheng (Meituan), Yaoming Wang (Meituan), Yaoming Zhu (Meituan), Yaqi Huo (Meituan), Yanyu Chen (Meituan), Yaorui Shi (Meituan), Yerui Sun (Meituan), Yi Zhang (Meituan), Yihao Chen (Meituan), Yi-Kai Zhang (Meituan), Yifan Lu (Meituan), Yifan Zhao (Meituan), Yitao Zhai (Meituan), Yongjing Yin (Meituan), Yongwei Zhou (Meituan), Youshao Xiao (Meituan), Yuchuan Dai (Meituan), Yuchen Xie (Meituan), Yuchen Yu (Meituan), Yufei Zhang (Meituan), Yuhuai Wei (Meituan), Yulei Qian (Meituan), Yunfan Liang (Meituan), Yunke Zhao (Meituan), Yuwei Jiang (Meituan), Yuxin Bian (Meituan), Yuxin Chen (Meituan), Yuxin Liu (Meituan), Yue Xu (Meituan), Yueqing Sun (Meituan), Zeyang Yu (Meituan), Zhao Yang (Meituan), Zhengsheng Huang (Meituan), Zhengyu Chen (Meituan), Zhijian Liu (Meituan), Zhikang Xia (Meituan), Zhimin Lin (Meituan), Zhiyuan Yao (Meituan), Zhuofan Chen (Meituan), Zhuowen Han (Meituan), Zijian Zhang (Meituan), Ziran Li (Meituan), Ziwen Wang (Meituan), Ziyuan Zhuang (Meituan)</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出560B参数MoE架构的LongCat-Flash-Thinking-2601模型，通过多环境训练、异步RL框架及Heavy Thinking模式提升agentic推理性能，解决大模型推理中的长尾任务与噪声鲁棒性问题，属于高效大模型训练与推理方向，具有大规模工程实践价值。
Score: 9
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.16725' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SALAD: Achieve High-Sparsity Attention via Efficient Linear Attention Tuning for Video Diffusion Transformer</h3>
<p><strong>Authors:</strong> Tongcheng Fang, Hanling Zhang, Ruiqi Xie, Zhuo Han, Xin Tao, Tianchen Zhao, Pengfei Wan, Wenbo Ding, Wanli Ouyang, Xuefei Ning, Yu Wang</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出SALAD方法，通过高效线性注意力调优实现高稀疏性注意力，在保持视频扩散模型生成质量的同时提升推理速度1.72倍，对高效大模型推理有贡献。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.16515' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SemanticALLI: Caching Reasoning, Not Just Responses, in Agentic Systems</h3>
<p><strong>Authors:</strong> Varun Chillara (Unknown), Dylan Kline (Unknown), Christopher Alvares (Unknown), Evan Wooten (Unknown), Huan Yang (Unknown), Shlok Khetan (Unknown), Cade Bauer (Unknown), Tré Guillory (Unknown), Tanishka Shah (Unknown), Yashodhara Dhariwal (Unknown), Volodymyr Pavlov (Unknown), George Popstefanov (Unknown)</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出SemanticALLI架构，通过缓存中间推理步骤（而非仅最终响应）减少Agentic系统中的LLM重复调用，将缓存命中率从38.7%提升至83.1%，显著提升推理效率，属于高效大模型训练与推理中的efficient LLM inference方向。
Score: 8
Field: 高效大模型训练与推理</p>
<p><a href='https://arxiv.org/abs/2601.16286' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态智能体</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VisGym: Diverse, Customizable, Scalable Environments for Multimodal Agents</h3>
<p><strong>Authors:</strong> Zirui Wang, Junyi Zhang, Jiaxin Ge, Long Lian, Letian Fu, Lisa Dunlap, Ken Goldberg (University of California, Berkeley), XuDong Wang, Ion Stoica (University of California, Berkeley), David M. Chan, Sewon Min, Joseph E. Gonzalez (University of California, Berkeley)</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出多模态智能体评估环境VisGym，覆盖符号谜题、真实图像理解等任务，支持多步交互能力评估，为多模态智能体研究提供关键工具，作者团队包含知名学者与机构。
Score: 8
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.16973' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation</h3>
<p><strong>Authors:</strong> Tims Pecerskis (Unknown), Aivars Smirnovs (Unknown)</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出NSED协议与MoM架构，通过动态专家 brokerage与宏尺度RNN审议机制统一异质agent，实现小模型ensemble超越大模型性能，属于多模态智能体方向，针对多agent系统的鲁棒性与效率提升有创新。
Score: 7
Field: 多模态智能体</p>
<p><a href='https://arxiv.org/abs/2601.16863' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>大模型安全与对齐</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Towards a Theoretical Understanding to the Generalization of RLHF</h3>
<p><strong>Authors:</strong> Zhaochun Li (Beijing Institute of Technology, Zhongguancun Academy), Mingyang Yi (Renmin University of China), Yue Wang (Zhongguancun Academy), Shisheng Cui (Beijing Institute of Technology), Yong Liu (Renmin University of China)</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 首次通过算法稳定性框架理论分析RLHF的泛化性，证明了特征覆盖条件下的泛化界，为大模型对齐的核心方法RLHF提供了理论支撑，填补了对齐理论的空白。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.16403' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Beyond Superficial Unlearning: Sharpness-Aware Robust Erasure of Hallucinations in Multimodal LLMs</h3>
<p><strong>Authors:</strong> Xianya Fang, Feiyang Ren, Xiang Chen, Yu Tian, Zhen Bi, Haiyang Yu, Sheng-Jun Huang</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出SARE方法解决多模态LLM的幻觉问题，通过最小-最大优化和目标SAM机制实现鲁棒遗忘，避免表面清除，实验证明在保持生成质量的同时有效消除幻觉，对大模型安全至关重要。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.16527' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints</h3>
<p><strong>Authors:</strong> Andy Zhu, Rongzhe Wei, Yupu Gu, Pan Li</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 提出GRIP框架解决MoE的机器遗忘问题，通过几何路由约束避免路由器表面操作，实验证明保持模型效用的同时实现有效遗忘，为大模型安全的机器遗忘研究提供了关键方法。
Score: 8
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.16905' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Theory of Minimal Weight Perturbations in Deep Networks and its Applications for Low-Rank Activated Backdoor Attacks</h3>
<p><strong>Authors:</strong> Bethan Evans, Jared Tanner</p>
<p><strong>Published:</strong> 2026-01-26</p>
<p><strong>Reason:</strong> 推导深度网络最小权重扰动理论，应用于低秩激活后门攻击，证明压缩阈值，为后门攻击的理论分析与防御提供依据，对大模型安全的理论研究有重要贡献。
Score: 7
Field: 大模型安全与对齐</p>
<p><a href='https://arxiv.org/abs/2601.16880' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>