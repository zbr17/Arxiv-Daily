# ArXiv 每日推荐 - 2026-02-07

> 更新于北京时间：2026-02-07 13:05:33
> 已自动阅读了 71 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：40800

## 多模态智能体

### [Score: 9.0/10] M²-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining
- **Authors:** Rui Lv, Juncheng Mo, Tianyi Chu, Chen Rao, Hongyi Jing, Jiajie Teng, Jiafu Chen, Shiqi Zhang, Liangzi Ding, Shuo Fang, Huaizhong Lin, Ziqiang Dang, Chenguang Ma, Lei Zhao
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05429](https://arxiv.org/abs/2602.05429)
- **Reason:** 提出M²-Miner框架，利用多智能体MCTS自动挖掘移动GUI智能体的高质量行为轨迹数据，解决GUI Agent构建中的数据稀缺与质量问题，直接对应多模态智能体中的GUI Agent方向。
Score: 9
Field: 多模态智能体

## 大模型安全与对齐

### [Score: 9.0/10] Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities
- **Authors:** Florian Dietz, William Wale, Oscar Gilg, Robert McCarthy, Felix Michalak, Gustavo Ewbank Rodrigues Danon, Miguelito de Guzman, Dietrich Klakow
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05532](https://arxiv.org/abs/2602.05532)
- **Reason:** 提出SPT方法，通过LoRA微调诚实人格来检测大模型中的隐藏偏差和错位，在Anthropic Auditing Game基准上实现96%准确率，解决大模型安全中的错位检测难题。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] Democratic Preference Alignment via Sortition-Weighted RLHF
- **Authors:** Suvadip Sana, Jinzhou Wu, Martin T. Wells
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05113](https://arxiv.org/abs/2602.05113)
- **Reason:** 提出DemPO框架，通过算法抽签优化RLHF的偏好数据代表性，解决大模型对齐中的数据偏差问题，理论推导与实验验证结合，提升模型对代表性公众价值的反映。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] LeakBoost: Perceptual-Loss-Based Membership Inference Attack
- **Authors:** Amit Kravchik Taub, Fred M. Grabovski, Guy Amit, Yisroel Mirsky
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05748](https://arxiv.org/abs/2602.05748)
- **Reason:** 提出基于感知损失的主动成员推理攻击框架，通过优化模型内部表示暴露隐藏的成员信号，显著提升低误报率下的攻击性能，属于大模型安全与对齐中的隐私风险研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy
- **Authors:** Lukas Stappen, Ahmet Erkan Turan, Johann Hagerer, Georg Groh
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05877](https://arxiv.org/abs/2602.05877)
- **Reason:** 针对安全关键系统中的Agent2Agent通信威胁，提出人类中心的威胁模型与攻击路径分析框架，属于大模型安全与对齐中的安全-critical系统研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink
- **Authors:** Guozhi Liu, Weiwei Lin, Tiansheng Huang, Ruichao Mo, Qi Mu, Xiumin Wang, Li Shen
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05228](https://arxiv.org/abs/2602.05228)
- **Reason:** 利用注意力Sink机制检测并抑制有害微调中的attention head异常，实验显示在BeaverTails等基准上提升防御性能，直接针对大模型安全中的有害微调问题。
Score: 7
Field: 大模型安全与对齐

## 高效大模型训练与推理

### [Score: 9.0/10] RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism
- **Authors:** Zhong Guan, Haoran Sun, Yongjian Guo, Shuai Di, Xiaodong Bai, Jing Long, Tianyun Zhao, Mingxi Luo, Chen Zhou, Yucheng Guo, Qiming Yang, Wanting Xu, Wen Huang, Yunxuan Ma, Hongke Zhao, Likang Wu, Xiaotie Deng, Xi Xiao, Sheng Wen, Yicheng Gong, Junwu Xiong
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05765](https://arxiv.org/abs/2602.05765)
- **Reason:** 提出全异步的VLA模型训练框架，通过多阶段解耦架构提升训练吞吐量与可扩展性，解决VLA模型训练效率瓶颈，属于高效大模型训练与推理方向。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs
- **Authors:** Youngcheon You, Banseok Lee, Minseop Choi, Seonyoung Kim, Hyochan Chong, Changdong Kim, Youngmin Kim, Dongkyu Kim
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05367](https://arxiv.org/abs/2602.05367)
- **Reason:** 提出RaBiT解决残差二值化中的特征共适应问题，实现2位量化下的SOTA性能，同时在RTX 4090上实现4.49倍推理加速，直接针对高效大模型推理中的量化优化。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration
- **Authors:** Hanyu Wei, Zunhai Su, Peng Lu, Chao Li, Spandan Tiwari, Ashish Sirasao, Yuhan Dong
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05499](https://arxiv.org/abs/2602.05499)
- **Reason:** 提出SDFP框架，通过FIT层剪枝构建轻量草稿模型，实现训练-free的投机解码加速，在不改变目标模型输出的前提下提升1.32-1.5倍推理速度，适用于低延迟多媒体应用。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions
- **Authors:** Yihao Ouyang, Shiwei Li, Haozhao Wang, Xiandi Luo, Zhuoqi Hu, Yuetong Song, Qiyu Qin, Yichen Li, Ruixuan Li
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05709](https://arxiv.org/abs/2602.05709)
- **Reason:** 提出GenLoRA，用径向基函数生成低秩基向量，提升低秩适应的参数效率（更少参数实现更高有效秩），在多个数据集上优于标准LoRA，直接针对高效大模型训练中的低秩微调问题。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Determining Energy Efficiency Sweet Spots in Production LLM Inference
- **Authors:** Hiari Pizzini Cavagna, Andrea Proia, Giacomo Madella, Giovanni B. Esposito, Francesco Antici, Daniele Cesarini, Zeynep Kiziltan, Andrea Bartolini
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05695](https://arxiv.org/abs/2602.05695)
- **Reason:** 提出分析模型确定LLM推理中的能量效率甜点（短输入+中输出），在H100 GPU上验证模型准确性（MAPE 1.79%），帮助生产系统优化能耗，直接针对高效大模型推理中的能量管理。
Score: 7
Field: 高效大模型训练与推理

## 深度学习可解释性

### [Score: 8.0/10] AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction
- **Authors:** Ruijie Shi, Houbin Zhang, Yuecheng Han, Yuheng Wang, Jingru Fan, Runde Yang, Yufan Dang, Huatao Li, Dewen Liu, Yuan Cheng, Chen Qian
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05353](https://arxiv.org/abs/2602.05353)
- **Reason:** 提出Agentic Workflow Reconstruction（AWR）任务和AgentXRay框架，将黑盒智能体工作流重构为可解释的白盒流程，直接对应深度学习可解释性中的白盒解释需求。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] NEX: Neuron Explore-Exploit Scoring for Label-Free Chain-of-Thought Selection and Model Ranking
- **Authors:** Kang Chen, Zhuoka Feng, Sihan Zhao, Kai Xiong, Junjie Nian, Yaoning Wang, Changyi Xiao, Yixin Cao
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05805](https://arxiv.org/abs/2602.05805)
- **Reason:** 提出白盒无监督的神经元探索-利用 scoring 框架，分析推理过程中的神经元动态以评估推理轨迹质量，属于深度学习可解释性中的white-box explanation研究。
Score: 8
Field: 深度学习可解释性

## 大模型新技术

### [Score: 8.0/10] Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach
- **Authors:** Zhengyi Guo, Wenpin Tang, Renyuan Xu
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05533](https://arxiv.org/abs/2602.05533)
- **Reason:** 提出基于Doob h-transform的条件扩散引导框架，结合鞅表示和二次变差分析解决硬约束下的生成问题，为扩散大模型的安全生成提供理论支撑，属于大模型新技术中的扩散模型方向。
Score: 8
Field: 大模型新技术

## 原生多模态大模型

### [Score: 8.0/10] TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?
- **Authors:** Yikun Zong, Cheston Tan
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05570](https://arxiv.org/abs/2602.05570)
- **Reason:** 研究视觉语言模型（VLM）在连续几何空间中的推理能力，提出测试时自优化框架提升几何推理性能（IoU从0.63到0.932），直接对应原生多模态大模型中的图像理解方向。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention
- **Authors:** Zhangquan Chen, Jiale Tao, Ruihuang Li, Yihao Hu, Ruitao Chen, Zhantao Yang, Xinlei Yu, Haodong Jing, Manyuan Zhang, Shuai Shao, Biao Wang, Qinglin Lu, Ruqi Huang
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05847](https://arxiv.org/abs/2602.05847)
- **Reason:** 提出基于查询意图与模态注意力的音视频推理增强框架，提升多模态理解的准确性与泛化性，属于原生多模态大模型方向。
Score: 7
Field: 原生多模态大模型

## 深度学习理论

### [Score: 8.0/10] Learning Compact Boolean Networks
- **Authors:** Shengpu Wang, Yuhao Mao, Yani Zhang, Martin Vechev
- **Published:** 2026-02-07
- **Link:** [https://arxiv.org/abs/2602.05830](https://arxiv.org/abs/2602.05830)
- **Reason:** 针对布尔网络的紧凑性与准确性权衡问题，提出高效连接学习、紧凑卷积设计与自适应离散化策略，属于深度学习理论中的network architecture方向。
Score: 8
Field: 深度学习理论

