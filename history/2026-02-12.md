# ArXiv 每日推荐 - 2026-02-12

> 更新于北京时间：2026-02-12 13:38:39
> 已自动阅读了 275 篇最新的论文。
> 使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：162037

## 大模型安全与对齐

### [Score: 9.0/10] When the Prompt Becomes Visual: Vision-Centric Jailbreak Attacks for Large Image Editing Models
- **Authors:** Jiacheng Hou, Yining Sun, Ruochong Jin, Haochen Han, Fangming Liu, Wai Kin Victor Chan, Alex Jinpeng Wang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10179](https://arxiv.org/abs/2602.10179)
- **Reason:** 提出视觉中心的越狱攻击（VJA）针对大图像编辑模型，构建安全基准IESBench并设计训练-free防御方法，暴露并缓解大模型的视觉安全漏洞。
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] Gauss-Newton Unlearning for the LLM Era
- **Authors:** Lev McKinney, Anvith Thudi, Juhan Bae, Tara Rezaei, Nicolas Papernot (University of Toronto), Sheila A. McIlraith (University of Toronto), Roger Grosse (University of Toronto)
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10568](https://arxiv.org/abs/2602.10568)
- **Reason:** 提出高斯-牛顿遗忘方法，解决LLM的unlearning问题，属于大模型安全与对齐中的关键技术，作者包含Nicolas Papernot、Roger Grosse，权威学者。
Score: 9
Field: 大模型安全与对齐

### [Score: 9.0/10] FormalJudge: A Neuro-Symbolic Paradigm for Agentic Oversight
- **Authors:** Jiayi Zhou, Yang Sheng, Hantao Lou, Yaodong Yang, Jie Fu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11136](https://arxiv.org/abs/2602.11136)
- **Reason:** 提出FormalJudge，用形式化验证监督LLM agents的安全，解决LLM-as-a-Judge的不确定性，符合大模型安全与对齐方向。
Score: 9
Field: 大模型安全与对齐

### [Score: 8.0/10] HII-DPO: Eliminate Hallucination via Accurate Hallucination-Inducing Counterfactual Images
- **Authors:** Yilin Yang, Zhenghui Guo, Yuke Wang, Omprakash Gnawali, Sheng Di, Chengming Zhang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10425](https://arxiv.org/abs/2602.10425)
- **Reason:** 通过生成幻觉诱导反事实图像（HIIs）揭示视觉语言模型（VLMs）的场景条件幻觉模式，并构建偏好数据集优化对齐，有效缓解幻觉问题。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] OmniVL-Guard: Towards Unified Vision-Language Forgery Detection and Grounding via Balanced RL
- **Authors:** Jinjie Shen, Jing Wu, Yaxiong Wang, Lechao Cheng, Shengeng Tang, Tianrui Hui, Nan Pu, Zhun Zhong
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10687](https://arxiv.org/abs/2602.10687)
- **Reason:** 提出统一的视觉语言伪造检测框架，用平衡RL解决多任务优化的难度偏差问题，提升伪造检测和grounding性能。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Temper-Then-Tilt: Principled Unlearning for Generative Models through Tempering and Classifier Guidance
- **Authors:** Jacob L. Block, Mehryar Mohri, Aryan Mokhtari, Sanjay Shakkottai
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10217](https://arxiv.org/abs/2602.10217)
- **Reason:** 该工作针对生成模型的机器遗忘问题，提出T3-Unlearning框架，通过tempering平滑分布并结合分类器引导，理论证明了有限样本下的遗忘误差保证，实验在TOFU基准上显著提升了遗忘质量与生成效用，属于大模型安全与对齐的核心研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Internalizing Meta-Experience into Memory for Guided Reinforcement Learning in Large Language Models
- **Authors:** Shiting Huang, Zecheng Li, Yu Zeng, Qingnan Ren, Zhen Fang, Qisheng Su, Kou Shi, Lin Chen, Zehui Chen, Feng Zhao
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10224](https://arxiv.org/abs/2602.10224)
- **Reason:** 该工作针对LLM强化学习（RLVR）的元学习瓶颈，提出MEL框架，通过模型自验证对比正确与错误推理轨迹，提炼元经验并内化为参数记忆，实现知识复用与推理能力提升，实验在多个基准上取得3.92%-4.73%的Pass@1增益，属于大模型安全与对齐中对齐方法的重要创新。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Mitigating Reward Hacking in RLHF via Bayesian Non-negative Reward Modeling
- **Authors:** Zhibin Duan, Guowei Rong, Zhuo Li, Bo Chen, Mingyuan Zhou, Dandan Guo
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10623](https://arxiv.org/abs/2602.10623)
- **Reason:** 提出BNRM框架，通过贝叶斯非负奖励模型缓解RLHF中的奖励 hacking，提升对齐过程的鲁棒性，属于大模型安全与对齐研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] Kill it with FIRE: On Leveraging Latent Space Directions for Runtime Backdoor Mitigation in Deep Neural Networks
- **Authors:** Enrico Ahlers, Daniel Passon, Yannic Noller, Lars Grunske
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10780](https://arxiv.org/abs/2602.10780)
- **Reason:** 提出FIRE方法，通过潜在空间方向缓解运行时后门攻击，提升模型的安全鲁棒性，属于大模型安全与对齐中的后门防御研究。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] RePO: Bridging On-Policy Learning and Off-Policy Knowledge through Rephrasing Policy Optimization
- **Authors:** Linxuan Xia, Xiaolong Yang, Yongyuan Chen, Enyue Zhao, Deng Cai, Yasheng Wang, Boxi Wu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10819](https://arxiv.org/abs/2602.10819)
- **Reason:** 提出RePO算法，通过重述策略优化桥接on-policy与off-policy知识，提升领域自适应对齐效率，属于大模型安全与对齐中的对齐优化。
Score: 8
Field: 大模型安全与对齐

### [Score: 8.0/10] In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution
- **Authors:** Frank Xiao, Santiago Aranguri
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11079](https://arxiv.org/abs/2602.11079)
- **Reason:** 提出激活-based数据归因方法，检测并缓解LLM post-training中的不良行为（如distractor-triggered compliance），符合大模型安全与对齐方向。
Score: 8
Field: 大模型安全与对齐

### [Score: 7.0/10] A Low-Rank Defense Method for Adversarial Attack on Diffusion Models
- **Authors:** Jiaxuan Zhu, Siyu Huang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10319](https://arxiv.org/abs/2602.10319)
- **Reason:** 提出低秩防御方法（LoRD）结合LoRA模块，检测并防御扩散模型的对抗攻击，同时保持生成质量。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] RealHD: A High-Quality Dataset for Robust Detection of State-of-the-Art AI-Generated Images
- **Authors:** Hanzhe Yu, Yun Ye, Jintao Rong, Qi Xuan, Chen Ma
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10546](https://arxiv.org/abs/2602.10546)
- **Reason:** 构建高质量AI生成图像检测数据集，涵盖多种生成方法和场景，提升检测模型的泛化能力。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] VideoSTF: Stress-Testing Output Repetition in Video Large Language Models
- **Authors:** Yuxin Cao, Wei Song, Shangzhi Xu, Jingling Xue, Jin Song Dong
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10639](https://arxiv.org/abs/2602.10639)
- **Reason:** 提出VideoSTF框架系统测试视频大语言模型的输出重复问题，揭示其稳定性漏洞，为模型优化提供依据。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Collaborative Threshold Watermarking
- **Authors:** Tameem Bakr, Anish Ambreth, Nils Lukas
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10765](https://arxiv.org/abs/2602.10765)
- **Reason:** 提出(t,K)-阈值水印协议，用于联邦学习中的模型溯源，只有至少t个客户端才能重构水印，提升模型知识产权保护能力，属于大模型安全与对齐研究。
Score: 7
Field: 大模型安全与对齐

### [Score: 7.0/10] Adaptive Sampling for Private Worst-Case Group Optimization
- **Authors:** Max Cairney-Leeming, Amartya Sanyal, Christoph H. Lampert
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10820](https://arxiv.org/abs/2602.10820)
- **Reason:** 提出ASC算法，通过自适应采样实现差分隐私的最坏情况组优化，平衡隐私与性能，属于大模型安全与对齐中的隐私保护研究。
Score: 7
Field: 大模型安全与对齐

## 高效大模型训练与推理

### [Score: 9.0/10] 1%>100%: High-Efficiency Visual Adapter with Complex Linear Projection Optimization
- **Authors:** Dongshuo Yin, Xue Yang, Deng-Ping Fan, Shi-Min Hu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10513](https://arxiv.org/abs/2602.10513)
- **Reason:** 提出仅用1%参数的低秩复杂适配器（CoLin），通过优化线性投影解决收敛问题，实现高效视觉模型适应，性能超过全微调。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] Configuration-to-Performance Scaling Law with Neural Ansatz
- **Authors:** Huaqing Zhang, Kaiyue Wen, Tengyu Ma (Massachusetts Institute of Technology)
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10300](https://arxiv.org/abs/2602.10300)
- **Reason:** 提出用LLM建模训练配置到性能的缩放律，解决传统缩放律忽略超参数的问题，作者包含大模型理论专家Tengyu Ma，对高效大模型训练配置优化有重要价值。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] SnapMLA: Efficient Long-Context MLA Decoding via Hardware-Aware FP8 Quantized Pipelining
- **Authors:** Yifan Zhang, Zunhai Su, Shuhao Hu, Rui Yang, Wei Wu, Yulei Qian, Yuchen Xie, Xunliang Cai
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10718](https://arxiv.org/abs/2602.10718)
- **Reason:** 提出SnapMLA框架，通过硬件感知的FP8量化流水线优化MLA的长上下文解码，实现1.91x吞吐量提升，属于高效大模型训练与推理中的推理优化。
Score: 9
Field: 高效大模型训练与推理

### [Score: 9.0/10] PRISM: Parallel Residual Iterative Sequence Model
- **Authors:** Jie Jiang, Ke Cheng, Xin Xu, Mengyang Pang, Tianhao Lu, Jiaheng Li, Yue Liu, Yuan Wang, Jun Zhang, Huan Yu, Zhouchen Lin
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10796](https://arxiv.org/abs/2602.10796)
- **Reason:** 提出PRISM模型，通过并行残差迭代实现高效序列建模，实现174x吞吐量提升，属于高效大模型训练与推理中的模型架构优化。
Score: 9
Field: 高效大模型训练与推理

### [Score: 8.0/10] Eliminating VAE for Fast and High-Resolution Generative Detail Restoration
- **Authors:** Yan Wang, Shijie Zhao, Junlin Li, Li Zhang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10630](https://arxiv.org/abs/2602.10630)
- **Reason:** 提出像素空间的生成细节恢复模型（GenDR-Pix），消除VAE瓶颈实现2.8倍加速和60%内存节省，同时保持生成质量。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Rank-Accuracy Trade-off for LoRA: A Gradient-Flow Analysis
- **Authors:** Michael Rushka, Diego Klabjan
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10212](https://arxiv.org/abs/2602.10212)
- **Reason:** 该工作从动力学系统视角严格推导LoRA的梯度流方程，建立了低秩更新秩与模型精度的闭式关系，填补了LoRA理论基础空白，对高效大模型微调中的低秩策略设计具有重要指导意义。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Hardware Co-Design Scaling Laws via Roofline Modelling for On-Device LLMs
- **Authors:** Luoyang Sun, Jiwen Jiang, Yifeng Ding, Fengfa Li, Yan Song, Haifeng Zhang, Jian Ying, Lei Ren, Kun Zhan, Wei Chen, Yan Xie, Cheng Deng
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10377](https://arxiv.org/abs/2602.10377)
- **Reason:** 提出硬件协同设计的缩放律，结合Roofline模型优化On-device LLM的准确性和延迟，对高效大模型的边缘部署有重要价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] QTALE: Quantization-Robust Token-Adaptive Layer Execution for LLMs
- **Authors:** Kanghyun Noh, Jinheon Choi, Yulwha Kim
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10431](https://arxiv.org/abs/2602.10431)
- **Reason:** 提出QTALE，结合token-adaptive layer execution和量化，实现高效推理，对高效大模型的部署优化有重要价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] $\mu$pscaling small models: Principled warm starts and hyperparameter transfer
- **Authors:** Yuxin Ma, Nan Chen, Mateo Díaz, Soufiane Hayou, Dmitriy Kunisky, Soledad Villar
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10545](https://arxiv.org/abs/2602.10545)
- **Reason:** 提出小模型的缩放方法，结合warm start和超参数转移，对高效大模型的训练优化有重要价值。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Roughness-Informed Federated Learning
- **Authors:** Mohammad Partohaghighi, Roummel Marcia, Bruce J. West, YangQuan Chen
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10595](https://arxiv.org/abs/2602.10595)
- **Reason:** 提出RI-FedAvg算法，利用损失景观的粗糙度指数正则化本地更新，缓解非IID数据下的客户端漂移，提升联邦学习的收敛性和准确性，属于高效大模型训练与推理研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] VESPO: Variational Sequence-Level Soft Policy Optimization for Stable Off-Policy LLM Training
- **Authors:** Guobin Shen, Chenxiao Zhao, Xiang Cheng, Lei Huang, Xing Yu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10693](https://arxiv.org/abs/2602.10693)
- **Reason:** 提出VESPO算法，通过变分序列级软策略优化解决off-policy LLM训练的稳定性问题，提升训练稳定性和效率，属于高效大模型训练与推理研究。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] Kalman Linear Attention: Parallel Bayesian Filtering For Efficient Language Modelling and State Tracking
- **Authors:** Vaisakh Shaj, Cameron Barker, Aidan Scannell, Andras Szecsenyi, Elliot J. Crowley, Amos Storkey
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10743](https://arxiv.org/abs/2602.10743)
- **Reason:** 提出KLA层，通过贝叶斯滤波的并行化实现高效语言建模，提供线性复杂度和并行训练能力，属于高效大模型训练与推理中的Attention优化。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] LOREN: Low Rank-Based Code-Rate Adaptation in Neural Receivers
- **Authors:** Bram Van Bolderik (Technische Universiteit Eindhoven, The Netherlands), Vlado Menkovski (Technische Universiteit Eindhoven, The Netherlands), Sonia Heemstra de Groot (Eindhoven Technical University, The Netherlands), Manil Dev Gomony (Eindhoven University of Technology, The Netherlands)
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10770](https://arxiv.org/abs/2602.10770)
- **Reason:** 提出LOREN框架，通过低秩自适应实现神经接收机的码率自适应，实现65%面积节省和15%功耗降低，属于高效大模型训练与推理中的低秩优化。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] MoEEdit: Efficient and Routing-Stable Knowledge Editing for Mixture-of-Experts LLMs
- **Authors:** Yupu Gu, Rongzhe Wei, Andy Zhu, Pan Li
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10965](https://arxiv.org/abs/2602.10965)
- **Reason:** 提出MoEEdit框架，实现MoE LLMs的高效路由稳定知识编辑，提升知识编辑的效率和稳定性，属于高效大模型训练与推理中的MoE优化。
Score: 8
Field: 高效大模型训练与推理

### [Score: 8.0/10] RiemannGL: Riemannian Geometry Changes Graph Deep Learning
- **Authors:** Li Sun
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11008](https://arxiv.org/abs/2602.11008)
- **Reason:** 提出训练-free的模型压缩方法ROCKET，通过背包问题分配层压缩预算和稀疏矩阵分解，支持大模型（如Qwen3-14B）的高效压缩，性能优于现有方法，符合高效大模型训练与推理方向。
Score: 8
Field: 高效大模型训练与推理

### [Score: 7.0/10] Time Series Foundation Models for Energy Load Forecasting on Consumer Hardware: A Multi-Dimensional Zero-Shot Benchmark
- **Authors:** Luigi Simeone
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10848](https://arxiv.org/abs/2602.10848)
- **Reason:** 评估时间序列基础模型在消费者硬件上的性能，发现预训练模型在短上下文下仍保持稳定 accuracy，属于高效大模型训练与推理中的推理优化。
Score: 7
Field: 高效大模型训练与推理

### [Score: 7.0/10] FedPS: Federated Data Preprocessing via aggregated Statistics
- **Authors:** Xuefeng Xu, Graham Cormode
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10870](https://arxiv.org/abs/2602.10870)
- **Reason:** 提出FedPS框架，通过聚合统计实现联邦数据预处理，提升预处理效率和一致性，属于高效大模型训练与推理中的联邦学习优化。
Score: 7
Field: 高效大模型训练与推理

## 深度学习理论

### [Score: 9.0/10] Versor: A Geometric Sequence Architecture
- **Authors:** Truong Minh Huy, Edward Hirst
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10195](https://arxiv.org/abs/2602.10195)
- **Reason:** 该工作提出基于共形几何代数的Versor序列架构，通过将状态嵌入Cl₄,₁流形并利用rotors演化，原生支持SE(3)等变关系，参数效率远超Transformer（200倍更少参数），推理复杂度线性，在混沌动力学、拓扑推理、CIFAR-10等任务上显著优于现有基线，属于深度学习理论中网络架构方向的重要突破。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] What Does Preference Learning Recover from Pairwise Comparison Data?
- **Authors:** Rattana Pukdee, Maria-Florina Balcan (Carnegie Mellon University), Pradeep Ravikumar (Carnegie Mellon University)
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10286](https://arxiv.org/abs/2602.10286)
- **Reason:** 研究偏好学习从成对比较数据中恢复的内容，涉及Bradley--Terry模型的理论分析，作者包含机器学习理论权威Maria-Florina Balcan，对深度学习理论中的学习过程有重要贡献。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] LUCID: Attention with Preconditioned Representations
- **Authors:** Sai Surya Duvvuri, Nirmal Patel, Nilesh Gupta, Inderjit S. Dhillon (University of Texas at Austin)
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10410](https://arxiv.org/abs/2602.10410)
- **Reason:** 提出LUCID Attention，通过预处理注意力概率解决长序列中的注意力扩散问题，属于深度学习理论中的注意力机制优化，作者包含Inderjit S. Dhillon，权威学者。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Hierarchical Zeroth-Order Optimization for Deep Neural Networks
- **Authors:** Sansheng Cao, Zhengyu Ma, Yonghong Tian
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10607](https://arxiv.org/abs/2602.10607)
- **Reason:** 提出分层零阶优化方法，将深度网络的优化分解为层级结构，将查询复杂度从O(ML²)降低到O(ML log L)，解决零阶优化的计算瓶颈，属于深度学习理论中的优化器研究。
Score: 9
Field: 深度学习理论

### [Score: 9.0/10] Rotary Positional Embeddings as Phase Modulation: Theoretical Bounds on the RoPE Base for Long-Context Transformers
- **Authors:** Feilong Liu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10959](https://arxiv.org/abs/2602.10959)
- **Reason:** 从相位调制角度分析RoPE，推导RoPE base的理论 bounds，解决长上下文Transformer的位置编码问题，属于深度学习理论中的位置嵌入研究。
Score: 9
Field: 深度学习理论

### [Score: 8.0/10] Characterizing and Optimizing the Spatial Kernel of Multi Resolution Hash Encodings
- **Authors:** Tianxiang Dai, Jonathan Fan
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10495](https://arxiv.org/abs/2602.10495)
- **Reason:** 从物理系统角度分析多分辨率哈希编码（MHE）的空间行为，提出旋转MHE优化其各向异性和分辨率，属于深度学习理论中的网络架构研究方向。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Adaptive Optimization via Momentum on Variance-Normalized Gradients
- **Authors:** Francisco Patitucci, Aryan Mokhtari
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10204](https://arxiv.org/abs/2602.10204)
- **Reason:** 该工作提出MVN-Grad优化器，创新结合方差归一化与动量机制，理论证明其梯度更新方差更小、对异常值更鲁棒，实验在CIFAR-100图像分类和GPT风格语言模型上均优于Adam等基线，属于深度学习理论中优化器方向的关键进展。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Gated Removal of Normalization in Transformers Enables Stable Training and Efficient Inference
- **Authors:** Andrei Kanavalau, Carmen Amo Alonso, Sanjay Lall (Stanford University)
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10408](https://arxiv.org/abs/2602.10408)
- **Reason:** 提出TaperNorm，逐步移除Transformer中的归一化层，实现稳定训练和高效推理，对深度学习理论中的网络架构优化有重要贡献。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] When Gradient Clipping Becomes a Control Mechanism for Differential Privacy in Deep Learning
- **Authors:** Mohammad Partohaghighi, Roummel Marcia, Bruce J. West, YangQuan Chen
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10584](https://arxiv.org/abs/2602.10584)
- **Reason:** 提出控制驱动的梯度裁剪策略，通过模型参数的光谱诊断自适应调整裁剪阈值，解决差分隐私优化中的偏差和噪声问题，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Learning Mixture Density via Natural Gradient Expectation Maximization
- **Authors:** Yutao Chen, Jasmine Bayrooti, Steven Morad
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10602](https://arxiv.org/abs/2602.10602)
- **Reason:** 结合自然梯度下降与期望最大化框架优化混合密度网络，解决收敛慢和模式崩溃问题，提升混合模型的优化效率，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Natural Hypergradient Descent: Algorithm Design, Convergence Analysis, and Parallel Implementation
- **Authors:** Deyi Kong, Zaiwei Chen, Shuzhong Zhang, Shancong Mou
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10905](https://arxiv.org/abs/2602.10905)
- **Reason:** 提出NHGD算法，通过自然超梯度下降解决双层优化问题，利用经验Fisher矩阵近似Hessian逆，提升优化效率，属于深度学习理论中的优化器研究。
Score: 8
Field: 深度学习理论

### [Score: 8.0/10] Weight Decay Improves Language Model Plasticity
- **Authors:** Tessa Han, Sebastian Bordt, Hanlin Zhang, Sham Kakade
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11137](https://arxiv.org/abs/2602.11137)
- **Reason:** 研究weight decay对LLM可塑性的影响，发现其提升模型下游适应能力，属于深度学习理论中的optimizer方向。
Score: 8
Field: 深度学习理论

### [Score: 7.0/10] Theoretical Analysis of Contrastive Learning under Imbalanced Data: From Training Dynamics to a Pruning Solution
- **Authors:** Haixu Liao, Yating Zhou, Songyang Zhang, Meng Wang, Shuai Zhang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10357](https://arxiv.org/abs/2602.10357)
- **Reason:** 理论分析不平衡数据下对比学习的训练动态，提出剪枝解决方案，对深度学习理论中的对比学习优化有重要意义。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] A Unified Theory of Random Projection for Influence Functions
- **Authors:** Pingbang Hu, Yuzheng Hu, Jiaqi W. Ma, Han Zhao
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10449](https://arxiv.org/abs/2602.10449)
- **Reason:** 提出随机投影对影响函数的统一理论，对深度学习理论中的influence function分析有重要意义。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Low-Dimensional Execution Manifolds in Transformer Learning Dynamics: Evidence from Modular Arithmetic Tasks
- **Authors:** Yongzhong Xu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10496](https://arxiv.org/abs/2602.10496)
- **Reason:** 研究Transformer训练动态中的低维流形，对深度学习理论中的训练动态和网络架构理解有重要贡献。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Online Min-Max Optimization: From Individual Regrets to Cumulative Saddle Points
- **Authors:** Abhijeet Vyas, Brian Bullins
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10565](https://arxiv.org/abs/2602.10565)
- **Reason:** 理论分析在线min-max优化，属于深度学习理论中的优化算法，对强化学习和对抗训练有重要意义。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Tuning the burn-in phase in training recurrent neural networks improves their performance
- **Authors:** Julian D. Schiller, Malte Heinrich, Victor G. Lopez, Matthias A. M\"uller
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10911](https://arxiv.org/abs/2602.10911)
- **Reason:** 研究调整RNN训练中的burn-in阶段对性能的影响，理论分析并实验验证其重要性，属于深度学习理论中的网络训练研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Stochastic Parroting in Temporal Attention -- Regulating the Diagonal Sink
- **Authors:** Victoria Hankemeier, Malte Hankemeier
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10956](https://arxiv.org/abs/2602.10956)
- **Reason:** 分析时间Attention中的对角 sink 问题，提出正则化方法，提升时间Attention的性能，属于深度学习理论中的Attention机制研究。
Score: 7
Field: 深度学习理论

### [Score: 7.0/10] Data-Efficient Hierarchical Goal-Conditioned Reinforcement Learning via Normalizing Flows
- **Authors:** Shaswat Garg, Matin Moezzi, Brandon Da Silva
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11142](https://arxiv.org/abs/2602.11142)
- **Reason:** 论文提出NF-HIQL框架，将归一化流应用于分层目标条件强化学习的政策网络设计，替换传统单模态高斯政策以建模多模态行为，并推导RealNVP政策的KL散度边界等理论保证，与深度学习理论中的网络架构方向高度相关，对提升强化学习样本效率和政策表达能力有重要价值。
Score: 7
Field: 深度学习理论

### [Score: 6.0/10] ContactGaussian-WM: Learning Physics-Grounded World Model from Videos
- **Authors:** Meizhong Wang, Wanxin Jin, Kun Cao, Lihua Xie, Yiguang Hong
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11021](https://arxiv.org/abs/2602.11021)
- **Reason:** 论文提出ContactGaussian-WM框架，采用统一高斯表示融合视觉外观与碰撞几何，通过端到端可微分学习从稀疏视频中推断物理属性，属于深度学习理论中的网络架构与表示学习方向，对物理接地世界模型的设计有创新贡献。
Score: 6
Field: 深度学习理论

## 原生多模态大模型

### [Score: 8.0/10] Multimodal Information Fusion for Chart Understanding: A Survey of MLLMs -- Evolution, Limitations, and Cognitive Enhancement
- **Authors:** Zhihang Yi, Jian Zhao, Jiancheng Lv, Tao Wang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10138](https://arxiv.org/abs/2602.10138)
- **Reason:** 该论文系统综述多模态大语言模型（MLLMs）在图表理解中的信息融合研究，梳理其演化、局限性及认知增强方向，直接对应原生多模态大模型的核心研究领域。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] VERA: Identifying and Leveraging Visual Evidence Retrieval Heads in Long-Context Understanding
- **Authors:** Rongcan Pei, Huan Li, Fang Guo, Qi Zhu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10146](https://arxiv.org/abs/2602.10146)
- **Reason:** 研究视觉语言模型（VLMs）长上下文理解中的视觉证据检索头（VER Heads），揭示其对模型性能的因果作用并提出增强框架，属于原生多模态大模型的内部机制研究。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] 3DXTalker: Unifying Identity, Lip Sync, Emotion, and Spatial Dynamics in Expressive 3D Talking Avatars
- **Authors:** Zhongju Wang, Zhenhong Sun, Beier Wang, Yifu Wang, Daoyi Dong, Huadong Mo, Hongdong Li
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10516](https://arxiv.org/abs/2602.10516)
- **Reason:** 提出统一的3D会说话头像模型，整合身份、唇同步、情感和空间动态，基于多模态数据和流匹配Transformer，属于原生多模态大模型方向。
Score: 8
Field: 原生多模态大模型

### [Score: 8.0/10] C^2ROPE: Causal Continuous Rotary Positional Encoding for 3D Large Multimodal-Models Reasoning
- **Authors:** Guanting Ye, Qiyan Zhao, Wenhao Yu, Xiaofeng Zhang, Jianmin Ji, Yanyong Zhang, Ka-Veng Yuen
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10551](https://arxiv.org/abs/2602.10551)
- **Reason:** 改进旋转位置编码（RoPE）用于3D多模态大模型，增强空间连续性和因果关系，提升3D场景推理和视觉问答性能。
Score: 8
Field: 原生多模态大模型

### [Score: 7.0/10] Frame-Level Internal Tool Use for Temporal Grounding in Audio LMs
- **Authors:** Joesph An, Phillip Keung, Jiaqi Wang, Orevaoghene Ahia, Noah A. Smith
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10230](https://arxiv.org/abs/2602.10230)
- **Reason:** 该工作针对音频大模型的时间接地问题，提出帧级内部工具使用方法，直接利用模型内部音频表示实现高效时间接地，实验实现50倍推理加速并提升了长音频泛化能力，属于原生多模态大模型中音频理解的关键进展。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] MoToRec: Sparse-Regularized Multimodal Tokenization for Cold-Start Recommendation
- **Authors:** Jialin Liu, Zhaorui Zhang, Ray C. C. Cheung
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11062](https://arxiv.org/abs/2602.11062)
- **Reason:** 提出基于稀疏正则化的多模态tokenization框架MoToRec，解决推荐系统冷启动问题，符合原生多模态大模型的tokenizer方向。
Score: 7
Field: 原生多模态大模型

### [Score: 7.0/10] GENIUS: Generative Fluid Intelligence Evaluation Suite
- **Authors:** Ruichuan An, Sihan Yang, Ziyu Guo, Wei Dai, Zijun Shen, Haodong Li, Renrui Zhang, Xinyu Wei, Guopeng Li, Wenshan Wu, Wentao Zhang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11144](https://arxiv.org/abs/2602.11144)
- **Reason:** 提出GENIUS基准评估多模态模型的生成流体智能，符合原生多模态大模型的image generation/understanding方向。
Score: 7
Field: 原生多模态大模型

### [Score: 6.0/10] Say, Dream, and Act: Learning Video World Models for Instruction-Driven Robot Manipulation
- **Authors:** Songen Gu, Yunuo Cai, Tianyu Wang, Simo Wu, Yanwei Fu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10717](https://arxiv.org/abs/2602.10717)
- **Reason:** 论文针对指令驱动机器人操纵任务，采用视频生成模型与对抗蒸馏技术实现高效一致的未来视频预测，属于原生多模态大模型中的视频/图像生成方向，对提升机器人操纵的预测能力有实际价值。
Score: 6
Field: 原生多模态大模型

## 大模型新技术

### [Score: 8.0/10] DEGMC: Denoising Diffusion Models Based on Riemannian Equivariant Group Morphological Convolutions
- **Authors:** El Hadji S. Diop, Thierno Fall, Mohamed Daoudi
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10221](https://arxiv.org/abs/2602.10221)
- **Reason:** 提出基于黎曼等变群形态卷积的扩散模型，解决扩散模型的几何关键特征提取和网络等变性问题，属于大模型新技术中的扩散模型改进方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Dynamic Frequency Modulation for Controllable Text-driven Image Generation
- **Authors:** Tiandong Shi, Ling Zhao, Ji Qi, Jiayi Ma, Chengli Peng
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10662](https://arxiv.org/abs/2602.10662)
- **Reason:** 从频率角度提出动态频率调制方法，解决文本驱动扩散模型的结构保持问题，实现结构一致的语义修改，属于大模型新技术中的扩散模型改进方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] ELROND: Exploring and decomposing intrinsic capabilities of diffusion models
- **Authors:** Paweł Skierś, Tomasz Trzciński, Kamil Deja
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10216](https://arxiv.org/abs/2602.10216)
- **Reason:** 该工作提出扩散模型输入嵌入空间的语义分解框架，通过梯度分解得到可解释的生成控制方向，有效缓解蒸馏模型的模式崩溃，并提出概念复杂度估计方法，属于大模型新技术中扩散模型方向的重要创新。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] Stop Training for the Worst: Progressive Unmasking Accelerates Masked Diffusion Training
- **Authors:** Jaeyeon Kim, Jonathan Geuter, David Alvarez-Melis, Sham Kakade (University of Washington, Microsoft Research), Sitan Chen (Massachusetts Institute of Technology)
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10314](https://arxiv.org/abs/2602.10314)
- **Reason:** 提出Progressive Unmasking加速掩码扩散模型训练，解决训练-测试不匹配问题，作者包含深度学习权威Sham Kakade和Sitan Chen，属于大模型新技术中的diffusion方向。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] LLM-Based Scientific Equation Discovery via Physics-Informed Token-regularized Policy Optimization
- **Authors:** Boxiao Wang, Kai Li, Tianyi Liu, Chen Li, Junzhe Wang, Yifan Zhang, Jian Cheng
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10576](https://arxiv.org/abs/2602.10576)
- **Reason:** 提出PiT-PO框架，通过强化学习将LLM进化为自适应生成器，生成物理一致且结构简洁的科学方程，属于大模型新技术研究。
Score: 8
Field: 大模型新技术

### [Score: 8.0/10] SimuScene: Training and Benchmarking Code Generation to Simulate Physical Scenarios
- **Authors:** Yanan Wang, Renxi Wang, Yongxin Wang, Xuezhi Liang, Fajri Koto, Timothy Baldwin, Xiaodan Liang, Haonan Li
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10840](https://arxiv.org/abs/2602.10840)
- **Reason:** 提出SimuScene基准和RL训练 pipeline，用于训练LLM生成物理模拟代码，拓展LLM的物理模拟能力，属于大模型新技术研究。
Score: 8
Field: 大模型新技术

### [Score: 7.0/10] Flow Matching with Uncertainty Quantification and Guidance
- **Authors:** Juyeop Han, Lukas Lao Beyer, Sertac Karaman
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10326](https://arxiv.org/abs/2602.10326)
- **Reason:** 提出不确定性感知的流匹配（UA-Flow），通过传播velocity不确定性提升样本可靠性，并结合不确定性引导生成，属于大模型新技术中的流匹配模型改进方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Binary Flow Matching: Prediction-Loss Space Alignment for Robust Learning
- **Authors:** Jiadong Hong, Lei Liu, Xinyu Bian, Wenjie Wang, Zhaoyang Zhang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10420](https://arxiv.org/abs/2602.10420)
- **Reason:** 研究二进制流匹配的理论，解决预测-损失空间的不匹配问题，属于大模型新技术中的diffusion方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] CMAD: Cooperative Multi-Agent Diffusion via Stochastic Optimal Control
- **Authors:** Riccardo Barbano, Alexander Denker, Zeljko Kereta, Runchang Li, Francisco Vargas
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10933](https://arxiv.org/abs/2602.10933)
- **Reason:** 提出CMAD框架，通过随机最优控制实现协作多智能体扩散，拓展扩散模型的多智能体应用，属于大模型新技术研究。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] From Circuits to Dynamics: Understanding and Stabilizing Failure in 3D Diffusion Transformers
- **Authors:** Maximilian Plattner, Fabian Paischer, Johannes Brandstetter, Arturs Berzins
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11130](https://arxiv.org/abs/2602.11130)
- **Reason:** 分析3D扩散Transformer的失败模式（Meltdown），提出PowerRemap解决，符合大模型新技术的diffusion LLM方向。
Score: 7
Field: 大模型新技术

### [Score: 7.0/10] Just on Time: Token-Level Early Stopping for Diffusion Language Models
- **Authors:** Zahar Kohut, Severyn Shykula, Dmytro Khamula, Mykola Vysotskyi, Taras Rumezhak, Volodymyr Karpiv
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11133](https://arxiv.org/abs/2602.11133)
- **Reason:** 提出token级早停方法，减少扩散语言模型的计算量，提升生成效率，符合大模型新技术的diffusion LLM方向。
Score: 7
Field: 大模型新技术

### [Score: 6.0/10] Diffusion-Pretrained Dense and Contextual Embeddings
- **Authors:** Sedigheh Eslami, Maksim Gaiduk, Markus Krimmel, Louis Milliken, Bo Wang, Denis Bykov
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11151](https://arxiv.org/abs/2602.11151)
- **Reason:** 用扩散预训练生成稠密和上下文嵌入，提升检索性能，符合大模型新技术的diffusion LLM方向。
Score: 6
Field: 大模型新技术

## 深度学习可解释性

### [Score: 8.0/10] XSPLAIN: XAI-enabling Splat-based Prototype Learning for Attribute-aware INterpretability
- **Authors:** Dominik Galus, Julia Farganus, Tymoteusz Zapala, Miko{\l}aj Czachorowski, Piotr Borycki, Przemys{\l}aw Spurek, Piotr Syga
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10239](https://arxiv.org/abs/2602.10239)
- **Reason:** 提出针对3D Gaussian Splatting分类的基于原型的可解释性框架，通过解耦特征通道实现属性感知的解释，提升模型透明度和用户信任。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Simple LLM Baselines are Competitive for Model Diffing
- **Authors:** Elias Kempf, Simon Schrodi, Bartosz Cywiński, Thomas Brox (University of Freiburg), Neel Nanda (EleutherAI), Arthur Conmy
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10371](https://arxiv.org/abs/2602.10371)
- **Reason:** 比较LLM和SAE在模型差异检测中的表现，提出更优的LLM基线，为深度学习可解释性中的模型行为差异解释提供新方法。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Control Reinforcement Learning: Token-Level Mechanistic Analysis via Learned SAE Feature Steering
- **Authors:** Seonglae Cho, Zekun Wu, Adriano Koshiyama
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10437](https://arxiv.org/abs/2602.10437)
- **Reason:** 提出CRL，用强化学习选择SAE特征进行token级 steering，实现可解释的模型干预，属于深度学习可解释性中的mechanistic interpretability。
Score: 8
Field: 深度学习可解释性

### [Score: 8.0/10] Neural Additive Experts: Context-Gated Experts for Controllable Model Additivity
- **Authors:** Guangzhi Xiong, Sanchit Sinha, Aidong Zhang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10585](https://arxiv.org/abs/2602.10585)
- **Reason:** 提出Neural Additive Experts框架，通过混合专家和动态门控机制平衡可解释性与准确性，实现特征级解释，解决GAMs的严格可加性限制，属于深度学习可解释性研究。
Score: 8
Field: 深度学习可解释性

### [Score: 7.0/10] Colorful Talks with Graphs: Human-Interpretable Graph Encodings for Large Language Models
- **Authors:** Angelo Zangari, Peyman Baghershahi, Sourav Medya
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10386](https://arxiv.org/abs/2602.10386)
- **Reason:** 提出可解释的图编码方法，将图结构转换为LLM可处理的自然语言提示，属于深度学习可解释性中的white-box explanation。
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] TRACE: Theoretical Risk Attribution under Covariate-shift Effects
- **Authors:** Hosein Anjidani, S. Yahya S. R. Tehrani, Mohammad Mahdi Mojahedian, Mohammad Hossein Yassaee
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10588](https://arxiv.org/abs/2602.10588)
- **Reason:** 提出TRACE框架分解协变量偏移下的风险变化，提供可解释的上界和诊断工具，帮助理解模型性能变化的四大因素，属于深度学习可解释性研究。
Score: 7
Field: 深度学习可解释性

### [Score: 7.0/10] Interpretable Graph-Level Anomaly Detection via Contrast with Normal Prototypes
- **Authors:** Qiuran Zhao, Kai Ming Ting, Xinpeng Li
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10708](https://arxiv.org/abs/2602.10708)
- **Reason:** 提出ProtoGLAD框架，通过正常原型对比实现可解释的图级异常检测，提供原型-based的解释，属于深度学习可解释性研究。
Score: 7
Field: 深度学习可解释性

## 多模态智能体

### [Score: 8.0/10] ICA: Information-Aware Credit Assignment for Visually Grounded Long-Horizon Information-Seeking Agents
- **Authors:** Cong Pang, Xuyu Feng, Yujie Yi, Zixuan Chen, Jiawei Hong, Tiankuo Yao, Nang Yuan, Jiapeng Luo, Lewei Lu, Xin Lou
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10863](https://arxiv.org/abs/2602.10863)
- **Reason:** 提出ICA框架，通过视觉 grounding 和信息感知的信用分配提升长 horizon 信息搜索代理的性能，属于多模态智能体中的GUI grounding研究。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch
- **Authors:** Xingyi Zhang, Yulei Ye, Kaifeng Huang, Wenhao Li, Xiangfeng Wang
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10814](https://arxiv.org/abs/2602.10814)
- **Reason:** 提出ScratchWorld基准，评估多模态GUI Agents在Scratch中的程序构建能力，符合多模态智能体的GUI Agent方向。
Score: 8
Field: 多模态智能体

### [Score: 8.0/10] LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer
- **Authors:** Lihan Zha, Asher J. Hancock, Mingtong Zhang, Tenny Yin, Yixuan Huang, Dhruv Shah, Allen Z. Ren, Anirudha Majumdar
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10556](https://arxiv.org/abs/2602.10556)
- **Reason:** 提出语言-动作预训练LAP，实现VLA的零-shot跨embodiment迁移，符合多模态智能体方向。
Score: 8
Field: 多模态智能体

### [Score: 7.0/10] AugVLA-3D: Depth-Driven Feature Augmentation for Vision-Language-Action Models
- **Authors:** Zhifeng Rao, Wenlong Chen, Lei Xie, Xia Hua, Dongfu Yin, Zhen Tian, F. Richard Yu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10698](https://arxiv.org/abs/2602.10698)
- **Reason:** 将深度估计融入视觉语言动作（VLA）模型，增强3D特征用于机器人感知和控制，提升模型在复杂3D环境中的泛化能力。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] CLI-Gym: Scalable CLI Task Generation via Agentic Environment Inversion
- **Authors:** Yusong Lin, Haiyang Wang, Shuzhe Wu, Lue Fan, Feiyang Pan, Sanyuan Zhao, Dandan Tu
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.10999](https://arxiv.org/abs/2602.10999)
- **Reason:** 提出CLI任务生成框架，训练的LiberCoder模型提升终端任务性能，符合多模态智能体的GUI grounding方向。
Score: 7
Field: 多模态智能体

### [Score: 7.0/10] GameDevBench: Evaluating Agentic Capabilities Through Game Development
- **Authors:** Wayne Chi, Yixiong Fang, Arnav Yayavaram, Siddharth Yayavaram, Seth Karten, Qiuhong Anna Wei, Runkun Chen, Alexander Wang, Valerie Chen, Ameet Talwalkar, Chris Donahue
- **Published:** 2026-02-12
- **Link:** [https://arxiv.org/abs/2602.11103](https://arxiv.org/abs/2602.11103)
- **Reason:** 提出GameDevBench基准，评估多模态agent在游戏开发中的能力，符合多模态智能体方向。
Score: 7
Field: 多模态智能体

