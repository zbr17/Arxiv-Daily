<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐</title>

    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
        .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
        h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
        h1 { font-size: 2em; }
        h2 { font-size: 1.5em; margin-top: 2.5em; }
        h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
        .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
        .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
        .navbar a:hover { background-color: #ddd; color: black; }
        .navbar a.active { background-color: #007bff; color: white; }
        .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
        .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
        .paper-card p { margin: 0.5em 0; }
        .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
        .paper-card a:hover { text-decoration: underline; }
        .score { font-weight: bold; color: #d9534f; }
        .field-section { padding-top: 60px; margin-top: -60px; } /* 确保锚点跳转时不会被导航栏遮挡 */
    </style>
    
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >自动驾驶与大模型</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐</h1>
<div class='meta-info'><p>更新于北京时间：2025-10-23 23:27:19</p>
<p>已自动阅读了 215 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：113335</p>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning</h3>
<p><strong>Authors:</strong> Fengyuan Sun, Hui Chen, Xinhao Xu, Dandan Zheng, Jingdong Chen, Jun Zhou, Jungong Han, Guiguang Ding</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对多模态大模型的幻觉问题，提出了自适应KV缓存修剪方法，通过增强模型对关键视觉信息的注意力，有效缓解了幻觉，且无需额外训练，属于多模态大模型的关键优化方向。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19183' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation</h3>
<p><strong>Authors:</strong> Su Ho Han, Jeongseok Hyun, Pilhyeon Lee, Minho Shim, Dongyoon Wee, Seon Joo Kim</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对MLLMs视频推理分割的注意力噪声问题，提出DecAF框架优化注意力图，结合SAM2实现无训练高精度分割，属于多模态大模型的视觉推理应用。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19592' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs</h3>
<p><strong>Authors:</strong> John Burden, Jonathan Prunty, Ben Slater, Matthieu Tehenan, Greg Davis, Lucy Cheke</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 用认知心理学的视觉搜索范式评估MLLMs的感知能力，揭示其类似人类的pop-out效应，结合可解释性分析，属于多模态大模型的能力与可解释性研究。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19678' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MoAlign: Motion-Centric Representation Alignment for Video Diffusion Models</h3>
<p><strong>Authors:</strong> Aritra Bhowmik, Denis Korzhenkov, Cees G. M. Snoek, Amirhossein Habibian, Mohsen Ghafoorian</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对视频扩散模型的运动一致性问题，提出了运动中心的表示对齐框架，通过从预训练视频编码器中学习解耦的运动子空间，提升了视频生成的运动合理性，属于多模态大模型中的图像/视频生成方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19022' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning</h3>
<p><strong>Authors:</strong> Takehiro Aoshima, Yusuke Shinohara, Park Byeongseon</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对图像到视频生成的时间一致性问题，提出了Video Consistency Distance指标，通过奖励微调提升了生成视频的时间连贯性，属于多模态大模型的图像/视频生成方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19193' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> D2D: Detector-to-Differentiable Critic for Improved Numeracy in Text-to-Image Generation</h3>
<p><strong>Authors:</strong> Nobline Yoo, Olga Russakovsky, Ye Zhu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对文本到图像生成的计数问题，将非微分的检测器转化为可微分的批评者，提升了模型的计数准确性，属于多模态大模型的图像生成方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19278' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unified Reinforcement and Imitation Learning for Vision-Language Models</h3>
<p><strong>Authors:</strong> Byung-Kwan Lee, Ryo Hachiuma, Yong Man Ro, Yu-Chiang Frank Wang, Yueh-Hua Wu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了统一的强化和模仿学习框架RIL，用于训练轻量级VLMs，结合了LLM判别器和多教师指导，提升了VLMs的性能，属于多模态大模型的训练优化方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19307' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents</h3>
<p><strong>Authors:</strong> Kai Shi, Jun Yang, Ni Yang, Binqiang Pan, Qingsong Xie, Chao Zhang, Zhenyu Yang, Tianhuang Su, Haonan Lu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了数据混合优化器DaMo，用于微调多模态LLMs作为手机Agent，通过预测最优数据组合提升了多任务性能，属于多模态大模型的GUI Agent方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19336' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Intricate Dance of Prompt Complexity, Quality, Diversity, and Consistency in T2I Models</h3>
<p><strong>Authors:</strong> Xiaofeng Zhang, Aaron Courville, Michal Drozdzal, Adriana Romero-Soriano</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 系统研究了prompt复杂度对T2I模型的质量、多样性和一致性的影响，提出了prompt扩展方法提升生成性能，属于多模态大模型的图像生成方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19557' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OmniMotion-X: Versatile Multimodal Whole-Body Motion Generation</h3>
<p><strong>Authors:</strong> Guowei Xu, Yuxuan Bian, Ailing Zeng, Mingyi Shi, Shaoli Huang, Wen Li, Lixin Duan, Qiang Xu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出OmniMotion-X框架，用自回归扩散Transformer支持文本、音乐、语音等多模态动作生成，构建大规模OmniMoCap-X数据集，属于多模态大模型的动作生成研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19789' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models</h3>
<p><strong>Authors:</strong> Xiaozhen Qiao, Jingkai Zhao, Yuqiu Jiang, Xianda Guo, Zhe Sun, Hongyuan Zhang, Xuelong Li</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对VLMs测试时的分布偏移问题，提出CPL-NC框架通过类别感知原型与负对比学习提升泛化能力，实验验证跨基准的性能优势。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19802' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing</h3>
<p><strong>Authors:</strong> Yusu Qian, Eli Bocek-Rivele, Liangchen Song, Jialing Tong, Yinfei Yang, Jiasen Lu, Wenze Hu, Zhe Gan</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 构建Pico-Banana-400K大规模文本引导图像编辑数据集，支持多轮编辑与偏好学习，为多模态大模型的图像生成研究提供关键数据支撑。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19808' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Steering Autoregressive Music Generation with Recursive Feature Machines</h3>
<p><strong>Authors:</strong> Daniel Zhao, Daniel Beaglehole, Taylor Berg-Kirkpatrick, Julian McAuley, Zachary Novack (UC San Diego)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出MusicRFM框架，用RFM分析模型内部梯度生成概念方向，实现音乐生成的细粒度控制，属于多模态大模型的可控生成研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19127' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GigaBrain-0: A World Model-Powered Vision-Language-Action Model</h3>
<p><strong>Authors:</strong> GigaBrain Team, Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao, Haoyun Li, Jie Li, Jiagang Zhu, Lv Feng, Peng Li, Qiuping Deng, Runqi Ouyang, Wenkang Qin, Xinze Chen, Xiaofeng Wang, Yang Wang, Yifan Li, Yilong Li, Yiran Ding, Yuan Xu, Yun Ye, Yukun Zhou, Zhehao Dong, Zhenan Wang, Zhichao Liu, Zheng Zhu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出世界模型驱动的视觉-语言-动作（VLA）多模态基础模型，利用生成数据降低真实机器人数据依赖，结合RGBD建模与具身链式思维（CoT）提升泛化与鲁棒性，属于多模态大模型研究方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19430' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments</h3>
<p><strong>Authors:</strong> Hongyu Ding, Ziming Xu, Yudong Fang, You Wu, Zixuan Chen, Jieqi Shi, Jing Huo, Yifan Zhang, Yang Gao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出语言-视觉-机器人动作分层分解的零-shot VLN框架，利用多模态大模型（MLLMs）的推理与感知 grounding 能力解决连续环境导航问题，符合多模态大模型方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19655' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions</h3>
<p><strong>Authors:</strong> Amith Ananthram, Elias Stengel-Eskin, Lorena A. Bradford, Julia Demarest, Adam Purvis, Keith Krut, Robert Stein, Rina Elster Pantalony, Mohit Bansal, Kathleen McKeown</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了基于场景图的图像描述评估方法，用LLM作为 judge，解决了现有评估指标对长文本描述不敏感的问题，属于多模态大模型的图像理解方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19060' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP</h3>
<p><strong>Authors:</strong> Ying Dai, Wei Yu Chen</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了无训练的开放词汇图像分割和识别框架，结合EfficientNet和CLIP的跨模态对齐，提升了开放场景的图像理解能力，属于多模态大模型的图像理解方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19333' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes</h3>
<p><strong>Authors:</strong> Zhiyuan Feng, Zhaolu Kang, Qijie Wang, Zhiying Du, Jiongrui Yan, Shubin Shi, Chengbo Yuan, Huizhi Liang, Yu Deng, Qixiu Li, Rushuai Yang, Arctanx An, Leqi Zheng, Weijie Wang, Shawn Chen, Sicheng Xu, Yaobo Liang, Jiaolong Yang, Baining Guo</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了多视角VLMs空间推理基准MV-RoboBench，用于评估机器人场景的空间推理能力，揭示了VLMs在多视角任务中的局限性，属于多模态大模型的空间理解方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19400' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Reasoning Like Experts: Leveraging Multimodal Large Language Models for Drawing-based Psychoanalysis</h3>
<p><strong>Authors:</strong> Xueqi Ma, Yanbei Jiang, Sarah Erfani, James Bailey, Weifeng Liu, Krista A. Ehinger, Jey Han Lau</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 用MLLMs进行绘画的心理分析，通过分层表示和知识注入提升了心理推理能力，属于多模态大模型的图像理解与专家推理结合方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19451' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CARES: Context-Aware Resolution Selector for VLMs</h3>
<p><strong>Authors:</strong> Moshe Kimhi, Nimrod Shabtay, Raja Giryes, Chaim Baskin, Eli Schwartz</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了上下文感知的分辨率选择器，用于VLMs，通过预测最小 sufficient分辨率提升了计算效率，属于多模态大模型的效率优化方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19496' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Matter of Time: Revealing the Structure of Time in Vision-Language Models</h3>
<p><strong>Authors:</strong> Nidham Tekaya, Manuela Waldner, Matthias Zeppelzauer</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究了VLMs的时间感知能力，提出了TIME10k基准和时间线表示方法，揭示了VLMs中时间信息的结构，属于多模态大模型的时间理解方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19559' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Noise-Resilient and Transferable Graph-Text Alignment via Dynamic Quality Assessment</h3>
<p><strong>Authors:</strong> Yuhang Liu, Minglai Shao, Zengyi Wo, Yunlong Chu, Bing Hao, Shengzhong Liu, Ruijie Wang, Jianxin Li</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Proposes dynamic quality-aware graph-text alignment, contributing to multi-modal large models.
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19384' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation</h3>
<p><strong>Authors:</strong> Jiacheng Liu, Xinyu Wang, Yuqi Lin, Zhikai Wang, Peiru Wang, Peiliang Cai, Qinming Zhou, Zhengan Yan, Zexuan Yan, Zhengyi Shi, Chang Zou, Yue Ma, Linfeng Zhang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 系统综述扩散模型中的缓存方法，针对多模态生成的效率优化，属于多模态大模型中图像生成的关键问题，对提升生成效率有参考价值。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19755' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Semantic World Models</h3>
<p><strong>Authors:</strong> Jacob Berg, Chuning Zhu, Yanda Bao, Ishan Durugkar, Abhishek Gupta</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 将视觉语言模型作为语义世界模型用于机器人规划，结合多模态大模型与自动驾驶中的多模态大模型方向，对多模态模型的实际应用有参考价值。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19818' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Affordances at Inference-Time for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Ameesh Shah, William Chen, Adwait Godbole, Federico Mora, Sanjit A. Seshia, Sergey Levine</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出在推理时通过视觉语言模型（VLM）反思过去经验，学习视觉-语言-动作（VLA）模型的affordances，结合多模态上下文学习优化长 horizon 任务执行，属于多模态大模型的推理优化方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19752' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Beyond sparse denoising in frames: minimax estimation with a scattering transform</h3>
<p><strong>Authors:</strong> Nathana\"el Cuvelle--Magar, St\'ephane Mallat (École Normale Supérieure, INRIA)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究散射变换的去噪估计，证明其能捕捉图像的几何正则性（如piecewise C^α曲线），连接调和分析与深度学习，作者Stéphane Mallat为领域权威，理论价值高。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19612' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping</h3>
<p><strong>Authors:</strong> Zhiheng Xi, Xin Guo, Yang Nan, Enyu Zhou, Junrui Shen, Wenxiang Chen, Jiaqi Liu, Jixuan Huang, Zhihao Zhang, Honglin Guo, Xun Deng, Zhikai Lei, Miao Zheng, Guoteng Wang, Shuo Zhang, Peng Sun, Rui Zheng, Hang Yan, Tao Gui, Qi Zhang, Xuanjing Huang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出BAPO框架，通过自适应裁剪解决离策略RL的优化不平衡与熵衰减问题，提升LLM的推理性能，实验验证在数学与代码任务的优势。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18927' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Position: Many generalization measures for deep learning are fragile</h3>
<p><strong>Authors:</strong> Shuofeng Zhang, Ard Louis (University of Oxford)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 指出多数深度学习泛化度量对训练修改（如学习率调整）脆弱，呼吁开发鲁棒度量，观点新颖且理论分析深入，属于深度学习理论中的泛化研究。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18934' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Category learning in deep neural networks: Information content and geometry of internal representations</h3>
<p><strong>Authors:</strong> Laurent Bonnasse-Gahot, Jean-Pierre Nadal (École Normale Supérieure, CNRS)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 理论分析类别学习中的互信息与Fisher信息，揭示表示几何的优化机制，属于深度学习理论中的表示学习研究，作者为领域权威。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19021' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Weight Decay may matter more than muP for Learning Rate Transfer in Practice</h3>
<p><strong>Authors:</strong> Atli Kosson, Jeremy Welborn, Yang Liu, Martin Jaggi, Xi Chen (EPFL, MIT)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 实证研究发现权重衰减比muP更能稳定学习率转移，挑战现有假设，实验覆盖LLM训练等实际场景，结论具有实践指导意义。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19093' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Addressing the Depth-of-Field Constraint: A New Paradigm for High Resolution Multi-Focus Image Fusion</h3>
<p><strong>Authors:</strong> Luca Piano, Peng Huanwen, Radu Ciprian Bilcu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 将蒸馏VAE用于多聚焦图像融合，提出VAEEDOF解决数据稀缺与域间隙问题，发布MattingMFIF数据集，属于VAE在图像融合的创新应用。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19581' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks</h3>
<p><strong>Authors:</strong> Shaohang Jia, Zhiyong Huang, Zhi Yu, Mingyang Hou, Shuai Miao, Han Yang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出ADQ框架，通过自适应权重量化与激活映射解决混合精度量化的分布偏移问题，提升量化模型性能，属于深度学习理论中的量化优化。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19760' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ADPO: Anchored Direct Preference Optimization</h3>
<p><strong>Authors:</strong> Wang Zixian</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 扩展DPO框架，支持软偏好与参考策略锚定，解决DPO的梯度漂移与稳定性问题，属于深度学习理论中的RLHF优化。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18913' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Noise-corrected GRPO: From Noisy Rewards to Unbiased Gradients</h3>
<p><strong>Authors:</strong> Omar El mansouri, Mohamed El Amine Seddik, Salem Lahlou</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出噪声鲁棒的GRPO框架，通过奖励翻转概率估计与校正解决RLHF中的噪声奖励问题，提升模型性能，属于深度学习理论中的RL优化。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18924' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> NeuroAda: Activating Each Neuron's Potential for Parameter-Efficient Fine-Tuning</h3>
<p><strong>Authors:</strong> Zhi Zhang, Yixian Shen, Congfeng Cao, Ekaterina Shutova</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出NeuroAda框架，通过旁路连接激活神经元潜力，实现参数高效微调，实验验证在NLP任务的性能与内存效率优势，属于深度学习理论中的参数高效学习。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18940' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> What Makes a Good Curriculum? Disentangling the Effects of Data Ordering on LLM Mathematical Reasoning</h3>
<p><strong>Authors:</strong> Yaning Jia, Chunhui Zhang, Xingjian Diao, Xiangchi Yuan, Zhongyu Ouyang, Soroush Vosoughi (Yale University)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 分解课程学习的难度维度（如问题难度、模型惊讶度），分析其对LLM推理的影响，属于深度学习理论中的数据驱动泛化研究，结论具有指导意义。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19099' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> MetaCluster: Enabling Deep Compression of Kolmogorov-Arnold Network</h3>
<p><strong>Authors:</strong> Matthew Raffel (Google DeepMind), Adwaith Renjith, Lizhong Chen</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出MetaCluster框架，通过元学习与聚类压缩KAN的参数，解决KAN参数过多问题，实验验证在图像分类任务的压缩效果，属于深度学习理论中的架构优化。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19105' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Feature Space Adaptation for Robust Model Fine-Tuning</h3>
<p><strong>Authors:</strong> Peng Wang, Minghao Gu, Qiang Huang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出LoRFA与VeFA方法，通过特征空间适应解决微调的灾难性遗忘问题，实验验证在图像与NLP任务的鲁棒性优势，属于深度学习理论中的微调优化。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19155' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Natural Gradient VI: Guarantees for Non-Conjugate Models</h3>
<p><strong>Authors:</strong> Fangyuan Sun, Ilyas Fatkhullin, Niao He</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Investigates natural gradient variational inference with theoretical guarantees for non-conjugate models, directly contributing to deep learning theory (optimizer/variational inference).
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19163' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Data Efficient Any Transformer-to-Mamba Distillation via Attention Bridge</h3>
<p><strong>Authors:</strong> Penghao Wang, Yuhao Zhou, Mengxuan Wu, Panpan Zhang, Zhangyang Wang, Kai Wang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Proposes an attention bridge for efficient Transformer-to-Mamba distillation, advancing network architecture (hybrid models) in deep learning theory.
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19266' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall</h3>
<p><strong>Authors:</strong> Mingyu Jo, Jaesik Yoon, Justin Deschenaux, Caglar Gulcehre, Sungjin Ahn</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Introduces a deterministic latent pathway to improve discrete diffusion models, contributing to deep learning theory (network architecture for generation).
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19304' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning</h3>
<p><strong>Authors:</strong> Ling Team, Bin Han, Caizhi Tang, Chen Liang, Donghao Zhang, Fan Yuan, Feng Zhu, Jie Gao, Jingyu Hu, Longfei Li, Meng Li, Mingyang Zhang, Peijie Jiang, Peng Jiao, Qian Zhao, Qingyuan Yang, Wenbo Shen, Xinxing Yang, Yalin Zhang, Yankun Ren, Yao Zhao, Yibo Cao, Yixuan Sun, Yue Zhang, Yuchen Fang, Zibin Lin, Zixuan Cheng, Jun Zhou</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Presents a hybrid linear-softmax attention architecture for long-context reasoning, relevant to network architecture in deep learning theory.
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19338' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Statistical Inference for Linear Functionals of Online Least-squares SGD when $t \gtrsim d^{1+\delta}$</h3>
<p><strong>Authors:</strong> Bhavya Agrawalla, Krishnakumar Balasubramanian, Promit Ghosal</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 建立在线最小二乘SGD线性泛函的非渐近Berry-Esseen界，改进高维场景下的统计推断效率，属于深度学习理论中优化器的统计分析，对SGD的不确定性量化有重要意义。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19734' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> When Do Transformers Learn Heuristics for Graph Connectivity?</h3>
<p><strong>Authors:</strong> Qilin Ye, Deqing Fu, Robin Jia, Vatsal Sharan</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 以图连通性为测试床，理论与实证分析Transformer学习启发式还是算法的条件，涉及Transformer模型容量与训练数据的关系，属于深度学习理论中网络架构的研究，对理解Transformer泛化性有帮助。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19753' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Transformers are almost optimal metalearners for linear classification</h3>
<p><strong>Authors:</strong> Roey Magen, Gal Vardi</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 理论分析简化Transformer作为元学习器的性能，证明其在线性分类中的近最优性，属于深度学习理论中Transformer架构与元学习的交叉研究，对元学习的模型设计有指导意义。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19797' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Towards Single-Source Domain Generalized Object Detection via Causal Visual Prompts</h3>
<p><strong>Authors:</strong> Chen Li, Huiying Xu, Changxin Gao, Zeyu Wang, Yun Liu, Xinzhong Zhu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对单源域泛化目标检测，提出了因果视觉提示方法，通过跨注意力提示和双分支适配器解耦因果-虚假特征，提升了域泛化性能，属于深度学习理论的网络架构优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19487' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Optimization Benchmark for Diffusion Models on Dynamical Systems</h3>
<p><strong>Authors:</strong> Fabian Schaipp</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Benchmarks optimization algorithms for training diffusion models, aligning with deep learning theory (optimizer).
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19376' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CPSVD: Enhancing Large Language Model Compression via Column-Preserving Singular Value Decomposition</h3>
<p><strong>Authors:</strong> Lin Xv, Jingsheng Gao, Xian Gao, Ting Li, Yuzhuo Fu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Uses column-preserving SVD for efficient LLM compression, relevant to network architecture in deep learning theory.
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19385' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ARA: Adaptive Rank Allocation for Efficient Large Language Model SVD Compression</h3>
<p><strong>Authors:</strong> Lin Xv, Jingsheng Gao, Xian Gao, Ting Liu, Yuzhuo Fu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Proposes adaptive rank allocation for SVD-based LLM compression, advancing network architecture in deep learning theory.
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19389' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Neural Variational Dropout Processes</h3>
<p><strong>Authors:</strong> Insu Jeon, Youngjin Park, Gunhee Kim</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Introduces variational dropout processes for meta-learning, contributing to deep learning theory (variational methods).
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19425' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> ELUTQ: Efficient LUT-Aware Quantization for Deploying Large Language Models on Edge Devices</h3>
<p><strong>Authors:</strong> Xin Nie, Liang Dong, HaiCheng Zhang, JiaWang Xiao, G. Sun</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Proposes LUT-aware quantization for LLMs, advancing network architecture/optimization in deep learning theory.
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19482' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Latent Space Factorization in LoRA</h3>
<p><strong>Authors:</strong> Shashi Kumar, Yacouba Kaloga, John Mitros, Petr Motlicek, Ina Kodrasi</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Uses VAE for latent factorization in LoRA, advancing deep learning theory (VAE/network architecture).
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19640' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Study of Training Dynamics for Memory-Constrained Fine-Tuning</h3>
<p><strong>Authors:</strong> Aël Quélennec, Nour Hezbri, Pavlo Mozharovskyi, Van-Tam Nguyen, Enzo Tartaglione</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对内存约束下的微调训练动态展开研究，提出TraDy方法通过层重要性分析和动态通道选择优化训练，属于深度学习理论中训练优化与网络架构的交叉研究，对内存高效训练有实际价值。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19675' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters</h3>
<p><strong>Authors:</strong> Anand Choudhary, Yasser Sulaiman, Lukas Mauch, Ghouthi Boukli Hacene, Fabien Cardinaux, Antoine Bosselut</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出GaLLoP稀疏微调方法，选择梯度大且预训练权重小的参数，优化LLM的微调效果，属于深度学习理论中训练优化的研究，对参数高效微调有实际应用价值。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19778' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model</h3>
<p><strong>Authors:</strong> Yu Fang, Xinyu Wang, Xuehe Zhang, Wanli Xue, Mingwei Zhang, Shengyong Chen, Jie Zhao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对flow-matching方法在机器人模仿学习中的高推理时间问题，提出多步一致集成捷径模型与自适应梯度分配策略，改进模型性能与优化稳定性，属于深度学习理论中的生成模型优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19356' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Revisiting the Relation Between Robustness and Universality</h3>
<p><strong>Authors:</strong> M. Klabunde, L. Caspari, F. Lemmerich</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Studies the robustness and universality of neural networks, relevant to deep learning theory.
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19427' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Matrix-Free Least Squares Solvers: Values, Gradients, and What to Do With Them</h3>
<p><strong>Authors:</strong> Hrittik Roy, Søren Hauberg, Nicholas Krämer</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Derives custom gradients for matrix-free least squares, contributing to deep learning theory (optimizer).
Score: 6
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19634' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> LyTimeT: Towards Robust and Interpretable State-Variable Discovery</h3>
<p><strong>Authors:</strong> Kuai Yu, Crystal Su, Xiang Liu, Judah Goldfeder, Mingyuan Shao, Hod Lipson</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出LyTimeT框架，结合时空注意力与Lyapunov稳定性约束，从视频中提取可解释的动态系统状态变量，属于深度学习可解释性的物理意义分析。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19716' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Empowering Decision Trees via Shape Function Branching</h3>
<p><strong>Authors:</strong> Nakul Upadhya, Eldan Cohen (Weizmann Institute of Science)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出SGT决策树，用形状函数实现非线性分割，提升可解释性与性能，属于深度学习可解释性中的white-box方法，方法新颖且效果显著。
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19040' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> [De|Re]constructing VLMs' Reasoning in Counting</h3>
<p><strong>Authors:</strong> Simone Alghisi, Gabriel Roccabruna, Massimo Rizzoli, Seyed Mahed Mousavi, Giuseppe Riccardi</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 深入分析了VLMs在计数任务中的推理错误，提出了微调输出层的方法，提升了计数准确性，属于深度学习可解释性中的white-box explanation方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19555' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> InvarGC: Invariant Granger Causality for Heterogeneous Interventional Time Series under Latent Confounding</h3>
<p><strong>Authors:</strong> Ziyi Zhang, Shaogang Ren, Xiaoning Qian, Nick Duffield</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出InvarGC框架，解决潜在混淆下的异质干预时间序列因果推断，属于深度学习可解释性中的因果推理研究，理论分析与实验验证充分。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19138' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees</h3>
<p><strong>Authors:</strong> Aman Bilkhoo (Department of Informatics, King's College London), Milad Kazemi (Department of Informatics, King's College London), Nicola Paoletti (Department of Informatics, King's College London), Mehran Hosseini (Department of Informatics, King's College London, Department of Computer Science, University of Manchester)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出CONFEX方法生成带不确定性和conformal保证的反事实解释，解决现有方法忽略不确定性的问题，属于深度学习可解释性的关键研究，提升了解释的可靠性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19754' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Interpret Policies in Deep Reinforcement Learning using SILVER with RL-Guided Labeling: A Model-level Approach to High-dimensional and Multi-action Environments</h3>
<p><strong>Authors:</strong> Yiyu Qian, Su Nguyen, Chao Chen, Qinyue Zhou, Liyuan Zhao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Uses Shapley-based regression (SILVER) to interpret RL policies in high-dimensional environments, aligning with deep learning可解释性 (Shapley value).
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19244' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for Multivariate Time-Series Multi-class Classification</h3>
<p><strong>Authors:</strong> Maciej Mozolewski, Betül Bayrak, Kerstin Bach, Grzegorz J. Nalepa</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> Uses SHAP for counterfactual explanations of ECG models, aligning with deep learning可解释性 (Shapley value).
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19514' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts</h3>
<p><strong>Authors:</strong> Seungjun Yu, Junsung Park, Youngsun Lim, Hyunjung Shim</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了用于自动驾驶的两阶段多模态LLM QA系统，结合了多相机输入、历史数据和任务特定提示，提升了驾驶QA的可靠性和抗干扰能力，属于自动驾驶与大模型的典型应用。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19001' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks</h3>
<p><strong>Authors:</strong> Kai Zeng, Zhanqian Wu, Kaixin Xiong, Xiaobao Wei, Xiangyu Guo, Zhenxin Zhu, Kalok Ho, Lijun Zhou, Bohan Zeng, Ming Lu, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Wentao Zhang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了自动驾驶合成数据生成框架Dream4Drive，通过3D资产和世界模型生成多视角 photorealistic视频，提升了下游感知任务性能，属于自动驾驶与大模型的关键应用。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19195' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction</h3>
<p><strong>Authors:</strong> Junhong Lin, Kangli Wang, Shunzhou Wang, Songlin Fan, Ge Li, Wei Gao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对自动驾驶环视重建的几何一致性与新颖视图质量问题，提出VGD框架融合几何分支与高斯头，在nuScenes验证了性能提升，属于自动驾驶场景重建的关键技术。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19578' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism</h3>
<p><strong>Authors:</strong> Junfei Zhou, Penglin Dai, Quanmin Wei, Bingyi Liu, Xiao Wu, Jianping Wang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对自动驾驶多智能体异质协作的域间隙问题，提出GenComm框架通过生成通信实现无缝感知，实验验证性能提升与计算成本降低。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19618' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction</h3>
<p><strong>Authors:</strong> Zhida Zhao, Talas Fu, Yifan Wang, Lijun Wang, Huchuan Lu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出PWM框架整合自动驾驶世界模型与轨迹规划，通过协同状态-动作预测提升规划可靠性，属于自动驾驶大模型的关键技术。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19654' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion</h3>
<p><strong>Authors:</strong> Xiaozhi Li, Huijun Di, Jian Li, Feng Liu, Wei Liang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 结合4D雷达和相机的3D目标检测框架，通过表面拟合增强了跨模态交互和空间表示，提升了自动驾驶感知性能，属于自动驾驶与大模型的多模态融合方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19215' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Background Fades, Foreground Leads: Curriculum-Guided Background Pruning for Efficient Foreground-Centric Collaborative Perception</h3>
<p><strong>Authors:</strong> Yuheng Wu, Xiangbo Gao, Quang Tau, Zhengzhong Tu, Dongman Lee</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对自动驾驶协作感知的带宽问题，提出了课程引导的背景修剪方法，将背景上下文融入前景特征，提升了协作感知效率，属于自动驾驶与大模型的关键优化。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19250' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection</h3>
<p><strong>Authors:</strong> Ariana Yi, Ce Zhou, Liyang Xiao, Qiben Yan</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出了针对视频目标检测的alpha通道无框攻击，揭示了视频感知系统的漏洞，属于自动驾驶与大模型的安全方向。
Score: 6
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19574' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

    <script>
    document.addEventListener('DOMContentLoaded', (event) => {
        const sections = document.querySelectorAll('.field-section');
        const navLinks = document.querySelectorAll('.navbar a');

        function changeLinkState() {
            let index = sections.length;

            while(--index && window.scrollY + 100 < sections[index].offsetTop) {} // 100 as offset

            navLinks.forEach((link) => link.classList.remove('active'));
            // Check if navLinks[index] exists
            if (navLinks[index]) {
                navLinks[index].classList.add('active');
            }
        }

        changeLinkState();
        window.addEventListener('scroll', changeLinkState);
    });
    </script>
    </body>
</html>