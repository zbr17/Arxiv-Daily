<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐 - 2025-10-29</title>

        <style>
            body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
            .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
            h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
            h1 { font-size: 2em; }
            h2 { font-size: 1.5em; margin-top: 2.5em; }
            h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
            .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
            .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
            .navbar a:hover { background-color: #ddd; color: black; }
            .navbar a.active { background-color: #007bff; color: white; }
            .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
            .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
            .paper-card p { margin: 0.5em 0; }
            .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
            .paper-card a:hover { text-decoration: underline; }
            .score { font-weight: bold; color: #d9534f; }
            .field-section { padding-top: 60px; margin-top: -60px; }
            .history-selector { margin: 20px 0; padding: 10px; background-color: #f8f9fa; border-radius: 5px; }
            .history-selector label { font-weight: bold; margin-right: 10px; }
            .history-selector select { padding: 5px 10px; border: 1px solid #ddd; border-radius: 3px; }
        </style>
        
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>自动驾驶与大模型</a>
<a href='#' >多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >深度学习可解释性</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐 - 2025-10-29</h1>
<div class='history-selector'>
<label for='history-date'>选择历史日期:</label>
<select id='history-date' onchange='onHistoryDateChange(this)'>
<option value='index.html'>最新 (2025-10-29)</option>
<option value='history/2025-10-28.html'>2025-10-28</option>
</select>
</div>
<div class='meta-info'><p>更新于北京时间：2025-10-29 12:28:07</p>
<p>已自动阅读了 271 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：132013</p>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning</h3>
<p><strong>Authors:</strong> Aodi Wu, Xubo Luo</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 针对自动驾驶场景优化Vision-Language Models（VLM），通过任务特定提示、空间推理和多视图视觉组装提升VLM在感知、预测等安全关键任务的性能，直接匹配“自动驾驶与大模型”研究方向。
Score: 9
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.24152' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle Decision-Making Systems via Multi-Dataset Integration</h3>
<p><strong>Authors:</strong> Xin Yang, Yuhang Zhang, Wei Li, Xin Lin, Wenbin Zou, Chen Xu</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 针对自动驾驶决策系统的运动规划问题，提出多数据集集成的统一框架，解决单数据集训练的鲁棒性限制，对自动驾驶与大模型方向的运动规划研究有重要参考价值。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.24166' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration</h3>
<p><strong>Authors:</strong> Jongsuk Kim, Jaeyoung Lee, Gyojin Han, Dongjae Lee, Minki Jeong, Junmo Kim</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出合成数据集成框架，解决纯实数据训练的场景多样性限制，增强端到端自动驾驶模型性能，对自动驾驶与大模型的模型数据增强研究有实际价值。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.24052' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring</h3>
<p><strong>Authors:</strong> Zhenxin Li, Wenhao Yao, Zi Wang, Xinglong Sun, Jingde Chen, Nadine Chang, Maying Shen, Jingyu Song, Zuxuan Wu, Shiyi Lan, Jose M. Alvarez</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出无模仿学习的端到端自动驾驶框架，结合强化学习处理高维传感器数据，解决传统模仿学习的次优演示与协变量偏移问题，在Navhard等基准测试中取得SOTA性能，对自动驾驶与大模型的端到端学习研究具有重要价值
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.24108' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder</h3>
<p><strong>Authors:</strong> Li Li, Tobias Brinkmann, Till Temmen, Markus Eisenbarth, Jakob Andert</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 针对自动驾驶环岛场景的多智能体场景生成需求，提出Transformer增强的条件变分自编码器模型，能生成真实、多样的合成场景，对自动驾驶大模型的虚拟测试和边缘案例探索具有实用价值
Score: 6
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.24671' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 6.0/10]</span> Fare: Failure Resilience in Learned Visual Navigation Control</h3>
<p><strong>Authors:</strong> Zishuo Wang, Joel Loo, David Hsu</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 针对模仿学习视觉导航的OOD故障问题，提出故障恢复框架Fare，整合故障检测与恢复策略，提升复杂环境下的鲁棒性，对自动驾驶与大模型中的视觉导航鲁棒性研究有价值
Score: 6
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.24680' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model</h3>
<p><strong>Authors:</strong> Juntian Zhang, Song Jin, Chuanqi Cheng, Yuhan Liu, Yankai Lin, Xun Zhang, Yufei Zhang, Fei Jiang, Guojun Yin, Wei Lin, Rui Yan</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出两阶段自进化框架，通过自批判和自预测提升VLM的精细视觉感知能力，在多基准上取得显著增益，直接匹配“多模态大模型”方向。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24285' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> MGA: Memory-Driven GUI Agent for Observation-Centric Interaction</h3>
<p><strong>Authors:</strong> Weihua Cheng, Ersheng Ni, Wenlong Wang, Yifei Sun, Junming Liu, Wangyu Shen, Yirong Chen, Botian Shi, Ding Wang</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出记忆驱动的GUI Agent框架，解决现有GUI Agent依赖历史轨迹和局部探索偏差的问题，属于多模态大模型中GUI Agent的关键研究方向，相关性高且具有实际应用价值。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24168' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> RoboOmni: Proactive Robot Manipulation in Omni-modal Context</h3>
<p><strong>Authors:</strong> Siyin Wang, Jinlan Fu, Feihong Liu, Xinzhe He, Huangxuan Wu, Junhao Shi, Kexin Huang, Zhaoye Fei, Jingjing Gong, Zuxuan Wu, Yugang Jiang, See-Kiong Ng, Tat-Seng Chua, Xipeng Qiu</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出基于端到端全模态LLM的机器人主动操作框架，解决现有方法依赖显式指令的问题，构建OmniAction数据集支持主动意图识别，属于多模态大模型在机器人交互中的关键研究。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.23763' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation</h3>
<p><strong>Authors:</strong> Jinxin Zhou, Jiachen Jiang, Zhihui Zhu</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 分析CLIP的层、头、token级视觉判别性，提出无训练框架提升开放词汇分割性能，改进多模态大模型（VLM）的视觉理解能力。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.23894' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Enhancing CLIP Robustness via Cross-Modality Alignment</h3>
<p><strong>Authors:</strong> Xingyu Zhu, Beier Zhu, Shuo Wang, Kesen Zhao, Hanwang Zhang</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出最优传输框架恢复CLIP的图像-文本对齐，提升对抗鲁棒性，属于多模态大模型（VLM）的鲁棒性改进。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24038' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation</h3>
<p><strong>Authors:</strong> Agus Gunawan, Samuel Teodoro, Yun Chen, Soo Ye Kim, Jihyong Oh, Munchurl Kim</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出无训练通用框架，支持文本图像的多种操作（去除、编辑、风格控制等），并构建OmniText-Bench基准，符合多模态大模型的文本-图像交互方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24093' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs</h3>
<p><strong>Authors:</strong> Huanyu Zhang, Wenshan Wu, Chengzu Li, Ning Shang, Yan Xia, Yangyu Huang, Yifan Zhang, Li Dong, Zhang Zhang, Liang Wang, Tieniu Tan, Furu Wei</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出为多模态大语言模型（MLLMs）引入内部视觉草稿本的框架，增强其视觉推理与生成能力，符合多模态大模型的研究方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24514' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models</h3>
<p><strong>Authors:</strong> Byeonghu Na, Minsang Park, Gyuwon Sim, Donghyeok Shin, HeeSun Bae, Mina Kang, Se Jung Kwon, Wanmo Kang, Il-Chul Moon</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出扩散自适应文本嵌入（DATE），动态调整文本嵌入以提升文本-图像对齐，属于多模态大模型中的图像生成方向，对文本到图像生成有显著改进。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.23974' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents</h3>
<p><strong>Authors:</strong> Zihao Wang, Xujing Li, Yining Ye, Junjie Fang, Haoming Wang, Longxiang Liu, Shihao Liang, Junting Lu, Zhiyong Wu, Jiazhan Feng, Wanjun Zhong, Zili Li, Yu Wang, Yu Miao, Bo Zhou, Yuanfan Li, Hao Wang, Zhongkai Zhao, Faming Wu, Zhengxuan Jiang, Weihao Tan, Heyuan Yao, Shi Yan, Xiangyang Li, Yitao Liang, Yujia Qin, Guang Shi</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出Game-TARS，一种支持OS、web及模拟游戏的多模态通用游戏代理基础模型，通过统一动作空间与持续预训练实现规模化泛化，属于多模态大模型中的multimodal large model研究，有实际应用价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.23691' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows</h3>
<p><strong>Authors:</strong> Qiushi Sun, Mukai Li, Zhoumianze Liu, Zhihui Xie, Fangzhi Xu, Zhangyue Yin, Kanzhi Cheng, Zehao Li, Zichen Ding, Qi Liu, Zhiyong Wu, Zhuosheng Zhang, Ben Kao, Lingpeng Kong</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 针对移动GUI Agent的安全问题，构建动态沙盒环境和安全检测基准，提出混合验证框架提升安全检测性能，对多模态大模型的GUI Agent安全增强研究有重要意义。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24411' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs</h3>
<p><strong>Authors:</strong> Jinhong Deng, Wen Li, Joey Tianyi Zhou, Yang He</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出显著性-覆盖度导向的视觉token剪枝策略，提升多模态大模型（MLLMs）的计算效率，保持任务性能。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24214' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> TRELLISWorld: Training-Free World Generation from Object Generators</h3>
<p><strong>Authors:</strong> Hanke Chen, Yuan Liu, Minchen Li</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 将text-to-3D对象生成模型作为模块化tile生成器，实现无训练的大规模3D场景合成，符合多模态大模型的text-to-3D生成方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.23880' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts</h3>
<p><strong>Authors:</strong> Yufan Liu, Wanqian Zhang, Huashan Chen, Lin Wang, Xiaojun Jia, Zheng Lin, Weiping Wang</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 用LLM生成人类可读的对抗prompt，提升text-to-image模型的红队测试效果，属于多模态大模型的安全性研究。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24034' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents</h3>
<p><strong>Authors:</strong> Hongrui Jia, Jitong Liao, Xi Zhang, Haiyang Xu, Tianbao Xie, Chaoya Jiang, Ming Yan, Si Liu, Wei Ye, Fei Huang</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 构建了评估计算机使用代理中MCP工具调用的基准，涉及多模态大模型中的GUI Agent与工具调用场景，符合研究方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24563' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection</h3>
<p><strong>Authors:</strong> Anisha Saha, Varsha Suresh, Timothy Hospedales, Vera Demberg</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection
Authors: Anisha Saha, Varsha Suresh, Timothy Hospedales, Vera Demberg
Published: 2025-10-29
Link: https://arxiv.org/abs/2510.23727
Reason: 提出针对视频大模型（Video-LMs）的多模态讽刺检测基准，聚焦多模态线索的语用推理，属于多模态大模型方向，有助于提升模型对隐含意图的理解能力。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.23727' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models</h3>
<p><strong>Authors:</strong> Byeonghu Na, Mina Kang, Jiseok Kwak, Minsang Park, Jiwoo Shin, SeJoon Jun, Gayoung Lee, Jin-Hwa Kim, Il-Chul Moon</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出无训练的安全文本嵌入引导方法，提升文本到图像扩散模型的安全性与内容合规性，属于多模态大模型中的图像生成方向，符合实际应用需求。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24012' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> What do vision-language models see in the context? Investigating multimodal in-context learning</h3>
<p><strong>Authors:</strong> Gabriel O. dos Santos, Esther Colombini, Sandra Avila</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 系统研究Vision-Language Models的多模态in-context learning能力，分析prompt设计、架构、训练策略的影响及attention模式，属于多模态大模型中的VLMs研究，对理解多模态模型的ICL机制有帮助。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24331' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> PFEA: An LLM-based High-Level Natural Language Planning and Feedback Embodied Agent for Human-Centered AI</h3>
<p><strong>Authors:</strong> Wenbin Ding, Jun Chen, Mingjia Chen, Fei Xie, Qi Mao, Philip Dames</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出基于视觉-语言模型（VLM）的具身Agent框架，整合自然语言交互、视觉任务规划与反馈机制，在模拟和真实环境中显著提升复杂自然语言指令任务的成功率，对多模态大模型与具身智能的结合研究有积极意义
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24109' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation</h3>
<p><strong>Authors:</strong> Haotian Zhou, Xiaole Wang, He Li, Fusheng Sun, Shengyu Guo, Guolei Qi, Jianghuan Xu, Huijing Zhao</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 针对多模态开放词汇多目标视觉导航问题，提出语言3D高斯记忆模块整合多模态信息，在自定义基准GOAT-Core上优于现有SOTA方法，为多模态大模型与视觉导航的融合研究提供了新思路
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.24118' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> How do simple rotations affect the implicit bias of Adam?</h3>
<p><strong>Authors:</strong> Adela DePavia, Vasileios Charisopoulos, Rebecca Willett</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 研究数据旋转对Adam优化器隐式偏差的影响，揭示其对正交变换的敏感性及解决方法，属于深度学习理论中的优化器方向，对优化器设计有重要意义。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.23804' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers</h3>
<p><strong>Authors:</strong> Marko Karbevski, Antonij Mijoski</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 理论证明Transformer中Query权重的冗余性，属于深度学习理论中的网络架构方向，对简化Transformer架构设计有突破性意义。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.23912' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> The Cost of Robustness: Tighter Bounds on Parameter Complexity for Robust Memorization in ReLU Nets</h3>
<p><strong>Authors:</strong> Yujun Kim, Chaewon Moon, Chulhee Yun</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 研究ReLU网络鲁棒记忆的参数复杂度，针对鲁棒性比率ρ∈(0,1)给出更紧的上下界，深化了对深度学习模型鲁棒性与参数效率关系的理解，属于深度学习理论中的理论分析方向。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24643' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?</h3>
<p><strong>Authors:</strong> Yihao Li, Saeed Salehi, Lyle Ungar, Konrad P. Kording</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 研究预训练视觉Transformer（ViT）中是否自然涌现目标绑定能力，涉及深度学习理论中的网络架构与表示学习，符合研究方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24709' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance</h3>
<p><strong>Authors:</strong> Yujie Wei, Shiwei Zhang, Hangjie Yuan, Yujin Han, Zhekai Chen, Jiayu Wang, Difan Zou, Xihui Liu, Yingya Zhang, Yu Liu, Hongming Shan</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出ProMoE框架，通过显式路由引导提升混合专家模型（MoE）在扩散Transformer中的性能，涉及深度学习理论中的网络架构（MoE、Diffusion Transformers），符合研究方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24711' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Sparsity and Superposition in Mixture of Experts</h3>
<p><strong>Authors:</strong> Marmik Chaudhari, Jeremi Nuer, Rome Thorstenson</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 研究混合专家模型（MoE）的稀疏性与叠加机制，探讨其与密集网络的 mechanistic 差异，属于深度学习理论中的网络架构方向，对大模型架构设计有重要参考价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.23671' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning</h3>
<p><strong>Authors:</strong> Yilang Zhang, Xiaodong Yang, Yiwei Cai, Georgios B. Giannakis</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出最优缩放的低秩适应（LoRA）方法，提升高秩微调的效率与性能，属于深度学习理论中的模型架构适应方向，对大模型微调有重要价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.23818' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic</h3>
<p><strong>Authors:</strong> Kanghyun Choi, Hyeyoon Lee, SunJong Park, Dain Kwon, Jinho Lee</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 利用低比特浮点算术加速LoRA微调，提升大模型微调的速度与效率，属于深度学习理论中的大模型优化方向，对大模型部署有重要价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24061' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Information-Theoretic Discrete Diffusion</h3>
<p><strong>Authors:</strong> Moongyu Jeon, Sangwoo Shin, Dongjae Jeon, Albert No</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出信息论框架的离散扩散模型，推导I-MDSE与I-MDCE关系，为离散扩散的对数似然估计提供理论基础，属于深度学习理论中的生成模型方向，有较高理论价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24088' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis</h3>
<p><strong>Authors:</strong> Qingyue Zhang, Chang Chu, Tianren Peng, Qi Li, Xiangyang Luo, Zhihao Jiang, Shao-Lun Huang</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 针对LoRA的初始化问题，提出基于渐近分析的data-aware策略，通过Fisher-gradient formulation和Fisher信息优化初始化，提升了LoRA的收敛速度与性能，属于深度学习理论中的网络架构（PEFT）方向，有实际应用价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24561' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Greedy Sampling Is Provably Efficient for RLHF</h3>
<p><strong>Authors:</strong> Di Wu, Chengshuai Shi, Jing Yang, Cong Shen</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 证明了RLHF中贪心采样的有效性，针对一般偏好模型获得比现有工作更优的性能保证，揭示了KL正则化目标下最优策略类的结构特性，属于深度学习理论中的优化算法方向，对RLHF的理论理解有贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24700' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Improving the Straight-Through Estimator with Zeroth-Order Information</h3>
<p><strong>Authors:</strong> Ningfeng Yang, Tor M. Aamodt</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 利用零阶信息改进直通估计器，提升量化感知预训练的性能与效率，属于深度学习理论中的量化训练优化方向，对低精度模型训练有实用价值。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.23926' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Sparse Optimistic Information Directed Sampling</h3>
<p><strong>Authors:</strong> Ludovic Schwartz, Hamish Flynn, Gergely Neu</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 研究高维在线决策场景下随机稀疏线性bandits的优化算法SOIDS，解决了现有算法在数据丰富与稀疏 regime下的regret平衡问题，属于深度学习理论中的优化算法方向，具有重要理论价值。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24234' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Eigenfunction Extraction for Ordered Representation Learning</h3>
<p><strong>Authors:</strong> Burak Varıcı, Che-Ping Tsai, Ritabrata Ray, Nicholas M. Boffi, Pradeep Ravikumar</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出提取有序、可识别特征函数的框架，基于上下文核的谱分解，通过低秩近似与Rayleigh quotient优化实现，验证了其在特征选择与表示学习中的有效性，属于深度学习理论中的表示学习方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.24672' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Enhancing Pre-trained Representation Classifiability can Boost its Interpretability</h3>
<p><strong>Authors:</strong> Shufan Shen, Zhaobo Qi, Junshu Sun, Qingming Huang, Qi Tian, Shuhui Wang</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 量化预训练表示的分类性与可解释性的正相关关系，提出Inherent Interpretability Score评估可解释性，直接匹配“深度学习可解释性”方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.24105' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> XAI Evaluation Framework for Semantic Segmentation</h3>
<p><strong>Authors:</strong> Reem Hammoud, Abdul karim Gizzini, Ali J. Ghandour</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出针对语义分割任务的可解释AI（XAI）评估框架，解决了语义分割中XAI方法评估不足的问题，直接关联深度学习可解释性研究方向。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.24414' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders</h3>
<p><strong>Authors:</strong> Nathan Paek, Yongyi Zang, Qihui Yang, Randal Leistikow</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 利用稀疏自编码器从音频 latent 空间提取可解释特征，属于深度学习可解释性方向，为音频生成模型的可解释分析提供了有效方法。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.23802' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes</h3>
<p><strong>Authors:</strong> Pedro Cortes dos Santos, Matheus Becali Rocha, Renato A Krohling</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 结合SHAP（用户关注的可解释性方法）与因果分析实现工业过程的可解释故障检测，属于深度学习可解释性方向，提升了故障诊断的 actionable  insights。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.23817' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Pragmatic Way to Measure Chain-of-Thought Monitorability</h3>
<p><strong>Authors:</strong> Scott Emmons, Roland S. Zimmermann, David K. Elson, Rohin Shah</p>
<p><strong>Published:</strong> 2025-10-29</p>
<p><strong>Reason:</strong> 提出思维链（CoT）可监控性的测量方法，属于深度学习可解释性方向，为CoT的可解释性与安全性评估提供了工具，符合用户对可解释性的关注。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.23966' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

        <script>
        document.addEventListener('DOMContentLoaded', (event) => {
            const sections = document.querySelectorAll('.field-section');
            const navLinks = document.querySelectorAll('.navbar a');

            function changeLinkState() {
                let index = sections.length;

                while(--index && window.scrollY + 100 < sections[index].offsetTop) {}

                navLinks.forEach((link) => link.classList.remove('active'));
                if (navLinks[index]) {
                    navLinks[index].classList.add('active');
                }
            }

            changeLinkState();
            window.addEventListener('scroll', changeLinkState);
        });

        function onHistoryDateChange(select) {
            if (select.value) {
                window.location.href = select.value;
            }
        }
        </script>
        </body>
</html>