<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐</title>

    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
        .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
        h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
        h1 { font-size: 2em; }
        h2 { font-size: 1.5em; margin-top: 2.5em; }
        h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
        .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
        .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
        .navbar a:hover { background-color: #ddd; color: black; }
        .navbar a.active { background-color: #007bff; color: white; }
        .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
        .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
        .paper-card p { margin: 0.5em 0; }
        .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
        .paper-card a:hover { text-decoration: underline; }
        .score { font-weight: bold; color: #d9534f; }
        .field-section { padding-top: 60px; margin-top: -60px; } /* 确保锚点跳转时不会被导航栏遮挡 */
    </style>
    
</head>
<body>
<div class='navbar'>
<a href='#' class='active'>多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >自动驾驶与大模型</a>
<a href='#' >深度学习可解释性</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐</h1>
<div class='meta-info'><p>更新于北京时间：2025-10-23 23:51:12</p>
<p>已自动阅读了 215 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：110291</p>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> PruneHal: Reducing Hallucinations in Multi-modal Large Language Models through Adaptive KV Cache Pruning</h3>
<p><strong>Authors:</strong> Fengyuan Sun, Hui Chen, Xinhao Xu, Dandan Zheng, Jingdong Chen, Jun Zhou, Jungong Han, Guiguang Ding</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对多模态大模型的幻觉问题，提出自适应KV缓存剪枝方法，无需额外训练即可增强模型对关键视觉信息的关注，是多模态大模型鲁棒性优化的重要工作。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19183' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> PoSh: Using Scene Graphs To Guide LLMs-as-a-Judge For Detailed Image Descriptions</h3>
<p><strong>Authors:</strong> Amith Ananthram, Elias Stengel-Eskin, Lorena A. Bradford, Julia Demarest, Adam Purvis, Keith Krut, Robert Stein, Rina Elster Pantalony, Mohit Bansal, Kathleen McKeown</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出基于场景图的LLM评估指标PoSh，用于细粒度图像描述的质量评估，解决VLMs图像理解中的评估难题，属于多模态大模型的图像理解方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19060' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Unified Reinforcement and Imitation Learning for Vision-Language Models</h3>
<p><strong>Authors:</strong> Byung-Kwan Lee, Ryo Hachiuma, Yong Man Ro, Yu-Chiang Frank Wang, Yueh-Hua Wu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出统一强化与模仿学习（RIL）算法，训练轻量型视觉语言模型，提升VLMs的生成能力，属于多模态大模型的训练优化方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19307' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents</h3>
<p><strong>Authors:</strong> Kai Shi, Jun Yang, Ni Yang, Binqiang Pan, Qingsong Xie, Chao Zhang, Zhenyu Yang, Tianhuang Su, Haonan Lu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出数据混合优化器DaMo，用于多模态大模型的微调，针对手机Agent场景设计，属于多模态大模型中的GUI Agent方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19336' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes</h3>
<p><strong>Authors:</strong> Zhiyuan Feng, Zhaolu Kang, Qijie Wang, Zhiying Du, Jiongrui Yan, Shubin Shi, Chengbo Yuan, Huizhi Liang, Yu Deng, Qixiu Li, Rushuai Yang, Arctanx An, Leqi Zheng, Weijie Wang, Shawn Chen, Sicheng Xu, Yaobo Liang, Jiaolong Yang, Baining Guo</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出MV-RoboBench基准，评估VLMs在机器人场景中的多视图空间推理能力，属于多模态大模型的空间理解方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19400' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> The Intricate Dance of Prompt Complexity, Quality, Diversity, and Consistency in T2I Models</h3>
<p><strong>Authors:</strong> Xiaofeng Zhang, Aaron Courville, Michal Drozdzal, Adriana Romero-Soriano</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 系统分析prompt复杂度对T2I模型生成质量、多样性与一致性的影响，属于多模态大模型中的图像生成方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19557' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation</h3>
<p><strong>Authors:</strong> Su Ho Han, Jeongseok Hyun, Pilhyeon Lee, Minho Shim, Dongyoon Wee, Seon Joo Kim</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对多模态大语言模型（MLLMs）的无训练视频推理分割任务，提出分解注意力融合方法优化注意力图，属于多模态大模型的核心应用研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19592' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs</h3>
<p><strong>Authors:</strong> John Burden, Jonathan Prunty, Ben Slater, Matthieu Tehenan, Greg Davis, Lucy Cheke</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 利用视觉搜索范式测试多模态大模型的感知能力，结合可解释性分析（如fine-tuning和机制解释），覆盖多模态大模型与可解释性两个核心方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19678' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> OmniMotion-X: Versatile Multimodal Whole-Body Motion Generation</h3>
<p><strong>Authors:</strong> Guowei Xu, Yuxuan Bian, Ailing Zeng, Mingyi Shi, Shaoli Huang, Wen Li, Lixin Duan, Qiang Xu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出多模态全身运动生成框架，支持text-to-motion、music-to-dance等任务，属于多模态大模型的核心应用方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19789' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GigaBrain-0: A World Model-Powered Vision-Language-Action Model</h3>
<p><strong>Authors:</strong> GigaBrain Team, Angen Ye, Boyuan Wang, Chaojun Ni, Guan Huang, Guosheng Zhao, Haoyun Li, Jie Li, Jiagang Zhu, Lv Feng, Peng Li, Qiuping Deng, Runqi Ouyang, Wenkang Qin, Xinze Chen, Xiaofeng Wang, Yang Wang, Yifan Li, Yilong Li, Yiran Ding, Yuan Xu, Yun Ye, Yukun Zhou, Zhehao Dong, Zhenan Wang, Zhichao Liu, Zheng Zhu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出世界模型驱动的视觉-语言-动作（VLA）基础模型，通过生成数据减少对真实机器人数据的依赖，提升跨任务泛化能力，属于多模态大模型中的VLA方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19430' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments</h3>
<p><strong>Authors:</strong> Hongyu Ding, Ziming Xu, Yudong Fang, You Wu, Zixuan Chen, Jieqi Shi, Jing Huo, Yifan Zhang, Yang Gao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出语言-视觉-机器人动作分层翻译框架，利用多模态大模型的推理与接地能力解决零-shot连续环境视觉语言导航问题，属于多模态大模型中的语言-视觉-动作对齐方向。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19655' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MoAlign: Motion-Centric Representation Alignment for Video Diffusion Models</h3>
<p><strong>Authors:</strong> Aritra Bhowmik, Denis Korzhenkov, Cees G. M. Snoek, Amirhossein Habibian, Mohsen Ghafoorian</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对视频扩散模型的运动一致性问题，提出运动中心的表示对齐框架，优化视频生成的时间连贯性，属于多模态大模型中的图像/视频生成方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19022' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning</h3>
<p><strong>Authors:</strong> Takehiro Aoshima, Yusuke Shinohara, Park Byeongseon</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出视频一致性距离（VCD）指标，通过奖励式微调优化图像到视频生成的时间连贯性，属于多模态大模型中的图像/视频生成方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19193' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Reasoning Like Experts: Leveraging Multimodal Large Language Models for Drawing-based Psychoanalysis</h3>
<p><strong>Authors:</strong> Xueqi Ma, Yanbei Jiang, Sarah Erfani, James Bailey, Weifeng Liu, Krista A. Ehinger, Jey Han Lau</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出PICK框架，利用多模态大模型分析绘画的心理状态，结合层次化表示与知识注入，属于多模态大模型的图像理解方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19451' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> CARES: Context-Aware Resolution Selector for VLMs</h3>
<p><strong>Authors:</strong> Moshe Kimhi, Nimrod Shabtay, Raja Giryes, Chaim Baskin, Eli Schwartz</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出上下文感知的分辨率选择器CARES，优化VLMs的图像输入分辨率，提升计算效率与性能平衡，属于多模态大模型的优化方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19496' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> [De|Re]constructing VLMs' Reasoning in Counting</h3>
<p><strong>Authors:</strong> Simone Alghisi, Gabriel Roccabruna, Massimo Rizzoli, Seyed Mahed Mousavi, Giuseppe Riccardi</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究VLMs在计数任务中的推理机制，通过层分析与目标微调提升计数准确性，属于多模态大模型的视觉推理方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19555' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Matter of Time: Revealing the Structure of Time in Vision-Language Models</h3>
<p><strong>Authors:</strong> Nidham Tekaya, Manuela Waldner, Matthias Zeppelzauer</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究VLMs的时间感知能力，提出从嵌入空间中提取时间线表示，属于多模态大模型的时间推理方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19559' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Class-Aware Prototype Learning with Negative Contrast for Test-Time Adaptation of Vision-Language Models</h3>
<p><strong>Authors:</strong> Xiaozhen Qiao, Jingkai Zhao, Yuqiu Jiang, Xianda Guo, Zhe Sun, Hongyuan Zhang, Xuelong Li</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出CPL-NC框架优化视觉语言模型的测试时适应，解决长-tailed分布与类混淆问题，属于多模态大模型的泛化研究。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19802' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing</h3>
<p><strong>Authors:</strong> Yusu Qian, Eli Bocek-Rivele, Liangchen Song, Jialing Tong, Yinfei Yang, Jiasen Lu, Wenze Hu, Zhe Gan</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 构建大规模文本引导图像编辑数据集，支持多模态大模型中的image generation任务，为研究提供重要数据资源。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19808' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Steering Autoregressive Music Generation with Recursive Feature Machines</h3>
<p><strong>Authors:</strong> Daniel Zhao, Daniel Beaglehole, Taylor Berg-Kirkpatrick, Julian McAuley, Zachary Novack</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出MusicRFM框架控制预训练音乐生成模型，实现fine-grained、可解释的音乐生成，属于多模态大模型中的可控生成研究。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19127' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation</h3>
<p><strong>Authors:</strong> Jiacheng Liu, Xinyu Wang, Yuqi Lin, Zhikai Wang, Peiru Wang, Peiliang Cai, Qinming Zhou, Zhengan Yan, Zexuan Yan, Zhengyi Shi, Chang Zou, Yue Ma, Linfeng Zhang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 系统综述扩散模型的缓存方法，分析从静态到动态复用的进化，对多模态生成中的高效推理有指导意义，属于多模态大模型方向
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19755' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Semantic World Models</h3>
<p><strong>Authors:</strong> Jacob Berg, Chuning Zhu, Yanda Bao, Ishan Durugkar, Abhishek Gupta</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出语义世界模型，将世界建模视为视觉问答问题结合VLM实现规划，对多模态大模型的世界建模有价值
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19818' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Learning Affordances at Inference-Time for Vision-Language-Action Models</h3>
<p><strong>Authors:</strong> Ameesh Shah, William Chen, Adwait Godbole, Federico Mora, Sanjit A. Seshia, Sergey Levine</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出LITEN框架，通过上下文视觉语言模型在推理时学习VLA模型的affordances，增强复杂任务的适应能力，属于多模态大模型中的VLA推理优化方向。
Score: 7
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19752' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Statistical Inference for Linear Functionals of Online Least-squares SGD when $t \gtrsim d^{1+\delta}$</h3>
<p><strong>Authors:</strong> Bhavya Agrawalla, Krishnakumar Balasubramanian, Promit Ghosal</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 建立在线最小二乘SGD线性泛函的非渐近Berry-Esseen界，解决高维情况下的统计推断问题，对深度学习理论中优化器（SGD）理论有重要突破
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19734' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Addressing the Depth-of-Field Constraint: A New Paradigm for High Resolution Multi-Focus Image Fusion</h3>
<p><strong>Authors:</strong> Luca Piano, Peng Huanwen, Radu Ciprian Bilcu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出VAEEDOF方法，将蒸馏变分自动编码器用于多焦点图像融合，直接关联深度学习理论中的VAE研究方向，解决深度-of-field约束问题。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19581' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ADPO: Anchored Direct Preference Optimization</h3>
<p><strong>Authors:</strong> Wang Zixian</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出ADPO框架扩展DPO，解决偏好优化中的噪声与稳定性问题，属于深度学习理论中的优化器研究方向。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18913' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping</h3>
<p><strong>Authors:</strong> Zhiheng Xi, Xin Guo, Yang Nan, Enyu Zhou, Junrui Shen, Wenxiang Chen, Jiaqi Liu, Jixuan Huang, Zhihao Zhang, Honglin Guo, Xun Deng, Zhikai Lei, Miao Zheng, Guoteng Wang, Shuo Zhang, Peng Sun, Rui Zheng, Hang Yan, Tao Gui, Qi Zhang, Xuanjing Huang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出BAPO方法稳定LLMs的off-policy RL优化，解决政策熵下降与优化不稳定问题，属于深度学习理论中的优化器核心研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18927' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Position: Many generalization measures for deep learning are fragile</h3>
<p><strong>Authors:</strong> Shuofeng Zhang, Ard Louis</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 分析深度学习泛化度量的脆弱性，指出多种度量对训练细节敏感，属于深度学习理论中的泛化研究，对理解模型泛化机制有重要价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18934' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> NeuroAda: Activating Each Neuron's Potential for Parameter-Efficient Fine-Tuning</h3>
<p><strong>Authors:</strong> Zhi Zhang, Yixian Shen, Congfeng Cao, Ekaterina Shutova</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出NeuroAda参数高效微调方法，通过激活神经元潜力实现更优的下游任务适应，属于深度学习理论中的网络架构研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18940' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Weight Decay may matter more than muP for Learning Rate Transfer in Practice</h3>
<p><strong>Authors:</strong> Atli Kosson, Jeremy Welborn, Yang Liu, Martin Jaggi, Xi Chen</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 实证分析weight decay在学习率迁移中的作用，挑战muP的主导地位，属于深度学习理论中的优化器与泛化研究。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19093' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Natural Gradient VI: Guarantees for Non-Conjugate Models</h3>
<p><strong>Authors:</strong> Fangyuan Sun, Ilyas Fatkhullin, Niao He</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究自然梯度变分推断在非共轭模型中的理论保证，推导变分损失的相对光滑性条件，提出改进算法并证明收敛性，属于深度学习理论中的变分推断方向，对VI的理论发展有重要贡献。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19163' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Latent Space Factorization in LoRA</h3>
<p><strong>Authors:</strong> Shashi Kumar, Yacouba Kaloga, John Mitros, Petr Motlicek, Ina Kodrasi</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出FVAE-LoRA用VAE分解LoRA潜在空间为任务相关和残留信息，提升多任务性能和鲁棒性，属于深度学习理论中的VAE和network architecture方向（LoRA是参数高效微调架构），对LoRA改进有理论和实践价值。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19640' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Fast Inference via Hierarchical Speculative Decoding</h3>
<p><strong>Authors:</strong> Amir Globerson, Haim Kaplan, Yishay Mansour, Clara Mohri, Tal Schuster</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出分层推测解码算法HSD，通过堆叠draft模型减少Transformer生成延迟，理论推导预期延迟并验证加速效果，对深度学习理论中推理优化有重要贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19705' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> When Do Transformers Learn Heuristics for Graph Connectivity?</h3>
<p><strong>Authors:</strong> Qilin Ye, Deqing Fu, Robin Jia, Vatsal Sharan</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 通过理论与实证分析Transformer学习图连通性的策略，揭示模型容量对学习算法的影响，对深度学习理论中网络架构（Transformer）能力分析有价值
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19753' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Transformers are almost optimal metalearners for linear classification</h3>
<p><strong>Authors:</strong> Roey Magen, Gal Vardi</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 理论证明简化Transformer作为元学习器在 linear classification 中的近最优性，对深度学习理论中网络架构（Transformer元学习）有贡献
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19797' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Beyond sparse denoising in frames: minimax estimation with a scattering transform</h3>
<p><strong>Authors:</strong> Nathanaël Cuvelle--Magar, Stéphane Mallat</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究分段Cα曲线的极小极大估计，涉及深度学习理论中的piece-wise linear相关问题，通过散射变换实现更优的信号估计。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19612' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Adaptive Distribution-aware Quantization for Mixed-Precision Neural Networks</h3>
<p><strong>Authors:</strong> Shaohang Jia, Zhiyong Huang, Zhi Yu, Mingyang Hou, Shuai Miao, Han Yang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出自适应分布感知量化方法优化混合精度神经网络，提升模型部署效率，属于深度学习理论中的网络架构优化方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19760' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Noise-corrected GRPO: From Noisy Rewards to Unbiased Gradients</h3>
<p><strong>Authors:</strong> Omar El mansouri, Mohamed El Amine Seddik, Salem Lahlou</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出噪声鲁棒的GRPO框架，解决RLHF/RLVR中的奖励噪声问题，提供无偏梯度估计，属于深度学习理论中的优化器研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.18924' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Category learning in deep neural networks: Information content and geometry of internal representations</h3>
<p><strong>Authors:</strong> Laurent Bonnasse-Gahot, Jean-Pierre Nadal</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究深度网络类别学习中的信息内容与表示几何，分析互信息与Fisher信息的作用，属于深度学习理论中的表示学习核心方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19021' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> MetaCluster: Enabling Deep Compression of Kolmogorov-Arnold Network</h3>
<p><strong>Authors:</strong> Matthew Raffel, Adwaith Renjith, Lizhong Chen</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出MetaCluster方法压缩Kolmogorov-Arnold网络，解决参数膨胀问题，属于深度学习理论中的网络架构优化。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19105' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Feature Space Adaptation for Robust Model Fine-Tuning</h3>
<p><strong>Authors:</strong> Peng Wang, Minghao Gu, Qiang Huang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出特征空间适应方法优化模型微调的鲁棒性，解决分布偏移问题，属于深度学习理论中的网络架构与泛化研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19155' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning</h3>
<p><strong>Authors:</strong> Ling Team, Bin Han, Caizhi Tang, Chen Liang, Donghao Zhang, Fan Yuan, Feng Zhu, Jie Gao, Jingyu Hu, Longfei Li, Meng Li, Mingyang Zhang, Peijie Jiang, Peng Jiao, Qian Zhao, Qingyuan Yang, Wenbo Shen, Xinxing Yang, Yalin Zhang, Yankun Ren, Yao Zhao, Yibo Cao, Yixuan Sun, Yue Zhang, Yuchen Fang, Zibin Lin, Zixuan Cheng, Jun Zhou</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出混合注意力架构整合线性和softmax注意力，降低长上下文推理的I/O和计算开销，属于深度学习理论中的network architecture方向，对长上下文模型的架构设计有实践指导。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19338' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Optimization Benchmark for Diffusion Models on Dynamical Systems</h3>
<p><strong>Authors:</strong> Fabian Schaipp</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 基准测试Muon、SOAP、AdamW等优化算法在扩散模型训练中的性能，分析学习率调度和优化器的影响，属于深度学习理论中的optimizer方向，为扩散模型优化提供实践参考。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19376' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Study of Training Dynamics for Memory-Constrained Fine-Tuning</h3>
<p><strong>Authors:</strong> Aël Quélennec, Nour Hezbri, Pavlo Mozharovskyi, Van-Tam Nguyen, Enzo Tartaglione</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 研究内存约束下的训练动态，提出TraDy方法通过动态通道选择和层重要性分析实现内存高效微调，对深度学习理论中训练动态与内存优化有价值
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19675' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters</h3>
<p><strong>Authors:</strong> Anand Choudhary, Yasser Sulaiman, Lukas Mauch, Ghouthi Boukli Hacene, Fabien Cardinaux, Antoine Bosselut</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出GaLLoP稀疏微调方法，选择高梯度低预训练量级的参数，提升微调性能与稳定性，对深度学习理论中网络架构（稀疏训练）有价值
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19778' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models</h3>
<p><strong>Authors:</strong> Yuqiao Tan, Shizhu He, Kang Liu, Jun Zhao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 分析推理模型的模式选择（Long-CoT vs Short-CoT），指出其作为更难的Early Exit问题，对深度学习理论中网络架构（推理优化）有帮助
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19176' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning</h3>
<p><strong>Authors:</strong> Gunshi Gupta, Karmesh Yadav, Zsolt Kira, Yarin Gal, Rahaf Aljundi</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出Memo架构通过周期性总结token实现内存高效的Embodied代理训练，对深度学习理论中网络架构（内存高效模型）有价值
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19732' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Benchmarking World-Model Learning</h3>
<p><strong>Authors:</strong> Archana Warrier, Dat Nyugen, Michelangelo Naim, Moksh Jain, Yichao Liang, Karen Schroeder, Cambridge Yang, Joshua B. Tenenbaum, Sebastian Vollmer, Kevin Ellis, Zenna Tavares</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出WorldTest基准评估世界模型的多任务能力，对深度学习理论中世界模型研究有指导意义
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19788' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model</h3>
<p><strong>Authors:</strong> Yu Fang, Xinyu Wang, Xuehe Zhang, Wanli Xue, Mingwei Zhang, Shengyong Chen, Jie Zhao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对flow-matching方法的高推理时间问题，提出多步一致集成捷径模型及自适应梯度分配策略，属于深度学习理论中的模型训练优化方法，解决了推理速度与性能的平衡问题。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19356' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Robust Driving QA through Metadata-Grounded Context and Task-Specific Prompts</h3>
<p><strong>Authors:</strong> Seungjun Yu, Junsung Park, Youngsun Lim, Hyunjung Shim</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对自动驾驶场景提出两阶段视觉语言QA系统，基于多模态大模型Qwen2.5-VL-32B，结合元数据和任务特定提示提升回答可靠性，直接关联自动驾驶与大模型方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19001' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Rethinking Driving World Model as Synthetic Data Generator for Perception Tasks</h3>
<p><strong>Authors:</strong> Kai Zeng, Zhanqian Wu, Kaixin Xiong, Xiaobao Wei, Xiangyu Guo, Zhenxin Zhu, Kalok Ho, Lijun Zhou, Bohan Zeng, Ming Lu, Haiyang Sun, Bing Wang, Guang Chen, Hangjun Ye, Wentao Zhang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出Dream4Drive框架，利用驾驶世界模型生成多视图合成数据，提升自动驾驶感知任务的性能，直接关联自动驾驶与大模型方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19195' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction</h3>
<p><strong>Authors:</strong> Zhida Zhao, Talas Fu, Yifan Wang, Lijun Wang, Huchuan Lu</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出Policy World Model整合自动驾驶的世界建模与轨迹规划，实现更可靠的状态-动作预测，属于自动驾驶与大模型的核心方向。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19654' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> SFGFusion: Surface Fitting Guided 3D Object Detection with 4D Radar and Camera Fusion</h3>
<p><strong>Authors:</strong> Xiaozhi Li, Huijun Di, Jian Li, Feng Liu, Wei Liang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出表面拟合引导的多模态融合框架，优化自动驾驶中的3D目标检测，结合4D雷达与相机数据，属于自动驾驶与大模型方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19215' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Background Fades, Foreground Leads: Curriculum-Guided Background Pruning for Efficient Foreground-Centric Collaborative Perception</h3>
<p><strong>Authors:</strong> Yuheng Wu, Xiangbo Gao, Quang Tau, Zhengzhong Tu, Dongman Lee</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 针对自动驾驶协同感知的带宽问题，提出课程学习引导的背景剪枝框架，优化前景特征的上下文融合，属于自动驾驶与大模型方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19250' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Can You Trust What You See? Alpha Channel No-Box Attacks on Video Object Detection</h3>
<p><strong>Authors:</strong> Ariana Yi, Ce Zhou, Liyang Xiao, Qiben Yan</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出alpha通道的无框 adversarial攻击，针对视频目标检测系统，揭示自动驾驶感知的安全漏洞，属于自动驾驶与大模型方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19574' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction</h3>
<p><strong>Authors:</strong> Junhong Lin, Kangli Wang, Shunzhou Wang, Songlin Fan, Ge Li, Wei Gao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出视觉几何高斯splatting方法解决自动驾驶前馈环视场景重建问题，属于自动驾驶与大模型的核心应用方向。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19578' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Pragmatic Heterogeneous Collaborative Perception via Generative Communication Mechanism</h3>
<p><strong>Authors:</strong> Junfei Zhou, Penglin Dai, Quanmin Wei, Bingyi Liu, Xiao Wu, Jianping Wang</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出生成式通信机制解决自动驾驶异质多智能体协作感知问题，提升感知效率与泛化能力，属于自动驾驶与大模型的关键技术研究。
Score: 7
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.19618' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LyTimeT: Towards Robust and Interpretable State-Variable Discovery</h3>
<p><strong>Authors:</strong> Kuai Yu, Crystal Su, Xiang Liu, Judah Goldfeder, Mingyuan Shao, Hod Lipson</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出LyTimeT框架从高维视频中提取可解释的动态系统状态变量，结合时空注意力与稳定性约束，属于深度学习可解释性的核心研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19716' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Empowering Decision Trees via Shape Function Branching</h3>
<p><strong>Authors:</strong> Nakul Upadhya, Eldan Cohen</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出Shape Generalized Tree扩展传统决策树，通过可学习形状函数实现可解释的非线性分割，属于深度学习可解释性中的white-box模型研究。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19040' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Interpret Policies in Deep Reinforcement Learning using SILVER with RL-Guided Labeling: A Model-level Approach to High-dimensional and Multi-action Environments</h3>
<p><strong>Authors:</strong> Yiyu Qian, Su Nguyen, Chao Chen, Qinyue Zhou, Liyuan Zhao</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 基于Shapley值扩展SILVER框架到高维多动作RL环境，通过RL引导标注生成行为一致的边界数据集，训练替代模型解释RL政策，属于深度学习可解释性中的Shapley值和white-box explanation方向，解决原有方法的局限性。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19244' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees</h3>
<p><strong>Authors:</strong> Aman Bilkhoo (Department of Informatics, King's College London), Milad Kazemi (Department of Informatics, King's College London), Nicola Paoletti (Department of Informatics, King's College London), Mehran Hosseini (Department of Informatics, King's College London, Department of Computer Science, University of Manchester)</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出CONFEX方法，结合保角预测与混合整数线性规划生成带不确定性保证的反事实解释，解决可解释性中的不确定性问题，对深度学习可解释性有贡献
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19754' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models</h3>
<p><strong>Authors:</strong> Yang Yang, Hua XU, Zhangyi Hu, Yutao Yue</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出RLIE框架结合LLM与逻辑回归生成加权规则，分析LLM在归纳推理中的潜力与局限，对深度学习可解释性中神经符号推理有贡献
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19698' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Explainable Face Presentation Attack Detection via Ensemble-CAM</h3>
<p><strong>Authors:</strong> Rashik Shadman, M G Sarwar Murshed, Faraz Hussain</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出Ensemble-CAM方法为深度学习-based人脸presentation attack检测提供视觉解释，属于深度学习可解释性的应用研究。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19695' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> InvarGC: Invariant Granger Causality for Heterogeneous Interventional Time Series under Latent Confounding</h3>
<p><strong>Authors:</strong> Ziyi Zhang, Shaogang Ren, Xiaoning Qian, Nick Duffield</p>
<p><strong>Published:</strong> 2025-10-23</p>
<p><strong>Reason:</strong> 提出InvarGC方法解决潜在混淆下的异质干预时间序列因果推断，属于深度学习可解释性中的因果解释研究。
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.19138' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

    <script>
    document.addEventListener('DOMContentLoaded', (event) => {
        const sections = document.querySelectorAll('.field-section');
        const navLinks = document.querySelectorAll('.navbar a');

        function changeLinkState() {
            let index = sections.length;

            while(--index && window.scrollY + 100 < sections[index].offsetTop) {} // 100 as offset

            navLinks.forEach((link) => link.classList.remove('active'));
            // Check if navLinks[index] exists
            if (navLinks[index]) {
                navLinks[index].classList.add('active');
            }
        }

        changeLinkState();
        window.addEventListener('scroll', changeLinkState);
    });
    </script>
    </body>
</html>