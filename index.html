<!DOCTYPE html>
<html lang='zh-CN'>
<head>
<meta charset='UTF-8'>
<meta name='viewport' content='width=device-width, initial-scale=1.0'>
<title>ArXiv 每日推荐</title>

    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif; line-height: 1.6; background-color: #f6f8fa; margin: 0; padding: 0; }
        .container { max-width: 900px; margin: 20px auto; padding: 20px; background-color: #ffffff; border-radius: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
        h1, h2, h3 { border-bottom: 2px solid #eaecef; padding-bottom: 0.3em; }
        h1 { font-size: 2em; }
        h2 { font-size: 1.5em; margin-top: 2.5em; }
        h3 { font-size: 1.2em; border-bottom: 1px solid #eee; }
        .navbar { background-color: #333; overflow: hidden; position: sticky; top: 0; z-index: 100; }
        .navbar a { float: left; display: block; color: white; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 17px; }
        .navbar a:hover { background-color: #ddd; color: black; }
        .navbar a.active { background-color: #007bff; color: white; }
        .meta-info { font-size: 0.9em; color: #586069; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 20px; }
        .paper-card { margin-bottom: 1.5em; padding-bottom: 1em; }
        .paper-card p { margin: 0.5em 0; }
        .paper-card a { color: #007bff; text-decoration: none; font-weight: bold; }
        .paper-card a:hover { text-decoration: underline; }
        .score { font-weight: bold; color: #d9534f; }
        .field-section { padding-top: 60px; margin-top: -60px; } /* 确保锚点跳转时不会被导航栏遮挡 */
    </style>
    
</head>
<body>
<div class='navbar'>
<a href='#Multi-modal-large-models' class='active'>Multi-modal large models</a>
<a href='#Deep-learning-theory' >Deep learning theory</a>
<a href='#' >多模态大模型</a>
<a href='#' >深度学习理论</a>
<a href='#' >深度学习可解释性</a>
<a href='#' >自动驾驶与大模型</a>
<a href='#Autonomous-driving-and-large-models' >Autonomous driving and large models</a>
</div>
<div class='container'>
<h1>ArXiv 每日推荐</h1>
<div class='meta-info'><p>更新于北京时间：2025-10-24 12:28:26</p>
<p>已自动阅读了 252 篇最新的论文。</p>
<p>使用模型：doubao-seed-1-6-thinking-250715 | 消耗 Tokens：135081</p>
</div>
<div id='Multi-modal-large-models' class='field-section'>
<h2>Multi-modal large models</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 10.0/10]</span> UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning</h3>
<p><strong>Authors:</strong> Liangyu Chen, Hanzhang Zhou, Chenglin Cai, Jianan Zhang, Panrong Tong, Quyu Kong, Xu Zhang, Chen Liu, Yuqi Liu, Wenxuan Wang, Yue Wang, Qin Jin, Steven Hoi</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Introduces an Instruction-as-Reasoning framework for GUI grounding, directly addressing a core capability of GUI agents. Achieves state-of-the-art on 5 benchmarks (e.g., 87.3% on UI-I2E-Bench) and demonstrates agentic potential on AndroidWorld.
Score: 10
Field: Multi-modal large models</p>
<p><a href='https://arxiv.org/abs/2510.20286' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling</h3>
<p><strong>Authors:</strong> Bingjie Gao, Qianli Ma, Xiaoxue Wu, Shuai Yang, Guanzhou Lan, Haonan Zhao, Jiaxuan Chen, Qingyang Liu, Yu Qiao, Xinyuan Chen, Yaohui Wang, Li Niu</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Unifies training-data alignment, test-time scaling, and LLM fine-tuning to improve text-to-video generation. Authors include Yu Qiao (renowned) and achieves state-of-the-art on multiple benchmarks with model-agnostic design.
Score: 9
Field: Multi-modal large models</p>
<p><a href='https://arxiv.org/abs/2510.20206' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence</h3>
<p><strong>Authors:</strong> Kun Ouyang, Yuanxin Liu, Linli Yao, Yishuo Cai, Hao Zhou, Jie Zhou, Fandong Meng, Xu Sun</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes an evidence-grounded video reasoning framework for MLLMs, using RL and a 91K dataset (Conan-91K) to improve multi-step deduction. Outperforms Qwen2.5-VL by 10% on average across reasoning benchmarks.
Score: 9
Field: Multi-modal large models</p>
<p><a href='https://arxiv.org/abs/2510.20470' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models</h3>
<p><strong>Authors:</strong> Huichan Seo, Sieun Choi, Minki Hong, Yi Zhou, Junseo Kim, Lukman Ismaila, Naome Etori, Mehul Agarwal, Zhixuan Liu, Jihie Kim, Jean Oh</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Provides a unified evaluation of cultural bias in T2I/I2I models, addressing a critical gap in generative AI fairness. Introduces a reproducible benchmark and reveals limitations in current systems' cultural fidelity.
Score: 8
Field: Multi-modal large models</p>
<p><a href='https://arxiv.org/abs/2510.20042' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models</h3>
<p><strong>Authors:</strong> Zelin Peng, Zhengqin Xu, Qingyang Liu, Xiaokang Yang, Wei Shen</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Leverages hyperbolic space to align visual-textual granularity in MLLMs, improving training efficiency with <1% extra parameters. Enhances performance across MLLM benchmarks for pre-training/fine-tuning.
Score: 8
Field: Multi-modal large models</p>
<p><a href='https://arxiv.org/abs/2510.20322' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback</h3>
<p><strong>Authors:</strong> Jiho Park, Sieun Choi, Jaeyoon Seo, Jihie Kim</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Improves diffusion-based sketch generation using VQA feedback and a custom VAE, addressing limitations in abstract image synthesis. Introduces SketchDUO, the first instance-level sketch-text-QA dataset.
Score: 7
Field: Multi-modal large models</p>
<p><a href='https://arxiv.org/abs/2510.20093' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing</h3>
<p><strong>Authors:</strong> Yanghao Wang, Zhen Wang, Long Chen</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Uses cycle-consistent flow models for inversion-free text-based image editing, addressing diffusion models' approximation errors. Achieves superior fidelity/consistency over SOTA diffusion baselines.
Score: 7
Field: Multi-modal large models</p>
<p><a href='https://arxiv.org/abs/2510.20212' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='Deep-learning-theory' class='field-section'>
<h2>Deep learning theory</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency</h3>
<p><strong>Authors:</strong> Hao Yu, Haoyu Chen, Yan Jiang, Wei Peng, Zhaodong Sun, Samuel Kaski, Guoying Zhao</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Reinvents convolution with self-attention principles (adaptive routing, lateral inhibition) to create Attentive Convolution (ATConv). Achieves state-of-the-art on ImageNet and diffusion models with 3x3 kernels, advancing network architecture design.
Score: 9
Field: Deep learning theory</p>
<p><a href='https://arxiv.org/abs/2510.20092' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Positional Encoding Field</h3>
<p><strong>Authors:</strong> Yunpeng Bai, Haoxiang Li, Qixing Huang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Extends positional encodings to a 3D field for Diffusion Transformers (DiTs), enabling volumetric reasoning and fine-grained control. Achieves state-of-the-art on novel view synthesis and spatial editing.
Score: 9
Field: Deep learning theory</p>
<p><a href='https://arxiv.org/abs/2510.20385' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks</h3>
<p><strong>Authors:</strong> Insu Jeon, Wonkwang Lee, Myeongjang Pyeon, Gunhee Kim</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Integrates the information bottleneck principle into GANs for disentangled representation learning. Outperforms InfoGAN and η-VAEs on disentanglement metrics and sample quality (FID on CelebA/3D Chairs).
Score: 8
Field: Deep learning theory</p>
<p><a href='https://arxiv.org/abs/2510.20165' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EditInfinity: Image Editing with Binary-Quantized Generative Models</h3>
<p><strong>Authors:</strong> Jiahuan Wang, Yuxin Chen, Jun Yu, Guangming Lu, Wenjie Pei</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Adapts binary-quantized VQ models (Infinity) for image editing, leveraging exact intermediate representations to avoid diffusion inversion errors. Outperforms diffusion baselines on PIE-Bench across "add/change/delete" tasks.
Score: 8
Field: Deep learning theory</p>
<p><a href='https://arxiv.org/abs/2510.20217' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models</h3>
<p><strong>Authors:</strong> Seunghoon Lee, Jeongwoo Choi, Byunggwan Son, Jaehyeon Moon, Jeimin Jeon, Bumsub Ham</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Addresses diffusion model quantization by simulating multi-step denoising to reduce error accumulation. Reduces memory complexity from O(n) to O(1) and improves performance across tasks/models.
Score: 8
Field: Deep learning theory</p>
<p><a href='https://arxiv.org/abs/2510.20348' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>多模态大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning</h3>
<p><strong>Authors:</strong> Xiaohan Lan, Fanfan Liu, Haibo Qiu, Siqi Yang, Delian Ruan Pan, Shi Lin Ma</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 构建混合专家框架解决多模态推理中"推理-泛化"权衡问题，通过动态路由分配查询至最优专家分支，显著提升复杂推理与通用理解能力，属于多模态大模型核心推理研究，实验效果优异。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20519' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward</h3>
<p><strong>Authors:</strong> Jing Bi, Guangyu Sun, Ali Vosoughi, Chen Chen, Chenliang Xu</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 系统分析多模态大模型的视觉推理缺陷，提出agent-based架构整合LLM与轻量视觉模块，显著提升推理性能，属于多模态大模型下的视觉推理研究，开源框架支持后续研究。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20696' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models</h3>
<p><strong>Authors:</strong> Xuyang Liu, Xiyan Gui, Yuchao Zhang, Linfeng Zhang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出MixKV解决大视觉语言模型的KV缓存内存瓶颈，通过平衡重要性与多样性提升压缩效果，在GUI Grounding任务上取得8%-9%性能提升，属于多模态大模型与自动驾驶的交叉研究。
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20707' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment</h3>
<p><strong>Authors:</strong> Abdulmomen Ghalkha, Zhuojun Tian, Chaouki Ben Issaid, Mehdi Bennis</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Introduces a sheaf-theoretic framework for decentralized multimodal alignment that avoids the mutual redundancy assumption, directly relevant to multi-modal large model alignment research.
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20540' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Surfer 2: The Next Generation of Cross-Platform Computer Use Agents</h3>
<p><strong>Authors:</strong> Mathieu Andreux, Mårten Bakler, Yanael Barbier, Hamza Ben Chekroun, Emilien Biré, Antoine Bonnet, Riaz Bordie, Nathan Bout, Matthias Brunel, Aleix Cambray, Pierre-Louis Cedoz, Antoine Chassang, Gautier Cloix, Ethan Connelly, Alexandra Constantinou, Ramzi De Coster, Hubert de la Jonquière, Aurélien Delfosse, Maxime Delpit, Alexis Deprez, Augustin Derupti, Mathieu Diaz, Shannon D'Souza, Julie Dujardin, Abai Edmund, Michael Eickenberg, Armand Fatalot, Wissem Felissi, Isaac Herring, Xavier Koegler, Erwan Le Jumeau de Kergaradec, Aurélien Lac, Maxime Langevin, Corentin Lauverjat, Antonio Loison, Avshalom Manevich, Axel Moyal, Axel Nguyen Kerbel, Marinela Parovic, Julien Revelle, Guillaume Richard, Mats Richter, Ronan Riochet, María Santos, Romain Savidan, Laurent Sifre, Maxime Theillard, Marc Thibault, Ivan Valentini, Tony Wu, Laura Yie, Kai Yuan, Jevgenij Zubovskij</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Presents a cross-platform computer use agent (Surfer 2) using visual observations, which is a GUI Agent—directly relevant to multi-modal large models (GUI Agent) and autonomous systems.
Score: 9
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.19949' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization</h3>
<p><strong>Authors:</strong> Yixiong Yang, Tao Wu, Senmao Li, Shiqi Yang, Yaxing Wang, Joost van de Weijer, Kai Wang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 针对单步扩散模型个性化难题，提出双向概念蒸馏框架，通过师生模型协同训练提升新概念捕捉能力与生成质量，属于多模态大模型下的图像生成研究，方法创新且实验验证有效。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20512' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence</h3>
<p><strong>Authors:</strong> Jiahao Meng, Xiangtai Li, Haochen Wang, Yue Tan, Tao Zhang, Lingdong Kong, Yunhai Tong, Anran Wang, Zhiyang Teng, Yujing Wang, Zhuochen Wang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出非代理框架将显式时空证据融入视频推理，通过构建时空标注数据集与强化学习策略提升推理的时空接地性，属于多模态大模型下的视频理解研究，实验性能优于现有方法。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20579' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models</h3>
<p><strong>Authors:</strong> Muhammad Atif Butt, Alexandra Gomez-Villa, Tao Wu, Javier Vazquez-Corral, Joost Van De Weijer, Kai Wang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 构建首个针对文本到图像生成的颜色评估基准，覆盖400+颜色与44K prompt，填补颜色精确性评估空白，对多模态大模型的图像生成优化具有重要价值。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20586' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding</h3>
<p><strong>Authors:</strong> Yuan Sheng, Yanbin Hao, Chenxu Li, Shuo Wang, Xiangnan He</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出语义-视觉共识证据选择框架，通过双分支选择与共识优化解决长视频信息过载问题，提升推理准确性与鲁棒性，属于多模态大模型下的视频理解研究，实验效果显著。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20622' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset</h3>
<p><strong>Authors:</strong> Chen Zhao, En Ci, Yunzhe Xu, Tiehan Fan, Shanyan Guan, Yanhao Ge, Jian Yang, Ying Tai</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 构建超高清图像合成数据集UltraHR-100K，结合频率感知后训练方法提升细节生成质量，填补超高清数据空白，属于多模态大模型下的图像生成研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20661' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion</h3>
<p><strong>Authors:</strong> Noam Issachar, Guy Yariv, Sagie Benaim, Yossi Adi, Dani Lischinski, Raanan Fattal</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出动态位置外推方法解决扩散Transformer的自注意力二次复杂度问题，支持超高清图像生成，属于多模态大模型下的图像生成研究，方法创新且效果显著。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20766' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation</h3>
<p><strong>Authors:</strong> Yuhan Liu, Lianhui Qin, Shengjie Wang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出推测性判决框架，通过小模型draft与大模型verdict解决信息密集型视觉推理问题，提升准确性与效率，属于多模态大模型下的视觉推理研究。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20812' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas</h3>
<p><strong>Authors:</strong> Guocheng Gordon Qian, Ruihang Zhang, Tsai-Shien Chen, Yusuf Dalva, Anujraaj Argo Goyal, Willi Menapace, Ivan Skorokhodov, Meng Dong, Arpit Sahni, Daniil Ostashev, Ju Hu, Sergey Tulyakov, Kuan-Chieh Jackson Wang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出分层画布框架解决个性化文本到图像的空间控制问题，支持多主体生成的身份保留与空间精确调整，属于多模态大模型下的图像生成研究，方法创新。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/251o.20820' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives</h3>
<p><strong>Authors:</strong> Yihao Meng, Hao Ouyang, Yue Yu, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Hanlin Wang, Yixuan Li, Cheng Chen, Yanhong Zeng, Yujun Shen, Huamin Qu</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出HoloCine生成电影级多镜头长视频叙事，通过窗口交叉注意力与稀疏跨镜头注意力提升叙事一致性，属于多模态大模型下的视频生成研究，实验效果显著。
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20822' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models</h3>
<p><strong>Authors:</strong> Rui Zhu, Song-Lin Lv, Zi-Kang Wang, Lan-Zhe Guo</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes a bi-consistency-guided self-training method for vision-language models (VLMs) to address model bias and hyperparameter sensitivity, which is highly relevant to multi-modal large model research.
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20477' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges</h3>
<p><strong>Authors:</strong> Hyun Jong Yang, Hyunsoo Kim, Hyeonho Noh, Seungnyun Kim, Byonghyo Shim</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Explores large multimodal models (LMMs) for task-oriented autonomous communications, demonstrating superior performance over conventional methods—relevant to multi-modal large model applications.
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20637' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process</h3>
<p><strong>Authors:</strong> Tsai Hor Chan, Feng Wu, Yihang Chen, Guosheng Yin, Lequan Yu</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes a Dirichlet process (DP)-driven framework for multimodal learning that balances prominent intra-modal representation learning and cross-modal alignment—directly relevant to multi-modal large model fusion.
Score: 8
Field: 多模态大模型</p>
<p><a href='https://arxiv.org/abs/2510.20736' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习理论</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> AlphaFlow: Understanding and Improving MeanFlow Models</h3>
<p><strong>Authors:</strong> Huijie Zhang, Aliaksandr Siarohin, Willi Menapace, Michael Vasilkovsky, Sergey Tulyakov, Qing Qu, Ivan Skorokhodov</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 分解MeanFlow目标函数并提出α-Flow框架，通过课程学习解决优化冲突，显著提升生成模型收敛速度与性能，属于深度学习理论下的生成模型优化研究，实验取得SOTA结果。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20771' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> ARGenSeg: Image Segmentation with Autoregressive Image Generation Model</h3>
<p><strong>Authors:</strong> Xiaolong Wang, Lixiang Ru, Ziyuan Huang, Kaixiang Ji, Dandan Zheng, Jingdong Chen, Jun Zhou</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出基于自回归生成的分割框架，利用VQ-VAE将视觉token解码为图像，提升分割细粒度理解，属于深度学习理论下的VQ-VAE研究与多模态大模型下的图像理解交叉领域，实验效果优于SOTA。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20803' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Beyond the Ideal: Analyzing the Inexact Muon Update</h3>
<p><strong>Authors:</strong> Egor Shulgin, Sultan AlRashed, Francesco Orabona, Peter Richtárik</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 针对Muon优化器的理论-实践 gap，分析不精确更新的影响并提出参数调优策略，属于深度学习理论下的优化器研究，实验验证结论有效性。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/25lo.19933' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models</h3>
<p><strong>Authors:</strong> Zachary Horvitz, Raghav Singhal, Hao Zou, Carles Domingo-Enrich, Zhou Yu, Rajesh Ranganath, Kathleen McKeown</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 重新思考掩码扩散模型的推理与采样，提出reasoning-as-infilling与多token熵解码，提升推理性能与效率，属于深度学习理论下的生成模型研究，实验效果显著。
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19990' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Convergence Analysis of SGD under Expected Smoothness</h3>
<p><strong>Authors:</strong> Yuta Kawamoto, Hideaki Iiduka</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Provides a self-contained convergence analysis of stochastic gradient descent (SGD) under expected smoothness, refining existing theory and deriving explicit bounds—core to deep learning theory (optimizer).
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20608' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning</h3>
<p><strong>Authors:</strong> Reuben Dorent, Polina Golland, William Wells III</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Derives a tight lower bound connecting Jensen-Shannon (JS) and Kullback-Leibler (KL) divergences for representation learning, providing theoretical justification for discriminative mutual information (MI) estimation—core to deep learning theory.
Score: 9
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20644' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization</h3>
<p><strong>Authors:</strong> Shaocong Ma, Heng Huang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出无偏梯度估计器解决零阶优化的偏差问题，分析最优扰动分布与步长，属于深度学习理论下的优化器研究，实验效果优于现有方法。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19953' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations</h3>
<p><strong>Authors:</strong> Shaocong Ma, Heng Huang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 研究零阶优化的两点估计器，提出方向对齐扰动提升估计精度，属于深度学习理论下的优化器研究，实验验证有效。
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19975' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> From Masks to Worlds: A Hitchhiker's Guide to World Models</h3>
<p><strong>Authors:</strong> Jinbin Bai, Yu Lei, Hecong Wu, Yuchen Zhu, Shufan Li, Yi Xin, Xiangtai Li, Molei Tao, Aditya Grover, Ming-Hsuan Yang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Guides building world models from masked models to interactive generative systems, covering representation learning and generative models—relevant to deep learning theory (network architecture, generative models).
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20668' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples</h3>
<p><strong>Authors:</strong> Shiva Sreeram, Alaa Maalouf, Pratyusha Sharma, Daniela Rus</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Introduces an efficient large language model (LLM) adaptation method via rank reduction and gradient steps, addressing practical deployment challenges—relevant to deep learning theory (network architecture, adaptation).
Score: 8
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20800' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling</h3>
<p><strong>Authors:</strong> Jinhee Kim, Jae Jun An, Kang Eun Jeon, Jong Hwan Ko</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出权重偏差校正与bit-wise coreset采样，解决多bit量化训练的高开销问题，提升量化模型准确性与训练效率，属于深度学习理论下的网络架构优化研究。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20673' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> An Integrated Approach to Neural Architecture Search for Deep Q-Networks</h3>
<p><strong>Authors:</strong> Iman Rahmani, Saman Yazdannik, Morteza Tayefi, Jafar Roshanian</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出NAS-DQN将神经架构搜索整合到DRL训练中，动态调整网络架构提升性能，属于深度学习理论下的网络架构研究，实验优于固定架构基线。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.19872' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning</h3>
<p><strong>Authors:</strong> Gabriel Y. Arteaga, Marius Aasan, Rwiddhi Chakraborty, Martine Hjelkrem-Tan, Thalles Silva, Michael Kampffmeyer, Adín Ramírez Rivera</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 分析原型自监督学习中部分原型崩溃的原因，提出解耦训练策略消除崩溃，提升表示学习效果，属于深度学习理论中的自监督学习方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20108' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models</h3>
<p><strong>Authors:</strong> Guangyu Dai, Siliang Tang, Yueting Zhuang</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出基于KAN的协作模型KCM，解决大-小模型协作中的准确性下降、灾难性遗忘等问题，KAN作为替代MLP的网络架构，属于深度学习理论中的network architecture方向。
Score: 7
Field: 深度学习理论</p>
<p><a href='https://arxiv.org/abs/2510.20278' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>深度学习可解释性</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 9.0/10]</span> Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms</h3>
<p><strong>Authors:</strong> Riccardo Guidotti, Martina Cinquini, Marta Marchiori Manerba, Mattia Setzu, Francesco Spinnato</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Formalizes a framework for generating interpretable-by-design models (feature importance, rule-based, instance-based) and integrates ethical properties (causality, fairness, privacy), directly contributing to deep learning explainability via white-box model design.
Score: 9
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.20621' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models</h3>
<p><strong>Authors:</strong> Bosong Huang, Ming Jin, Yuxuan Liang, Johan Barthelemy, Debo Cheng, Qingsong Wen, Chenghao Liu, Shirui Pan</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出ShapeX框架，通过Shapelet分割时间序列并使用Shapley值评估显著性，解决时间序列分类模型的事后解释问题，直接关联深度学习可解释性中的Shapley value方向。
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.20084' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning</h3>
<p><strong>Authors:</strong> Morris Yu-Chao Huang, Zhen Tan, Mohan Zhang, Pingzhi Li, Zhuo Zhang, Tianlong Chen</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes a decentralized auditing framework for large language model (LLM) reasoning, addressing faithfulness, transparency, and robustness—directly relevant to deep learning explainability (white-box explanation).
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.20188' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation</h3>
<p><strong>Authors:</strong> Heejin Do, Jaehui Hwang, Dongyoon Han, Seong Joon Oh, Sangdoo Yun</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes a causal stepwise evaluation (CaSE) framework to measure LLM reasoning quality by decomposing it into relevance and coherence, enabling granular assessment of reasoning processes which advances deep learning explainability.
Score: 8
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.20603' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models</h3>
<p><strong>Authors:</strong> Xue Wen Tan, Nathaniel Tan, Galen Lee, Stanley Kok</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Uses topological data analysis (TDA) to characterize the geometry of LLM reasoning traces, providing a novel automated method to evaluate reasoning quality which supports deep learning explainability.
Score: 7
Field: 深度学习可解释性</p>
<p><a href='https://arxiv.org/abs/2510.20665' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='' class='field-section'>
<h2>自动驾驶与大模型</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> AutoScape: Geometry-Consistent Long-Horizon Scene Generation</h3>
<p><strong>Authors:</strong> Jiacheng Chen, Ziyu Jiang, Mingfu Liang, Bingbing Zhuang, Jong-Chyi Su, Sparsh Garg, Ying Wu, Manmohan Chandraker</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> 提出RGB-D扩散模型生成几何一致的长 horizon 驾驶场景，通过关键帧引导与几何约束提升场景真实性，属于自动驾驶与大模型下的场景生成研究，实验性能优异。
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.20726' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 8.0/10]</span> Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking</h3>
<p><strong>Authors:</strong> Zixuan Wu, Hengyuan Zhang, Ting-Hsuan Chen, Yuliang Guo, David Paz, Xinyu Huang, Liu Ren</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes a domain-agnostic autonomous parking pipeline integrating visual foundation models with diffusion-based planning, addressing cross-domain robustness in autonomous driving using large models.
Score: 8
Field: 自动驾驶与大模型</p>
<p><a href='https://arxiv.org/abs/2510.20335' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
<div id='Autonomous-driving-and-large-models' class='field-section'>
<h2>Autonomous driving and large models</h2>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking</h3>
<p><strong>Authors:</strong> Martha Teiko Teye, Ori Maoz, Matthias Rottmann</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes a camera-LiDAR fusion transformer for 3D multi-object tracking, addressing key challenges in autonomous driving (e.g., occlusion, viewpoint changes). Improves robustness over single-sensor methods and achieves strong performance on nuScenes/KITTI.
Score: 7
Field: Autonomous driving and large models</p>
<p><a href='https://arxiv.org/abs/2510.19981' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects</h3>
<p><strong>Authors:</strong> Prithvi Raj Singh, Raju Gottumukkala, Anthony S. Maida, Alan B. Barhorst, Vijaya Gopu</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Combines deep learning with physics-based kinematics to track fast-moving small objects (e.g., racquetballs) in 3D. Reduces average displacement error by 70% vs. Kalman filters, relevant to autonomous robot perception.
Score: 7
Field: Autonomous driving and large models</p>
<p><a href='https://arxiv.org/abs/2510.20126' target='_blank'>阅读论文 &raquo;</a></p>
</div>
<div class='paper-card'>
<h3><span class='score'>[Score: 7.0/10]</span> Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories</h3>
<p><strong>Authors:</strong> Aaron Appelle, Jerome P. Lynch</p>
<p><strong>Published:</strong> 2025-10-24</p>
<p><strong>Reason:</strong> Proposes a protocol to evaluate video models as pedestrian trajectory simulators, critical for autonomous driving's multi-agent behavior prediction. Reveals strengths/limitations of current T2V/I2V models in crowd dynamics.
Score: 7
Field: Autonomous driving and large models</p>
<p><a href='https://arxiv.org/abs/2510.20182' target='_blank'>阅读论文 &raquo;</a></p>
</div>
</div>
</div>

    <script>
    document.addEventListener('DOMContentLoaded', (event) => {
        const sections = document.querySelectorAll('.field-section');
        const navLinks = document.querySelectorAll('.navbar a');

        function changeLinkState() {
            let index = sections.length;

            while(--index && window.scrollY + 100 < sections[index].offsetTop) {} // 100 as offset

            navLinks.forEach((link) => link.classList.remove('active'));
            // Check if navLinks[index] exists
            if (navLinks[index]) {
                navLinks[index].classList.add('active');
            }
        }

        changeLinkState();
        window.addEventListener('scroll', changeLinkState);
    });
    </script>
    </body>
</html>